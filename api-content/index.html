{"posts":[{"title":"JavaScript——7 个角度吃透 Lodash 防抖节流原理","content":" 浅出篇 7 个角度吃透 Lodash 防抖节流原理 节流函数 Throttle 我们先来看一张图，这张图充分说明了 Throttle（节流）和 Debounce（防抖）的区别，以及在不同配置下产生的不同效果，其中 mousemove 事件每 50 ms 触发一次，即下图中的每一小隔是 50 ms。今天这篇文章就从下面这张图开始介绍。 角度 1 lodash.throttle(fn, 200, {leading: true, trailing: true}) mousemove 第一次触发 先来看下 throttle 源码 function throttle(func, wait, options) { // 首尾调用默认为 true let leading = true let trailing = true if (typeof func !== 'function') { throw new TypeError('Expected a function') } // options 是否是对象 if (isObject(options)) { leading = 'leading' in options ? !!options.leading : leading trailing = 'trailing' in options ? !!options.trailing : trailing } // maxWait 为 wait 的防抖函数 return debounce(func, wait, { leading, trailing, 'maxWait': wait, }) } 所以 throttle(fn, 200, {leading: true, trailing: true}) 返回内容是 debounce(fn, 200, {leading: true, trailing: true, maxWait: 200})，多了 maxWait: 200 这部分。 先打个预防针，后面即将开始比较难的部分，看下 debounce 入口函数。 // 入口函数，返回此函数 function debounced(...args) { // 获取当前时间 const time = Date.now() // 判断此时是否应该执行 func 函数 const isInvoking = shouldInvoke(time) // 赋值给闭包，用于其他函数调用 lastArgs = args lastThis = this lastCallTime = time // 执行 if (isInvoking) { // 无 timerId 的情况有两种： // 1、首次调用 // 2、trailingEdge 执行过函数 if (timerId === undefined) { return leadingEdge(lastCallTime) } // 如果设置了最大等待时间，则立即执行 func // 1、开启定时器，到时间后触发 trailingEdge 这个函数。 // 2、执行 func，并返回结果 if (maxing) { // 循环定时器中处理调用 timerId = startTimer(timerExpired, wait) return invokeFunc(lastCallTime) } } // 一种特殊情况，trailing 设置为 true 时，前一个 wait 的 trailingEdge 已经执行了函数 // 此时函数被调用时 shouldInvoke 返回 false，所以要开启定时器 if (timerId === undefined) { timerId = startTimer(timerExpired, wait) } // 不需要执行时，返回结果 return result } 对于 debounce(fn, 200, {leading: true, trailing: true, maxWait: 200}) 来说，会经历如下过程。 shouldInvoke(time) 中，因为满足条件 lastCallTime === undefined，所以返回 true。 lastCallTime = time，所以 lastCallTime 等于当前时间，假设为 0。 timerId === undefined 满足，执行 leadingEdge(lastCallTime) 方法。 // 执行连续事件刚开始的那次回调 function leadingEdge(time) { // 1、设置上一次执行 func 的时间 lastInvokeTime = time // 2、开启定时器，为了事件结束后的那次回调 timerId = startTimer(timerExpired, wait) // 3、如果配置了 leading 执行传入函数 func // leading 来源自 !!options.leading return leading ? invokeFunc(time) : result } 在 leadingEdge(time) 中，设置 lastInvokeTime 为当前时间即 0，开启 200 毫秒定时器，执行 invokeFunc(time) 并返回。 // 执行 Func 函数 function invokeFunc(time) { // 获取上一次执行 debounced 的参数 const args = lastArgs // 获取上一次的 this const thisArg = lastThis // 重置 lastArgs = lastThis = undefined lastInvokeTime = time result = func.apply(thisArg, args) return result } 在 invokeFunc(time) 中，执行 func.apply(thisArg, args)，即 fn 函数第一次执行，并把结果赋值给 result，便于后续触发时直接返回。同时重置 lastInvokeTime 为当前时间即 0，清空 lastArgs 和 lastThis。 第一次触发已经完成，注意此时 lastCallTime 和 lastInvokeTime 都为 0，200 毫秒的定时器还在运行中。 mousemove 第二次触发 50 毫秒后第二次触发到来，此时当前时间 time 为 50，wait 为 200， maxWait 为 200，maxing 为 true，lastCallTime 和 lastInvokeTime 都为 0，timerId 定时器存在，我们来看下执行步骤。 function shouldInvoke(time) { // 当前时间距离上一次调用 debounce 的时间差 const timeSinceLastCall = time - lastCallTime // 当前时间距离上一次执行 func 的时间差 const timeSinceLastInvoke = time - lastInvokeTime // 下述 4 种情况返回 true return ( lastCallTime === undefined || (timeSinceLastCall &gt;= wait) || (timeSinceLastCall &lt; 0) || (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait) ) } shouldInvoke(time) 中，timeSinceLastCall 为 50，timeSinceLastInvoke 为 50，4 种条件都不满足，返回 false。 此时 isInvoking 为 false，同时 timerId === undefined 不满足，直接返回第一次触发时的 result。 第二次触发完成，并不会执行 fn，只会返回上次执行的结果 result。 第三次和第四次触发时，效果一样，就不再重复了。 mousemove 第五次触发 距第一次触发 200 毫秒后第五次触发到来，此时当前时间 time 为 200，wait 为 200， maxWait 为 200，maxing 为 true，lastCallTime 为 150，lastInvokeTime 为 0，timerId 定时器存在，我们来看下执行步骤。 shouldInvoke(time) 中，timeSinceLastInvoke 为 200，满足 (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait)，所以返回 true。 // debounced 方法中执行到这部分 if (maxing) { // 循环定时器中处理调用 timerId = startTimer(timerExpired, wait) return invokeFunc(lastCallTime) } 满足 maxing 条件，重新开启 200 毫秒的定时器，并执行 invokeFunc(lastCallTime) 函数。 invokeFunc(time) 中，重置 lastInvokeTime 为当前时间即 200，清空 lastArgs 和 lastThis。 第六、七、八次触发时，同第二次触发效果一致，就不再重复了。 mousemove 停止触发 假设第八次触发之后就停止了滚动，在第八次触发时 time 为 350，所以如果有第九次触发，那么此时是应该执行 fn 的，但是此时 mousemove 已经停止了触发，那么还会执行 fn 吗？答案是依旧执行，因为最开始设置了 {trailing: true}。 // 开启定时器 function startTimer(pendingFunc, wait) { // 没传 wait 时调用 window.requestAnimationFrame() if (useRAF) { // 若想在浏览器下次重绘之前继续更新下一帧动画 // 那么回调函数自身必须再次调用 window.requestAnimationFrame() root.cancelAnimationFrame(timerId); return root.requestAnimationFrame(pendingFunc) } // 不使用 RAF 时开启定时器 return setTimeout(pendingFunc, wait) } 在第五次触发时开启了 200 毫秒的定时器，所以在时间 time 到 400 时会执行 pendingFunc，此时的 pendingFunc 就是 timerExpired 函数，来看下具体的代码。 // 定时器回调函数，表示定时结束后的操作 function timerExpired() { const time = Date.now() // 1、是否需要执行 // 执行事件结束后的那次回调，否则重启定时器 if (shouldInvoke(time)) { return trailingEdge(time) } // 2、否则 计算剩余等待时间，重启定时器，保证下一次时延的末尾触发 timerId = startTimer(timerExpired, remainingWait(time)) } 此时在 shouldInvoke(time) 中，time 为 400，lastInvokeTime 为 200，timeSinceLastInvoke 为 200，满足 (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait)，所以返回 true。 // 执行连续事件结束后的那次回调 function trailingEdge(time) { // 清空定时器 timerId = undefined // trailing 和 lastArgs 两者同时存在时执行 // trailing 来源自 'trailing' in options ? !!options.trailing : trailing // lastArgs 标记位的作用，意味着 debounce 至少执行过一次 if (trailing &amp;&amp; lastArgs) { return invokeFunc(time) } // 清空参数 lastArgs = lastThis = undefined return result } 之后执行 trailingEdge(time)，在这个函数中判断 trailing 和 lastArgs，此时这两个条件都是 true，所以会执行 invokeFunc(time)，最终执行函数 fn。 这里需要说明以下两点： 如果设置了 {trailing: false}，那么最后一次是不会执行的。对于 throttle 和 debounce 来说，默认值是 true，所以如果没有特意指定 trailing，那么最后一次是一定会执行的。 对于 lastArgs 来说，执行 debounced 时会赋值，即每次触发都会重新赋值一次，那什么时候清空呢，在 invokeFunc(time) 中执行 fn 函数时重置为 undefined，所以如果 debounced 只触发了一次，即使设置了 {trailing: true} 那也不会再执行 fn 函数，这个就解答了上篇文章留下的第一道思考题。 角度 2 lodash.throttle(fn, 200, {leading: true, trailing: false}) 在角度 1 之 mousemove 停止触发这部分中说到，如果不设置 trailing 和设置 {trailing: true} 效果是一样的，事件回调结束后都会再执行一次传入函数 fn，但是如果设置了 {trailing: false}，那么事件回调结束后是不会再执行 fn 的。 此时的配置对比角度 1 来说，区别在于设置了 {trailing: false}，所以实际效果对比 1 来说，就是最后不会额外再执行一次，效果见第一张图。 角度 3 lodash.throttle(fn, 200, {leading: false, trailing: true}) 此时的配置和角度 1 相比，区别在于设置了 {leading: false}，所以直接看 leadingEdge(time) 方法就可以了。 // 执行连续事件刚开始的那次回调 function leadingEdge(time) { // 1、设置上一次执行 func 的时间 lastInvokeTime = time // 2、开启定时器，为了事件结束后的那次回调 timerId = startTimer(timerExpired, wait) // 3、如果配置了 leading 执行传入函数 func // leading 来源自 !!options.leading return leading ? invokeFunc(time) : result } 在这里，会开启 200 毫秒的定时器，同时因为 leading 为 false，所以并不会执行 invokeFunc(time)，只会返回 result，此时的 result 值是 undefined。 这里开启一个定时器的目的是为了事件结束后的那次回调，即如果设置了 {trailing: true} 那么最后一次回调将执行传入函数 fn，哪怕 debounced 函数只触发一次。 这里指定了 {leading: false}，那么 leading 的初始值是什么呢？在 debounce 中是 false，在 throttle 中是 true。所以在 throttle 中不需要刚开始就触发时，必须指定 {leading: false}，在 debounce 中就不需要了，默认不触发。 防抖函数 Debounce 角度 4 lodash.debounce(fn, 200, {leading: false, trailing: true}) 此时相比较 throttle 来说，缺少了 maxWait 值，所以具体触发过程中的判断就不一样了，来详细看一遍。 在入口函数 debounced 中，执行 shouldInvoke(time)，前面讨论过因为第一次触发所以会返回 true，之后执行 leadingEdge(lastCallTime)。 // 执行连续事件刚开始的那次回调 function leadingEdge(time) { // 1、设置上一次执行 func 的时间 lastInvokeTime = time // 2、开启定时器，为了事件结束后的那次回调 timerId = startTimer(timerExpired, wait) // 3、如果配置了 leading 执行传入函数 func // leading 来源自 !!options.leading return leading ? invokeFunc(time) : result } 在 leadingEdge 中，因为 leading 为 false，所以并不执行 fn，只开启 200 毫秒的定时器，并返回 undefined。此时 lastInvokeTime 为当前时间，假设为 0。 // 判断此时是否应该执行 func 函数 function shouldInvoke(time) { // 当前时间距离上一次调用 debounce 的时间差 const timeSinceLastCall = time - lastCallTime // 当前时间距离上一次执行 func 的时间差 const timeSinceLastInvoke = time - lastInvokeTime // 下述 4 种情况返回 true return ( lastCallTime === undefined || (timeSinceLastCall &gt;= wait) || (timeSinceLastCall &lt; 0) || (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait) ) } 之后每次触发时，timeSinceLastCall 总是为 50 毫秒，maxing 为 false，所以 shouldInvoke(time) 总是返回 false，并不会执行传入函数 fn，只返回 result，即为 undefined。 到现在为止，fn 一次还没有执行，200 毫秒后，定时器回调函数触发，执行 timerExpired 函数。 // 定时器回调函数，表示定时结束后的操作 function timerExpired() { const time = Date.now() // 1、是否需要执行 // 执行事件结束后的那次回调，否则重启定时器 if (shouldInvoke(time)) { return trailingEdge(time) } // 2、否则 计算剩余等待时间，重启定时器，保证下一次时延的末尾触发 timerId = startTimer(timerExpired, remainingWait(time)) } 此时存在两种情况，第一种是 mousemove 事件一直在触发，根据前面介绍 shouldInvoke(time) 会返回 false，之后就将计算剩余等待时间，重启定时器。时间计算公式为 wait - (time - lastCallTime)，即 200 - 50，所以只要 shouldInvoke(time) 返回 false，就每隔 150 毫秒后执行一次 timerExpired()。 第二种情况是 mousemove 事件不再触发，因为 timerExpired() 在循环执行，所以肯定会存在一种情况满足 timeSinceLastCall &gt;= wait，即 shouldInvoke(time) 返回 true，终结 timerExpired() 的循环，并执行 trailingEdge(time)。 // 执行连续事件结束后的那次回调 function trailingEdge(time) { // 清空定时器 timerId = undefined // trailing 和 lastArgs 两者同时存在时执行 // trailing 来源自 'trailing' in options ? !!options.trailing : trailing // lastArgs 标记位的作用，意味着 debounce 至少执行过一次 if (trailing &amp;&amp; lastArgs) { return invokeFunc(time) } // 清空参数 lastArgs = lastThis = undefined return result } 在 trailingEdge 中 trailing 和 lastArgs 都是 true，所以会执行 invokeFunc(time)，即执行传入函数 fn。 所以整个过程中只在最后执行一次传入函数 fn，效果同上面第一张图所示。 角度 5 lodash.debounce(fn, 200, {leading: true, trailing: false}) 此时相比角度 4 来说，差异在于 {leading: true, trailing: false}，但是 wait 和 maxWait 都和角度 4 一致，所以只存在下面 2 种区别，效果同上面第一张图所示。 区别 1：leadingEdge 中会执行传入函数 fn 区别 2：trailingEdge 中不再执行传入函数 fn 角度 6 lodash.debounce(fn, 200, {leading: true, trailing: true}) 此时相比角度 4 来说，差异仅仅在于设置了 {leading: true}，所以只存在一个区别，那就是在 leadingEdge 中会执行传入函数 fn，当然在 trailingEdge 中依旧执行传入函数 fn，所以会出现在 mousemove 事件触发过程中首尾都会执行的情况，效果同上面第一张图所示。 当然一种情况除外，那就是 mousemove 事件永远只触发一次的情况，关键在于 lastArgs 变量。 对于 lastArgs 变量来说，在入口函数 debounced 中赋值，即每次触发都会重新赋值一次，那什么时候清空呢，在 invokeFunc(time) 中重置为 undefined，所以如果 debounced 只触发了一次，而且在 {leading: true} 时执行过一次 fn，那么即使设置了 {trailing: true} 也不会再执行传入函数 fn。 角度 7 lodash.debounce(fn, 200, {leading: false, trailing: true, maxWait: 400}) 此时 wait 为 200，maxWait 为 400，maxing 为 true，我们来看下执行过程。 第一次触发时，因为 {leading: false}，所以肯定不会执行 fn，此时开启了一个 200 毫秒的定时器。 // 判断此时是否应该执行 func 函数 function shouldInvoke(time) { // 当前时间距离上一次调用 debounce 的时间差 const timeSinceLastCall = time - lastCallTime // 当前时间距离上一次执行 func 的时间差 const timeSinceLastInvoke = time - lastInvokeTime // 下述 4 种情况返回 true return ( lastCallTime === undefined || (timeSinceLastCall &gt;= wait) || (timeSinceLastCall &lt; 0) || (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait) ) } 之后每隔 50 毫秒触发一次，每次都会执行 shouldInvoke(time) 函数，只有在第 400 毫秒时，才会满足 maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait，返回 true。 // 计算仍需等待的时间 function remainingWait(time) { // 当前时间距离上一次调用 debounce 的时间差 const timeSinceLastCall = time - lastCallTime // 当前时间距离上一次执行 func 的时间差 const timeSinceLastInvoke = time - lastInvokeTime // 剩余等待时间 const timeWaiting = wait - timeSinceLastCall // 是否设置了最大等待时间 // 是（节流）：返回「剩余等待时间」和「距上次执行 func 的剩余等待时间」中的最小值 // 否：返回剩余等待时间 return maxing ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke) : timeWaiting } 但是在这之前的第 200 毫秒，定时器触发回调函数，执行 timerExpired，因为此时 shouldInvoke(time) 返回 false，所以会重新计算剩余等待时间并重启计时器，其中 timeWaiting 是 150 毫秒，maxWait - timeSinceLastInvoke 是 200 毫秒，所以计算结果是 150 毫秒。 150 毫秒之后，即自开始之后的第 350 毫秒时，会重新计算时间，其中 timeWaiting 依旧是 150 毫秒，maxWait - timeSinceLastInvoke 是 50 毫秒，所以重新开启 50 毫秒的定时器，即在第 400 毫秒时触发。 此时会发现定时器触发的时间是第 400 毫秒，shouldInvoke(time) 中返回 true 的时间也是在第 400 毫秒，为什么要这样呢？这样会冲突吗？首先定时器剩余时间判断和 shouldInvoke(time) 判断中，只要有一处满足执行 fn 条件，就会立马执行，同时 lastInvokeTime 值也会发生改变，所以另一处判断就不会生效了。另外本身定时器是不精准的，所以通过 Math.min(timeWaiting, maxWait - timeSinceLastInvoke) 取最小值的方式来减少误差。 于此同时，需要在 debounced 入口函数添加这么一句 if (timerId === undefined) {timerId = startTimer(timerExpired, wait)}，避免 trailingEdge 执行后定时器被清空。 最终效果和节流是一样的，只是时间间隔变大了而已，具体效果同第一张图所示。 ","link":"https://tdmaker.github.io/faded/post/javascript-a-simple-explanation-to-debounce-and-throttle-in-lodash/"},{"title":"JavaScript——防抖和节流","content":" JS简单实现防抖和节流 1 防抖 - debounce 其中一种解决方案就是每次用户停止输入后，延迟超过 500ms 时，才去搜索此时的 string，这就是防抖。 1.1 原理 将若干个函数调用合成为一次，并在给定时间过去之后仅被调用一次。 1.2 代码实现 function debounce(fn, delay) { // 维护一个 timer，用来记录当前执行函数状态 let timer = null; return function() { // 通过 'this' 和 'arguments' 获取函数的作用域和变量 let context = this; let args = arguments; // 清理掉正在执行的函数，并重新执行 clearTimeout(timer); timer = setTimeout(function() { fn.apply(context, args); }, delay); } } let flag = 0; // 记录当前函数调用次数 // 当用户滚动时被调用的函数 function foo() { flag++; console.log('Number of calls: %d', flag); } // 在 debounce 中包装我们的函数，过 2 秒触发一次 document.body.addEventListener('scroll', debounce(foo, 2000)); 1.3 解释 debounce 函数封装后，返回内部函数。 每一次事件被触发，都会清除当前的 timer 然后重新设置超时并调用。这会导致每一次高频事件都会取消前一次的超时调用，导致事件处理程序不能被触发。 只有当高频事件停止，最后一次事件触发的超时调用才能在 delay 时间后执行。 2 节流 - throttle 另一种解决方案比防抖要宽松些，这时我们不想用户一味的输入，而是给用户一些搜索提示，所以在当中限制每过 500ms 就查询一次此时的 string，这就是节流。 2.1 原理 节流函数不管事件触发有多频繁，都会保证在规定时间内一定会执行一次真正的事件处理函数。 2.2 代码实现 代码实现有两种，一种是时间戳，另一种是定时器。 2.2.1 时间戳实现 function throttle(func, delay){ let prev = Date.now(); return function(){ const context = this; const args = arguments; const now = Date.now(); if(now - prev &gt;= delay){ func.apply(context, args); prev = Date.now(); } } } 当高频事件触发时，第一次应该会立即执行（给事件绑定函数与真正触发事件的间隔如果大于 delay 的话），而后再怎么频繁触发事件，也都是会每 delay 秒才执行一次。而当最后一次事件触发完毕后，事件也不会再被执行了。 2.2.2 定时器实现 当触发事件的时候，我们设置一个定时器，再触发事件的时候，如果定时器存在，就不执行；直到 delay 秒后，定时器执行执行函数，清空定时器，这样就可以设置下个定时器。 fucntion throttle(func, delay){ let timer = null; return funtion(){ let context = this; let args = arguments; if(!timer){ timer = setTimeout(function(){ func.apply(context, args); timer = null; }, delay); } } } 当第一次触发事件时，肯定不会立即执行函数，而是在 delay 秒后才执行。 之后连续不断触发事件，也会每 delay 秒执行一次。 当最后一次停止触发后，由于定时器的 delay 延迟，可能还会执行一次函数。 2.2.3 综合使用时间戳与定时器 完成一个事件触发时立即执行，触发完毕还能执行一次的节流函数。 function throttle(func, delay){ let timer = null; let startTime = Date.now(); return function(){ let curTime = Date.now(); let remaining = delay - (curTime - startTime); const context = this; const args = arguments; clearTimeout(timer); if(remaining &lt;= 0){ func.apply(context,args); startTime = Date.now(); }else{ timer = setTimeout(func, remaining); } } } 需要在每个 delay 时间中一定会执行一次函数，因此在节流函数内部使用开始时间、当前时间与 delay 来计算 remaining，当 remaining &lt;= 0 时表示该执行函数了，如果还没到时间的话就设定在 remaining 时间后再触发。当然在 remaining 这段时间中如果又一次发生事件，那么会取消当前的计时器，并重新计算一个 remaining 来判断当前状态。 ","link":"https://tdmaker.github.io/faded/post/javascript-debounce-throttle/"},{"title":"什么是 P 问题、NP 问题和 NPC 问题","content":" 什么是P问题、NP问题和NPC问题 [转载] 什么是P问题、NP问题和NPC问题 1 总结 Problem Introduction P 能在多项式时间里找到一个解决算法 NP 能在多项式时间里验证一个解是否正确 NPC 1. 首先必须是一个NP问题 2. 所有的NP问题都能 reduce 成该问题 NP-Hard 只需要满足 NPC 问题的第二个条件即可 下面的一些说法或许是众多 OIer 最大的误区之一。 你会经常看到网上出现“这怎么做，这不是 NP 问题吗”、“这个只有搜了，这已经被证明是 NP 问题了”之类的话。你要知道，大多数人此时所说的 NP 问题其实都是指的 NPC 问题。他们没有搞清楚 NP 问题和 NPC 问题的概念。NP 问题并不是那种“只有搜才行”的问题，NPC 问题才是。好，行了，基本上这个误解已经被澄清了。下面的内容都是在讲什么是 P 问题，什么是 NP 问题，什么是 NPC 问题，你如果不是很感兴趣就可以不看了。接下来你可以看到，把 NP 问题当成是 NPC 问题是一个多大的错误。 2 时间复杂度 还是先用几句话简单说明一下时间复杂度。时间复杂度并不是表示一个程序解决问题需要花多少时间，而是当问题规模扩大后，程序需要的时间长度增长得有多快。也就是说，对于高速处理数据的计算机来说，处理某一个特定数据的效率不能衡量一个程序的好坏，而应该看当这个数据的规模变大到数百倍后，程序运行时间是否还是一样，或者也跟着慢了数百倍，或者变慢了数万倍。不管数据有多大，程序处理花的时间始终是那么多的，我们就说这个程序很好，具有 O(1)O(1)O(1) 的时间复杂度，也称常数级复杂度；数据规模变得有多大，花的时间也跟着变得有多长，这个程序的时间复杂度就是 O(n)O(n)O(n)，比如找 nnn 个数中的最大值；而像冒泡排序、插入排序等，数据扩大 2 倍，时间变慢 4 倍的，属于 O(n2)O(n^2)O(n2) 的复杂度。还有一些穷举类的算法，所需时间长度成几何阶数上涨，这就是 O(an)O(a^n)O(an) 的指数级复杂度，甚至 O(n!)O(n!)O(n!) 的阶乘级复杂度。不会存在 O(2n2)O(2n^2)O(2n2) 的复杂度，因为前面的那个“2”是系数，根本不会影响到整个程序的时间增长。同样地，O(n3+n2)O(n^3+n^2)O(n3+n2) 的复杂度也就是 O(n3)O(n^3)O(n3) 的复杂度。因此，我们会说，一个 O(0.01∗n3)O(0.01*n^3)O(0.01∗n3) 的程序的效率比 O(100n2)O(100n^2)O(100n2) 的效率低，尽管在 nnn 很小的时候，前者优于后者，但后者时间随数据规模增长得慢，最终 O(n3)O(n^3)O(n3) 的复杂度将远远超过 O(n2)O(n^2)O(n2)。我们也说，O(n100)O(n^{100})O(n100) 的复杂度小于 O(1.01n)O(1.01^n)O(1.01n) 的复杂度。 容易看出，前面的几类复杂度被分为两种级别，其中后者的复杂度无论如何都远远大于前者：一种是 O(1)O(1)O(1)，O(log⁡(n))O(\\log(n))O(log(n))，O(na)O(n^a)O(na)等，我们把它叫做多项式级的复杂度，因为它的规模 n 出现在底数的位置；另一种是 O(an)O(a^n)O(an) 和 O(n!)O(n!)O(n!) 型复杂度，它是非多项式级的，其复杂度计算机往往不能承受。当我们在解决一个问题时，我们选择的算法通常都需要是多项式级的复杂度，非多项式级的复杂度需要的时间太多，往往会超时，除非是数据规模非常小。 自然地，人们会想到一个问题：会不会所有的问题都可以找到复杂度为多项式级的算法呢？很遗憾，答案是否定的。有些问题甚至根本不可能找到一个正确的算法来，这称之为“不可解问题”(Undecidable Decision Problem)。The Halting Problem 就是一个著名的不可解问题，在我的 Blog 上有过专门的介绍和证明。再比如，输出从 1 到 n 这 n 个数的全排列。不管你用什么方法，你的复杂度都是阶乘级，因为你总得用阶乘级的时间打印出结果来。有人说，这样的“问题”不是一个“正规”的问题，正规的问题是让程序解决一个问题，输出一个“YES”或“NO”（这被称为判定性问题），或者一个什么什么的最优值（这被称为最优化问题）。那么，根据这个定义，我也能举出一个不大可能会有多项式级算法的问题来：Hamilton 回路。问题是这样的：给你一个图，问你能否找到一条经过每个顶点一次且恰好一次（不遗漏也不重复）最后又走回来的路（满足这个条件的路径叫做 Hamilton 回路）。这个问题现在还没有找到多项式级的算法。事实上，这个问题就是我们后面要说的 NPC 问题。 3 P 问题 下面引入 P 类问题的概念：如果一个问题可以找到一个能在多项式的时间里解决它的算法，那么这个问题就属于 P 问题。P 是英文单词多项式的第一个字母。哪些问题是 P 类问题呢？通常 NOI 和 NOIP 不会出不属于 P 类问题的题目。我们常见到的一些信息奥赛的题目都是 P 问题。道理很简单，一个用穷举换来的非多项式级时间的超时程序不会涵盖任何有价值的算法。 4 NP 问题 接下来引入 NP 问题的概念。这个就有点难理解了，或者说容易理解错误。在这里强调（回到我竭力想澄清的误区上），NP 问题不是非 P 类问题。NP 问题是指可以在多项式的时间里验证一个解的问题。NP 问题的另一个定义是，可以在多项式的时间里猜出一个解的问题。比方说，我 RP 很好，在程序中需要枚举时，我可以一猜一个准。现在某人拿到了一个求最短路径的问题，问从起点到终点是否有一条小于 100 个单位长度的路线。它根据数据画好了图，但怎么也算不出来，于是来问我：你看怎么选条路走得最少？我说，我 RP 很好，肯定能随便给你指条很短的路出来。然后我就胡乱画了几条线，说就这条吧。那人按我指的这条把权值加起来一看，嘿，神了，路径长度 98，比 100 小。于是答案出来了，存在比 100 小的路径。别人会问他这题怎么做出来的，他就可以说，因为我找到了一个比 100 小的解。在这个题中，找一个解很困难，但验证一个解很容易。验证一个解只需要 O(n)O(n)O(n) 的时间复杂度，也就是说我可以花 O(n)O(n)O(n) 的时间把我猜的路径的长度加出来。那么，只要我 RP 好，猜得准，我一定能在多项式的时间里解决这个问题。我猜到的方案总是最优的，不满足题意的方案也不会来骗我去选它。这就是 NP 问题。当然有不是 NP 问题的问题，即你猜到了解但是没用，因为你不能在多项式的时间里去验证它。下面我要举的例子是一个经典的例子，它指出了一个目前还没有办法在多项式的时间里验证一个解的问题。很显然，前面所说的 Hamilton 回路是 NP 问题，因为验证一条路是否恰好经过了每一个顶点非常容易。但我要把问题换成这样：试问一个图中是否不存在 Hamilton 回路。这样问题就没法在多项式的时间里进行验证了，因为除非你试过所有的路，否则你不敢断定它“没有 Hamilton 回路”。 之所以要定义 NP 问题，是因为通常只有 NP 问题才可能找到多项式的算法。我们不会指望一个连多项式地验证一个解都不行的问题存在一个解决它的多项式级的算法。相信读者很快明白，信息学中的号称最困难的问题——“NP 问题”，实际上是在探讨 NP 问题与 P 类问题的关系。 很显然，所有的 P 类问题都是 NP 问题。也就是说，能多项式地解决一个问题，必然能多项式地验证一个问题的解——既然正解都出来了，验证任意给定的解也只需要比较一下就可以了。关键是，人们想知道，是否所有的 NP 问题都是 P 类问题。我们可以再用集合的观点来说明。如果把所有 P 类问题归为一个集合 P 中，把所有 NP 问题划进另一个集合 NP 中，那么，显然有 P 属于 NP。现在，所有对 NP 问题的研究都集中在一个问题上，即究竟是否有 P=NP ？通常所谓的“NP 问题”，其实就一句话：证明或推翻 P=NP。 NP 问题一直都是信息学的巅峰。巅峰，意即很引人注目但难以解决。在信息学研究中，这是一个耗费了很多时间和精力也没有解决的终极问题，好比物理学中的大统一和数学中的歌德巴赫猜想等。 目前为止这个问题还“啃不动”。但是，一个总的趋势、一个大方向是有的。人们普遍认为，P=NP 不成立，也就是说，多数人相信，存在至少一个不可能有多项式级复杂度的算法的 NP 问题。人们如此坚信 P≠NP 是有原因的，就是在研究 NP 问题的过程中找出了一类非常特殊的 NP 问题叫做 NP-完全问题，也即所谓的 NPC 问题。C 是英文单词“完全”的第一个字母。正是 NPC 问题的存在，使人们相信 P≠NP。下文将花大量篇幅介绍 NPC 问题，你从中可以体会到 NPC 问题使 P=NP 变得多么不可思议。 5 规约 为了说明 NPC 问题，我们先引入一个概念——约化(Reducibility，有的资料上叫“归约”)。 简单地说，一个问题 A 可以约化为问题 B 的含义即是，可以用问题 B 的解法解决问题 A，或者说，问题 A 可以“变成”问题 B。《算法导论》上举了这么一个例子。比如说，现在有两个问题：求解一个一元一次方程和求解一个一元二次方程。那么我们说，前者可以约化为后者，意即知道如何解一个一元二次方程那么一定能解出一元一次方程。我们可以写出两个程序分别对应两个问题，那么我们能找到一个“规则”，按照这个规则把解一元一次方程程序的输入数据变一下，用在解一元二次方程的程序上，两个程序总能得到一样的结果。这个规则即是：两个方程的对应项系数不变，一元二次方程的二次项系数为 0。按照这个规则把前一个问题转换成后一个问题，两个问题就等价了。同样地，我们可以说，Hamilton 回路可以约化为 TSP(Travelling Salesman Problem，旅行商问题)：在Hamilton 回路问题中，两点相连即这两点距离为 0，两点不直接相连则令其距离为 1，于是问题转化为在 TSP 中，是否存在一条长为 0 的路径。Hamilton 回路存在当且仅当 TSP 中存在长为 0 的回路。 “问题 A 可约化为问题 B”有一个重要的直观意义：B 的时间复杂度高于或者等于 A 的时间复杂度。也就是说，问题 A 不比问题 B 难。这很容易理解。既然问题 A 能用问题 B 来解决，倘若 B 的时间复杂度比 A 的时间复杂度还低了，那 A 的算法就可以改进为 B 的算法，两者的时间复杂度还是相同。正如解一元二次方程比解一元一次方程难，因为解决前者的方法可以用来解决后者。 很显然，约化具有一项重要的性质：约化具有传递性。如果问题 A 可约化为问题 B，问题 B 可约化为问题 C，则问题 A 一定可约化为问题 C。这个道理非常简单，就不必阐述了。 现在再来说一下约化的标准概念就不难理解了：如果能找到这样一个变化法则，对任意一个程序 A 的输入，都能按这个法则变换成程序 B 的输入，使两程序的输出相同，那么我们说，问题 A 可约化为问题 B。 当然，我们所说的“可约化”是指的可“多项式地”约化(Polynomial-time Reducible)，即变换输入的方法是能在多项式的时间里完成的。约化的过程只有用多项式的时间完成才有意义。 好了，从约化的定义中我们看到，一个问题约化为另一个问题，时间复杂度增加了，问题的应用范围也增大了。通过对某些问题的不断约化，我们能够不断寻找复杂度更高，但应用范围更广的算法来代替复杂度虽然低，但只能用于很小的一类问题的算法。再回想前面讲的 P 和 NP 问题，联想起约化的传递性，自然地，我们会想问，如果不断地约化上去，不断找到能“通吃”若干小 NP 问题的一个稍复杂的大 NP 问题，那么最后是否有可能找到一个时间复杂度最高，并且能“通吃”所有的 NP 问题的这样一个超级 NP 问题？答案居然是肯定的。也就是说，存在这样一个 NP 问题，所有的 NP 问题都可以约化成它。换句话说，只要解决了这个问题，那么所有的 NP 问题都解决了。这种问题的存在难以置信，并且更加不可思议的是，这种问题不只一个，它有很多个，它是一类问题。这一类问题就是传说中的 NPC 问题，也就是 NP-完全问题。NPC 问题的出现使整个 NP 问题的研究得到了飞跃式的发展。我们有理由相信，NPC 问题是最复杂的问题。再次回到全文开头，我们可以看到，人们想表达一个问题不存在多项式的高效算法时应该说它“属于 NPC 问题”。此时，我的目的终于达到了，我已经把 NP 问题和 NPC 问题区别开了。到此为止，本文已经写了近 5000 字了，我佩服你还能看到这里来，同时也佩服一下自己能写到这里来。 6 NPC 问题 NPC 问题的定义非常简单。同时满足下面两个条件的问题就是 NPC 问题。 首先，它得是一个 NP 问题； 然后，所有的 NP 问题都可以约化到它。 证明一个问题是 NPC 问题也很简单。先证明它至少是一个 NP 问题，再证明其中一个已知的 NPC 问题能约化到它（由约化的传递性，则 NPC 问题定义的第二条也得以满足；至于第一个 NPC 问题是怎么来的，下文将介绍），这样就可以说它是 NPC 问题了。 既然所有的 NP 问题都能约化成 NPC 问题，那么只要任意一个 NPC 问题找到了一个多项式的算法，那么所有的 NP 问题都能用这个算法解决了，NP 也就等于 P 了。因此，给 NPC 找一个多项式算法太不可思议了。因此，前文才说，“正是 NPC 问题的存在，使人们相信 P≠NP”。我们可以就此直观地理解，NPC 问题目前没有多项式的有效算法，只能用指数级甚至阶乘级复杂度的搜索。 7 NP-Hard 问题 顺便讲一下 NP-Hard 问题。NP-Hard 问题是这样一种问题，它满足 NPC 问题定义的第二条但不一定要满足第一条（就是说，NP-Hard 问题要比 NPC 问题的范围广）。NP-Hard 问题同样难以找到多项式的算法，但它不列入我们的研究范围，因为它不一定是 NP 问题。即使 NPC 问题发现了多项式级的算法，NP-Hard 问题有可能仍然无法得到多项式级的算法。事实上，由于 NP-Hard 放宽了限定条件，它将有可能比所有的 NPC 问题的时间复杂度更高从而更难以解决。 8 NPC 问题示例 不要以为 NPC 问题是一纸空谈。NPC 问题是存在的。确实有这么一个非常具体的问题属于 NPC 问题。下文即将介绍它。 下文即将介绍逻辑电路问题。这是第一个 NPC 问题。其它的 NPC 问题都是由这个问题约化而来的。因此，逻辑电路问题是 NPC 类问题的“鼻祖”。 逻辑电路问题是指的这样一个问题：给定一个逻辑电路，问是否存在一种输入使输出为 True。 什么叫做逻辑电路呢？一个逻辑电路由若干个输入，一个输出，若干“逻辑门”和密密麻麻的线组成。看下面一例，不需要解释你马上就明白了。 +----------+ | Input 1 +---+ +----------+ | | +----------+ +--&gt;+ | | OR +---+ +--&gt;+ | | | +----------+ | +----------+ +----------+ | +---&gt;+ | | Input 2 +---+ | AND +---&gt; Output +----------+ +---&gt;+ | +----------+ | +----------+ | | | +--&gt;+ NOT +---+ | | | +----------+ | +----------+ | Input 3 +---+ +----------+ 这是个较简单的逻辑电路，当输入 1、输入 2、输入 3分别为 True、True、False 或 False、True、False 时，输出为True。 有输出无论如何都不可能为 True 的逻辑电路吗？有。下面就是一个简单的例子。 +----------+ | Input 1 +---+ +----------+ | | +----------+ +---+ | | AND +---+ +---+ | | | +----------+ | +----------+ | +---&gt;+ | | | AND +---&gt; Output | +---&gt;+ | | +----------+ | +----------+ | | | | +---+ NOT +---+ | | | +----------+ | +----------+ | Input 2 +---+ +----------+ 上面这个逻辑电路中，无论输入是什么，输出都是 False。我们就说，这个逻辑电路不存在使输出为 True 的一组输入。 回到上文，给定一个逻辑电路，问是否存在一种输入使输出为 True，这即逻辑电路问题。 逻辑电路问题属于 NPC 问题。这是有严格证明的。它显然属于 NP 问题，并且可以直接证明所有的 NP 问题都可以约化到它（不要以为 NP 问题有无穷多个将给证明造成不可逾越的困难）。证明过程相当复杂，其大概意思是说任意一个 NP 问题的输入和输出都可以转换成逻辑电路的输入和输出（想想计算机内部也不过是一些 0 和 1 的运算），因此对于一个 NP 问题来说，问题转化为了求出满足结果为 True 的一个输入（即一个可行解）。 有了第一个 NPC 问题后，一大堆 NPC 问题就出现了，因为再证明一个新的 NPC 问题只需要将一个已知的 NPC 问题约化到它就行了。后来，Hamilton 回路成了 NPC 问题，TSP 问题也成了 NPC 问题。现在被证明是 NPC 问题的有很多，任何一个找到了多项式算法的话所有的 NP 问题都可以完美解决了。因此说，正是因为 NPC 问题的存在，P=NP 变得难以置信。P=NP 问题还有许多有趣的东西，有待大家自己进一步的挖掘。攀登这个信息学的巅峰是我们这一代的终极目标。现在我们需要做的，至少是不要把概念弄混淆了。 ","link":"https://tdmaker.github.io/faded/post/what-is-p-problem-np-problem-and-npc-problem/"},{"title":"NP 完全性理论","content":"1 计算模型 1.1 随机存取机 RAM 1.2 随机存取存储程序机 RASP 1.3 图灵机 1.4 图灵机模型与 RAM 模型的关系 1.5 问题变换与计算复杂性归约 1.1 随机存取机RAM 1.1.1 RAM 的结构 1.1.2 RAM 程序 一个RAM程序定义了从输入带到输出带的一个映射。可以对这种映射关系作 2 种不同的解释。 解释一：把 RAM 程序看成是计算一个函数 若一个 RAM 程序 PPP 总是从输入带前 nnn 个方格中读入 nnn 个整数 x1,x2,…,xnx_1, x_2,\\ldots,x_nx1​,x2​,…,xn​，并且在输出带的第一个方格上输出一个整数 yyy 后停机，那么就说程序 PPP 计算了函数 f(x1,x2,…,xn)=yf(x_1, x_2,\\ldots,x_n)=yf(x1​,x2​,…,xn​)=y。 解释二：把 RAM 程序当作一个语言接受器。 将字符串 S=a1a2…anS=a_1a_2\\ldots a_nS=a1​a2​…an​ 放在输入带上。在输入带的第一个方格中放入符号 a1a_1a1​，第二个方格中放入符号 a2a_2a2​，……，第 nnn 个方格中放入符号 ana_nan​。然后在第 n+1n+1n+1 个方格中放入000，作为输入串的结束标志符。如果一个 RAM 程序 PPP 读了字符串 SSS 及结束标志符 000 后，在输出带的第一格输出一个 111 并停机，就说程序 PPP 接受字符串SSS。 1.1.3 RAM程序的耗费标准 标准一：均匀耗费标准 在均匀耗费标准下，每条 RAM 指令需要一个单位时间；每个寄存器占用一个单位空间。以后除特别注明，RAM 程序的复杂性将按照均匀耗费标准衡量。 标准二：对数耗费标准 对数耗费标准是基于这样的假定，即执行一条指令的耗费与以二进制表示的指令的操作数长度成比例。在 RAM 计算模型下，假定一个寄存器可存放一个任意大小的整数。 1.2 随机存取存储程序机 RASP 1.2.1 RASP的结构 RASP 的整体结构类似于 RAM，所不同的是 RASP 的程序是存储在寄存器中的。每条 RASP 指令占据 2 个连续的寄存器。第一个寄存器存放操作码的编码，第二个寄存器存放地址。RASP 指令用整数进行编码。 1.2.2 RASP程序的复杂性 不管是在均匀耗费标准下，还是在对数耗费标准下，RAM 程序和 RASP 程序的复杂性只差一个常数因子。在一个计算模型下 T(n)T(n)T(n) 时间内完成的输入-输出映射可在另一个计算模型下模拟，并在 kT(n)kT(n)kT(n) 时间内完成。其中 kkk 是一个常数因子。空间复杂性的情况也是类似的。 1.3 图灵机 1.3.1 多带图灵机 根据有限状态控制器的当前状态及每个读写头读到的带符号，图灵机的一个计算步可实现下面 3 个操作之一或全部。 改变有限状态控制器中的状态。 清除当前读写头下的方格中原有带符号并写上新的带符号。 独立地将任何一个或所有读写头，向左移动一个方格（L）或向右移动一个方格（R）或停在当前单元不动（S）。 k 带图灵机可形式化地描述为一个 7 元组 (Q,T,I,δ,b,q0,qf)(Q,T,I,\\delta,b,q_0,q_f)(Q,T,I,δ,b,q0​,qf​)，其中: QQQ 是有限个状态的集合。 TTT 是有限个带符号的集合。 III 是输入符号的集合，I⊆TI\\subseteq TI⊆T。 bbb 是惟一的空白符，b∈T−Ib \\in T-Ib∈T−I。 q0q_0q0​ 是初始状态。 qfq_fqf​ 是终止（或接受）状态。 δ\\deltaδ 是移动函数。它是从 Q×TkQ\\times T^kQ×Tk 的某一子集映射到 Q×(T×{L,R,S})kQ\\times(T\\times \\lbrace L, R, S\\rbrace)^kQ×(T×{L,R,S})k 的函数。 与 RAM 模型类似，图灵机既可作为语言接受器，也可作为计算函数的装置。 图灵机 M 的时间复杂性 T(n)T(n)T(n) 是它处理所有长度为 nnn 的输入所需的最大计算步数。如果对某个长度为 nnn 的输入，图灵机不停机，T(n)T(n)T(n) 对这个 nnn 值无定义。 图灵机的空间复杂性 S(n)S(n)S(n) 是它处理所有长度为 nnn 的输入时，在 k 条带上所使用过的方格数的总和。如果某个读写头无限地向右移动而不停机，S(n)S(n)S(n) 也无定义。 1.4 图灵机模型与 RAM 模型的关系 图灵机模型与 RAM 模型的关系是指同一问题在这 2 种不同计算模型下的复杂性之间的关系。 定理 8-3 对于问题 PPP 的任何长度为 nnn 的输入，设求解问题 PPP 的算法 AAA 在 k 带图灵机模型 TM 下的时间复杂性为 T(n)T(n)T(n)，那么，算法 AAA 在 RAM 模型下的时间复杂性为 O(T2(n))O(T^2(n))O(T2(n))。 定理 8-4 对于问题 PPP 的任何长度为 nnn 的输入，设求解问题 PPP 的算法 AAA 在 RAM 模型下，不含有乘法和除法指令，且按对数耗费标准其时间复杂性为 T(n)T(n)T(n)，那么，算法 AAA 在 k 带图灵机模型 TM 下的时间复杂性为 O(T2(n))O(T^2(n))O(T2(n))。 1.5 问题变换与计算复杂性归约 通过问题变换的技巧，可以将 2 个不同问题的计算复杂性联系在一起。这样就可以将一个问题的计算复杂性归结为另一个问题的计算复杂性，从而实现问题的计算复杂性归约。 具体地说，假设有 2 个问题 A 和 B，将问题 A 变换为问题 B 是指： 将问题 A 的输入变换为问题 B 的适当输入。 解出问题 B。 把问题 B 的输出变换为问题 A 的正确解。 若用 O(τ(n))O(\\tau(n))O(τ(n)) 时间能完成上述变换的第 1 步和第 3 步，则称问题 A 是τ(n)\\tau(n)τ(n) 时间可变换到问题 B，且简记为 A∝τ(n)BA\\propto _{\\tau(n)}BA∝τ(n)​B。其中的 nnn 通常为问题 A 的规模(大小)。 当 τ(n)\\tau(n)τ(n) 为 nnn 的多项式时，称问题 A 可在多项式时间内变换为问题 B。特别地，当 τ(n)\\tau(n)τ(n) 为 nnn 的线性函数时，称问题 A 可线性地变换为问题 B。 问题的变换与问题的计算复杂性归约的关系： 命题 1（计算时间下界归约）：若已知问题 A 的计算时间下界为 T(n)T(n)T(n)，且问题 AAA 是τ(n)\\tau(n)τ(n) 可变换到问题 B，即 A∝τ(n)BA \\propto _{\\tau(n)}BA∝τ(n)​B，则 T(n)−O(τ(n))T(n)-O(\\tau(n))T(n)−O(τ(n)) 为问题 B 的一个计算时间下界。 命题 2（计算时间上界归约）：若已知问题 B 的计算时间上界为 T(n)T(n)T(n)，且问题 A 是 τ(n)\\tau(n)τ(n) 可变换到问题 B，即 A∝τ(n)BA\\propto _{\\tau(n)}BA∝τ(n)​B，则 T(n)+O(τ(n))T(n)+O(\\tau(n))T(n)+O(τ(n)) 是问题 A 的一个计算时间上界。 在命题 1 和命题 2 中，当 τ(n)=O(T(n))\\tau(n)=O(T(n))τ(n)=O(T(n)) 时，问题 A 的下界归约为问题 B 的下界，问题 B 的上界归约为问题 A 的上界。 2 P 类与 NP 类问题 2.1 非确定性图灵机 2.2 P类与NP类语言 2.3 多项式时间验证 2.1 非确定性图灵机 在图灵机计算模型中，移动函数 δ\\deltaδ 是单值的，即对于 Q×TkQ\\times T^kQ×Tk中的每一个值，当它属于 δ\\deltaδ 的定义域时，Q×(T×{L，R，S})kQ \\times (T \\times \\lbrace L，R，S\\rbrace)^kQ×(T×{L，R，S})k 中只有惟一的值与之对应，称这种图灵机为确定性图灵机，简记为 DTM(Deterministic Turing Machine)。 非确定性图灵机（NDTM）：一个 k 带的非确定性图灵机 M 是一个 7 元组：(Q,T,I,δ,b,q0,qf)(Q, T, I, \\delta, b, q_0, q_f)(Q,T,I,δ,b,q0​,qf​)。与确定性图灵机不同的是非确定性图灵机允许移动函数 δ\\deltaδ 具有不确定性，即对于 Q×TkQ\\times T^kQ×Tk 中的每一个值 (q;x1,x2,…,xk)(q; x_1, x_2,\\ldots, x_k)(q;x1​,x2​,…,xk​)，当它属于 δ\\deltaδ 的定义域时，Q×(T×{L,R,S})kQ \\times (T \\times \\lbrace L, R, S \\rbrace)^kQ×(T×{L,R,S})k 中有惟一的一个子集 δ(q;x1,x2,…,xk)\\delta(q; x_1, x_2,\\ldots, x_k)δ(q;x1​,x2​,…,xk​) 与之对应。可以在 δ(q;x1,x2,…,xk)\\delta(q; x_1, x_2, \\ldots, x_k)δ(q;x1​,x2​,…,xk​) 中随意选定一个值作为它的函数值。 2.2 P 类与 NP 类语言 2.2.1 P 类和 NP 类语言的定义： P = {L∣L\\lbrace L|L{L∣L 是一个能在多项式时间内被一台 DTM 所接受的语言}\\rbrace} NP = {L∣L\\lbrace L|L{L∣L 是一个能在多项式时间内被一台 NDTM 所接受的语言}\\rbrace} 由于一台确定性图灵机可看作是非确定性图灵机的特例，所以可在多项式时间内被确定性图灵机接受的语言也可在多项式时间内被非确定性图灵机接受。故 P⊆NPP \\subseteq NPP⊆NP。 2.2.2 NP 类语言举例——无向图的团问题 该问题的输入是一个有 nnn 个顶点的无向图 G=(V,E)G=(V, E)G=(V,E) 和一个整数 kkk。要求判定图 GGG 是否包含一个 kkk 顶点的完全子图（团），即判定是否存在 V′⊆V,∣V′∣=kV&#x27; \\subseteq V, \\vert V&#x27;\\vert=kV′⊆V,∣V′∣=k，且对于所有的 u,v∈V′u, v\\in V&#x27;u,v∈V′，有 (u,v)∈E(u, v)\\in E(u,v)∈E。 若用邻接矩阵表示图 GGG，用二进制串表示整数 kkk，则团问题的一个实例可以用长度为 n2+log⁡k+1n^2+\\log{k}+1n2+logk+1 的二进位串表示。因此，团问题可表示为语言： CLIQUE = {w#v∣w，v∈{0,1}∗\\lbrace w\\# v\\vert w，v\\in \\lbrace 0, 1\\rbrace ^*{w#v∣w，v∈{0,1}∗，以 www 为邻接矩阵的图 GGG 有一个 kkk 顶点的团，其中 vvv 是 kkk 的二进制表示。}\\rbrace} 接受该语言 CLIQUE 的非确定性算法：用非确定性选择指令选出包含 kkk 个顶点的候选顶点子集 VVV，然后确定性地检查该子集是否是团问题的一个解。算法分为 3 个阶段： 算法的第一阶段将输入串 w#vw\\#vw#v 分解，并计算出 n=∣w,∣n= \\sqrt{\\vert w, \\vert}n=∣w,∣​，以及用 vvv 表示的整数 kkk。若输入不具有形式 w#vw\\#vw#v 或 ∣w∣\\vert w\\vert∣w∣ 不是一个平方数就拒绝该输入。显而易见，第一阶段可 O(n2)O(n^2)O(n2) 在时间内完成。 在算法的第二阶段中，非确定性地选择V的一个 kkk 元子集 V′⊆VV&#x27;\\subseteq VV′⊆V。 算法的第三阶段是确定性地检查 V′V&#x27;V′ 的团性质。若 V′V&#x27;V′ 是一个团则接受输入，否则拒绝输入。这显然可以在 O(n4)O(n^4)O(n4) 时间内完成。因此，整个算法的时间复杂性为 O(n4)O(n^4)O(n4)。 非确定性算法在多项式时间内接受语言 CLIQUE，故 CLIQUE ∈\\in∈ NP 2.3 多项式时间验证 多项式时间可验证语言类 VP 可定义为： VP={L∣L∈∑∗\\text{VP}=\\lbrace L\\vert L\\in \\sum*VP={L∣L∈∑∗，∑\\sum∑ 为一有限字符集，存在一个多项式 ppp 和一个多项式时间验证算法 A(X,Y)A(X, Y)A(X,Y) 使得对任意 X∈∑∗X\\in \\sum*X∈∑∗，X∈LX\\in LX∈L 当且仅当存在 Y∈∑∗,∣Y∣≤p(∣X∣)Y\\in \\sum*, \\vert Y\\vert \\le p(\\vert X\\vert )Y∈∑∗,∣Y∣≤p(∣X∣) 且 A(X,Y)=1}A(X, Y)=1\\rbraceA(X,Y)=1}。 定理8-5：VP=NP 例如（哈密顿回路问题）：一个无向图 GGG 含有哈密顿回路吗? 无向图 GGG 的哈密顿回路是通过 GGG 的每个顶点恰好一次的简单回路。可用语言 HAM-CYCLE 定义该问题如下： HAM-CYCLE={G∣G含有哈密顿回路}\\text{HAM-CYCLE}=\\lbrace G \\vert G 含有哈密顿回路\\rbrace HAM-CYCLE={G∣G含有哈密顿回路} 3 NP 完全问题 3.1 多项式时间变换 3.2 Cook 定理 3.1 多项式时间变换 设 L1⊆∑1∗,L2⊆∑2∗L_1\\subseteq \\sum_1^*, L_2\\subseteq \\sum_2^*L1​⊆∑1∗​,L2​⊆∑2∗​， 是 2 个语言。所谓语言 L1L_1L1​ 能在多项式时间内变换为语言 L2L_2L2​(简记为 L1∝pL2L_1 \\propto _p L_2L1​∝p​L2​) 是指存在映身 f:⊆∑1∗→∑2∗f: \\subseteq \\sum_1^* \\to \\sum_2^*f:⊆∑1∗​→∑2∗​，且 fff 满足： 有一个计算 fff 的多项式时间确定性图灵机； 对于所有 x∈∑1∗,x∈L1x\\in \\sum_1^*, x\\in L_1x∈∑1∗​,x∈L1​，当且仅当 f(x)∈L2f(x)\\in L_2f(x)∈L2​。 定义： 语言 L 是 NP 完全的当且仅当 L∈NPL\\in \\text{NP}L∈NP； 对于所有 L′∈NPL&#x27; \\in \\text{NP}L′∈NP 有 L′∝pLL&#x27; \\propto_p LL′∝p​L。 如果有一个语言 LLL 满足上述性质 2，但不一定满足性质 1，则称该语言是 NP 难的。所有 NP 完全语言构成的语言类称为 NP 完全语言类，记为 NPC。 定理8-6：设 LLL 是 NP 完全的，则 L∈PL\\in PL∈P 当且仅当 P＝NPP＝\\text{NP}P＝NP； 若 L∝pL1L\\propto_p L_1L∝p​L1​，且 L1∈NPL_1\\in \\text{NP}L1​∈NP，则 L1L_1L1​ 是 NP 完全的。 定理 8-6 的 2 可用来证明问题的 NP 完全性。但前提是：要有第一个 NP 完全问题 LLL。 3.2 Cook 定理 定理 8-7（Cook 定理）：布尔表达式的可满足性问题 SAT 是 NP 完全的。 Cook 定理的重要性在于，它给出了第一个NP完全问题，使得对于任何问题 QQQ，只要能证明 Q∈NPQ \\in \\text{NP}Q∈NP 且 SAT∝pQ\\text{SAT} \\propto_p QSAT∝p​Q，就有 Q∈NPCQ\\in \\text{NPC}Q∈NPC. 4 一些典型的 NP 完全问题 4.1 合取范式的可满足性问题（CNF-SAT） 问题描述： 给定一个合取范式 α\\alphaα，判定它是否可满足。 如果一个布尔表达式是一些因子和之积，则称之为合取范式，简称 CNF (Conjunctive Normal Form)。这里的因子是变量 χ\\chiχ 或xxx。例如：(x1+x2)(x2+x3)(x1+x2+x3)(x_1+x_2)(x_2+x_3)(x_1+x_2+x_3)(x1​+x2​)(x2​+x3​)(x1​+x2​+x3​) 就是一个合取范式，而 x1x2+x3x_1x_2+x_3x1​x2​+x3​ 就不是合取范式。 要证明 CNF-SAT∈NPC\\text{CNF-SAT}\\in\\text{NPC}CNF-SAT∈NPC，只要证明在 Cook 定理中定义的布尔表达式 A,…,GA, \\ldots, GA,…,G 或者已是合取范式，或者有的虽然不是合取范式，但可以用布尔代数中的变换方法将它们化成合取范式，而且合取范式的长度与原表达式的长度只差一个常数因子。 4.2 三元合取范式的可满足性问题（3-SAT） 问题描述： 给定一个三元合取范式 α\\alphaα，判定它是否可满足。 证明思路： 3-SAT∈NP\\text{3-SAT}\\in\\text{NP}3-SAT∈NP 是显而易见的。为了证明 3-SAT∈NPC\\text{3-SAT}\\in\\text{NPC}3-SAT∈NPC，只要证明 CNF-SAT∝p3-SAT\\text{CNF-SAT}\\propto_p\\text{3-SAT}CNF-SAT∝p​3-SAT，即合取范式的可满足性问题可在多项式时间内变换为 3-SAT。 4.3 团问题（CLIQUE） 问题描述： 给定一个无向图 G=(V,E)G=(V, E)G=(V,E) 和一个正整数 kkk，判定图 GGG 是否包含一个 kkk 团，即是否存在，V′⊆V，∣V′∣=kV&#x27;\\subseteq V，\\vert V&#x27; \\vert=kV′⊆V，∣V′∣=k，且对任意 u,w∈V′u, w\\in V&#x27;u,w∈V′ 有 (u，w)∈E(u，w)\\in E(u，w)∈E。 证明思路： 已经知道 CLIQUE∈NP\\text{CLIQUE}\\in\\text{NP}CLIQUE∈NP。通过 3-SAT∝pCLIQUE\\text{3-SAT}\\propto_p\\text{CLIQUE}3-SAT∝p​CLIQUE 来证明 CLIQUE 是 NP 难的，从而证明团问题是 NP 完全的。 4.4 顶点覆盖问题（VERTEX-COVER） 问题描述： 给定一个无向图 G=(V,E)G=(V, E)G=(V,E) 和一个正整数 kkk，判定是否存在 V′⊆V,∣V′∣=kV&#x27; \\subseteq V, \\vert V&#x27;\\vert=kV′⊆V,∣V′∣=k，使得对于任意 (u,v)∈E(u, v)\\in E(u,v)∈E 有 u∈V′u\\in V&#x27;u∈V′ 或 v∈V′v\\in V&#x27;v∈V′。如果存在这样的 V′V&#x27;V′，就称 V′V&#x27;V′ 为图 GGG 的一个大小为 kkk 顶点覆盖。 证明思路： 首先，VERTEX-COVER∈NP\\text{VERTEX-COVER}\\in\\text{NP}VERTEX-COVER∈NP。因为对于给定的图 GGG 和正整数 kkk 以及一个“证书”V′V&#x27;V′，验证 ∣V′∣=k\\vert V&#x27;\\vert=k∣V′∣=k，然后对每条边 (u,v)∈E(u, v)\\in E(u,v)∈E，检查是否有 u∈V′u\\in V&#x27;u∈V′ 或 v∈V′v\\in V&#x27;v∈V′，显然可在多项式时间内完成。 其次，通过 CLIQUE∝pVERTEX-COVER\\text{CLIQUE}\\propto_p \\text{VERTEX-COVER}CLIQUE∝p​VERTEX-COVER 来证明顶点覆盖问题是 NP 难的。 4.5 子集和问题（SUBSET-SUM） 问题描述： 给定整数集合 SSS 和一个整数 ttt，判定是否存在 SSS 的一个子集S′⊆SS&#x27;\\subseteq SS′⊆S，使得 S′S&#x27;S′ 中整数的和为 ttt。例如，若 S={1,4,16,64,256,1040,1041,1093,1284,1344}S=\\lbrace 1, 4, 16, 64, 256, 1040, 1041, 1093, 1284, 1344\\rbraceS={1,4,16,64,256,1040,1041,1093,1284,1344} 且 t=3754t=3754t=3754，则子集 S′={1,16,64,256,1040,1093,1284}S&#x27;=\\lbrace 1, 16, 64, 256, 1040, 1093, 1284\\rbraceS′={1,16,64,256,1040,1093,1284} 是一个解。 证明思路： 首先，对于子集和问题的一个实例 ⟨S,t⟩\\langle S, t\\rangle⟨S,t⟩，给定一个“证书”S′S&#x27;S′，要验证 t=∑i∈S′it= \\sum_{i\\in S&#x27;}it=∑i∈S′​i 是否成立，显然可在多项式时间内完成。因此，SUBSET-SUM∈NP\\text{SUBSET-SUM}\\in \\text{NP}SUBSET-SUM∈NP； 其次，证明 VERTEX-COVER∝pSUBSET-SUM\\text{VERTEX-COVER}\\propto_p \\text{SUBSET-SUM}VERTEX-COVER∝p​SUBSET-SUM。 4.6 哈密顿回路问题（HAM-CYCLE） 问题描述： 给定无向图 G=(V,E)G=(V, E)G=(V,E)，判定其是否含有一哈密顿回路。 证明思路： 首先，已知哈密顿回路问题是一个 NP 类问题。 其次，通过证明 3-SAT∝pHAM-CYCLE\\text{3-SAT}\\propto_p\\text{HAM-CYCLE}3-SAT∝p​HAM-CYCLE。 得出：HAM-CYCLE∈NPC\\text{HAM-CYCLE}\\in\\text{NPC}HAM-CYCLE∈NPC。 4.7 旅行售货员问题（TSP） 问题描述： 给定一个无向完全图 G=(V,E)G=(V, E)G=(V,E) 及定义在 V×VV\\times VV×V 上的一个费用函数 ccc 和一个整数 kkk，判定 GGG 是否存在经过 VVV 中各顶点恰好一次的回路，使得该回路的费用不超过 kkk。 首先，给定 TSP 的一个实例 (G,c,k)(G, c, k)(G,c,k)，和一个由 nnn 个顶点组成的顶点序列。验证算法要验证这 nnn 个顶点组成的序列是图 GGG 的一条回路，且经过每个顶点一次。另外，将每条边的费用加起来，并验证所得的和不超过 kkk。这个过程显然可在多项式时间内完成，即 TSP∈NP\\text{TSP}\\in\\text{NP}TSP∈NP。 其次，旅行售货员问题与哈密顿回路问题有着密切的联系。哈密顿回路问题可在多项式时间内变换为旅行售货员问题。即 HAM-CYCLE∝pTSP\\text{HAM-CYCLE}\\propto_p\\text{TSP}HAM-CYCLE∝p​TSP。从而，旅行售货员问题是 NP 难的。 因此，TSP∈NPC\\text{TSP}\\in\\text{NPC}TSP∈NPC。 ","link":"https://tdmaker.github.io/faded/post/np-completeness-theory/"},{"title":"算法复杂度比较","content":" 算法复杂度学习（上） 算法复杂度学习（下） 1 定义 时间复杂度一般采用 大 O 标记法, 即 T(n)=O(f(n))T(n)=O(f(n))T(n)=O(f(n)), 其中 T(n)T(n)T(n) 表示代码运行时间；nnn 表示数据规模大小；f(n)f(n)f(n) 表示每行代码执行次数总和，OOO 表示 T(n)T(n)T(n) 与 f(n)f(n)f(n) 的正比关系。大 OOO 时间复杂度实际上并不具体表示代码的真正运行时间，而是表示代码执行时间随数据规模增长的变化趋势。 在大 OOO 表示分析中，低阶项和常数项都可以省略，只保留最高阶项即可；如 f(n)=2n+2f(n)=2n+2f(n)=2n+2 在大 OOO 标记法中记为 T(n)=O(n)T(n)=O(n)T(n)=O(n)，而对于形如 f(n)=2n2+2n+3f(n)=2n^2+2n+3f(n)=2n2+2n+3 表示为 T(n)=O(n2)T(n)=O(n^2)T(n)=O(n2)。 2 时间复杂度分析 2.1 关注循环次数多的代码 public int accumulate(int n) { int sum = 0; int i = 1; for (; i &lt;= n; i++) { sum += i; } return sum; } 其中 for 循环内的代码执行 nnn 次，而其余代码执行 1 次，与 nnn 的大小无关，忽略常数项，该段代码的时间复杂度为 O(n)O(n)O(n)。 2.2 加法法则 总复杂度为量级最大的那段代码的复杂度，抽象为公式为： 若 T1(N)=O(f(n)),T2(N)=O(g(n))T_{1}(N)=O(f(n)), T_{2}(N)=O(g(n))T1​(N)=O(f(n)),T2​(N)=O(g(n))，那么 T(N)=T1(N)+T2(N)=O(f(n))+O(g(n))=max⁡(O(f(n)),O(g(n)))T(N)=T_{1}(N)+T_{2}(N)=O(f(n))+O(g(n)) = \\max(O(f(n)), O(g(n)))T(N)=T1​(N)+T2​(N)=O(f(n))+O(g(n))=max(O(f(n)),O(g(n))) public int accumulate(int n) { int sum1 = 0; for (int i = 1; i &lt;= 100; i++) { sum1 += i; } int sum2 = 0; for (int i = 1; i &lt;= n; i++) { sum2 += i; } int sum3 = 0; for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= n; j++) { sum3 += i * j; } } return sum1 + sum2 + sum3; } 其中 sum1 段的代码循环执行了 100 次，与 nnn 无关。sum2 段代码的复杂度为 O(N)O(N)O(N)，sum3 段的代码复杂度为 O(N2)O(N^2)O(N2)；根据加法法则，我们只去其中最大量级的复杂度，所以该段代码的时间复杂度为 O(N2)O(N^2)O(N2)。 2.3 乘法法则 嵌套代码的复杂度等于嵌套内外代码复杂度的乘积，抽象为公式为： 若 T1(N)=O(f(n)),T2(N)=O(g(n))T_{1}(N)=O(f(n)), T_{2}(N)=O(g(n))T1​(N)=O(f(n)),T2​(N)=O(g(n))，那么 T(N)=T1(N)×T2(N)=O(f(n)×g(n))T(N)=T_{1}(N) \\times T_{2}(N)=O(f(n) \\times g(n))T(N)=T1​(N)×T2​(N)=O(f(n)×g(n)) 3 常见时间复杂度量级 度量级 大 O 表示 常量阶 O(1)O(1)O(1) 对数阶 O(log⁡N)O(\\log{N})O(logN) 线性阶 O(N)O(N)O(N) 线性对数阶 O(Nlog⁡N)O(N\\log{N})O(NlogN) 平方阶 O(N2)O(N^2)O(N2) 立方阶 O(N3)O(N^3)O(N3) 指数阶 O(2n)O(2^n)O(2n) 阶乘阶 O(N!)O(N!)O(N!) 3.1 常见的时间复杂度 常见的时间复杂度有常量阶、对数阶、线性阶、线性对数阶以及平方阶，常量阶、线性阶与平方阶在第二节中已经分析，不再赘述；而一些高效的排序算法的时间复杂度就是线性对数阶，如快速排序，归并排序以及堆排序等。 3.2 对数阶 我们所熟知的二分查找的复杂度就是 O(log⁡N)O(\\log{N})O(logN)，以下通过一段代码来分析对数阶复杂度： public int test(int n) { int res = 1; while (res &lt;= n) { res *= 2; } return res; } 该段代码是求 2x=n2^x=n2x=n 的解，更确切的说，是找出 2x2^x2x 在小于或等于 nnn 的范围内最接近 nnn 的xxx 的值；其中 x=log⁡2nx=\\log_{2}{n}x=log2​n，即 while 循环体内代码要执行 log⁡2n\\log_{2}{n}log2​n 次，即其时间复杂度为 O(log⁡2n)O(\\log_{2}{n})O(log2​n)。 若把循环体内代码 res *= 2 改为 res *= 3，不难分析出其时间复杂度就变为 O(log⁡3n)O(\\log_{3}{n})O(log3​n)；但是为什么所有对数阶的时间复杂度都统一表示为 O(log⁡N)O(\\log{N})O(logN)？ 首先我们先复习对数换底公式: log⁡AB=log⁡CBlog⁡CA\\log_{A}{B}=\\frac{\\log_{C}{B}}{\\log_{C}{A}} logA​B=logC​AlogC​B​ 则 log⁡3n=log⁡2nlog⁡23=log⁡22log⁡23⋅log⁡2n=log⁡32⋅log⁡2n\\log_{3}{n}=\\frac{\\log_{2}{n}}{\\log_{2}{3}}=\\frac{\\log_{2}{2}}{\\log_{2}{3}}\\cdot\\log_{2}{n}=\\log_{3}{2}\\cdot\\log_{2}{n} log3​n=log2​3log2​n​=log2​3log2​2​⋅log2​n=log3​2⋅log2​n 所以 O(log⁡3n)=O(log⁡32⋅log⁡2n)O(\\log_{3}{n})=O(\\log_{3}{2}\\cdot\\log_{2}{n})O(log3​n)=O(log3​2⋅log2​n)，因为 log⁡32\\log_{3}{2}log3​2 为常数项，所以该项可以忽略，因此 O(log⁡3n)=O(log⁡2n)O(\\log_{3}{n})=O(\\log_{2}{n})O(log3​n)=O(log2​n)；所以无论对数以哪个数为底，最后都可以转化为一个常数项与以 222 为底的对数相乘，因此在对数阶时间复杂度的表示方法里，就忽略对数的底，统一表示为 O(log⁡N)O(\\log{N})O(logN) 3.3 O(m+n)O(m+n)O(m+n) 与 O(m×n)O(m \\times n)O(m×n) 此种表示形式的时间复杂度是由两个数据规模来决定的 public int accumulate(int m, int n) { int sum1 = 0; for (int i = 1; i &lt;= m; i++) { sum1 += i; } int sum2 = 0; for (int i = 1; i &lt;= n; i++) { sum2 += i; } return sum1 + sum2; } 由于我们不能事先知晓 mmm 与 nnn 哪个量级大，所以就不能简单的利用加法规则取其最大量级，那么像这种代码的时间复杂度就为 O(m+n)O(m+n)O(m+n)。 public int accumulate(int m, int n) { int sum = 0; for (int i = 1; i &lt;= m; i++) { for (int j = 1; j &lt;= n; j++) { sum += i * j; } } return sum; } 而类似上述代码依然可以使用乘法法则，其时间复杂度为 O(m×n)O(m \\times n)O(m×n)。 4 最好、最坏、平均和均摊时间复杂度 以下将通过一段代码来讲述这几个时间复杂度： public class Test { private int[] array = new int[5]; private int N = 0; public void push(int item) { if (N == array.length) { resize(2 * array.length); } array[N++] = item; } private void resize(int size) { int[] temp = new int[size]; for (int i = 0; i &lt; N; i++) { temp[i] = array[i]; } array = temp; } } 上述代码是用数组模拟一个栈的部分代码，其中 push 表示压栈操作，resize 表示对数组进行扩容的操作；当压入栈中的元素数量达到数组的容量时，就定义一个容量为之前两倍的新数组 temp，将旧数组 array 中的元素复制到新数组中，然后将 array 指向 temp。 4.1 最好时间复杂度 最理想的情况下，当前栈中元素数量比数组的容量小，此时就直接执行代码块 array[N++] = item;，即此时的时间复杂度为 O(1)O(1)O(1)。 4.2 最坏时间复杂度 最糟糕的情况下，当前栈中元素数量与数组的容量相等，此时就要执行 resize 方法进行扩容了，进入循环体，执行 N 次复制操作，此时的时间复杂度为 O(N)O(N)O(N)。 4.3 平均时间复杂度 当栈中元素小于数组容量时，此时进行压栈就有 NNN 种情况，且每种情况的时间复杂度为 O(1)O(1)O(1)；当栈中元素与数组容量相等时，此时进行压栈就只有一种情况了，要进行扩容操作，这种情况的时间复杂度为 O(N)O(N)O(N)；则总共有 N+N+N+` 种情况，对其取平均值： 1+1+1+…+1+NN+1=2NN+1\\cfrac{1+1+1+\\ldots+1+N}{N+1}=\\cfrac{2N}{N+1} N+11+1+1+…+1+N​=N+12N​ 在大 O 标记法中，可以省略系数与低阶项，所以其平均时间复杂度为 O(1)O(1)O(1) 下面使用概率来分析，由于有 N+1N+1N+1 种情况，每种情况的发生概率为 1N+1\\frac{1}{N+1}N+11​，则其平均时间复杂度为： 1×1N+1+1×1N+1+…+1×1N+1+N×1N+1=O(1)1\\times\\frac{1}{N+1}+1\\times\\frac{1}{N+1}+\\ldots+1\\times\\frac{1}{N+1}+N\\times\\frac{1}{N+1}=O(1) 1×N+11​+1×N+11​+…+1×N+11​+N×N+11​=O(1) 4.4 均摊时间复杂度 是一种特殊的平均时间复杂度，根据上述代码，每出现一次扩容操作时，即此时压栈的时间复杂度为 O(N)O(N)O(N)，那么后面的 NNN 次压栈操作的时间复杂度均为 O(1)O(1)O(1)，前后是连贯的，因此将 O(N)O(N)O(N) 平摊到前 NNN 次上，得出均摊时间复杂度为 O(1)O(1)O(1)。 5 不同时间复杂度算法对比 这一节将以一个具体的算法题给出 4 种不同解法，分析各自的时间复杂度并比较其各自的运行性能。 给出两个求和公式，以下分析中会用到： ∑i=1Ni=N(N+1)2∑i=1Ni2=N(N+1)(2N+1)6\\begin{aligned} \\sum_{i=1}^{N}i &amp;=\\frac{N(N+1)}{2} \\\\ \\sum_{i=1}^{N}i^2 &amp;=\\frac{N(N+1)(2N+1)}{6} \\end{aligned} i=1∑N​ii=1∑N​i2​=2N(N+1)​=6N(N+1)(2N+1)​​ 最大子序列和问题 A1,A2,A3,…,ANA_1, A_2, A_3, \\ldots, A_NA1​,A2​,A3​,…,AN​，求 ∑k=ijAk\\sum_{k=i}^{j}A_k∑k=ij​Ak​ 的最大值。（为方便起见，若所有整数均为负数，则最大子序列和为 0）。 例如：输入 −2,11,−4,13,−5,−2-2, 11, -4, 13, -5, -2−2,11,−4,13,−5,−2，其最大子序列和为 11+(−4)+13=2011+(-4)+13=2011+(−4)+13=20。 5.1 时间复杂度为 O(N3)O(N^3)O(N3) 的解法 public static int maxSubSum1(int[] a) { int maxSum = 0; for (int i = 0; i &lt; a.length; i++) { for (int j = i; j &lt; a.length; j++) { int thisSum = 0; for (int k = i; k &lt;= j; k++) { thisSum += a[k]; } if (thisSum &gt; maxSum) { maxSum = thisSum; } } } return maxSum; } 该种解法最简单暴力，定义子序列的起始位置为 i，结束位置为 j，假设数组 a 的长度为 NNN，当 i=0i=0i=0 时，j=0,1,2,3,…,N−1j=0,1,2,3, \\ldots,N-1j=0,1,2,3,…,N−1，共 NNN 种情况，当 N=1N=1N=1 时，j=1,2,3,⋯ ,N−1j=1,2,3,\\cdots,N-1j=1,2,3,⋯,N−1，共 N−1N-1N−1 种情况，以此类推，当 i=N−1i=N-1i=N−1 时，j=N−1j=N-1j=N−1，仅此一种情况；将 i 与 j 之间的所有元素和记为 thisSum，一旦 thisSum 的值比 maxSum 大，就更新 maxSum 的值为 thisSum。 第一个循环大小为 NNN，第二个循环大小为 N−iN-iN−i，第三个循环大小为 j−i+1j-i+1j−i+1，则总运行次数和为: ∑i=0N−1∑j=iN−1∑k=ij1\\sum_{i=0}^{N-1}\\sum_{j=i}^{N-1}\\sum_{k=i}^{j}1 i=0∑N−1​j=i∑N−1​k=i∑j​1 首先有： ∑k=ij1=j−i+1\\sum_{k=i}^{j}1 =j-i+1 k=i∑j​1=j−i+1 接着： ∑j=iN−1(j−i+1)=(N−i+1)(N−i)2\\sum_{j=i}^{N-1}(j-i+1)=\\frac{(N-i+1)(N-i)}{2} j=i∑N−1​(j−i+1)=2(N−i+1)(N−i)​ 那么： ∑i=0N−1(N−i+1)(N−i)2=∑i=1N(N−i+1)(N−i+2)2=12∑i=1Ni2−(N+32)∑i=1Ni+12(N2+3N+2)∑i=1N1=12N(N+1)(2N+1)6−(N+32)N(N+1)2+N2+3N+22N=N3+3N2+2N6\\begin{aligned} \\sum_{i=0}^{N-1} \\frac{(N-i+1)(N-i)}{2} &amp;= \\sum_{i=1}^{N}\\frac{(N-i+1)(N-i+2)}{2}\\\\ &amp;=\\frac{1}{2}\\sum_{i=1}^{N}i^2-(N+\\frac{3}{2})\\sum_{i=1}^{N}i +\\frac{1}{2}(N^2+3N+2)\\sum_{i=1}^{N}1\\\\ &amp;=\\frac{1}{2}\\frac{N(N+1)(2N+1)}{6}-(N+\\frac{3}{2})\\frac{N(N+1)}{2}+\\frac{N^2+3N+2}{2}N\\\\ &amp;=\\frac{N^3+3N^2+2N}{6} \\end{aligned} i=0∑N−1​2(N−i+1)(N−i)​​=i=1∑N​2(N−i+1)(N−i+2)​=21​i=1∑N​i2−(N+23​)i=1∑N​i+21​(N2+3N+2)i=1∑N​1=21​6N(N+1)(2N+1)​−(N+23​)2N(N+1)​+2N2+3N+2​N=6N3+3N2+2N​​ 所以该种解法的时间复杂度为：O(N3+3N2+2N6)=O(N3)O(\\frac{N^3+3N^2+2N}{6})=O(N^3)O(6N3+3N2+2N​)=O(N3)。 5.2 时间复杂度为 O(N2)O(N^2)O(N2)的解法 public static int maxSubSum2(int[] a) { int maxSum = 0; for (int i = 0; i &lt; a.length; i++) { int thisSum = 0; for (int j = i; j &lt; a.length; j++) { thisSum += a[j]; if (thisSum &gt; maxSum) { maxSum = thisSum; } } } return maxSum; } 在第一种解法中，拿掉最里面的那层循环，并稍做改动，就是现在的解法 2。 其中第一层循环大小为 NNN，第二层循环为 N−iN-iN−i，则总运行次数为： ∑i=0N−1∑j=iN−11\\sum_{i=0}^{N-1} \\sum_{j=i}^{N-1}1 i=0∑N−1​j=i∑N−1​1 其中： ∑j=iN−11=N−1−i+1=N−i\\sum_{j=i}^{N-1}1 = N-1-i+1=N-i j=i∑N−1​1=N−1−i+1=N−i 那么： ∑i=0N−1(N−i)=N∑i=0N−11−∑i=0N−1i=N(N−1+1)−(N−1)N2=N2−N2\\begin{aligned} \\sum_{i=0}^{N-1}(N-i) &amp;= N\\sum_{i=0}^{N-1}1- \\sum_{i=0}^{N-1} i \\\\ &amp;= N(N-1+1) - \\frac{(N-1)N}{2} \\\\ &amp;= \\frac{N^2-N}{2} \\end{aligned} i=0∑N−1​(N−i)​=Ni=0∑N−1​1−i=0∑N−1​i=N(N−1+1)−2(N−1)N​=2N2−N​​ 所以第二种解法的时间复杂度为 O(N2−N2)=O(N2)O(\\frac{N^2-N}{2})=O(N^2)O(2N2−N​)=O(N2)。 5.3 时间复杂度为 O(Nlog⁡N)O(N\\log{N})O(NlogN) 的解法 如下图所示，可以将数组分为三部分，分别为前中后三部分。 最大子序列和就可能出现在这三个部分中，其中 mid=start+end2=0+52=2\\text{mid}=\\frac{\\text{start}+\\text{end}}{2}=\\frac{0+5}{2}=2mid=2start+end​=20+5​=2，前半部分是从 start\\text{start}start 到 mid\\text{mid}mid 这一部分的元素，即 −2,11,−4-2,11,-4−2,11,−4，所以该部分最大元素为 111111；后半部分是从 mid+1\\text{mid+1}mid+1 到 end\\text{end}end 这一部分的元素，即 13,−5,−213,-5,-213,−5,−2，所以该部分最大元素为 13\\text{13}13；而中间部分元素是以 mid\\text{mid}mid 起始，分别向左和向右进行累加计算，分别求出其向左和向右部分的最大值，从 mid\\text{mid}mid 向左得到其最大值：−4+11=7-4+11=7−4+11=7，而向右是从 mid+1\\text{mid+1}mid+1 开始算起得到其最大值：131313，最后将左右两部分和相加即为中间部分的最大值：7+13=207+13=207+13=20；比较前中后部分的最大值，发现中间部分的值 202020 最大，所以该数组最大子序列和为 202020。 那么在程序中如何实现呢？这就要采用分治策略，将数组 a 分为前后两半子数组 b, c，再将前半数组 b 分为前后两半子数组 d, e，后半数组 c 分为前后两半子数组 f, g, ……，直到数组不能再分为止，此时子数组中就只有一个元素，一个元素就好判断了，该元素为正就直接把该元素值返回给上一级子数组，为负就返回 0，然后回到上一级子数组，将之前返回的前后部分子数组的最大值与中间部分最大值进行比较，得出其最大值，接着将最大值返回其上一级子数组，直至回到原数组，这时原数组就得到了前后部分子数组的最大值，接着求出中间部分子数组的最大值并与前后部分进行比较即可得到整个数组的最大子序列和。 public static int maxSubSum3(int[] a) { return a.length &gt; 0 ? maxSumRec(a, 0, a.length - 1) : 0; } private static int maxSumRec(int[] a, int left, int right) { if (left == right) { if (a[left] &gt; 0) { return a[left]; } else { return 0; } } int center = (left + right) / 2; int maxLeftSum = maxSumRec(a, left, center); int maxRightSum = maxSumRec(a, center + 1, right); int maxLeftBorderSum = 0; int leftBorderSum = 0; for (int i = center; i &gt;= left; i--) { leftBorderSum += a[i]; if (leftBorderSum &gt; maxLeftBorderSum) { maxLeftBorderSum = leftBorderSum; } } int maxRightBorderSum = 0; int rightBorderSum = 0; for (int i = center + 1; i &lt;= right; i++) { rightBorderSum += a[i]; if (rightBorderSum &gt; maxRightBorderSum) { maxRightBorderSum = rightBorderSum; } } return max3(maxLeftSum, maxRightSum, maxLeftBorderSum + maxRightBorderSum); } private static int max3(int a, int b, int c) { return a &gt; b ? a &gt; c ? a : c : b &gt; c ? b : c; } 其中 center 为数组中间元素的下标，maxLeftSum 和 maxRightSum 分别为数组前后部分的最大值，maxLeftBorderSum 为中间部分向左计算的最大值，maxRightBorderSum 为中间部分向右计算最大值；maxLeftBorderSum + maxRightBorderSum 即为中间部分的最大值。 计算中间部分，即计算 maxLeftBorderSum 和 maxRightBorderSum 总花费时间为 NNN，而计算前后两半部分，即 maxLeftSum 和 maxRightSum 每个花费 T(N/2)T(N/2)T(N/2) 个时间单元，则总共花费时间： T(N)=2T(N/2)+NT(N)=2T(N/2)+N T(N)=2T(N/2)+N 其中 T(1)=1T(1)=1T(1)=1，则 T(2)=4=2×2T(2)=4=2 \\times 2T(2)=4=2×2，T(4)=12=4×3T(4)=12=4 \\times 3T(4)=12=4×3，T(8)=32=8×4T(8)=32=8 \\times 4T(8)=32=8×4，T(16)=80=16×5T(16)=80=16 \\times 5T(16)=80=16×5。 那么当 N=2kN=2^kN=2k，则 T(N)=N×(k+1)=N(log⁡N+1)T(N)=N \\times (k+1)=N(\\log{N}+1)T(N)=N×(k+1)=N(logN+1)，忽略低阶项，所以该方法的时间复杂度为：O(Nlog⁡N)O(N\\log{N})O(NlogN)。 5.4 时间复杂度为 O(N)O(N)O(N) 的解法 public static int maxSubSum4(int[] a) { int maxSum = 0; int thisSum = 0; for (int i = 0; i &lt; a.length; i++) { thisSum += a[i]; if (thisSum &gt; maxSum) { maxSum = thisSum; } else if (thisSum &lt; 0) { thisSum = 0; } } return maxSum; } 此种方法将时间复杂度优化到了 O(N)O(N)O(N)，只需一轮循环即可找到最大子序列；其思路为：若当前子序列的和 thisSum 为负数，则将 thisSum 置为 000，下一个数组元素作为新的子序列的起始位置，thisSum 从该元素开始累加，直至找到最大子序列的和。 5.5 对比分析 使用下面代码测试上述 4 中解法所消耗的时间： public static void getTimingInfo(int n, int alg) { int[] test = new int[n]; Random rand = new Random(); long startTime = System.currentTimeMillis(); long totalTime = 0; int i; for (i = 0; totalTime &lt; 4000; i++) { for (int j = 0; j &lt; test.length; j++) { test[j] = rand.nextInt(100) - 50; } switch (alg) { case 1: maxSubSum1(test); break; case 2: maxSubSum2(test); break; case 3: maxSubSum3(test); break; case 4: maxSubSum4(test); break; default: } totalTime = System.currentTimeMillis() - startTime; } System.out.print(String.format(&quot;\\t%12.6f&quot;, (totalTime * 1000 / i) / (double) 1000000)); } public static void main(String[] args) { for (int n = 100; n &lt;= 1000000; n *= 10) { System.out.print(String.format(&quot;N = %7d&quot;, n)); for (int alg = 1; alg &lt;= 4; alg++) { if ((alg == 1 &amp;&amp; n &gt; 50000) || (alg == 2 &amp;&amp; n &gt; 500000)) { System.out.print(&quot;\\t NA &quot;); continue; } getTimingInfo(n, alg); } System.out.println(); } } 运行结果如下图，当预测时间过长，将其设为 NA，从图中可以看出，不同时间复杂度的程序虽然得出的结果是一样的，但运行性能相差巨大，犹如波音与摩拜的差别。 输入大小 N O(N3)O(N^3)O(N3) O(N2)O(N^2)O(N2) O(Nlog⁡N)O(N\\log{N})O(NlogN) O(N)O(N)O(N) 100 0.000063 0.000005 0.000003 0.000001 1000 0.054986 0.000201 0.000036 0.000014 10000 55.234000 0.018058 0.000371 0.000125 100000 NA 1.790000 0.003937 0.001249 1000000 NA NA 0.041979 0.012479 6 总结 以后写代码之前要多思考，避免一上来就暴力求解，造成巨大的性能开销，应尽量将程序优化到线性阶或线性对数阶以内。 ","link":"https://tdmaker.github.io/faded/post/algorithm-complexity-comparison/"},{"title":"笔算平方根","content":"我以计算 2016 的算术平方根作为例子。全程用竖式计算。 首先， 以小数点为基准，每两位数作为一组。像这样写： 注意，平方根的两倍那个位置要往左边写一点，不然后面不够位置。接下来估算第一节，是 202020，42&lt;20&lt;524^2 \\lt 20 \\lt 5^242&lt;20&lt;52，所以在第一节的上面写上 444，对应的在左边写上 888，42=164^2=1642=16 写到 202020 的下面，减一下，把下一节拉下来： 估计下一位的方法是： 8?×?=4168?\\times?=4168?×?=416。因为 83×3=24983 \\times 3=24983×3=249，84×4=33684 \\times 4=33684×4=336，85×5=42585 \\times 5=42585×5=425， 425425425 大于 416416416 了，所以下一位就是 444 了，更新算式，把下一节拉下来： 再估计下一位： 88?×?=800088? \\times ?=800088?×?=8000。 888×8=7104888 \\times 8=7104888×8=7104，889×9=8001889 \\times 9=8001889×9=8001， 哎呀，差一点点，还是 888 吧： 下一位：896?×?=89600896? \\times ?=89600896?×?=89600， 由于刚才就差一点点，这次应该是 999 了。8969×9=807218969 \\times 9=807218969×9=80721，没问题： 8978?×?=8879008978? \\times ?=8879008978?×?=887900，凭感觉应该还是 999，89789×9=80810189789 \\times 9=80810189789×9=808101，OK： 89798?×?=797990089798? \\times ?=797990089798?×?=7979900，这回是 888 了。 不过我还是不写下去了, 因为示范了那么多步，大家应该知道步骤了吧？ ","link":"https://tdmaker.github.io/faded/post/written-calculation-of-square-root/"},{"title":"算法复杂度分析","content":" 算法复杂度分析 为什么要进行算法分析？ 预测算法所需的资源 计算时间（CPU 消耗） 内存空间（RAM 消耗） 通信时间（带宽消耗） 预测算法的运行时间 在给定输入规模时，所执行的基本操作数量。 或者称为算法复杂度（Algorithm Complexity） 如何衡量算法复杂度？ 内存（Memory） 时间（Time） 指令的数量（Number of Steps） 特定操作的数量 磁盘访问数量 网络包数量 渐进复杂度（Asymptotic Complexity） 算法的运行时间与什么相关？ 取决于输入的数据。（例如：如果数据已经是排好序的，时间消耗可能会减少。） 取决于输入数据的规模。（例如：6 和 6 * 109） 取决于运行时间的上限。（因为运行时间的上限是对使用者的承诺。） 算法分析的种类： 最坏情况（Worst Case）：任意输入规模的最大运行时间。（Usually） 平均情况（Average Case）：任意输入规模的期待运行时间。（Sometimes） 最佳情况（Best Case）：通常最佳情况不会出现。（Bogus） 例如，在一个长度为 n 的列表中顺序搜索指定的值，则 最坏情况：n 次比较 平均情况：n/2 次比较 最佳情况：1 次比较 而实际中，我们一般仅考量算法在最坏情况下的运行情况，也就是对于规模为 n 的任何输入，算法的最长运行时间。这样做的理由是： 一个算法的最坏情况运行时间是在任何输入下运行时间的一个上界（Upper Bound）。 对于某些算法，最坏情况出现的较为频繁。 大体上看，平均情况通常与最坏情况一样差。 算法分析要保持大局观（Big Idea），其基本思路： 忽略掉那些依赖于机器的常量。 关注运行时间的增长趋势。 比如：T(n)=73n3+29n3+8888T(n) = 73n^3 + 29n^3 + 8888T(n)=73n3+29n3+8888 的趋势就相当于 T(n)=Θ(n3)T(n) = \\Theta(n^3)T(n)=Θ(n3)。 渐近记号（Asymptotic Notation）通常有 OOO、Θ\\ThetaΘ 和 Ω\\OmegaΩ 记号法。Θ\\ThetaΘ 记号渐进地给出了一个函数的上界和下界，当只有渐近上界时使用 OOO 记号，当只有渐近下界时使用 Ω\\OmegaΩ 记号。尽管技术上 Θ\\ThetaΘ 记号较为准确，但通常仍然使用 OOO 记号表示。 使用 OOO 记号法（Big O Notation）表示最坏运行情况的上界。例如， 线性复杂度 O(n)O(n)O(n) 表示每个元素都要被处理一次。 平方复杂度 O(n2)O(n^2)O(n2) 表示每个元素都要被处理 nnn 次。 Notation Intuition Informal Definition f(n)∈O(g(n))f(n) \\in O(g(n))f(n)∈O(g(n)) fff is bounded above by ggg asymptotically ∣f(n)∣≤g(n)⋅k\\lvert f(n) \\rvert \\le g(n) \\cdot k∣f(n)∣≤g(n)⋅k f(n)∈Ω(g(n))f(n) \\in \\Omega(g(n))f(n)∈Ω(g(n)) Two definitions: Number theory: fff is not dominated by ggg asymptotically Complexity theory: fff is bounded below by ggg asymptotically f(n)≥g(n)⋅kf(n) \\ge g(n) \\cdot kf(n)≥g(n)⋅k f(n)∈Θ(g(n))f(n) \\in \\Theta(g(n))f(n)∈Θ(g(n)) fff is bounded both above and below by ggg asymptotically g(n)⋅k1≤f(n)≤g(n)⋅k2g(n) \\cdot k_1 \\le f(n) \\le g(n) \\cdot k_2g(n)⋅k1​≤f(n)≤g(n)⋅k2​ 例如： T(n)=O(n3)T(n) = O(n^3)T(n)=O(n3) 等同于 T(n)∈O(n3)T(n) \\in O(n^3)T(n)∈O(n3) T(n)=Θ(n3)T(n) = \\Theta(n^3)T(n)=Θ(n3) 等同于 T(n)∈Θ(n3)T(n) \\in \\Theta(n3)T(n)∈Θ(n3). 相当于: T(n)T(n)T(n) 的渐近增长不快于 n3n^3n3。 T(n)T(n)T(n) 的渐近增长与 n3n^3n3 一样快。 复杂度 标记符号 描述 常量（Constant） O(1)O(1)O(1) 操作的数量为常数，与输入的数据的规模无关。 n = 1,000,000 →\\to→ 1-2 operations 对数（Logarithmic） O(log⁡2n)O(\\log_{2}{n})O(log2​n) 操作的数量与输入数据的规模 nnn 的比例是 log⁡2n\\log_{2}{n}log2​n。 n = 1,000,000 →\\to→ 30 operations 线性（Linear） O(n)O(n)O(n) 操作的数量与输入数据的规模 nnn 成正比。 n = 10,000 →\\to→ 5000 operations 平方（Quadratic） O(n2)O(n^2)O(n2) 操作的数量与输入数据的规模 nnn 的比例为二次平方。 n = 500 →\\to→ 250,000 operations 立方（Cubic） O(n3)O(n^3)O(n3) 操作的数量与输入数据的规模 nnn 的比例为三次方。 n = 200 →\\to→ 8,000,000 operations 指数（Exponential） O(2n)O(2^n)O(2n) O(kn)O(k^n)O(kn) O(n!)O(n!)O(n!) 指数级的操作，快速的增长。 n = 20 →\\to→ 1048576 operations 注1：快速的数学回忆，log⁡ab=y\\log_{a}{b} = yloga​b=y 其实就是 ay=ba^y = bay=b。所以，log⁡24=2\\log_{2}{4} = 2log2​4=2，因为 22=42^2 = 422=4。同样 log⁡28=3\\log_{2}{8} = 3log2​8=3，因为 23=82^3 = 823=8。我们说，log⁡2n\\log_{2}{n}log2​n 的增长速度要慢于 nnn，因为当 n=8n = 8n=8 时，log⁡2n=3\\log_{2}{n} = 3log2​n=3。 注2：通常将以 10 为底的对数叫做常用对数。为了简便，NNN 的常用对数 log⁡10N\\log_{10}{N}log10​N 简写做 lg⁡N\\lg{N}lgN，例如 log⁡105\\log_{10}{5}log10​5 记做 lg⁡5\\lg{5}lg5。 注3：通常将以无理数 eee 为底的对数叫做自然对数。为了方便，NNN 的自然对数 log⁡eN\\log_{e}{N}loge​N 简写做 ln⁡N\\ln{N}lnN，例如 loge3log_{e}{3}loge​3 记做 ln⁡3\\ln{3}ln3。 注4：在算法导论中，采用记号 lg⁡n=log⁡2n\\lg{n} = \\log_{2}{n}lgn=log2​n ，也就是以 2 为底的对数。改变一个对数的底只是把对数的值改变了一个常数倍，所以当不在意这些常数因子时，我们将经常采用 &quot;lg n&quot;记号，就像使用 OOO 记号一样。计算机工作者常常认为对数的底取 2 最自然，因为很多算法和数据结构都涉及到对问题进行二分。 而通常时间复杂度与运行时间有一些常见的比例关系： 复杂度 10 20 50 100 1000 10000 100000 O(1)O(1)O(1) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s O(log⁡2(n))O(\\log_{2}{(n)})O(log2​(n)) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s O(n)O(n)O(n) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s O(n∗log⁡2(n))O(n*\\log_{2}{(n)})O(n∗log2​(n)) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s O(n2)O(n^2)O(n2) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s 2s 3-4 min O(n3)O(n^3)O(n3) &lt;1s &lt;1s &lt;1s &lt;1s 20s 5 hours 231 days O(2n)O(2^n)O(2n) &lt;1s &lt;1s 260 days hangs hangs hangs hangs O(n!)O(n!)O(n!) &lt;1s hangs hangs hangs hangs hangs hangs O(nn)O(n^n)O(nn) 3-4 min hangs hangs hangs hangs hangs hangs 计算代码块的渐进运行时间的方法有如下步骤： 确定决定算法运行时间的组成步骤。 找到执行该步骤的代码，标记为 1。 查看标记为 1 的代码的下一行代码。如果下一行代码是一个循环，则将标记 1 修改为 1 倍于循环的次数 1 * n。如果包含多个嵌套的循环，则将继续计算倍数，例如 1 * n * m。 找到标记到的最大的值，就是运行时间的最大值，即算法复杂度描述的上界。 示例代码（1）： decimal Factorial(int n) { if (n == 0) return 1; else return n * Factorial(n - 1); } 阶乘（factorial），给定规模 nnn，算法基本步骤执行的数量为 nnn，所以算法复杂度为 O(n)O(n)O(n)。 示例代码（2）： int FindMaxElement(int[] array) { int max = array[0]; for (int i = 0; i &lt; array.Length; i++) { if (array[i] &gt; max) { max = array[i]; } } return max; } 这里，nnn 为数组 array 的大小，则最坏情况下需要比较 nnn 次以得到最大值，所以算法复杂度为 O(n)O(n)O(n)。 示例代码（3）： long FindInversions(int[] array) { long inversions = 0; for (int i = 0; i &lt; array.Length; i++) for (int j = i + 1; j &lt; array.Length; j++) if (array[i] &gt; array[j]) inversions++; return inversions; } 这里，nnn 为数组 array 的大小，则基本步骤的执行数量约为 n×n−12n \\times \\frac{n - 1}{2}n×2n−1​，所以算法复杂度为 O(n2)O(n^2)O(n2)。 示例代码（4）： long SumMN(int n, int m) { long sum = 0; for (int x = 0; x &lt; n; x++) for (int y = 0; y &lt; m; y++) sum += x * y; return sum; } 给定规模 nnn 和 mmm，则基本步骤的执行数量为 n×mn \\times mn×m，所以算法复杂度为 O(n2)O(n^2)O(n2)。 示例代码（5）： decimal Sum3(int n) { decimal sum = 0; for (int a = 0; a &lt; n; a++) for (int b = 0; b &lt; n; b++) for (int c = 0; c &lt; n; c++) sum += a * b * c; return sum; } 这里，给定规模 nnn，则基本步骤的执行数量约为 n×n×nn \\times n \\times nn×n×n ，所以算法复杂度为 O(n3)O(n^3)O(n3)。 示例代码（6）： decimal Calculation(int n) { decimal result = 0; for (int i = 0; i &lt; (1 &lt;&lt; n); i++) result += i; return result; } 这里，给定规模 nnn，则基本步骤的执行数量为 2n2^n2n，所以算法复杂度为 O(2n)O(2^n)O(2n)。 示例代码（7）： 斐波那契数列： fib(0)=0fib(0) = 0fib(0)=0 fib(1)=1fib(1) = 1fib(1)=1 fib(n)=fib(n−1)+fib(n−2)fib(n) = fib(n-1) + fib(n-2)fib(n)=fib(n−1)+fib(n−2) fib()=0,1,1,2,3,5,8,13,21,34...fib() = 0, 1, 1, 2, 3, 5, 8, 13, 21, 34 ...fib()=0,1,1,2,3,5,8,13,21,34... int Fibonacci(int n) { if (n &lt;= 1) return n; else return Fibonacci(n - 1) + Fibonacci(n - 2); } 这里，给定规模 nnn，计算 fib(n)fib(n)fib(n) 所需的时间为计算 fib(n−1)fib(n-1)fib(n−1) 的时间和计算 fib(n−2)fib(n-2)fib(n−2) 的时间的和。 T(n≤1)=O(1)T(n \\le 1) = O(1)T(n≤1)=O(1) T(n)=T(n−1)+T(n−2)+O(1)T(n) = T(n-1) + T(n-2) + O(1)T(n)=T(n−1)+T(n−2)+O(1) fib(5) / \\ fib(4) fib(3) / \\ / \\ fib(3) fib(2) fib(2) fib(1) / \\ / \\ / \\ 通过使用递归树的结构描述可知算法复杂度为 O(2n)O(2^n)O(2n)。 示例代码（8）： int Fibonacci(int n) { if (n &lt;= 1) return n; else { int[] f = new int[n + 1]; f[0] = 0; f[1] = 1; for (int i = 2; i &lt;= n; i++) { f[i] = f[i - 1] + f[i - 2]; } return f[n]; } } 同样是斐波那契数列，我们使用数组 f 来存储计算结果，这样算法复杂度优化为 O(n)O(n)O(n)。 示例代码（9）： int Fibonacci(int n) { if (n &lt;= 1) return n; else { int iter1 = 0; int iter2 = 1; int f = 0; for (int i = 2; i &lt;= n; i++) { f = iter1 + iter2; iter1 = iter2; iter2 = f; } return f; } } 同样是斐波那契数列，由于实际只有前两个计算结果有用，我们可以使用中间变量来存储，这样就不用创建数组以节省空间。同样算法复杂度优化为 O(n)。 示例代码（10）： 通过使用矩阵乘方的算法来优化斐波那契数列算法。 static int Fibonacci(int n) { if (n &lt;= 1) return n; int[,] f = { { 1, 1 }, { 1, 0 } }; Power(f, n - 1); return f[0, 0]; } static void Power(int[,] f, int n) { if (n &lt;= 1) return; int[,] m = { { 1, 1 }, { 1, 0 } }; Power(f, n / 2); Multiply(f, f); if (n % 2 != 0) Multiply(f, m); } static void Multiply(int[,] f, int[,] m) { int x = f[0, 0] * m[0, 0] + f[0, 1] * m[1, 0]; int y = f[0, 0] * m[0, 1] + f[0, 1] * m[1, 1]; int z = f[1, 0] * m[0, 0] + f[1, 1] * m[1, 0]; int w = f[1, 0] * m[0, 1] + f[1, 1] * m[1, 1]; f[0, 0] = x; f[0, 1] = y; f[1, 0] = z; f[1, 1] = w; } 优化之后算法复杂度为 O(log⁡2n)O(\\log_{2}{n})O(log2​n)。 示例代码（11）： 在 C# 中更简洁的代码如下。 static double Fibonacci(int n) { double sqrt5 = Math.Sqrt(5); double phi = (1 + sqrt5) / 2.0; double fn = (Math.Pow(phi, n) - Math.Pow(1 - phi, n)) / sqrt5; return fn; } 示例代码（12）： 插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的有序数据。算法适用于少量数据的排序，时间复杂度为 O(n2)O(n^2)O(n2)。 private static void InsertionSortInPlace(int[] unsorted) { for (int i = 1; i &lt; unsorted.Length; i++) { if (unsorted[i - 1] &gt; unsorted[i]) { int key = unsorted[i]; int j = i; while (j &gt; 0 &amp;&amp; unsorted[j - 1] &gt; key) { unsorted[j] = unsorted[j - 1]; j--; } unsorted[j] = key; } } } ","link":"https://tdmaker.github.io/faded/post/algorithm-complexity-analysis/"},{"title":"一个漂亮的大 O 速查表","content":" 每个程序员都应该收藏的算法复杂度速查表 图例 绝佳 不错 一般 不佳 糟糕 数据结构操作 数据结构时间复杂度空间复杂度 &nbsp;平均最差最差 &nbsp;访问搜索插入删除访问搜索插入删除&nbsp; Array O(1) O(n) O(n) O(n) O(1) O(n) O(n) O(n) O(n) Stack O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Singly-Linked List O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Doubly-Linked List O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Skip List O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) O(n) O(n) O(n) O(n log(n)) Hash Table - O(1) O(1) O(1) - O(n) O(n) O(n) O(n) Binary Search Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) O(n) O(n) O(n) O(n) Cartesian Tree - O(log(n)) O(log(n)) O(log(n)) - O(n) O(n) O(n) O(n) B-Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) Red-Black Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) Splay Tree - O(log(n)) O(log(n)) O(log(n)) - O(log(n)) O(log(n)) O(log(n)) O(n) AVL Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) 数组排序算法 算法时间复杂度空间复杂度 &nbsp;最佳平均最差最差 Quicksort O(n log(n)) O(n log(n)) O(n^2) O(log(n)) Mergesort O(n log(n)) O(n log(n)) O(n log(n)) O(n) Timsort O(n) O(n log(n)) O(n log(n)) O(n) Heapsort O(n log(n)) O(n log(n)) O(n log(n)) O(1) Bubble Sort O(n) O(n^2) O(n^2) O(1) Insertion Sort O(n) O(n^2) O(n^2) O(1) Selection Sort O(n^2) O(n^2) O(n^2) O(1) Shell Sort O(n) O((nlog(n))^2) O((nlog(n))^2) O(1) Bucket Sort O(n+k) O(n+k) O(n^2) O(n) Radix Sort O(nk) O(nk) O(nk) O(n+k) 图操作 节点 / 边界管理存储增加顶点增加边界移除顶点移除边界查询 Adjacency list O(|V|+|E|) O(1) O(1) O(|V| + |E|) O(|E|) O(|V|) Incidence list O(|V|+|E|) O(1) O(1) O(|E|) O(|E|) O(|E|) Adjacency matrix O(|V|^2) O(|V|^2) O(1) O(|V|^2) O(1) O(1) Incidence matrix O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|E|) 堆操作 类型时间复杂度 &nbsp;Heapify查找最大值分离最大值提升键插入删除合并 Linked List (sorted) - O(1) O(1) O(n) O(n) O(1) O(m+n) Linked List (unsorted) - O(n) O(n) O(1) O(1) O(1) O(1) Binary Heap O(n) O(1) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(m+n) Binomial Heap - O(1) O(log(n)) O(log(n)) O(1) O(log(n)) O(log(n)) Fibonacci Heap - O(1) O(log(n)) O(1) O(1) O(log(n)) O(1) 大 O 复杂度图表 ","link":"https://tdmaker.github.io/faded/post/a-beautiful-big-o-cheatsheet/"},{"title":"《雷神之锤 3》中的平方根算法","content":"《雷神之锤 3》的作者是约翰卡马克，早前，《雷神之锤 3》的源码公开。卡马克大神有一段代码，简直是吊炸天。 float Q_rsqrt(float number) { long i; float x2, y; const float threehalfs = 1.5F; x2 = number * 0.5F; y = number; i = *(long) &amp;y; // evil floating point bit level hacking i = 0x5f3759df - (i &gt;&gt; 1); // what the fuck? y= *(float*) &amp;i; y = y * (threehalfs - (x2 * y * y)); //1st iteration // y = y * (threehalfs - (x2 * y * y)); // 2nd iteration, this can be removed #ifndef Q_3VM #ifdef __linux__ assert(!isnan(y)); //bk010122 - FPE? #endif #endif return y; } 这段代码，据说主要用处是把一个数开平方并且取倒。经过测试之后，据说上面这段代码，尽然比 (float)(1.0/sqrt(x)) 更快，而且是快 4 倍。 具体的实现过程比较复杂，下面是实现过程。 函数返回 1 / sqr(x)，这个函数在图像处理中比 sqrt(x) 更有用。 注意到这个函数只用了一次迭代！（其实就是根本没用迭代，直接运算）。编译，实验，这个函数不仅工作的很好，而且比标准的 sqrt() 函数快 4 倍！要知道，编译器自带的函数，可是经过严格仔细的汇编优化的啊！ 这个简洁的函数，最核心，也是最让人费解的，就是标注了 &quot;what the fuck?&quot; 的一句 i = 0x5f3759df - (i &gt;&gt; 1); 再加上 y = y * ( threehalfs - (x2 * y * y)); 两句话就完成了开方运算!而且注意到，核心那句是定点移位运算，速度极快!特别在很多没有乘法指令的 RISC结构 CPU上，这样做是极其高效的。算法的原理其实不复杂就是牛顿迭代法用 x−f(x)f′(x)x-f(x)f&#x27;(x)x−f(x)f′(x) 不断的逼近 f(x)=af(x)=af(x)=a 的根。 简单来说比如求平方根，f(x) = x ^ 2 = a，f'(x) = 2 * x，f(x) / f'(x) = x / 2， 把 f(x) 代入 x - f(x) / f'(x) 后有 (x + a / x) / 2，现在我们选 a = 5，选一个猜测值比如 2， 那么我们可以这么算 5 / 2 = 2.5; (2.5 + 2) / 2 = 2.25; 5 / 2 .25 = xxx; (2.25 + xxx) / 2 = xxxx ... 这样反复迭代下去，结果必定收敛于 sqrt(5)，没错，一般的求平方根都是这么算的 但是卡马克（quake 3 作者）真正牛B的地方是他选择了一个神秘的常数 0x5f3759df 来计算那个猜测值 就是我们加注释的那一行，那一行算出的值非常接近 1 / sqrt(n)，这样我们只需要 2 次牛顿迭代就可以达到我们所需要的精度。 ","link":"https://tdmaker.github.io/faded/post/square-root-algorithm-in-quake-3/"},{"title":"Vim——常用命令大全","content":" VIM快捷键大全 目录 1 关于VIM 1.1 VIM 的几种模式 正常模式：可以使用快捷键命令，或按:输入命令行。 插入模式：可以输入文本，在正常模式下，按 i、a、o 等都可以进入插入模式。 可视模式：正常模式下按v可以进入可视模式， 在可视模式下，移动光标可以选择文本。按 V 进入可视行模式， 总是整行整行的选中。ctrl+v 进入可视块模式。 替换模式：正常模式下，按 R 进入。 2 启动Vim vim -c cmd file: 在打开文件前，先执行指定的命令； vim -r file: 恢复上次异常退出的文件； vim -R file: 以只读的方式打开文件，但可以强制保存； vim -M file: 以只读的方式打开文件，不可以强制保存； vim -y num file: 将编辑窗口的大小设为 num 行； vim + file: 从文件的末尾开始； vim +num file: 从第num行开始； vim +/string file: 打开 file，并将光标停留在第一个找到的 string 上。 vim --remote file: 用已有的 VIM 进程打开指定的文件。 如果你不想启用多个 VIM 会话，这个很有用。但要注意， 如果你用 VIM，会寻找名叫 VIM 的服务器；如果你已经有一个 gvim 在运行了， 你可以用 gvim --remote file 在已有的 gvim p 中打开文件。 3 文档操作 :e file --关闭当前编辑的文件，并开启新的文件。 如果对当前文件的修改未保存，vi 会警告。 :e! file --放弃对当前文件的修改，编辑新的文件。 :e+file -- 开始新的文件，并从文件尾开始编辑。 :e+n file -- 开始新的文件，并从第 n 行开始编辑。 :enew --编译一个未命名的新文档。(CTRL-W n)。 :e -- 重新加载当前文档。 :e! -- 重新加载当前文档，并丢弃已做的改动。 :e#或ctrl+^ -- 回到刚才编辑的文件，很实用。 :f或ctrl+g -- 显示文档名，是否修改，和光标位置。 :f filename -- 改变编辑的文件名，这时再保存相当于另存为。 gf -- 打开以光标所在字符串为文件名的文件。 :w -- 保存修改。 :n1,n2w filename -- 选择性保存从某 n1 行到另 n2 行的内容。 :wq -- 保存并退出。 ZZ -- 保存并退出。 :x -- 保存并退出。 :q[uit] --退出当前窗口。(CTRL-W q 或 CTRL-W CTRL-Q) :saveas newfilename -- 另存为 :browse e -- 会打开一个文件浏览器让你选择要编辑的文件。 如果是终端中，则会打开 netrw 的文件浏览窗口； 如果是 gvim，则会打开一个图形界面的浏览窗口。 实际上 :browse 后可以跟任何编辑文档的命令，如 sp 等。 用 browse 打开的起始目录可以由 browsedir 来设置： :set browsedir=last -- 用上次访问过的目录（默认）； :set browsedir=buffer -- 用当前文件所在目录； :set browsedir=current -- 用当前工作目录； :Sex -- 水平分割一个窗口，浏览文件系统； :Vex -- 垂直分割一个窗口，浏览文件系统； 4 光标的移动 4.1 基本移动 以下移动都是在 normal 模式下。 h 或退格: 左移一个字符； l 或空格: 右移一个字符； j: 下移一行； k: 上移一行； gj: 移动到一段内的下一行； gk: 移动到一段内的上一行； + 或 Enter: 把光标移至下一行第一个非空白字符。 -: 把光标移至上一行第一个非空白字符。 w: 前移一个单词，光标停在下一个单词开头； W: 移动下一个单词开头，但忽略一些标点； e: 前移一个单词，光标停在下一个单词末尾； E: 移动到下一个单词末尾，如果词尾有标点，则移动到标点； b: 后移一个单词，光标停在上一个单词开头； B: 移动到上一个单词开头，忽略一些标点； ge: 后移一个单词，光标停在上一个单词末尾； gE: 同 ge ，不过‘单词’包含单词相邻的标点。 (: 前移 1 句。 ): 后移 1 句。 {: 前移 1 段。 }: 后移 1 段。 fc: 把光标移到同一行的下一个 c 字符处 Fc: 把光标移到同一行的上一个 c 字符处 tc: 把光标移到同一行的下一个 c 字符前 Tc: 把光标移到同一行的上一个 c 字符后 ;: 配合 f &amp; t 使用，重复一次 ,: 配合 f &amp; t 使用，反向重复一次 上面的操作都可以配合 n 使用，比如在正常模式(下面会讲到)下输入 3h， 则光标向左移动 3 个字符。 27. 0: 移动到行首。 28. g0: 移到光标所在屏幕行行首。 29. ^: 移动到本行第一个非空白字符。 30. g^: 同 ^ ，但是移动到当前屏幕行第一个非空字符处。 31. $: 移动到行尾。 32. g$: 移动光标所在屏幕行行尾。 33. n|: 把光标移到递 n 列上。 34. nG: 到文件第 n 行。 35. :n 移动到第 n 行。 36. :$ 移动到最后一行。 37. H: 把光标移到屏幕最顶端一行。 38. M: 把光标移到屏幕中间一行。 39. L: 把光标移到屏幕最底端一行。 40. gg: 到文件头部。 41. G: 到文件尾部。 4.2 翻屏 ctrl+f: 下翻一屏。 ctrl+b: 上翻一屏。 ctrl+d: 下翻半屏。 ctrl+u: 上翻半屏。 ctrl+e: 向下滚动一行。 ctrl+y: 向上滚动一行。 n%: 到文件 n% 的位置。 zz: 将当前行移动到屏幕中央。 zt: 将当前行移动到屏幕顶端。 zb: 将当前行移动到屏幕底端。 4.3 标记 使用标记可以快速移动。到达标记后，可以用 Ctrl+o 返回原来的位置。Ctrl+o 和 Ctrl+i 很像浏览器上的 后退 和 前进 。 m{a-z}: 标记光标所在位置，局部标记，只用于当前文件。 m{A-Z}: 标记光标所在位置，全局标记。标记之后，退出 VIM， 重新启动，标记仍然有效。 `{a-z}: 移动到标记位置。 '{a-z}: 移动到标记行的行首。 `{0-9}：回到上 [2-10] 次关闭 VIM 时最后离开的位置。 ``: 移动到上次编辑的位置。'' 也可以，不过 `` 精确到列，而 '' 精确到行 。如果想跳转到更老的位置，可以按 C-o，跳转到更新的位置用 C-i。 `&quot;: 移动到上次离开的地方。 `.: 移动到最后改动的地方。 :marks 显示所有标记。 :delmarks a b -- 删除标记 a 和 b。 :delmarks a-c -- 删除标记 a、b 和 c。 :delmarks a c-f -- 删除标记 a、c、d、e、f。 :delmarks! -- 删除当前缓冲区的所有标记。 :help mark-motions 查看更多关于 mark 的知识。 5 插入文本 5.1 基本插入 i: 在光标前插入；一个小技巧：按 8，再按 i，进入插入模式，输入 =， 按 esc 进入命令模式，就会出现 8 个 =。 这在插入分割线时非常有用，如 30i+ 就插入了 36 个 + 组成的分割线。 I: 在当前行第一个非空字符前插入； gI: 在当前行第一列插入； a: 在光标后插入； A: 在当前行最后插入； o: 在下面新建一行插入； O: 在上面新建一行插入； :r filename 在当前位置插入另一个文件的内容。 :[n]r filename 在第 n 行插入另一个文件的内容。 :r !date 在光标处插入当前日期与时间。同理，:r !command 可以将其它 shell 命令的输出插入当前文档。 5.2 改写插入 c[n]w: 改写光标后 1(n) 个词。 c[n]l: 改写光标后 n 个字母。 c[n]h: 改写光标前 n 个字母。 [n]cc: 修改当前 [n] 行。 [n]s: 以输入的文本替代光标之后 1(n) 个字符，相当于 c[n]l。 [n]S: 删除指定数目的行，并以所输入文本代替之。 注意，类似 cnw，dnw，ynw 的形式同样可以写为 ncw，ndw，nyw。 6 剪切复制和寄存器 6.1 剪切和复制、粘贴 [n]x: 剪切光标右边 n 个字符，相当于 d[n]l。 [n]X: 剪切光标左边 n 个字符，相当于 d[n]h。 y: 复制在可视模式下选中的文本。 yy or Y: 复制整行文本。 y[n]w: 复制一(n)个词。 y[n]l: 复制光标右边1(n)个字符。 y[n]h: 复制光标左边1(n)个字符。 y$: 从光标当前位置复制到行尾。 y0: 从光标当前位置复制到行首。 :m,ny 复制 m 行到 n 行的内容。 y1G 或 ygg: 复制光标以上的所有行。 yG: 复制光标以下的所有行。 yaw 和 yas：复制一个词和复制一个句子，即使光标不在词首和句首也没关系。 d: 删除（剪切）在可视模式下选中的文本。 d$ or D: 删除（剪切）当前位置到行尾的内容。 d[n]w: 删除（剪切）1(n) 个单词。 d[n]l: 删除（剪切）光标右边 1(n) 个字符。 d[n]h: 删除（剪切）光标左边 1(n) 个字符。 d0: 删除（剪切）当前位置到行首的内容。 [n] dd: 删除（剪切）1(n) 行。 :m,nd 剪切 m 行到 n 行的内容。 d1G 或 dgg: 剪切光标以上的所有行。 dG: 剪切光标以下的所有行。 daw 和 das：剪切一个词和剪切一个句子，即使光标不在词首和句首也没关系。 d/f：这是一个比较高级的组合命令，它将删除当前位置 到下一个 f 之间的内容。 p: 在光标之后粘贴。 P: 在光标之前粘贴。 6.2 文本对象 aw：一个词 as：一句。 ap：一段。 ab：一块（包含在圆括号中的）。 y，d，c，v 都可以跟文本对象。 6.3 寄存器 a-z：都可以用作寄存器名。&quot;ayy 把当前行的内容放入 a 寄存器。 A-Z：用大写字母索引寄存器，可以在寄存器中追加内容。 如 &quot;Ayy 把当前行的内容追加到 a 寄存器中。 :reg 显示所有寄存器的内容。 &quot;&quot;：不加寄存器索引时，默认使用的寄存器。 &quot;*：当前选择缓冲区，&quot;*yy 把当前行的内容放入当前选择缓冲区。 &quot;+：系统剪贴板。&quot;+yy 把当前行的内容放入系统剪贴板。 7 查找与替换 7.1 查找 /something: 在后面的文本中查找 something。 ?something: 在前面的文本中查找 something。 /pattern/+number: 将光标停在包含 pattern 的行后面第 number 行上。 /pattern/-number: 将光标停在包含 pattern 的行前面第 number 行上。 n: 向后查找下一个。 N: 向前查找下一个。 可以用 grep 或 vimgrep 查找一个模式都在哪些地方出现过，其中: grep 是调用外部的 grep 程序，而 :vimgrep 是 VIM 自己的查找算法。用法为：:vim[grep]/pattern/[g] [j] files g 的含义是如果一个模式在一行中多次出现，则这一行也在结果中多次出现。j 的含义是 grep 结束后，结果停在第 j 项，默认是停在第一项。vimgrep 前面可以加数字限定搜索结果的上限，如 :1vim/pattern/ % 只查找那个模式在本文件中的第一个出现。 其实 vimgrep 在读纯文本电子书时特别有用，可以生成导航的目录。比如电子书中每一节的标题形式为：n. xxxx。你就可以这样：:vim/^d{1,}./ % 然后用 :cw 或 :copen 查看结果，可以用 C-w H 把 quickfix 窗口移到左侧，就更像个目录了。 7.2 替换 :s/old/new - 用 new 替换当前行第一个 old。 :s/old/new/g - 用 new 替换当前行所有的 old。 :n1,n2s/old/new/g - 用 new 替换文件 n1 行到 n2 行所有的 old。 :%s/old/new/g - 用 new 替换文件中所有的 old。 :%s/^/xxx/g - 在每一行的行首插入 xxx，^ 表示行首。 :%s/$/xxx/g - 在每一行的行尾插入 xxx，$ 表示行尾。 所有替换命令末尾加上 c，每个替换都将需要用户确认。 如：%s/old/new/gc，加上 i 则忽略大小写(ignore)。 还有一种比替换更灵活的方式，它是匹配到某个模式后执行某种命令， 语法为 :[range]g/pattern/command 例如 :%g/^ xyz/normal dd。 表示对于以一个空格和 xyz 开头的行执行 normal 模式下的 dd 命令。 关于 range 的规定为： 如果不指定 range，则表示当前行。 m,n: 从 m 行到 n 行。 0: 最开始一行（可能是这样）。 $: 最后一行 .: 当前行 %: 所有行 7.3 正则表达式 高级的查找替换就要用到正则表达式。 \\d: 表示十进制数（我猜的） \\s: 表示空格 \\S: 非空字符 \\a: 英文字母 \\|: 表示 或 \\.: 表示. {m,n}: 表示 m 到 n 个字符。这要和 \\s 与 \\a 等连用，如 \\a\\{m,n} 表示 m 到 n 个英文字母。 {m,}: 表示 m 到无限多个字符。 **: 当前目录下的所有子目录。 :help pattern 得到更多帮助。 8 排版 8.1 基本排版 &lt;&lt; 向左缩进一个 shiftwidth &gt;&gt; 向右缩进一个 shiftwidth :ce(nter) 本行文字居中 :le(ft) 本行文字靠左 :ri(ght) 本行文字靠右 gq 对选中的文字重排，即对过长的文字进行断行 gqq 重排当前行 gqnq 重排 n 行 gqap 重排当前段 gqnap 重排 n 段 gqnj 重排当前行和下面 n 行 gqQ 重排当前段对文章末尾 J 拼接当前行和下一行 gJ 同 J，不过合并后不留空格。 8.2 拼写检查 :set spell－开启拼写检查功能 :set nospell－关闭拼写检查功能 ]s－移到下一个拼写错误的单词 [s－作用与上一命令类似，但它是从相反方向进行搜索 z=－显示一个有关拼写错误单词的列表，可从中选择 zg－告诉拼写检查器该单词是拼写正确的 zw－与上一命令相反，告诉拼写检查器该单词是拼写错误的 8.3 统计字数 g ^g 可以统计文档字符数，行数。 将光标放在最后一个字符上，用字符数减去行数可以粗略统计中文文档的字数。 以上对 Mac 或 Unix 的文件格式适用。 如果是 Windows 文件格式（即换行符有两个字节），字数的统计方法为：字符数 - 行数 * 2。 9 编辑多个文件 9.1 一次编辑多个文件 我们可以一次打开多个文件，如 vi a.txt b.txt c.txt 使用 :next(:n) 编辑下一个文件。 :2n 编辑下 2 个文件。 使用 :previous 或 :N 编辑上一个文件。 使用 :wnext，保存当前文件，并编辑下一个文件。 使用 :wprevious，保存当前文件，并编辑上一个文件。 使用 :args 显示文件列表。 :n filenames 或 :args filenames 指定新的文件列表。 vi -o filenames 在水平分割的多个窗口中编辑多个文件。 vi -O filenames 在垂直分割的多个窗口中编辑多个文件。 9.2 多标签编辑 vim -p files: 打开多个文件，每个文件占用一个标签页。 :tabe, tabnew -- 如果加文件名，就在新的标签中打开这个文件， 否则打开一个空缓冲区。 ^w gf -- 在新的标签页里打开光标下路径指定的文件。 :tabn -- 切换到下一个标签。Control + PageDown，也可以。 :tabp -- 切换到上一个标签。Control + PageUp，也可以。 [n] gt -- 切换到下一个标签。如果前面加了 n ， 就切换到第 n 个标签。第一个标签的序号就是 1。 :tab split -- 将当前缓冲区的内容在新页签中打开。 :tabc[lose] -- 关闭当前的标签页。 :tabo[nly] -- 关闭其它的标签页。 :tabs -- 列出所有的标签页和它们包含的窗口。 :tabm[ove] [N] -- 移动标签页，移动到第 N 个标签页之后。 如 tabm 0 当前标签页，就会变成第一个标签页。 9.3 缓冲区 :buffers 或 :ls 或 :files 显示缓冲区列表。 ctrl+^：在最近两个缓冲区间切换。 :bn -- 下一个缓冲区。 :bp -- 上一个缓冲区。 :bl -- 最后一个缓冲区。 :b[n] 或 :[n]b -- 切换到第 n 个缓冲区。 :nbw(ipeout) -- 彻底删除第 n 个缓冲区。 :nbd(elete) -- 删除第 n 个缓冲区，并未真正删除，还在 unlisted 列表中。 :ba[ll] -- 把所有的缓冲区在当前页中打开，每个缓冲区占一个窗口。 10 分屏编辑 vim -o file1 file2: 水平分割窗口，同时打开 file1 和 file2 vim -O file1 file2: 垂直分割窗口，同时打开 file1 和 file2 10.1 水平分割 :split(:sp) -- 把当前窗水平分割成两个窗口。(CTRL-W s 或 CTRL-W CTRL-S) 注意如果在终端下，CTRL-S 可能会冻结终端，请按 CTRL-Q 继续。 :split filename -- 水平分割窗口，并在新窗口中显示另一个文件。 :nsplit(:nsp) -- 水平分割出一个 n 行高的窗口 :[N]new -- 水平分割出一个 N 行高的窗口，并编辑一个新文件。 (CTRL-W n 或 CTRL-W CTRL-N) ctrl+w f --水平分割出一个窗口，并在新窗口打开名称为光标所在词的文件 。 C-w C-^ -- 水平分割一个窗口，打开刚才编辑的文件。 10.2 垂直分割 :vsplit(:vsp) -- 把当前窗口分割成水平分布的两个窗口。 (CTRL-W v 或 CTRL CTRL-V) :[N]vne[w] -- 垂直分割出一个新窗口。 :vertical 水平分割的命令： 相应的垂直分割。 10.3 关闭子窗口 :qall -- 关闭所有窗口，退出 VIM。 :wall -- 保存所有修改过的窗口。 :only -- 只保留当前窗口，关闭其它窗口。(CTRL-W o) :close -- 关闭当前窗口，CTRL-W c 能实现同样的功能。 (象 :q :x 同样工作 ) 10.4 调整窗口大小 ctrl+w + --当前窗口增高一行。也可以用 n 增高 n 行。 ctrl+w - --当前窗口减小一行。也可以用 n 减小 n 行。 ctrl+w _ --当前窗口扩展到尽可能的大。也可以用 n 设定行数。 :resize n -- 当前窗口 n 行高。 ctrl+w = -- 所有窗口同样高度。 n ctrl+w _ -- 当前窗口的高度设定为 n 行。 ctrl+w &lt; --当前窗口减少一列。也可以用 n 减少 n 列。 ctrl+w &gt; --当前窗口增宽一列。也可以用 n 增宽 n 列。 ctrl+w | --当前窗口尽可能的宽。也可以用 n 设定列数。 10.5 切换和移动窗口 如果支持鼠标，切换和调整子窗口的大小就简单了。 ctrl+w ctrl+w: 切换到下一个窗口。或者是 ctrl+w w。 ctrl+w p: 切换到前一个窗口。 ctrl+w h(l,j,k):切换到左（右，下，上）的窗口。 ctrl+w t(b):切换到最上（下）面的窗口。 ctrl+w H(L,K,J): 将当前窗口移动到最左（右、上、下）面。 ctrl+w r：旋转窗口的位置。 ctrl+w T: 将当前的窗口移动到新的标签页上。 11 快速编辑 11.1 改变大小写 ~: 反转光标所在字符的大小写。 可视模式下的 U 或 u：把选中的文本变为大写或小写。 gu(U) 接范围（如 $，或 G），可以把从光标当前位置到指定位置之间字母全部转换成小写或大写。如 ggguG，就是把开头到最后一行之间的字母全部变为小 写。再如 gu5j，把当前行和下面四行全部变成小写。 11.2 替换（normal模式） r: 替换光标处的字符，同样支持汉字。 R: 进入替换模式，按 esc 回到正常模式。 11.3 撤消与重做（normal模式） [n] u: 取消一 (n) 个改动。 :undo 5 -- 撤销 5 个改变。 :undolist -- 你的撤销历史。 ctrl + r: 重做最后的改动。 U: 取消当前行中所有的改动。 :earlier 4m -- 回到 4 分钟前 :later 55s -- 前进 55 秒 11.4 宏 . --重复上一个编辑动作 qa：开始录制宏 a（键盘操作记录） q：停止录制 @a：播放宏 a 12 编辑特殊文件 12.1 文件加解密 vim -x file: 开始编辑一个加密的文件。 :X -- 为当前文件设置密码。 :set key= -- 去除文件的密码。 12.2 文件的编码 :e ++enc=utf8 filename, 让 VIM 用 utf-8 的编码打开这个文件。 :w ++enc=gbk，不管当前文件什么编码，把它转存成 gbk 编码。 :set fenc 或 :set fileencoding，查看当前文件的编码。 在 vimrc 中添加 set fileencoding=ucs-bom,utf-8,cp936，VIM 会根据要打开的文件选择合适的编码。 注意：编码之间不要留空格。cp936 对应于 gbk 编码。ucs-bom 对应于 Windows 下的文件格式。 让 VIM 正确处理文件格式和文件编码，有赖于 ~/.vimrc 的正确配置 12.3 文件格式 大致有三种文件格式：unix，dos，mac。 三种格式的区别主要在于回车键的编码：dos 下是回车加换行，unix 下只有换行符，mac 下只有回车符。 :e ++ff=dos filename, 让 VIM 用 dos 格式打开这个文件。 :w ++ff=mac filename, 以 mac 格式存储这个文件。 :set ff，显示当前文件的格式。 在 vimrc 中添加 set fileformats=unix,dos,mac，让 VIM 自动识别文件格式。 13 编程辅助 13.1 一些按键 gd: 跳转到局部变量的定义处； gD: 跳转到全局变量的定义处，从当前文件开头开始搜索； g;: 上一个修改过的地方； g,: 下一个修改过的地方； [[: 跳转到上一个函数块开始，需要有单独一行的 {。 ]]: 跳转到下一个函数块开始，需要有单独一行的 {。 []: 跳转到上一个函数块结束，需要有单独一行的 }。 ][: 跳转到下一个函数块结束，需要有单独一行的 }。 [{: 跳转到当前块开始处； ]}: 跳转到当前块结束处； [/: 跳转到当前注释块开始处； ]/: 跳转到当前注释块结束处； %: 不仅能移动到匹配的 (),{} 或 [] 上，而且能在 #if，#else，#endif 之间跳跃。 下面的括号匹配对编程很实用的。 ci', di', yi'：修改、剪切或复制 ' 之间的内容。 ca', da', ya'：修改、剪切或复制'之间的内容，包含 '。 ci&quot;, di&quot;, yi&quot;：修改、剪切或复制 &quot; 之间的内容。 ca&quot;, da&quot;, ya&quot;：修改、剪切或复制 &quot; 之间的内容，包含 &quot;。 ci(, di(, yi(：修改、剪切或复制 () 之间的内容。 ca(, da(, ya(：修改、剪切或复制 () 之间的内容，包含()。 ci[, di[, yi[：修改、剪切或复制 [] 之间的内容。 ca[, da[, ya[：修改、剪切或复制 [] 之间的内容，包含 []。 ci{, di{, yi{：修改、剪切或复制 {} 之间的内容。 ca{, da{, ya{：修改、剪切或复制 {} 之间的内容，包含 {}。 ci&lt;, di&lt;, yi&lt;：修改、剪切或复制 &lt;&gt; 之间的内容。 ca&lt;, da&lt;, ya&lt;：修改、剪切或复制 &lt;&gt; 之间的内容，包含 &lt;&gt;。 13.2 ctags ctags -R: 生成 tag 文件，-R 表示也为子目录中的文件生成 tags。 :set tags=path/tags -- 告诉 ctags 使用哪个 tag 文件。 :tag xyz -- 跳到 xyz 的定义处，或者将光标放在 xyz 上按 C-]，返回用 C-t :stag xyz -- 用分割的窗口显示 xyz 的定义，或者 C-w ]， 如果用 C-w n ]，就会打开一个 n 行高的窗口 :ptag xyz -- 在预览窗口中打开 xyz 的定义，热键是 C-w }。 :pclose -- 关闭预览窗口。热键是 C-w z。 :pedit abc.h -- 在预览窗口中编辑 abc.h :psearch abc -- 搜索当前文件和当前文件 include 的文件，显示包含 abc 的行。 有时一个 tag 可能有多个匹配，如函数重载，一个函数名就会有多个匹配。 这种情况会先跳转到第一个匹配处。 :[n]tnext -- 下一 [n] 个匹配。 :[n]tprev -- 上一 [n] 个匹配。 :tfirst -- 第一个匹配 :tlast -- 最后一个匹配 :tselect tagname -- 打开选择列表 tab 键补齐 :tag xyz-- 补齐以 xyz 开头的 tag 名，继续按 tab 键，会显示其他的。 :tag /xyz-- 会用名字中含有 xyz 的 tag 名补全。 13.3 cscope cscope -Rbq: 生成 cscope.out 文件 :cs add /path/to/cscope.out /your/work/dir :cs find c func -- 查找 func 在哪些地方被调用 :cw -- 打开 quickfix 窗口查看结果 13.4 gtags Gtags 综合了 ctags 和 cscope 的功能。 使用 Gtags 之前，你需要安装 GNU Gtags。 然后在工程目录运行 gtags 。 :Gtags funcname 定位到 funcname 的定义处。 :Gtags -r funcname 查询 funcname 被引用的地方。 :Gtags -s symbol 定位 symbol 出现的地方。 :Gtags -g string Goto string 出现的地方。:Gtags -gi string 忽略大小写。 :Gtags -f filename 显示 filename 中的函数列表。 你可以用 :Gtags -f % 显示当前文件。 :Gtags -P pattern 显示路径中包含特定模式的文件。 如 :Gtags -P .h$ 显示所有头文件，:Gtags -P /vm/ 显示 vm 目录下的文件。 13.5 编译 VIM 提供了 :make 来编译程序，默认调用的是 make， 如果你当前目录下有 makefile，简单地 :make 即可。 如果你没有 make 程序，你可以通过配置 makeprg 选项来更改 make 调用的程序。 如果你只有一个abc.java文件，你可以这样设置： set makeprg=javac\\ abc.java 然后 :make 即可。如果程序有错，可以通过 quickfix 窗口查看错误。 不过如果要正确定位错误，需要设置好 errorformat，让 VIM 识别错误信息。 如： :setl efm=%A%f:%l:\\ %m,%-Z%p^,%-C%.%# %f 表示文件名，%l 表示行号，%m 表示错误信息，其它的还不能理解。 请参考 :help errorformat。 13.6 快速修改窗口 其实是 quickfix 插件提供的功能， 对编译调试程序非常有用 😃 :copen -- 打开快速修改窗口。 :cclose -- 关闭快速修改窗口。 快速修改窗口在 make 程序时非常有用，当 make 之后： :cl -- 在快速修改窗口中列出错误。 :cn -- 定位到下一个错误。 :cp -- 定位到上一个错误。 :cr -- 定位到第一个错误。 13.7 自动补全 C-x C-s -- 拼写建议。 C-x C-v -- 补全 VIM 选项和命令。 C-x C-l -- 整行补全。 C-x C-f -- 自动补全文件路径。弹出菜单后，按 C-f 循环选择，当然也可以按 C-n 和 C-p。 C-x C-p 和 C-x C-n -- 用文档中出现过的单词补全当前的词。 直接按 C-p 和 C-n 也可以。 C-x C-o -- 编程时可以补全关键字和函数名啊。 C-x C-i -- 根据头文件内关键字补全。 C-x C-d -- 补全宏定义。 C-x C-n -- 按缓冲区中出现过的关键字补全。 直接按 C-n 或 C-p 即可。 当弹出补全菜单后： C-p 向前切换成员； C-n 向后切换成员； C-e 退出下拉菜单，并退回到原来录入的文字； C-y 退出下拉菜单，并接受当前选项。 13.8 多行缩进缩出 正常模式下，按两下 &gt;; 光标所在行会缩进。 如果先按了 n，再按两下 &gt;;，光标以下的 n 行会缩进。 对应的，按两下 &lt;;，光标所在行会缩出。 如果在编辑代码文件，可以用 = 进行调整。 在可视模式下，选择要调整的代码块，按 =，代码会按书写规则缩排好。 或者 n =，调整 n 行代码的缩排。 13.9 折叠 zf -- 创建折叠的命令，可以在一个可视区域上使用该命令； zd -- 删除当前行的折叠； zD -- 删除当前行的折叠； zfap -- 折叠光标所在的段； zo -- 打开折叠的文本； zc -- 收起折叠； za -- 打开/关闭当前折叠； zr -- 打开嵌套的折行； zm -- 收起嵌套的折行； zR (zO) -- 打开所有折行； zM (zC) -- 收起所有折行； zj -- 跳到下一个折叠处； zk -- 跳到上一个折叠处； zi -- enable/disable fold; 14 命令行 normal 模式下按:进入命令行模式 14.1 命令行模式下的快捷键： 上下方向键：上一条或者下一条命令。如果已经输入了部分命令，则找上一 条或者下一条匹配的命令。 左右方向键：左 / 右移一个字符。 C-w： 向前删除一个单词。 C-h： 向前删除一个字符，等同于 Backspace。 C-u： 从当前位置移动到命令行开头。 C-b： 移动到命令行开头。 C-e： 移动到命令行末尾。 Shift-Left：左移一个单词。 Shift-Right：右移一个单词。 @： 重复上一次的冒号命令。 q： 正常模式下，q 然后按 ':'，打开命令行历史缓冲区， 可以像编辑文件一样编辑命令。 q/ 和 q? 可以打开查找历史记录。 14.2 执行外部命令 :! cmd 执行外部命令。 :!! 执行上一次的外部命令。 :sh 调用 shell，用 exit 返回 VIM。 :r !cmd 将命令的返回结果插入文件当前位置。 :m,nw !cmd 将文件的 m 行到 n 行之间的内容做为命令输入执行命令。 15 其它 15.1 工作目录 :pwd 显示 VIM 的工作目录。 :cd path 改变 VIM 的工作目录。 :set autochdir 可以让 VIM 根据编辑的文件自动切换工作目录。 15.2 一些快捷键（收集中） K: 打开光标所在词的 manpage。 *: 向下搜索光标所在词。 g*: 同上，但部分符合即可。 #: 向上搜索光标所在词。 g#: 同上，但部分符合即可。 g C-g: 统计全文或统计部分的字数。 15.3 在线帮助 :h(elp) 或 F1 打开总的帮助。 :help user-manual 打开用户手册。 命令帮助的格式为：第一行指明怎么使用那个命令； 然后是缩进的一段解释这个命令的作用，然后是进一步的信息。 :helptags somepath 为 somepath 中的文档生成索引。 :helpgrep 可以搜索整个帮助文档，匹配的列表显示在 quickfix 窗口中。 Ctrl+] 跳转到 tag 主题，Ctrl+t 跳回。 :ver 显示版本信息。 15.4 一些小功能 简单计算器: 在插入模式下，输入 C-r =，然后输入表达式，就能在 光标处得到计算结果。 ","link":"https://tdmaker.github.io/faded/post/vim-common-commands/"},{"title":"Vim——配置入门","content":" Vim 配置入门 Vim 的配置不太容易，它有自己的语法，许许多多的命令。我总是记不清楚，所以就整理了下面这篇文章，列出主要配置项的含义。 1 基础知识 Vim 的全局配置一般在 /etc/vim/vimrc 或者 /etc/vimrc，对所有用户生效。用户个人的配置在 ~/.vimrc。 如果只对单次编辑启用某个配置项，可以在命令模式下，先输入一个冒号，再输入配置。举例来说，set number 这个配置可以写在 .vimrc 里面，也可以在命令模式输入。 :set number 配置项一般都有“打开”和“关闭”两个设置。“关闭”就是在“打开”前面加上前缀 &quot;no&quot;。 &quot; 打开 set number &quot; 关闭 set nonumber 上面代码中，双引号开始的行表示注释。 查询某个配置项是打开还是关闭，可以在命令模式下，输入该配置，并在后面加上问号。 :set number? 上面的命令会返回 number 或者 nonumber。 如果想查看帮助，可以使用 help 命令。 :help number 2 基本配置 （1） set nocompatible 不与 Vi 兼容（采用 Vim 自己的操作命令）。 （2） syntax on 打开语法高亮。自动识别代码，使用多种颜色显示。 （3） set showmode 在底部显示，当前处于命令模式还是插入模式。 （4） set showcmd 命令模式下，在底部显示，当前键入的指令。比如，键入的指令是 2y3d，那么底部就会显示 2y3，当键入 d 的时候，操作完成，显示消失。 （5） set mouse=a 支持使用鼠标。 （6） set encoding=utf-8 使用 utf-8 编码。 （7） set t_Co=256 启用256色。 （8） filetype indent on 开启文件类型检查，并且载入与该类型对应的缩进规则。比如，如果编辑的是 .py 文件，Vim 就是会找 Python 的缩进规则 ~/.vim/indent/python.vim。 3 缩进 9） set autoindent 按下回车键后，下一行的缩进会自动跟上一行的缩进保持一致。 （10） set tabstop=2 按下 Tab 键时，Vim 显示的空格数。 （11） set shiftwidth=4 在文本上按下 &gt;&gt;（增加一级缩进）、&lt;&lt;（取消一级缩进）或者 ==（取消全部缩进）时，每一级的字符数。 （12） set expandtab 由于 Tab 键在不同的编辑器缩进不一致，该设置自动将 Tab 转为空格。 （13） set softtabstop=2 Tab 转为多少个空格。 4 外观 14） set number 显示行号 （15） set relativenumber 显示光标所在的当前行的行号，其他行都为相对于该行的相对行号。 （16） set cursorline 光标所在的当前行高亮。 （17） set textwidth=80 设置行宽，即一行显示多少个字符。 （18） set wrap 自动折行，即太长的行分成几行显示。 set nowrap 关闭自动折行 （19） set linebreak 只有遇到指定的符号（比如空格、连词号和其他标点符号），才发生折行。也就是说，不会在单词内部折行。 （20） set wrapmargin=2 指定折行处与编辑窗口的右边缘之间空出的字符数。 （21） set scrolloff=5 垂直滚动时，光标距离顶部/底部的位置（单位：行）。 （22） set sidescrolloff=15 水平滚动时，光标距离行首或行尾的位置（单位：字符）。该配置在不折行时比较有用。 （23） set laststatus=2 是否显示状态栏。0 表示不显示，1 表示只在多窗口时显示，2 表示显示。 （24） set ruler 在状态栏显示光标的当前位置（位于哪一行哪一列）。 5 搜索 25） set showmatch 光标遇到圆括号、方括号、大括号时，自动高亮对应的另一个圆括号、方括号和大括号。 （26） set hlsearch 搜索时，高亮显示匹配结果。 （27） set incsearch 输入搜索模式时，每输入一个字符，就自动跳到第一个匹配的结果。 （28） set ignorecase 搜索时忽略大小写。 （29） set smartcase 如果同时打开了 ignorecase，那么对于只有一个大写字母的搜索词，将大小写敏感；其他情况都是大小写不敏感。比如，搜索 Test 时，将不匹配 test；搜索 test 时，将匹配 Test。 6 编辑 30） set spell spelllang=en_us 打开英语单词的拼写检查。 （31） set nobackup 不创建备份文件。默认情况下，文件保存时，会额外创建一个备份文件，它的文件名是在原文件名的末尾，再添加一个波浪号（〜）。 （32） set noswapfile 不创建交换文件。交换文件主要用于系统崩溃时恢复文件，文件名的开头是 .、结尾是 .swp。 （33） set undofile 保留撤销历史。 Vim 会在编辑时保存操作历史，用来供用户撤消更改。默认情况下，操作记录只在本次编辑时有效，一旦编辑结束、文件关闭，操作历史就消失了。 打开这个设置，可以在文件关闭后，操作记录保留在一个文件里面，继续存在。这意味着，重新打开一个文件，可以撤销上一次编辑时的操作。撤消文件是跟原文件保存在一起的隐藏文件，文件名以 .un~ 开头。 （34） set backupdir=~/.vim/.backup// set directory=~/.vim/.swp// set undodir=~/.vim/.undo// 设置备份文件、交换文件、操作历史文件的保存位置。 结尾的 //表示生成的文件名带有绝对路径，路径中用 % 替换目录分隔符，这样可以防止文件重名。 （35） set autochdir 自动切换工作目录。这主要用在一个 Vim 会话之中打开多个文件的情况，默认的工作目录是打开的第一个文件的目录。该配置可以将工作目录自动切换到，正在编辑的文件的目录。 （36） set noerrorbells 出错时，不要发出响声。 （37） set visualbell 出错时，发出视觉提示，通常是屏幕闪烁。 （38） set history=1000 Vim 需要记住多少次历史操作。 （39） set autoread 打开文件监视。如果在编辑过程中文件发生外部改变（比如被别的编辑器编辑了），就会发出提示。 （40） set listchars=tab:»■,trail:■ set list 如果行尾有多余的空格（包括 Tab 键），该配置将让这些空格显示成可见的小方块。 （41） set wildmenu set wildmode=longest:list,full 命令模式下，底部操作指令按下 Tab 键自动补全。第一次按下 Tab，会显示所有匹配的操作指令的清单；第二次按下 Tab，会依次选择各个指令。 ","link":"https://tdmaker.github.io/faded/post/vim-configuration-introduction/"},{"title":"Vim——重要的命令","content":" 一些不起眼但非常有用的 Vim 命令 1 保存文件并退出 :x :wq 都是保存当前文件并退出。这两个命令实际上并不完全等价，当文件被修改时两个命令时相同的。但如果未被修改，使用 :x 不会更改文件的修改时间，而使用 :wq 会改变文件的修改时间。 2 基本计算器 在插入模式下，你可以使用 Ctrl+r 键然后输入 =，再输入一个简单的算式。按 Enter 键，计算结果就会插入到文件中。例如，尝试输入： Ctrl+r '=2+2' ENTER 然后计算结果“4 ”会被插入到文件中。 3 查找重复的连续的单词 当你很快地打字时，很有可能会连续输入同一个单词两次，就像 this this。这种错误可能骗过任何一个人，即使是你自己重新阅读一遍也不可避免。幸运的是，有一个简单的正则表达式可以用来预防这个错误。使用搜索命令（默认时 /）然后输入： \\(\\&lt;\\w\\+\\&gt;\\)\\_s*\\1 这会显示所有重复的单词。要达到最好的效果，不要忘记把下面的命令： set hlsearch 放到你的 .vimrc 文件中高亮所有的匹配。 4 缩写 一个很可能是最令人印象深刻的窍门是你可以在 Vim 中定义缩写，它可以实时地把你输入的东西替换为另外的东西。语法格式如下： :ab [缩写] [要替换的文字] 一个通用的例子是： :ab asap as soon as possible 会把你输入的 “asap” 替换为 “as soon as possible”。 5 在你忘记用 root 方式打开文件时的文件保存 这可能是一个在论坛中一直受欢迎的命令。每当你打开一个你没有写入权限的文件（比如系统配置文件）并做了一些修改，Vim 无法通过普通的 :w 命令来保存。 你不需要重新以 root 方式打开文件再进行修改，只需要运行： :w !sudo tee % 这会直接以 root 方式保存。 6 实时加密文本 如果你不想让别人看懂你的屏幕上的内容，你可以使用一个内置的选项，通过下面的命令使用 ROT13 来对文本进行编码： ggVGg? gg 把光标移动到 Vim 缓冲区的第一行，V 进入可视模式，G 把光标移动到缓冲区的最后一行。因此，ggVG 使可视模式覆盖这个当前缓冲区。最后 g? 使用 ROT13 对整个区域进行编码。 注意它可以被映射到一个最常使用的键。它对字母符号也可以很好地工作。要对它进行撤销，最好的方法就是使用撤销命令：u。 7 自动补全 这是另外一个令我感到惭愧的功能，但我发现周围很多人并不知道。Vim 默认有自动补全的功能。的确这个功能是很基本的，并且可以通过插件来增强，但它也很有帮助。方法很简单。Vim 尝试通过已经输入的单词来预测单词的结尾。比如当你在同一个文件中第二次输入 “compiler” 时，仅仅输入 “com” 然后保持在插入模式，按 Ctrl+n 键就可以看到 Vim 为你补全了单词。很简单，但也很有用。 8 比较两个文件的不同 你们中的大多数很可能都知道 vimdiff 命令，它可以使用分离模式打开 Vim 并比较两个文件的不同。语法如下： $ vimdiff [文件1] [文件2] 但同样的结果也可以通过下面的 Vim 命令来获得： :diffthis 首先在 Vim 中打开原始文件。然后使用分离模式带来第二个文件： :vsp [文件2] 最后在第一个缓冲区里输入： :diffthis 通过 Ctrl+w 来切换缓冲区并再次输入： :diffthis 这样两个文件中不同的部分就会被高亮。 （译者注：可以直接在一个缓冲区里使用命令 :windo diffthis，而不用输入 :diffthis 两次） 要停止比较，使用： :diffoff 9 按时间回退文件 Vim 会记录文件的更改，你很容易可以回退到之前某个时间。该命令是相当直观的。比如： :earlier 1m 会把文件回退到 1 分钟以前的状态。 注意，你可以使用下面的命令进行相反的转换： :later 10 删除标记内部的文字 当我开始使用 Vim 时，一件我总是想很方便做的事情是如何轻松的删除方括号或圆括号里的内容。转到开始的标记，然后使用下面的语法： di[标记] 比如，把光标放在开始的圆括号上，使用下面的命令来删除圆括号内的文字： di( 如果是方括号或者是引号，则使用： di{ 和： di&quot; 11 删除指定标记前的内容 和删除标记内部有些相似，但目的不同。命令如下： dt[标记] 会删除所有光标和标记之间的内容（保持标记不动），如果在同一行有这个标记的话。例如 dt. 会删除至句子的末尾，但保持 . 不动。 12 把 Vim 变为十六进制编辑器 这不是我最喜欢的窍门，但有时会很有趣。你可以把 Vim 和 xxd 功能连起来来把文件转换为十六进制模式。命令如下：:%!xxd 类似的，你可以通过下面的命令恢复原来的状态： :%!xxd -r 13 把光标下的文字置于屏幕中央 我们所要做的事情如标题所示。如果你想强制滚动屏幕来把光标下的文字置于屏幕的中央，在可视模式中使用命令（译者注：在普通模式中也可以）： zz 14 跳到上一个／下一个位置 当你编辑一个很大的文件时，经常要做的事是在某处进行修改，然后跳到另外一处。如果你想跳回之前修改的地方，使用命令： Ctrl+o 来回到之前修改的地方；类似的： Ctrl+i 会回退上面的跳动。 15 把当前文件转化为网页 这会生成一个 HTML 文件来显示文本，并在分开的窗口显示源代码： :%TOhtml ","link":"https://tdmaker.github.io/faded/post/vim-key-instruct/"},{"title":"Vim——光标移动篇","content":" Vim常用文档动作命令总结 1 基本方向移动 h ： 向左移动一列 l ： 向右移动一列 j ： 向下移动一个实际行 k ： 向上移动一个实际行 所谓列可能指一个字节，也可能是一个字符，根据文件内容决定。 实际行指的是文本截止到一个换行符为止称为一个实际行。有时因为文本太长，一个实际行在窗口中会显示成好几行。可以通过 :set number 命令查看实际的行数。 2 基于单词的移动 Vim有一组基于单词的正向和反向移动的命令。 w ： 正向移动到下一单词的开头 e ： 正向移动到当前/下一单词的结尾 b ： 反向移动到当前/上一单词的开头 ge ： 反向移动到上一单词的结尾 基于单词的移动命令可以和其他命令结合使用。例如 :ea 可以跳转到单词的结尾并进入插入模式。 3 基于查找的移动 f 命令是最常用的查找命令，用于当前行进行指定字符的查找。如果找到则光标移动到目标字符，否则不移动。 Vim 会记录上一次执行的查找命令，再次查找时可以使用 ; 命令来完成相同查找。如果查询跳过头了，可以使用 , 命令返回光标之前的位置。 查询不止 f 命令，其他命令总结如下 f{char} : 正向移动到下一个{char}所在位置 F{char} : 反向移动到上一个{char}所在位置 t{char} : 正向移动到下一个{char}的前一个字符上 T{char} : 反向移动到上一个{char}的后一个字符上 除了上述查询方式， / 也是一种常用的查询方式，基于字符串的查询，/{str} 可以高亮目标字符串。可以通过 n 命令跳到下一个匹配处， N 返回前一匹配处。 同样的， / 也可以和其他命令结合使用，例如选择文本。点击 v 进入可视模式，然后输入 /{str} 也有例如 d/{str} 删除光标到目标字符串之间的所有内容的操作方式。 4 精确的文本对象选择 这个是一个很NB的功能，完全颠覆了对文本编辑器的认知。 现在有一个 JS 文件，内容如图： 这里认识 a 和 i 两个命令，不是普通的插入命令，需要和 v 命令配合使用，选中匹配的文本对象。例如在当前光标所在处输入 vi} 会达到以下效果。 如果光标的位置在 href 上呢？相同命令下： 如果换做是 a 命令呢？ i 命令可以理解为 inside，即选中匹配符号之间不包含匹配符号的内容。而 a 则选中包含匹配项的内容。 常见分隔符总结： 'a)' 或 'ab' : 一对() 'a}' 或 'aB' : 一对{} a] : 一对[] a&gt; : 一对&lt;&gt; a' : 一对'' a&quot; : 一对&quot;&quot; a` : 一对`` at : 一对xml标签 i 与 a 对应，只不过是针对分隔符内部的内容而已。 5 删除周边、修改内部 Vim 除了可以根据分隔符操作，也可以操作文本块，如单词，句子，段落等。 常见文本范围： iw : 当前单词 aw : 当前单词及一个空格 iW : 当前字符串 aW : 当前字符串及一个空格 is : 当前句子 as : 当前句子及一个空格 ip : 当前段落 ap : 当前段落及一个空行 上面的范围命令可以和 v 、 c 等操作一起使用。 6 快速回跳 这些命令用的相对少一些，常用一些的有 `` : 当前文件上次跳转操作的位置 `. : 上次修改操作的地方 `^ : 上次插入的地方 `[ : 上次修改或复制的起始位置 `] : 上次修改或复制的结束位置 `&lt; : 上次高亮选区的起始位置 `&gt; : 上次高亮选区的结束位置 7 匹配括号间跳转 Vim的 % 命令允许光标在一对闭括号间跳转。例如当前光标在 [ 上， % 命令可以跳转到对应的 ] 上，反过来也一样ok。例如将一对 {} 修改为一对 []。 当前光标在 { 上，输入 % 命令 替换当前光标下的字符，通过 r] 将 } 替换为 ]。 输入 `` 命令，跳转回上次跳转的位置。 之后再通过 'r[' 将 '{' 转为 '['。 ","link":"https://tdmaker.github.io/faded/post/vim-cursor-movement/"},{"title":"Bash 移动光标快捷键","content":" 快捷键 行为 ctrl+a 移动到行首 ctrl+e 移动到行尾 ctrl+f 向右移动一个字符 ctrl+b 向左移动一个字符 alt+f 向右移动一个单词 alt+b 向左移动一个单词 ","link":"https://tdmaker.github.io/faded/post/bash-key-for-cursor-movement/"},{"title":"Vim——CheatSheet","content":" Vim速查表-帮你提高N倍效率 进入 vim 命令 描述 vim filename 打开或新建文件,并将光标置于第一行首 vim +n filename 打开文件，并将光标置于第n行首 vim + filename 打开文件，并将光标置于最后一行首 vim +/pattern filename 打开文件，并将光标置于第一个与pattern匹配的串处 vim -r filename 在上次正用vim编辑时发生系统崩溃，恢复filename vim filename….filename 打开多个文件，依次编辑 vim 配置 命令 描述 all 列出所有选项设置情况 term 设置终端类型 ignorance 在搜索中忽略大小写 list 显示制表位(Ctrl+I)和行尾标志（$) number 显示行号 report 显示由面向行的命令修改过的数目 terse 显示简短的警告信息 warn 在转到别的文件时若没保存当前文件则显示NO write信息 nomagic 允许在搜索模式中，使用前面不带“\\”的特殊字符 nowrapscan 禁止vi在搜索到达文件两端时，又从另一端开始 mesg 允许vi显示其他用户用write写到自己终端上的信息 :set number / set nonumber 显示/不显示行号 :set ruler /set noruler 显示/不显示标尺 :set hlsearch 高亮显示查找到的单词 :set nohlsearch 关闭高亮显示 :syntax on 语法高亮 :set nu 显示行号 :set tabstop=8 设置tab大小,8为最常用最普遍的设置 :set softtabstop=8 4:4个空格,8:正常的制表符,12:一个制表符4个空格,16:两个制表符 :set autoindent 自动缩进 :set cindent C语言格式里面的自动缩进 移动光标 命令 描述 k nk 上 向上移动n行 j nj 下 向下移动n行 h nh 左 向左移动n行 l nl 右 向右移动n行 Space 光标右移一个字符 Backspace 光标左移一个字符 Enter 光标下移一行 w/W 光标右移一个字至字首 b/B 光标左移一个字至字首 e或E 光标右移一个字至字尾 ) 光标移至句尾 ( 光标移至句首 } 光标移至段落开头 { 光标移至段落结尾 n$ 光标移至第n行尾 H 光标移至屏幕顶行 M 光标移至屏幕中间行 L 光标移至屏幕最后行 0 （注意是数字零）光标移至当前行首 ^ 移动光标到行首第一个非空字符上去 $ 光标移至当前行尾 gg 移到第一行 G 移到最后一行 f 移动光标到当前行的字符a上 F 相反 % 移动到与制匹配的括号上去（），{}，[]，&lt;&gt;等 nG 移动到第n行上 G 到最后一行 屏幕滚动 命令 描述 Ctrl+u 向文件首翻半屏 Ctrl+d 向文件尾翻半屏 Ctrl+f 向文件尾翻一屏 Ctrl＋b 向文件首翻一屏 nz 将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部 插入文本类 命令 描述 i 在光标前 I 在当前行首 a 光标后 A 在当前行尾 o 在当前行之下新开一行 O 在当前行之上新开一行 r 替换当前字符 R 替换当前字符及其后的字符，直至按ESC键 s 从当前光标位置处开始，以输入的文本替代指定数目的字符 S 删除指定数目的行，并以所输入文本代替之 ncw/nCW 修改指定数目的字 nCC 修改指定数目的行 删除命令 命令 描述 x/X 删除一个字符，x删除光标后的，而X删除光标前的 dw 删除一个单词(删除光标位置到下一个单词开始的位置) dnw 删除n个单词 dne 也可，只是删除到单词尾 do 删至行首 d$ 删至行尾 dd 删除一行 ndd 删除当前行及其后n-1行 dnl 向右删除n个字母 dnh 向左删除n个字母 dnj 向下删除n行,当前行+其上n行 dnk 向上删除n行,当期行+其下n行 cnw[word] 将n个word改变为word C$ 改变到行尾 cc 改变整行 shift+j 删除行尾的换行符，下一行接上来了 复制粘贴 命令 描述 p 粘贴用x或d删除的文本 ynw 复制n个单词 yy 复制一行 ynl 复制n个字符 y$ 复制当前光标至行尾处 nyy 拷贝n行 撤销 命令 描述 u 撤销前一次的操作 shif+u(U) 撤销对该行的所有操作 搜索及替换 命令 描述 /pattern 从光标开始处向文件尾搜索pattern ?pattern 从光标开始处向文件首搜索pattern n 在同一方向重复上一次搜索命令 N 在反方向上重复上一次搜索命令 cw newword 替换为newword n 继续查找 . 执行替换 :s/p1/p2/g 将当前行中所有p1均用p2替代,g表示执行 用c表示需要确认 :n1,n2 s/p1/p2/g 将第n1至n2行中所有p1均用p2替代 :g/p1/s//p2/g 将文件中所有p1均用p2替换 :1,$ s/string1/string2/g 在全文中将string1替换为string2 书签 命令 描述 m[a-z] 在文中做标记，标记号可为a-z的26个字母 `a 移动到标记a处 visual 模式 命令 描述 v 进入visual 模式 V 进入行的visual 模式 ctrl+v 进如块操作模式用o和O改变选择的边的大小 在所有行插入相同的内容如include&lt; 将光标移到开始插入的位置，按CTRL+V进入VISUAL模式，选择好模块后按I（shift+i)，后插入要插入的文本，按[ESC]完成 行方式命令 命令 描述 :n1,n2 co n3 将n1行到n2行之间的内容拷贝到第n3行下 :n1,n2 m n3 将n1行到n2行之间的内容移至到第n3行下 :n1,n2 d 将n1行到n2行之间的内容删除 :n1,n2 w!command 将文件中n1行至n2行的内容作为command的输入并执行之 若不指定n1，n2，则表示将整个文件内容作为command的输入 宏 命令 描述 q[a-z] 开始记录但前开始的操作为宏，名称可为【a-z】，然后用q终止录制宏 reg 显示当前定义的所有的宏，用@[a-z]来在当前光标处执行宏[a-z] 窗口操作 命令 描述 :split 分割一个窗口 :split file.c 为另一个文件file.c分隔窗口 :nsplit file.c 为另一个文件file.c分隔窗口，并指定其行数 ctrl＋w 在窗口中切换 :close 关闭当前窗口 文件及其他 命令 描述 :q 退出vi :q! 不保存文件并退出vi :e filename 打开文件filename进行编辑 :e! 放弃修改文件内容，重新载入该文件编辑 :w 保存当前文件 :wq 存盘退出 :ZZ 保存当前文档并退出VIM :!command 执行shell命令command :r!command 将命令command的输出结果放到当前行 :n1,n2 write temp.c :read file.c 将文件file.c的内容插入到当前光标所在的下面 几张图 vim 工作模式 vim 快捷键盘图 vim 快捷键思维导图 vimium 快捷键盘图 ","link":"https://tdmaker.github.io/faded/post/vim-cheatsheet/"},{"title":"区块链——商用调查","content":" 区块链商用调查 1 信息共享——信息对齐、提高效率 这应该是区块链最简单的应用场景，就是信息互通有无。 1.1 传统的信息共享的痛点 要么是统一由一个中心进行信息发布和分发，要么是彼此之间定时批量对账（典型的每天一次），对于有时效性要求的信息共享，难以达到实时共享。 信息共享的双方缺少一种相互信任的通信方式，难以确定收到的信息是否是对方发送的。 1.2 区块链 + 信息共享 首先，区块链本身就是需要保持各个节点的数据一致性的，可以说是自带信息共享功能；其次，实时的问题通过区块链的 P2P 技术可以实现；最后，利用区块链的不可篡改和共识机制，可构建其一条安全可靠的信息共享通道。 也行你会有这样的疑问：解决上面的问题，不用区块链技术，我自己建个加密通道也可以搞定啊！但我想说，既然区块链技术能够解决这些问题，并且增加节点非常方便，在你没有已经建好一套安全可靠的信息共享系统之前，为什么不用区块链技术呢？ 2 版权保护——不可篡改、永久保存 2.1 传统鉴证证明的痛点 流程复杂：以版权保护为例，现有鉴证证明方式，登记时间长，且费用高。 公信力不足：以法务存证为例，个人或中心化的机构存在篡改数据的可能，公信力难以得到保证。 2.2 区块链 + 鉴证证明 流程简化：区块链应用到鉴证证明后，无论是登记还是查询都非常方便，无需再奔走于各个部门之间， 安全可靠：区块链的去中心化存储，保证没有一家机构可以任意篡改数据， 2.3 应用案例 区块链在鉴权证明领域的应用有版权保护、法务存证等，下面以版权保护为例，简单说下如何区块链如何实现版权登记和查询。 电子身份证：将“申请人+发布时间+发布内容”等版权信息加密后上传，版权信息用于唯一区块链 ID，相当拥有了一张电子身份证。 时间戳保护：版权信息存储时，是加上时间戳信息的，如右雷同，可用于证明先后。 可靠性保证：区块链的去中心化存储、私钥签名、不可篡改的特性提升了鉴权信息的可靠性。 2016 年 8 月，由 Onchain、微软（中国）、法大大等多个机构在北京成立了电子存证区块链联盟“法链”。 2017 年 12 月，微众银行、仲裁委（广州仲裁委）、杭州亦笔科技有限公司共同推出的仲裁联盟链，用于司法场景下的存证；2018 年 3 月，广州首个“仲裁链”判决书出炉。 3 物流链——溯源防伪 商品从生产商到消费者手中，需要经历多个环节（流程可能如上图所示），跨境购物则更加复杂；中间环节经常出问题，消费者很容易购买的假货。而假货问题正是困扰着各大商家和平台，至今无解。 3.1 传统是防伪溯源手段 以一直受假冒伪劣产品困扰的茅台酒的防伪技术为例，2000 年起，其酒盖里有一个唯一的 RFID 标签，可通过手机等设备以 NFC 方式读出，然后通过茅台的 APP 进行校验，以此防止伪造产品。 咋一看，这种防伪效果非常可靠。但 2016 年还是引爆了茅台酒防伪造假，虽然通过 NFC 方式验证 OK，但经茅台专业人士鉴定为假酒。后来，在“国酒茅台防伪溯源系统”数据库审计中发现 80 万条假的防伪标签记录，系防伪技术公司人员参与伪造；随后，茅台改用安全芯片防伪标签。 但这里暴露出来的痛点并没有解决，即防伪信息掌握在某个中心机构中，有权限的人可以任意修改。(备注：茅台的这种防伪方式，也衍生了旧瓶回收，旧瓶装假酒的产业，防伪道路任重而道远)。 2017 年 05 月贵阳数博会上，小马哥就建议茅台防伪使用区块链；那么区块链和物流链的结合有什么优势呢？ 3.2 区块链+物流链 区块链没有中心化节点，各节点是平等的，掌握单个节点无法实现修改数据；需要掌控足够多的节点，才可能伪造数据，大大提高伪造数据的成本。 区块链天生的开放、透明，使得任何人都可以公开查询，伪造数据被发现的概率大增。 区块链的数据不可篡改性，也保证了已销售出去的产品信息已永久记录，无法通过简单复制防伪信息蒙混过关，实现二次销售。 物流链的所有节点上区块链后，商品从生产商到消费者手里都有迹可循，形成完整链条；商品缺失的环节越多，将暴露出其是伪劣产品概率更大。 ##3.3 应用案例 目前，入局物流链的玩家较多，包括腾讯、阿里、京东、沃尔玛等。 据说，阿里的菜鸟在海淘进口应用区块链上，走在了前面，已经初步实现海外商品溯源，国际物流及进口申报溯源、境内物流溯源；下一步就是生产企业溯源了。下图是网上流传的关于阿里的菜鸟在海淘场景运用区块链的示意图。 4 供应链金融——解决中小微企业融资难 4.1 传统的供应链单点融资 在一般供应链贸易中，从原材料的采购、加工、组装到销售的各企业间都涉及到资金的支出和收入，而企业的资金支出和收入是有时间差的，这就形成了资金缺口，多数需要进行融资生产。我们先来看个简单的供应链，如下图： 我们再来看看图中各个角色的融资情况： 核心企业或大企业：规模大、信用好，议价能力强，通过先拿货后付款，延长账期将资金压力传导给后续供应商；此外，其融资能力也是最强的。 一级供应商：通过核心企业的债权转让，可以获得银行的融资。 其他供应商（多数是中小微企业）：规模小、发展不稳定、信用低，风险高，难以获得银行的贷款；也无法想核心企业一样有很长的账期；一般越小的企业其账期越短，微小企业还需要现金拿货。这样一出一入对比就像是：中小微企业无息借钱给大企业做生意。 4.2 区块链 + 供应链金融 面对，上述供应链里的中小微企业融资难问题，主要原因是银行和中小企业之间缺乏一个有效的信任机制。 假如供应链所有节点上链后，通过区块链的私钥签名技术，保证了核心企业等的数据可靠性；而合同、票据等上链，是对资产的数字化，便于流通，实现了价值传递。 如上图所示，在区块链解决了数据可靠性和价值流通后，银行等金融机构面对中小企业的融资，不再是对这个企业进行单独评估；而是站在整个供应链的顶端，通过信任核心企业的付款意愿，对链条上的票据、合同等交易信息进行全方位分析和评估。即借助核心企业的信用实力以及可靠的交易链条，为中小微企业融资背书，实现从单环节融资到全链条融资的跨越，从而缓解中小微企业融资难问题。 5 跨境支付——提高效率、降低费用 5.1 传统跨境支付 跨境支付涉及多种币种，存在汇率问题，传统跨境支付非常依赖于第三方机构，大致的简化模型如上图所示，存在着两个问题； 流程繁琐，结算周期长：传统跨境支付基本都是非实时的，银行日终进行交易的批量处理，通常一笔交易需要 24 小时以上才能完成；某些银行的跨境支付看起来是实时的，但实际上，是收款银行基于汇款银行的信用做了一定额度的垫付，在日终再进行资金清算和对账，业务处理速度慢。 手续费高：传统跨境支付模式存在大量人工对账操作，加之依赖第三方机构，导致手续费居高不下，麦肯锡《2016 全球支付》报告数据显示，通过代理行模式完成一笔跨境支付的平均成本在 25 美元到 35 美元之间。 5.2 区块链 + 跨境支付 这些问题的存在，很大原因还是信息不对称，没有建立有效的信任机制。 如上图所示，区块链的引入，解决了跨境支付信息不对称的问题，并建立起一定程度的信任机制；带来了两个好处。 效率提高，费用降低：接入区块链技术后，通过公私钥技术，保证数据的可靠性，再通过加密技术和去中心，达到数据不可篡改的目的，最后，通过 P2P 技术，实现点对点的结算；去除了传统中心转发，提高了效率，降低了成本(也展望了普及跨境小额支付的可能性)。 可追溯，符合监管需求：传统的点对点结算不能不规模应用，除了信任问题，还有就是存在监管漏洞（点对点私下交易，存在洗黑钱的风险），而区块链的交易透明，信息公开，交易记录永久保存实现了可追溯，符合监管的需求。 6 资产数字化——便于资产流通 6.1 实体资产存在的问题 实体资产往往难以分割，不便于流通 实体资产的流通难以监控，存在洗黑钱等风险 6.2 区块链实现资产数字化 资产数字化后，易于分割、流通方便，交易成本低 用区块链技术实现资产数字化后，所有资产交易记录公开、透明、永久存储、可追溯，完全符合监管需求 6.3 应用案例 还是以腾讯的微黄金应用为例，继续借用腾讯区块链官网（trustsql.qq.com）上的图片，可以看到，在资产数字化之后，流通更为方便了，不再依赖于发行机构；且购买 0.001g 黄金成为了可能，降低了参与门槛。 7 代币——去中介、去信任 本来不像把代币加进来的，但说到区块链，始终绕不开代币；因区块链脱胎于比特币，天生具有代币的属性，目前区块链最成功的应用也正是比特币。 7.1 传统货币存在的问题 传统的货币发行权掌握在国家手中，存在着货币滥发的风险 货币滥发案例 1：元朝自 1271 年建立后，依然四处征战，消耗大量的钱财和粮食，为了财政问题，长期滥发货币，造成严重通货膨胀，多数百姓生活在水生火热中，导致流民四起，国家大乱，1368 年，不可一世的元朝成了只有 97 年短命鬼，走向了灭亡。 货币滥发案例 2：1980 年津巴布韦独立，后因土改失败，经济崩溃，政府入不敷出，开始印钞；2001 年时 100 津巴布韦币可兑换约 1 美元；2009 年 1 月，津央行发行 100 万亿面值新津元（如下图）加速货币崩溃，最终津元被废弃，改用“美元化”货币政策。2017 年津巴布韦发生政变，总统穆加贝被赶下台。 传统的记账权掌握在一个中心化的中介机构手中，存在中介系统瘫痪、中介违约、中介欺瞒、甚至是中介耍赖等风险。 2013 年 3 月，塞浦路斯为获得救助，对银行储户进行一次性征税约 58 亿欧元, 向不低于 10 万欧元的存款一次性征税 9.9%，向低于 10 万欧元的一次性征税 6.75%。 2017 年 4 月，民生银行 30 亿假理财事件暴露，系一支行行长伪造保本保息理财产品所致，超过 150 名投资者被套。 7.2 区块链如何解决这些问题 比特币解决了货币在发行和记账环节的信任问题，我们来看下比特币是如何一一破解上面的两个问题。 7.2.1 滥发问题 比特币的获取只能通过挖矿获得，且比特币总量为 2100 万个，在发行环节解决了货币滥发的问题； 7.2.2 账本修改问题 比特币的交易记录通过链式存储和去中心化的全球节点构成网络来解决账本修改问题。 7.2.3 链式存储 可以简单理解为：存储记录的块是一块连着一块的，形成一个链条；除第一个块的所有区块都的记录包含了前一区块的校验信息，改变任一区块的信息，都将导致后续区块校验出错。因为这种关联性，中间也无法插入其他块，所以修改已有记录是困难的。 7.2.4 去中心化节点 可以简单理解为：全球的中心节点都是平等的，都拥有一模一样的账本，所以，任一节点出问题都不影响账本记录。而要修改账本，必须修改超过全球一半的节点才能完成；而这在目前看来几乎不可能。 既然账本无法修改，那要是记账的时候作弊呢？ 首先，比特币的每条交易记录是有私钥签名的，别人伪造不了这个记录。你能修改的仅仅自己发起的交易记录。 其次，是关于记账权问题：比特币的记账权，通过工作量证明获得，可以简单理解为：通过算法确定同一时刻，全球只有一个节点获得了记账权，基本规律是谁拥有的计算资源越多，谁获得记账权的概率越大，只有超过全网一半的算力，才可能实现双花。 7.2.5 备注 比特币的模式是不可复制的，比特币已经吸引了全球绝大多数的算力，从而降低 51% 攻击发生等问题；其他的复制品基本无法获得相应的算力保证。 目前，比特币还存在着 51% 和效率低等问题有待解决，另外，关于交易本身的信任问题是个社会问题，比特币是没有解决的，也解决不了的。 7.3 应用案例 最具代表性的当然是比特币，也不用多说了。 备注：代币这块真的不看好，比特币目前吸引了全球绝大部分的算力，有独一无二的算力资源作为支撑还稍好一点，其他的代币和传统的货币相比，其背后缺乏国家和武力为其做信用背书，且夺取了国家发币带来的各种好处（如宏观调控），仔细想想就知道有多不靠谱。 8 小结 区块链应用的场景肯定还有很多，但很多都还不大明朗，暂时就先梳理以上7种场景，顺便归纳一下。 ","link":"https://tdmaker.github.io/faded/post/blockchain-commercial-survey/"},{"title":"区块链——行业名词","content":" 名称 中文 解释 2-Way Peg 双向锚定 一种跨链技术 ABI 智能合约的接口说明 Application Binary Interface，ABI 是以太坊的一种合约间调用的消息格式，类似于 WebService 的 SOAP 协议一样，也就是定义操作函数签名，参数编码，返回结果编码等的协议。 altcoin 山寨币 AML 反洗钱 Anti-Money Laundering ASIC 专用集成电路 Application Specific Integrated Circuit，通常，与 GPU 相比，ASIC 专门用于挖矿，可能会节省大量能源。 autonomous 自治 BAAS 区块链服务 Blockchain As A Service，区块链即服务。 BIP 比特币改进建议 Bitcoin Improvement Proposals Block 区块 用于记录区块链系统中数据的存储。 Block Explorer 区块资源管理器 区块资源管理器是一种用来来查看区块上的所有交易（过去和当前）在线工具。 它们提供有用的信息，如网络哈希率和交易增长率。 Block Height 区块高度 连接在区块链上的块数。 Block Reward 出块奖励 它是在采矿期间成功计算区块中的哈希的矿工的一种激励形式。 在区块链上的交易验证的过程中产生新的币，并且矿工被奖励其中的一部分。 Blockchain 区块链 分布式存储、加密算法、共识机制、P2P传输等计算机技术结合的新型应用模式。 Blockchain Wallet 区块链钱包 一个包含私钥的文件。 它通常包含一个软件客户端，允许访问查看和创建钱包所设计的特定块链的交易。 Bulletproofs Bulletproofs 由斯坦福大学提出的，把膨胀系数减少到普通交易的三倍（原来是 60 倍），可以大幅降低隐私交易的数据量大小的算法 CAP CAP 分布式异步网络模型中，不能同时保证**一致性**，**可用性**和**分区容错性**，只能三选二 Central Ledger 中央帐簿 由中央机构维持的分类帐。 Chain 链 区块头中通过引用哈希值链接。 Confirmation 确认 去中心化的一次交易，将其添加到 blockchain 的成功确认。 Consensus 共识机制 区块链中事务达成的分布式共识算法。 Consensus 共识 当所有网络参与者同意交易的有效性时，达成共识，确保分布式账本是彼此的精确副本。 Consortium Block Chains 联盟链 共识过程由预选节点控制，一般为各企业机构互联形成。 Corda Corda R3联盟推出的金融联盟“类区块链”技术架构，Corda 中同样是用交易组成账本，但并没有区块，交易仅在参与方和公证人间传播 Cryptocurrency 加密货币 也称为令牌，加密货币是数字资产的呈现方式。 Cryptographic Hash Function 加密哈希函数 密码哈希产生从可变大小交易输入固定大小和唯一哈希值。 SHA-256计算算法是加密散列的一个例子。 DAO 去中心化自治组织 Decentralized Autonomous Organizations，去中心化自治组织可以被认为是在没有任何人为干预的情况下运行的公司，并将一切形式的控制交给一套不可破坏的业务规则。 Dapp 去中心化应用 是一种开源的应用程序，自动运行，将其数据存储在区块链上，以密码令牌的形式激励，并以显示有价值证明的协议进行操作。 DD 尽职调查 Due Diligence Decentralized 分布式 不依赖中心服务器，分布的计算机资源进行计算处理的模式。 Difficulty 挖矿难度 这是指成功挖掘交易信息的数据块的容易程度。 Distributed Ledger 分布式账本 分布式账本，数据通过分布式节点网络进行存储。 分布式账本不是必须具有自己的货币，它可能会被许可和私有。 Distributed Network 分布式网络 处理能力和数据分布在节点上而不是拥有集中式数据中心的一种网络。 Double Spending 双重支付 当花费一笔钱多于一次支付限额时，就会发生双重支付。 DPoS 委托权益证明 Delegated Proof Of Stake，一种共识算法 EIP 以太坊改进建议 Ethereum Improvement Proposals EOA 外部账户 Externally Owned Accounts ERC 以太坊意见征求 Ethereum Requests for Comment，讨论项目时，一开始会用EIP提出建议，在讨论过程中有一些要征求更多人意见时，就会把细节放在ERC中，而且他们会用同一个号码，比如ERC-20 对应 EIP-20 Ethash Ethash 以前这个算法称为 Dagger Hashimoto，Ethash是最新版本的 Dagger-Hashimoto 改良算法，是 Hashimoto 算法结合 Dagger 算法产成的一个新变种。实现两个主要目的：抵抗 ASIC 矿机和轻客户端易验证 Ethereum 以太坊 Ethereum是一个基于blockchain的去中心化运行智能合约的平台，旨在解决与审查，欺诈和第三方干扰相关的问题。 EVM 以太坊虚拟机 Ethereum Virtual Machine，借助以太坊虚拟机将 Solidity 代码变成可以在区块链上执行的加密代码。以太坊虚拟机是设计运行在点对点网络中所有参与节点上的一个虚拟机，它可以读写一个区块链中可执行的代码和数据，校验数据签名，并以半图灵完备的方式来运行代码。每个Ethereum节点都运行在 EVM 上，以保持整个块链的一致性。 FLP FLP 在网络可靠并且存在节点失效的异步模型中，不存在一个可以解决一致性问题的确定性算法 Fork 分叉 分叉可以创建区块链的交叉版本，在网络不同的地方兼容的运行两个区块链。 Frontier 前沿 以太坊开发第一阶段 gas gas gas是在以太坊网络中用于衡量执行交易或智能合约工作量的计算单位 gas limit gas limit 某笔具体的交易能够消耗的 gas 最大值，一笔标准的以太坊交易需要 21,000 gas。当交易的 gas limit 不足时，会出现 out of gas 错误 gas price gas price 以另一种货币或 token（例如 Ether）计量交易花费的价格。为了稳定消耗 gas 的价值，gas price 是浮动的，根据货币或 token 价格浮动而相应变动以保持总价格稳定。gas price 由市场供需决定（用户愿意支出的价格和矿工节点愿意接受的价格的博弈） gas used gas used 有效支付用于计算或智能合约运行的 gas 数量（在成功的交易中 gas fee 小于 gas limit)，一笔以太坊交易的实际矿工费(Tx Fees) = gas used * gas price Genesis Block 创世区块 区块链的第一个区块。 Go Ethereum geth 实现了以太坊协议的 JavaScript运行时环境，可以以交互式或非交互式模式运行 Hard Fork 硬分叉 区块链发生永久性分歧，在新共识规则发布后，部分没有升级的节点无法验证已经升级的节点生产的区块，产生硬分叉。 Hash 哈希 对输出数据执行散列函数的行为。 这是用于确认货币交易。 Hash Rate 哈希率 采矿钻机的性能测量值以秒为单位表示。 Homestead 家园 以太坊开发第二阶段 Hybrid PoS/PoW 混合PoS / PoW 混合 PoS / PoW 可以将网络上的共享分发算法作为共享证明和工作证明。 在这种方法中，可以实现矿工和选民（持有者）之间的平衡，由内部人（持有人）和外部人（矿工）创建一个基于社区的治理体系。 I2P I2P Invisible Internet Project，建立在互联网上的隐匿网络层，用于为网络通讯提供隐私保护 Infura Infura 提供全球范围区块链集群和 API 端点等基础架构服务；可用于以太坊，IPFS 等其他新兴的分布式平台。致力于提供安全，稳定，高容错性金额可扩展的区块链访问接口 keccak keccak 一种SHA-3加密算法 Kovri Kovri I2P 网络的 C++ 实现版本，目前还在开发中尚未集成到门罗币中，可以提高交易的安全等级（可以隐藏 IP 地址） KYC 了解你的客户 Know Your Customer Metropolis 大都会 以太坊开发第三阶段 Mining 挖矿 挖矿是验证区块链交易的行为。 验证的必要性通常以货币的形式奖励给矿工。 在这个密码安全的繁荣期间，当正确完成计算，采矿可以是一个有利可图的业务。 通过选择最有效和最适合的硬件和采矿目标，采矿可以产生稳定的被动收入形式。 Multi-Signature 多重签名 多重签名地址需要一个以上的密钥来授权交易，从而增加了一层安全性。 Node 节点 由区块链网络的参与者操作的分类帐的副本。 Oracles 预言机 Oracle 通过向智能合约提供数据，它现实世界和区块链之间的桥梁。注意此 Oracle不是指数据库。预言机连接虚拟与现实，核心功能是提供数据上链服务，是实现智能合约的必要条件。智能合约是在区块链提供的沙盒环境中运行，沙盒是个封闭环境，使合约代码不能读取链外数据，但很多时候智能合约又必须依赖外部数据，Oracle 在这里就承担了提供外部数据的功能。 P2P Peer-to-Peer 对等互联网网络技术。 Paxos Paxos 一种用于传统分布式系统的共识协议 Payment Codes 可重用支付码 BIP47，支付码是一种用于创建永久性比特币地址的技术，这些地址可以重复使用，与现实生活中的身份公开相关，同时无损于财务隐私。它们类似于隐形地址。即使他人知道你的支付码也无法追踪你的交易历史，可以用于想要私密的接收BTC的场景 PBFT 实用拜占庭容错 Practical Byzantine Fault Tolerance pegged zone 锚定分区 一种锚定分区的桥接机制，出现于Cosmos项目 POA 权威证明 Proof Of Authority，一种共识算法 portfolio 投资组合 POS 权益证明 Proof of Stake，根据你持有货币的量和时间进行利息分配的制度，在 POS 模式下，你的“挖矿”收益正比于你的币龄，而与电脑的计算性能无关。 POW 工作量证明 Proof of Work，是指获得多少货币，取决于你挖矿贡献的工作量，电脑性能越好，分给你的矿就会越多。 Private Block Chains 私有链 私有区块链，数据记录在单一组织机构中，分权限对外开放，一般是单一企业机构构建。 Private Key 私钥 私钥是一串数据，它是允许您访问特定钱包中的令牌。 它们作为密码，除了地址的所有者之外，都被隐藏。 Public Address 公用地址 公共地址是公钥的密码哈希值。 它们作为可以在任何地方发布的电子邮件地址，与私钥不同。 Public Block Chains 公有链 公共网络中任何个人团体接入，任何节点均可参与共识过程。 Raft Raft Paxos协议的一种简单实现 Ring Signatures 环签名 用于隐匿发送发信息的技术，门罗币采用 RingCT 环加密交易 Ring Confidential Transactions，隐藏交易信息（包括交易双方信息和交易金额）的加密技术，门罗币采用 RLP RLP 编码 Recursive Length Prefix（递归长度前缀）是一种适用于任意二进制数据数组的编码。是以太坊中对象进行序列化/反序列化的主要编码方式。区块，交易等数据结构在持久化时会先经过RLP编码后再存储到持久层中。 RPCA 瑞波共识算法 Ripple Protocol Consensus Algorithm，类似PBFT的共识机制 Scrypt Scrypt 是一种由 Litecoin 使用加密算法。 与 SHA256 相比，它的速度更快，因为它不会占用很多处理时间。 Serenity 宁静 以太坊开发第四阶段（也是最后一个阶段） SHA-256 SHA-256 是比特币一些列数字货币使用的加密算法。 然而，它使用了大量的计算能力和处理时间，迫使矿工组建采矿池以获取收益。 Smart Contracts 智能合约 智能合约将可编程语言的业务规则编码到区块上，并由网络的参与者实施。部署在区块链系统中，一段合约代码，或一套以数字形式定义的承诺，包括合约参与方可以在其上执行承诺的协议。 Soft Fork 软分叉 软分叉与硬分叉不同之处在于，只有先前有效的交易才能使其无效。 由于旧节点将新的块识别为有效，所以软分叉基本上是向后兼容的。 这种分叉需要大多数矿工升级才能执行，而硬分叉需要所有节点就新版本达成一致。 Solidity Solidity 是 Ethereum 用于开发智能合约的编程语言。 SPV 简单支付验证 Simplified Payment Verification Stealth Address 隐匿地址 能够隐藏接收方信息 Swarm Swarm 去中心化的数据存储访问协议，以 ETH 作为激励。类似使用了 Filecoin 的 IPFS Sybil Attack 女巫攻击 P2P网络中的一种攻击形式：攻击者利用单个节点来伪造多个身份存在于 P2P 网络中，从而达到削弱网络的冗余性，降低网络健壮性，监视或干扰网络正常活动等目的 Testnet Testnet 开发商使用的测试区块链，它主要是用来防止改变在主链上的资产。 testrpc testrpc 以太坊节点客户端 Transaction Block 交易区块 聚集到一个块中的交易的集合，然后可以将其散列并添加到区块链中。 Transaction Fee 交易费 所有的加密货币交易都会涉及到一笔很小的手续费。这些手续费用加起来给矿工在成功处理区块时收到的区块奖励。 Truffle Truffle 一个基于以太坊技术的开发、测试和部署框架，旨在帮助以太坊开发者更容易开发去中心化应用（DApp） Turing Complete 图灵完备 图灵完备是指计算机中一切计算的问题都可以计算，这样的虚拟机或者编程语言称为图灵完备。一个例子是 Ethereum 虚拟机（EVM）。 Unlinkability 无关联性 whisper whisper 去中心化的通信协议 YC YC Y Combinator，成立于 2005 年是美国著名创业孵化器，扶持初创企业并为其提供创业指南（Airbnb，Dropbox，Stripe，Reddit, Docker, Coinbase 等），投资孵化过多个区块链项目 ZKRP 零知识范围证明 Zero Knownledge Range Proof，证明一个具体声明的真实性而不会泄露它试图证明的额外信息 ZK-SNARKs 零知识证明 ZK-Succint Non-interactive Arguments of Knownledge ","link":"https://tdmaker.github.io/faded/post/blockchain-industry-terms/"},{"title":"区块链——行业名词","content":" 名称 中文 解释 2-Way Peg 双向锚定 一种跨链技术 ABI 智能合约的接口说明 Application Binary Interface，ABI 是以太坊的一种合约间调用的消息格式，类似于 WebService 的 SOAP 协议一样，也就是定义操作函数签名，参数编码，返回结果编码等的协议。 altcoin 山寨币 AML 反洗钱 Anti-Money Laundering ASIC 专用集成电路 Application Specific Integrated Circuit，通常，与 GPU 相比，ASIC 专门用于挖矿，可能会节省大量能源。 autonomous 自治 BAAS 区块链服务 Blockchain As A Service，区块链即服务。 BIP 比特币改进建议 Bitcoin Improvement Proposals Block 区块 用于记录区块链系统中数据的存储。 Block Explorer 区块资源管理器 区块资源管理器是一种用来来查看区块上的所有交易（过去和当前）在线工具。 它们提供有用的信息，如网络哈希率和交易增长率。 Block Height 区块高度 连接在区块链上的块数。 Block Reward 出块奖励 它是在采矿期间成功计算区块中的哈希的矿工的一种激励形式。 在区块链上的交易验证的过程中产生新的币，并且矿工被奖励其中的一部分。 Blockchain 区块链 分布式存储、加密算法、共识机制、P2P传输等计算机技术结合的新型应用模式。 Blockchain Wallet 区块链钱包 一个包含私钥的文件。 它通常包含一个软件客户端，允许访问查看和创建钱包所设计的特定块链的交易。 Bulletproofs Bulletproofs 由斯坦福大学提出的，把膨胀系数减少到普通交易的三倍（原来是 60 倍），可以大幅降低隐私交易的数据量大小的算法 CAP CAP 分布式异步网络模型中，不能同时保证**一致性**，**可用性**和**分区容错性**，只能三选二 Central Ledger 中央帐簿 由中央机构维持的分类帐。 Chain 链 区块头中通过引用哈希值链接。 Confirmation 确认 去中心化的一次交易，将其添加到 blockchain 的成功确认。 Consensus 共识机制 区块链中事务达成的分布式共识算法。 Consensus 共识 当所有网络参与者同意交易的有效性时，达成共识，确保分布式账本是彼此的精确副本。 Consortium Block Chains 联盟链 共识过程由预选节点控制，一般为各企业机构互联形成。 Corda Corda R3联盟推出的金融联盟“类区块链”技术架构，Corda 中同样是用交易组成账本，但并没有区块，交易仅在参与方和公证人间传播 Cryptocurrency 加密货币 也称为令牌，加密货币是数字资产的呈现方式。 Cryptographic Hash Function 加密哈希函数 密码哈希产生从可变大小交易输入固定大小和唯一哈希值。 SHA-256计算算法是加密散列的一个例子。 DAO 去中心化自治组织 Decentralized Autonomous Organizations，去中心化自治组织可以被认为是在没有任何人为干预的情况下运行的公司，并将一切形式的控制交给一套不可破坏的业务规则。 Dapp 去中心化应用 是一种开源的应用程序，自动运行，将其数据存储在区块链上，以密码令牌的形式激励，并以显示有价值证明的协议进行操作。 DD 尽职调查 Due Diligence Decentralized 分布式 不依赖中心服务器，分布的计算机资源进行计算处理的模式。 Difficulty 挖矿难度 这是指成功挖掘交易信息的数据块的容易程度。 Distributed Ledger 分布式账本 分布式账本，数据通过分布式节点网络进行存储。 分布式账本不是必须具有自己的货币，它可能会被许可和私有。 Distributed Network 分布式网络 处理能力和数据分布在节点上而不是拥有集中式数据中心的一种网络。 Double Spending 双重支付 当花费一笔钱多于一次支付限额时，就会发生双重支付。 DPoS 委托权益证明 Delegated Proof Of Stake，一种共识算法 EIP 以太坊改进建议 Ethereum Improvement Proposals EOA 外部账户 Externally Owned Accounts ERC 以太坊意见征求 Ethereum Requests for Comment，讨论项目时，一开始会用EIP提出建议，在讨论过程中有一些要征求更多人意见时，就会把细节放在ERC中，而且他们会用同一个号码，比如ERC-20 对应 EIP-20 Ethash Ethash 以前这个算法称为 Dagger Hashimoto，Ethash是最新版本的 Dagger-Hashimoto 改良算法，是 Hashimoto 算法结合 Dagger 算法产成的一个新变种。实现两个主要目的：抵抗 ASIC 矿机和轻客户端易验证 Ethereum 以太坊 Ethereum是一个基于blockchain的去中心化运行智能合约的平台，旨在解决与审查，欺诈和第三方干扰相关的问题。 EVM 以太坊虚拟机 Ethereum Virtual Machine，借助以太坊虚拟机将 Solidity 代码变成可以在区块链上执行的加密代码。以太坊虚拟机是设计运行在点对点网络中所有参与节点上的一个虚拟机，它可以读写一个区块链中可执行的代码和数据，校验数据签名，并以半图灵完备的方式来运行代码。每个Ethereum节点都运行在 EVM 上，以保持整个块链的一致性。 FLP FLP 在网络可靠并且存在节点失效的异步模型中，不存在一个可以解决一致性问题的确定性算法 Fork 分叉 分叉可以创建区块链的交叉版本，在网络不同的地方兼容的运行两个区块链。 Frontier 前沿 以太坊开发第一阶段 gas gas gas是在以太坊网络中用于衡量执行交易或智能合约工作量的计算单位 gas limit gas limit 某笔具体的交易能够消耗的 gas 最大值，一笔标准的以太坊交易需要 21,000 gas。当交易的 gas limit 不足时，会出现 out of gas 错误 gas price gas price 以另一种货币或 token（例如 Ether）计量交易花费的价格。为了稳定消耗 gas 的价值，gas price 是浮动的，根据货币或 token 价格浮动而相应变动以保持总价格稳定。gas price 由市场供需决定（用户愿意支出的价格和矿工节点愿意接受的价格的博弈） gas used gas used 有效支付用于计算或智能合约运行的 gas 数量（在成功的交易中 gas fee 小于 gas limit)，一笔以太坊交易的实际矿工费(Tx Fees) = gas used * gas price Genesis Block 创世区块 区块链的第一个区块。 Go Ethereum geth 实现了以太坊协议的 JavaScript运行时环境，可以以交互式或非交互式模式运行 Hard Fork 硬分叉 区块链发生永久性分歧，在新共识规则发布后，部分没有升级的节点无法验证已经升级的节点生产的区块，产生硬分叉。 Hash 哈希 对输出数据执行散列函数的行为。 这是用于确认货币交易。 Hash Rate 哈希率 采矿钻机的性能测量值以秒为单位表示。 Homestead 家园 以太坊开发第二阶段 Hybrid PoS/PoW 混合PoS / PoW 混合 PoS / PoW 可以将网络上的共享分发算法作为共享证明和工作证明。 在这种方法中，可以实现矿工和选民（持有者）之间的平衡，由内部人（持有人）和外部人（矿工）创建一个基于社区的治理体系。 I2P I2P Invisible Internet Project，建立在互联网上的隐匿网络层，用于为网络通讯提供隐私保护 Infura Infura 提供全球范围区块链集群和 API 端点等基础架构服务；可用于以太坊，IPFS 等其他新兴的分布式平台。致力于提供安全，稳定，高容错性金额可扩展的区块链访问接口 keccak keccak 一种SHA-3加密算法 Kovri Kovri I2P 网络的 C++ 实现版本，目前还在开发中尚未集成到门罗币中，可以提高交易的安全等级（可以隐藏 IP 地址） KYC 了解你的客户 Know Your Customer Metropolis 大都会 以太坊开发第三阶段 Mining 挖矿 挖矿是验证区块链交易的行为。 验证的必要性通常以货币的形式奖励给矿工。 在这个密码安全的繁荣期间，当正确完成计算，采矿可以是一个有利可图的业务。 通过选择最有效和最适合的硬件和采矿目标，采矿可以产生稳定的被动收入形式。 Multi-Signature 多重签名 多重签名地址需要一个以上的密钥来授权交易，从而增加了一层安全性。 Node 节点 由区块链网络的参与者操作的分类帐的副本。 Oracles 预言机 Oracle 通过向智能合约提供数据，它现实世界和区块链之间的桥梁。注意此 Oracle不是指数据库。预言机连接虚拟与现实，核心功能是提供数据上链服务，是实现智能合约的必要条件。智能合约是在区块链提供的沙盒环境中运行，沙盒是个封闭环境，使合约代码不能读取链外数据，但很多时候智能合约又必须依赖外部数据，Oracle 在这里就承担了提供外部数据的功能。 P2P Peer-to-Peer 对等互联网网络技术。 Paxos Paxos 一种用于传统分布式系统的共识协议 Payment Codes 可重用支付码 BIP47，支付码是一种用于创建永久性比特币地址的技术，这些地址可以重复使用，与现实生活中的身份公开相关，同时无损于财务隐私。它们类似于隐形地址。即使他人知道你的支付码也无法追踪你的交易历史，可以用于想要私密的接收BTC的场景 PBFT 实用拜占庭容错 Practical Byzantine Fault Tolerance pegged zone 锚定分区 一种锚定分区的桥接机制，出现于Cosmos项目 POA 权威证明 Proof Of Authority，一种共识算法 portfolio 投资组合 POS 权益证明 Proof of Stake，根据你持有货币的量和时间进行利息分配的制度，在 POS 模式下，你的“挖矿”收益正比于你的币龄，而与电脑的计算性能无关。 POW 工作量证明 Proof of Work，是指获得多少货币，取决于你挖矿贡献的工作量，电脑性能越好，分给你的矿就会越多。 Private Block Chains 私有链 私有区块链，数据记录在单一组织机构中，分权限对外开放，一般是单一企业机构构建。 Private Key 私钥 私钥是一串数据，它是允许您访问特定钱包中的令牌。 它们作为密码，除了地址的所有者之外，都被隐藏。 Public Address 公用地址 公共地址是公钥的密码哈希值。 它们作为可以在任何地方发布的电子邮件地址，与私钥不同。 Public Block Chains 公有链 公共网络中任何个人团体接入，任何节点均可参与共识过程。 Raft Raft Paxos协议的一种简单实现 Ring Signatures 环签名 用于隐匿发送发信息的技术，门罗币采用 RingCT 环加密交易 Ring Confidential Transactions，隐藏交易信息（包括交易双方信息和交易金额）的加密技术，门罗币采用 RLP RLP 编码 Recursive Length Prefix（递归长度前缀）是一种适用于任意二进制数据数组的编码。是以太坊中对象进行序列化/反序列化的主要编码方式。区块，交易等数据结构在持久化时会先经过RLP编码后再存储到持久层中。 RPCA 瑞波共识算法 Ripple Protocol Consensus Algorithm，类似PBFT的共识机制 Scrypt Scrypt 是一种由 Litecoin 使用加密算法。 与 SHA256 相比，它的速度更快，因为它不会占用很多处理时间。 Serenity 宁静 以太坊开发第四阶段（也是最后一个阶段） SHA-256 SHA-256 是比特币一些列数字货币使用的加密算法。 然而，它使用了大量的计算能力和处理时间，迫使矿工组建采矿池以获取收益。 Smart Contracts 智能合约 智能合约将可编程语言的业务规则编码到区块上，并由网络的参与者实施。部署在区块链系统中，一段合约代码，或一套以数字形式定义的承诺，包括合约参与方可以在其上执行承诺的协议。 Soft Fork 软分叉 软分叉与硬分叉不同之处在于，只有先前有效的交易才能使其无效。 由于旧节点将新的块识别为有效，所以软分叉基本上是向后兼容的。 这种分叉需要大多数矿工升级才能执行，而硬分叉需要所有节点就新版本达成一致。 Solidity Solidity 是 Ethereum 用于开发智能合约的编程语言。 SPV 简单支付验证 Simplified Payment Verification Stealth Address 隐匿地址 能够隐藏接收方信息 Swarm Swarm 去中心化的数据存储访问协议，以 ETH 作为激励。类似使用了 Filecoin 的 IPFS Sybil Attack 女巫攻击 P2P网络中的一种攻击形式：攻击者利用单个节点来伪造多个身份存在于 P2P 网络中，从而达到削弱网络的冗余性，降低网络健壮性，监视或干扰网络正常活动等目的 Testnet Testnet 开发商使用的测试区块链，它主要是用来防止改变在主链上的资产。 testrpc testrpc 以太坊节点客户端 Transaction Block 交易区块 聚集到一个块中的交易的集合，然后可以将其散列并添加到区块链中。 Transaction Fee 交易费 所有的加密货币交易都会涉及到一笔很小的手续费。这些手续费用加起来给矿工在成功处理区块时收到的区块奖励。 Truffle Truffle 一个基于以太坊技术的开发、测试和部署框架，旨在帮助以太坊开发者更容易开发去中心化应用（DApp） Turing Complete 图灵完备 图灵完备是指计算机中一切计算的问题都可以计算，这样的虚拟机或者编程语言称为图灵完备。一个例子是 Ethereum 虚拟机（EVM）。 Unlinkability 无关联性 whisper whisper 去中心化的通信协议 YC YC Y Combinator，成立于 2005 年是美国著名创业孵化器，扶持初创企业并为其提供创业指南（Airbnb，Dropbox，Stripe，Reddit, Docker, Coinbase 等），投资孵化过多个区块链项目 ZKRP 零知识范围证明 Zero Knownledge Range Proof，证明一个具体声明的真实性而不会泄露它试图证明的额外信息 ZK-SNARKs 零知识证明 ZK-Succint Non-interactive Arguments of Knownledge ","link":"https://tdmaker.github.io/faded/post/blockchain-profession-words/"},{"title":"区块链——六大核心算法","content":" 区块链技术六大核心算法 拜占庭协定 拜占庭的故事大概是这么说的：拜占庭帝国拥有巨大的财富，周围 10 个邻邦垂诞已久，但拜占庭高墙耸立，固若金汤，没有一个单独的邻邦能够成功入侵。任何单个邻邦入侵的都会失败，同时也有可能自身被其他 9 个邻邦入侵。拜占庭帝国防御能力如此之强，至少要有十个邻邦中的一半以上同时进攻，才有可能攻破。然而，如果其中的一个或者几个邻邦本身答应好一起进攻，但实际过程出现背叛，那么入侵者可能都会被歼灭。于是每一方都小心行事，不敢轻易相信邻国。这就是拜占庭将军问题。 在这个分布式网络里：每个将军都有一份实时与其他将军同步的消息账本。账本里有每个将军的签名都是可以验证身份的。如果有哪些消息不一致，可以知道消息不一致的是哪些将军。尽管有消息不一致的，只要超过半数同意进攻，少数服从多数，共识达成。 由此，在一个分布式的系统中，尽管有坏人，坏人可以做任意事情（不受protocol限制），比如不响应、发送错误信息、对不同节点发送不同决定、不同错误节点联合起来干坏事等等。但是，只要大多数人是好人，就完全有可能去中心化地实现共识。 非对称加密技术 在上述拜占庭协定中，如果 10 个将军中的几个同时发起消息，势必会造成系统的混乱，造成各说各的攻击时间方案，行动难以一致。谁都可以发起进攻的信息，但由谁来发出呢？其实这只要加入一个成本就可以了，即：一段时间内只有一个节点可以传播信息。当某个节点发出统一进攻的消息后，各个节点收到发起者的消息必须签名盖章，确认各自的身份。 在如今看来，非对称加密技术完全可以解决这个签名问题。非对称加密算法的加密和解密使用不同的两个密钥.这两个密钥就是我们经常听到的“公钥”和“私钥”。公钥和私钥一般成对出现, 如果消息使用公钥加密,那么需要该公钥对应的私钥才能解密; 同样，如果消息使用私钥加密,那么需要该私钥对应的公钥才能解密。 容错问题 我们假设在此网络中，消息可能会丢失、损坏、延迟、重复发送，并且接受的顺序与发送的顺序不一致。此外，节点的行为可以是任意的：可以随时加入、退出网络，可以丢弃消息、伪造消息、停止工作等，还可能发生各种人为或非人为的故障。我们的算法对由共识节点组成的共识系统，提供的容错能力，这种容错能力同时包含安全性和可用性，并适用于任何网络环境。 Paxos 算法（一致性算法） Paxos算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。 节点通信存在两种模型：共享内存和消息传递。Paxos 算法就是一种基于消息传递模型的一致性算法。 共识机制 区块链共识算法主要是工作量证明和权益证明。拿比特币来说，其实从技术角度来看可以把 PoW 看做重复使用的 Hashcash，生成工作量证明在概率上来说是一个随机的过程。开采新的机密货币，生成区块时，必须得到所有参与者的同意，那矿工必须得到区块中所有数据的 PoW 工作证明。与此同时矿工还要时时观察调整这项工作的难度，因为对网络要求是平均每 10 分钟生成一个区块。 分布式存储 分布式存储是一种数据存储技术，通过网络使用每台机器上的磁盘空间，并将这些分散的存储资源构成一个虚拟的存储设备，数据分散的存储在网络中的各个角落。所以，分布式存储技术并不是每台电脑都存放完整的数据，而是把数据切割后存放在不同的电脑里。就像存放 100 个鸡蛋，不是放在同一个篮子里，而是分开放在不同的地方，加起来的总和是 100 个。 ","link":"https://tdmaker.github.io/faded/post/blockchain-core-algorithms/"},{"title":"区块链——入门","content":"狭义来讲，区块链是一种按照时间顺序将数据区块以顺序相连的方式组合成的一种链式数据结构， 并以密码学方式保证的不可篡改和不可伪造的分布式账本。广义来讲，区块链技术是利用块链式数据结构来验证与存储数据、利用分布式节点共识算法来生成和更新数据、利用密码学的方式保证数据传输和访问的安全、利用由自动化脚本代码组成的智能合约来编程和操作数据的一种全新的分布式基础架构与计算范式。 1 涉及到的技术 密码学 分布式一致性协议 点对点网络通信技术 智能合约编程语言等。 2 区块链的分类 区块链严格定义上被划分为 3 种类型：公有链，私有链、和联盟链，但是在实际应用中单一的某种链常常无法满足用户需求，就出现了多种类型的结合，比如私有链 + 联盟链、联盟链 + 公有链等不同组合形式，最后产生了侧链和互联链。掌握了这 5 种区块链类型的各自特点，是理解和设计区块链网络系统架构的基础和核心，其重要性不言而喻。 2.1 公有链（Public blockchains） 公有链是对所有人公开，用户不需要注册和授权就能够匿名访问网络和区块，任何人都可以自由加入和退出网络，并参与记账和交易。 公有链是真正完全意义上的去中心化区块链，它通过密码学（非对称加密）算法保证了交易的安全性和不可篡改性，在陌生的网络（非安全）环境中，建立了互信和共识机制。在公有链中共识机制一般是工作量证明（POW）和权益证明（POS）。 公有链因为人人可参与，无需授权的特点又被称为非许可链，即不需要验证身份即可参与一切网络活动。目前比特币、以太坊、超级账本、大多数山寨币以及智能合约都是建立在公有链上，其中公有链的始祖是比特币区块链。 公有链适用于数字货币、电子商务、互联网金融、知识产权等应用场景。 2.2 联盟链（Consortium blockchains） 联盟链仅限于联盟成员，因其只针对成员开放全部或部分功能，所以联盟链上的读写权限、以及记账规则都按联盟规则来“私人定制”。联盟链上的共识过程由预先选好的节点控制，一般来说，他适用于机构间的交易、结算、或清算等 B2B 场景。比如人民银行开发一个基于联盟链的结算、清算系统，工建中农等银行作为联盟成员加入这个系统，获得相应的授权，就可以实时进行不同银行之间的实时结算、清算，与现有的中心化系统相比，这样不仅大大提升了结算、清算效率，几乎不需要人工参与，还能大大降低结算、清算成本。联盟链几乎不采用工作量证明共识机制而是采用权益证明或PBTF等共识算法。 联盟链由参与成员机构共同维护，并提供了对参与成员的管理、认证、授权、监控、审计等全套安全管理功能。2015 年成立的 R3 联盟，就是银行业的一个联盟链，目前已加入的成员多达 40 多个，包括世界著名的银行摩根大通、汇丰、高盛等。 联盟链适用于行业协会、高级别机构组织、大型连锁企业对下属单位和分管机构的交易和监管。 2.3 私有链（Private blockchain） 私有链对单独的个人或实体开放，仅在私有组织，比如公司内部使用，私有链上的读写权限，参与记账的权限都由私有组织来制定。比如企业内部的办公审批、财务审计；政府行业的预算和执行。私有链的主要价值在于提供安全、可塑源，不可篡改，自动执行，这是传统系统很难同时做到的。 因为私有链加入结点少，所以交易速度快。私有链的交易速度可以比任何其他的区块链都快，甚至接近了并不是一个区块链的常规数据库的速度。而且因为就算少量的节点，也都具有很高的信任度，所以并不需要每个节点来验证一个交易(无需挖矿)。 由于私有链和联盟链都需要授权加入和访问，私有链和联盟链也被称作许可链。 私有链适用于企业、组织内部。 2.4 侧链（Side Chains） 严格来说侧链不是区块链的一种类型，它只是在现实应用中，开发者对区块链的一种延伸（扩展），而特别取了个绰号。目前，市场上公开的虚拟货币系统，绝大多数都是基于比特币系统进行规则修改或扩展而来，因为比特币的设计规则已十分固定，难以做出较大修改和扩展，于是这些代币系统的开发者门干脆以比特币平台为基础，重构出一条区块链，然后使用新的规则，发布新的虚拟货币，这条重构出来的区块链就被称为侧链。普遍认为能和比特币区块链进行交互，并能与比特币挂钩的区块链就是侧链。 侧链目前主要适用于代币发行。 2.5 互联链（InteChains） 互联链就是各种不同的区块链之间的互联互通所形成的一个更大的生态区块链。比如电商平台公有链 + 物流公有链 + 物流联盟链 + 银行联盟链 +.....，它们之间的相互协作、通讯、共识、就是一个典型的互联链。 3 区块链的工作量证明机制 3.1 POW：proof of power, 工作量证明机制 PoW（工作量证明），也就是像比特币的挖矿机制，矿工通过把网络尚未记录的现有交易打包到一个区块，然后不断遍历尝试来寻找一个随机数，使得新区块加上随机数的哈希值满足一定的难度条件，例如前面 10 位是零。找到满足条件的随机数，就相当于确定了区块链最新的一个区块，也相当于获得了区块链的本轮记账权。矿工把满足挖矿难度条件的区块在网络中广播出去，全网其他节点在验证该区块满足挖矿难度条件，同时区块里的交易数据符合协议规范后，将各自把该区块链接到自己版本的区块链上，从而在全网形成对当前网络状态的共识。 优点：完全去中心化，节点自由进出，避免了建立和维护中心化信用机构的成本。只要网络破坏者的算力不超过网络总算力的 50%，网络的交易状态就能达成一致。 缺点：目前比特币挖矿造成大量的资源浪费；另外挖矿的激励机制也造成矿池算力的高度集中，背离了当初去中心化设计的初衷。更大的问题是 PoW 机制的共识达成的周期较长，每秒只能最多做 7 笔交易，不适合商业应用。 3.2 POS：proof of stake, 股权证明 PoS 权益证明，要求节点提供拥有一定数量的代币证明来获取竞争区块链记账权的一种分布式共识机制。如果单纯依靠代币余额来决定记账者必然使得富有者胜出，导致记账权的中心化，降低共识的公正性，因此不同的 PoS 机制在权益证明的基础上，采用不同方式来增加记账权的随机性来避免中心化。例如点点币（PeerCoin）PoS 机制中，拥有最多链龄长的比特币获得记账权的几率就越大。NXT 和 Blackcoin 则采用一个公式来预测下一个记账的节点。拥有多的代币被选为记账节点的概率就会大。未来以太坊也会从目前的 PoW 机制转换到 PoS 机制，从目前看到的资料看，以太坊的 PoS 机制将采用节点下赌注来赌下一个区块，赌中者有额外以太币奖，赌不中者会被扣以太币的方式来达成下一区块的共识。 优点：在一定程度上缩短了共识达成的时间，降低了 PoW 机制的资源浪费。 缺点：破坏者对网络攻击的成本低，网络的安全性有待验证。另外拥有代币数量大的节点获得记账权的几率更大，会使得网络的共识受少数富裕账户支配，从而失去公正性。 3.3 DPOS：delegated proof of stake, 共识机制，委托权以证明 DPoS（股份授权证明）机制，类似于董事会投票。比特股（bitshares）采用的 PoS 机制是持股者投票选出一定数量的见证人，每个见证人按序有两秒的权限时间生成区块，若见证人在给定的时间片不能生成区块，区块生成权限交给下一个时间片对应的见证人。持股人可以随时通过投票更换这些见证人。DPoS 的这种设计使得区块的生成更为快速，也更加节能。 优点：大幅缩小参与验证和记账节点的数量，可以达到秒级的共识验证。 缺点：选举固定数量的见证人作为记账候选人有可能不适合于完全去中心化的场景。另外在网络节点数少的场景，选举的见证人的代表性也不强。 4 分布式一致性算法 分布式一致性算法是基于传统的分布式一致性技术。其中有分为解决拜占庭将军问题的拜占庭容错算法，如 PBFT。另外解决非拜占庭问题的分布式一致性算法（Pasox、Raft）。该类算法目前是联盟链和私有链场景中常用的共识机制。 优点：实现秒级的快速共识机制，保证一致性。 缺点：去中心化程度不如公有链上的共识机制；更适合多方参与的多中心商业模式。 4.1 拜占庭将军问题/ Byzantine Generals Problem/ BGP 拜占庭将军问题由莱斯利·兰波特在其同名论文中提出的分布式对等网络通信容错问题。在分布式计算中，不同的计算机通过通讯交换信息达成共识而按照同一套协作策略行动。但有时候，系统中的成员计算机可能出错而发送错误的信息，用于传递信息的通讯网络也可能导致信息损坏，使得网络中不同的成员关于全体协作的策略得出不同结论，从而破坏系统一致性。拜占庭将军问题被认为是容错性问题中最难的问题类型之一。 4.2 改进型实用拜占庭容错/ Practical Byzantine Fault Tolerance/ PBFT PBET 共识机制是少数服从多数，根据信息在分布式网络中节点间互相交换后各节点列出所有得到的信息，一个节点代表一票，选择大多数的结果作为解决办法。PBET 将容错量控制在全部节点数的 1/3，即如只要有超过 2/3 的正常节点，整个系统便可正常运作。 4.3 授权拜占庭容错算法/ Delegated Byzantine Fault Tolerance /dBFT dBFT，是基于持有权益比例来选出专门的记账人（记账节点），然后记账人之间通过拜占庭容错算法（即少数服从多数的投票机制）来达成共识，决定动态参与节点。dBFT 可以容忍任何类型的错误，且专门的多个记账人使得每一个区块都有最终性、不会分叉。 4.4 联邦拜占庭协议/ Federated Byzantine Agreement / FBA 联邦拜占庭协议的主要特性是去中心化和任意行为容错，通过分布式的方法，达到法定人数或者节点足够的群体能达成共识，每一个节点不需要依赖相同的参与者就能决定信任的对象来完成共识。 5 图灵完备 一切可计算的问题都能计算，这样的虚拟机或者编程语言就叫图灵完备的。 5.1 图灵完备的系统和图灵完备的语言 一个能计算出每个图灵可计算函数（Turing-computable function）的计算系统被称为图灵完备的。一个语言是图灵完备的，意味着该语言的计算能力与一个通用图灵机 （Universal Turing Machine）相当，这也是现代计算机语言所能拥有的最高能力。 5.2 图灵完备深入解释 在可计算理论中，当一组数据操作的规则（一组指令集，编程语言，或者元胞自动机）满足任意数据按照一定的顺序可以计算出结果，被称为图灵完备（turing complete）。一个有图灵完备指令集的设备被定义为通用计算机。如果是图灵完备的，它（计算机设备）有能力执行条件跳转（“if” 和 “goto”语句）以及改变内存数据。 如果某个东西展现出了图灵完备，它就有能力表现出可以模拟原始计算机，而即使最简单的计算机也能模拟出最复杂的计算机。所有的通用编程语言和现代计算机的指令集都是图灵完备的（C++ template 就是图灵完备的），都能解决内存有限的问题。图灵完备的机器都被定义有无限内存，但是机器指令集却通常定义为只工作在特定的，有限数量的 RAM 上。 5.3 图灵完备优缺点 图灵完备意味着你的语言可以做到能够用图灵机能做到的所有事情，可以解决所有的可计算问题。 图灵不完备也不是没有意义，有些场景我们需要限制语言本身。 如限制循环和递归，可以保证该语言能写的程序一定是终止的。图灵不完备会更安全些，图灵完备会更智能些。 5.4比特币的图灵非完备性 比特币脚本语言包含许多操作，但都故意限定为一种重要的方式——没有循环或者复杂流控制功能以外的其他条件的流控制。这样就保证了脚本语言的图灵非完备性，这意味着脚本的复杂性有限，交易可执行的次数也可预见。脚本并不是一种通用语言，施加的这些限制确保该语言不被用于创造无限循环或其它类型的逻辑炸弹，这样的炸弹可以植入在一笔交易中，通过引起拒绝服务的方式攻击比特币网络。受限制的语言能防止交易激活机制被人当作薄弱环节而加以利用。 5.5 以太坊是一个图灵完备的区块链 以太坊的核心就是能够运行“无所不能”的智能合约，拥有图灵完备的编程语言，比如 Solidity，可以解决所有可计算问题。 6 零知识证明 “零知识证明”－zero-knowledge proof，是由S.Goldwasser、S.Micali及C.Rackoff在20世纪80年代初提出的。它指的是证明者能够在不向验证者提供任何有用的信息的情况下，使验证者相信某个论断是正确的。零知识证明实质上是一种涉及两方或更多方的协议，即两方或更多方完成一项任务所需采取的一系列步骤。证明者向验证者证明并使其相信自己知道或拥有某一消息，但证明过程不能向验证者泄漏任何关于被证明消息的信息。大量事实证明，零知识证明在密码学中非常有用。如果能够将零知识证明用于验证，将可以有效解决许多问题。 6.1 定义 零知识证明满足三个属性： 如果语句为真，诚实的验证者（即，正确遵循协议的验证者）将由诚实的证明者确信这一事实。 如果语句为假，不排除有概率欺骗者可以说服诚实的验证者它是真的。 如果语句为真，证明者的目的就是向验证者证明并使验证者相信自己知道或拥有某一消息，而在证明过程中不可向验证者泄漏任何有关被证明消息的内容。 零知识证明并不是数学意义上的证明，因为它存在小概率的误差，欺骗者有可能通过虚假陈述骗过证明者。换句话来说，零知识证明是概率证明而不是确定性证明。但是也存在有技术能将误差降低到可以忽略的值。 零知识的形式定义必须使用一些计算模型，最常见的是图灵机的计算模型。 6.2 证明举例 6.2.1 案例一 A 要向 B 证明自己拥有某个房间的钥匙，假设该房间只能用钥匙打开锁，而其他任何方法都打不开。这时有 2 个方法： A 把钥匙出示给 B，B 用这把钥匙打开该房间的锁，从而证明 A 拥有该房间的正确的钥匙。 B 确定该房间内有某一物体，A 用自己拥有的钥匙打开该房间的门，然后把物体拿出来出示给 B，从而证明自己确实拥有该房间的钥匙。 后面的方法 2 属于零知识证明。好处在于在整个证明的过程中，B 始终不能看到钥匙的样子，从而避免了钥匙的泄露。 6.2.2 案例二 A 拥有 B 的公钥，A 没有见过 B，而 B 见过 A 的照片，偶然一天 2 人见面了，B 认出了 A，但 A 不能确定面前的人是否是 B，这时 B 要向 A 证明自己是 B，也有 2 个方法。 B 把自己的私钥给 A，A 用这个私钥对某个数据加密，然后用 B 的公钥解密，如果正确，则证明对方确实是B。 A 给出一个随机值，B 用自己的私钥对其加密，然后把加密后的数据交给 A，A 用 B 的公钥解密，如果能够得到原来的随机值，则证明对方是 B。 后面方法 2 属于零知识证明。 ","link":"https://tdmaker.github.io/faded/post/blockchain-introduction/"},{"title":"正则表达式——完整版教程","content":" JS正则表达式完整教程（略长） 引言 本文内容共有七章，用 JavaScript 语言完整地讨论了正则表达式的方方面面。 具体章节如下： 引言 第 1 章 正则表达式字符匹配攻略 第 2 章 正则表达式位置匹配攻略 第 3 章 正则表达式括号的作用 第 4 章 正则表达式回溯法原理 第 5 章 正则表达式的拆分 第 6 章 正则表达式的构建 第 7 章 正则表达式编程后记 下面简单地说说每一章都讨论了什么。 正则是匹配模式，要么匹配字符，要么匹配位置。 第 1 章和第 2 章以这个角度去讲解了正则的基础。 在正则中可以使用括号捕获数据，要么在 API 中进行分组引用，要么在正则里进行反向引用。 这是第 3 章的主题，讲解了正则中括号的作用。 学习正则表达式，是需要了解其匹配原理的。第 4 章，讲解了正则了正则表达式的回溯法原理。另外在第 6 章里，也讲解了正则的表达式的整体工作原理。 不仅能看懂别人的正则，还要自己会写正则。 第 5 章，是从读的角度，去拆分一个正则表达式，而第 6 章是从写的角度，去构建一个正则表达式。 学习正则，是为了在真实世界里应用的。 第 7 章讲解了正则的用法，和相关 API 需要注意的地方。 第 1 章 正则表达式字符匹配攻略 正则表达式是匹配模式，要么匹配字符，要么匹配位置。请记住这句话。 然而关于正则如何匹配字符的学习，大部分人都觉得这块比较杂乱。 毕竟元字符太多了，看起来没有系统性，不好记。本章就解决这个问题。 内容包括： 两种模糊匹配 字符组 量词 多选分支 案例分析 1.1 两种模糊匹配 如果正则只有精确匹配是没多大意义的，比如 /hello/，也只能匹配字符串中的 &quot;hello&quot; 这个子串。 const regex = /hello/; console.log(regex.test('hello')); // =&gt; true 正则表达式之所以强大，是因为其能实现模糊匹配。而模糊匹配，有两个方向上的“模糊”：横向模糊匹配和纵向模糊匹配。 1.1.1 横向模糊匹配 横向模糊指的是，一个正则可匹配的字符串的长度不是固定的，可以是多种情况的。其实现的方式是使用量词。譬如 {m,n}，表示连续出现最少 m 次，最多 n 次。比如 /ab{2,5}c/ 表示匹配这样一个字符串：第一个字符是 &quot;a&quot;，接下来是 2 到 5 个字符是 &quot;b&quot;，最后是字符 &quot;c&quot;。测试如下： const regex = /ab{2,5}c/g; const string = 'abc abbc abbbc abbbbc abbbbbc abbbbbbc'; console.log(string.match(regex)); // =&gt; [&quot;abbc&quot;, &quot;abbbc&quot;, &quot;abbbbc&quot;, &quot;abbbbbc&quot;] 注意：案例中用的正则是 /ab{2,5}c/g，后面多了 g，它是正则的一个修饰符。表示全局匹配，即在目标字符串中按顺序找到满足匹配模式的所有子串，强调的是“所有”，而不只是“第一个”。g 是单词 global 的首字母。 1.1.2 纵向模糊匹配 纵向模糊指的是，一个正则匹配的字符串，具体到某一位字符时，它可以不是某个确定的字符，可以有多种可能。其实现的方式是使用字符组。譬如 [abc]，表示该字符是可以字符 &quot;a&quot;、&quot;b&quot;、&quot;c&quot; 中的任何一个。比如 /a[123]b/ 可以匹配如下三种字符串：&quot;a1b&quot;、&quot;a2b&quot;、&quot;a3b&quot;。测试如下： const regex = /a[123]b/g; const string = 'a0b a1b a2b a3b a4b'; console.log(string.match(regex)); // =&gt; [&quot;a1b&quot;, &quot;a2b&quot;, &quot;a3b&quot;] 以上就是本章讲的主体内容，只要掌握横向和纵向模糊匹配，就能解决很大部分正则匹配问题。 接下来的内容就是展开说了，如果对此都比较熟悉的话，可以跳过，直接看本章案例那节。 1.2 字符组 需要强调的是，虽叫字符组（字符类），但只是其中一个字符。例如 [abc]，表示匹配一个字符，它可以是 &quot;a&quot;、&quot;b&quot;、&quot;c&quot; 之一。 1.2.1 范围表示法 如果字符组里的字符特别多的话，怎么办？可以使用范围表示法。 比如 [123456abcdefGHIJKLM]，可以写成 [1-6a-fG-M]。用连字符 - 来省略和简写。 因为连字符有特殊用途，那么要匹配 &quot;a&quot;、&quot;-&quot;、&quot;z&quot; 这三者中任意一个字符，该怎么做呢？ 不能写成 [a-z]，因为其表示小写字符中的任何一个字符。 可以写成如下的方式：[-az] 或[az-] 或 [a\\-z]。即要么放在开头，要么放在结尾，要么转义。总之不会让引擎认为是范围表示法就行了。 1.2.2 排除字符组 纵向模糊匹配，还有一种情形就是，某位字符可以是任何东西，但就不能是 &quot;a&quot;、&quot;b&quot;、&quot;c&quot;。 此时就是排除字符组（反义字符组）的概念。例如 [^abc]，表示是一个除 &quot;a&quot;、&quot;b&quot;、&quot;c&quot; 之外的任意一个字符。字符组的第一位放 ^（脱字符），表示求反的概念。 当然，也有相应的范围表示法。 1.2.3 常见的简写形式 有了字符组的概念后，一些常见的符号我们也就理解了。因为它们都是系统自带的简写形式。 \\d 就是 [0-9]。表示是一位数字。记忆方式：其英文是 digit（数字）； \\D 就是 [^0-9]。表示除数字外的任意字符； \\w 就是 [0-9a-zA-Z_]。表示数字、大小写字母和下划线。记忆方式：w 是 word 的简写，也称单词字符； \\W 是 [^0-9a-zA-Z_]。非单词字符； \\s是 [ \\t\\v\\n\\r\\f]。表示空白符，包括空格、水平制表符、垂直制表符、换行符、回车符、换页符。记忆方式：s 是 space character 的首字母； \\S 是 [^ \\t\\v\\n\\r\\f]。 非空白符。 . 就是 [^\\n\\r\\u2028\\u2029]。通配符，表示几乎任意字符。换行符、回车符、行分隔符和段分隔符除外。记忆方式：想想省略号...中的每个点，都可以理解成占位符，表示任何类似的东西。 如果要匹配任意字符怎么办？可以使用 [\\d\\D]、[\\w\\W]、[\\s\\S] 和 [^] 中任何的一个。 1.3 量词 量词也称重复。掌握 {m,n} 的准确含义后，只需要记住一些简写形式。 1.3.1 简写形式 {m,} 表示至少出现 m 次。 {m} 等价于 {m,m}，表示出现 m 次。 ? 等价于 {0,1}，表示出现或者不出现。记忆方式：问号的意思表示，有吗？ + 等价于 {1,}，表示出现至少一次。记忆方式：加号是追加的意思，得先有一个，然后才考虑追加。 * 等价于 {0,}，表示出现任意次，有可能不出现。记忆方式：看看天上的星星，可能一颗没有，可能零散有几颗，可能数也数不过来。 1.3.2 贪婪匹配和惰性匹配 看如下的例子： const regex = /\\d{2,5}/g; const string = '123 1234 12345 123456'; console.log(string.match(regex)); // =&gt; [&quot;123&quot;, &quot;1234&quot;, &quot;12345&quot;, &quot;12345&quot;] 其中正则 /\\d{2,5}/，表示数字连续出现 2 到 5 次。会匹配 2 位、3 位、4 位、5 位连续数字。 但是其是贪婪的，它会尽可能多的匹配。你能给我 6 个，我就要 5 个。你能给我3个，我就要 3 个。反正只要在能力范围内，越多越好。 我们知道有时贪婪不是一件好事（请看文章最后一个例子）。而惰性匹配，就是尽可能少的匹配： const regex = /\\d{2,5}?/g; const string = '123 1234 12345 123456'; console.log(string.match(regex)); // =&gt; [&quot;12&quot;, &quot;12&quot;, &quot;34&quot;, &quot;12&quot;, &quot;34&quot;, &quot;12&quot;, &quot;34&quot;, &quot;56&quot;] 其中 /\\d{2,5}?/ 表示，虽然 2 到 5 次都行，当 2 个就够的时候，就不在往下尝试了。 通过在量词后面加个问号就能实现惰性匹配，因此所有惰性匹配情形如下： {m,n}? {m,}? ?? +? *? 1.4 多选分支 一个模式可以实现横向和纵向模糊匹配。而多选分支可以支持多个子模式任选其一。 具体形式如下：(p1|p2|p3)，其中 p1、p2 和 p3 是子模式，用 |（管道符）分隔，表示其中任何之一。 例如要匹配 &quot;good&quot; 和 &quot;nice&quot; 可以使用 /good|nice/。测试如下： const regex = /good|nice/g; const string = 'good idea, nice try.'; console.log(string.match(regex)); // =&gt; [&quot;good&quot;, &quot;nice&quot;] 但有个事实我们应该注意，比如我用 /good|goodbye/，去匹配 &quot;goodbye&quot; 字符串时，结果是 &quot;good&quot;： const regex = /good|goodbye/g; const string = 'goodbye'; console.log(string.match(regex)); // =&gt; [&quot;good&quot;] 而把正则改成 /goodbye|good/，结果是： var regex = /goodbye|good/g; var string = 'goodbye'; console.log(string.match(regex)); // =&gt; [&quot;goodbye&quot;] 也就是说，分支结构也是惰性的，即当前面的匹配上了，后面的就不再尝试了。 1.5 案例分析 匹配字符，无非就是字符组、量词和分支结构的组合使用罢了。 下面找几个例子演练一下（其中，每个正则并不是只有唯一写法）： 1.5.1 匹配 16 进制颜色值 要求匹配： #ffbbad #Fc01DF #FFF #ffE 分析： 表示一个 16 进制字符，可以用字符组 [0-9a-fA-F]。 其中字符可以出现 3 或 6 次，需要是用量词和分支结构。 使用分支结构时，需要注意顺序。 正则如下： const regex = /#([0-9a-fA-F]{6}|[0-9a-fA-F]{3})/g; const string = '#ffbbad #Fc01DF #FFF #ffE'; console.log(string.match(regex)); // =&gt; [&quot;#ffbbad&quot;, &quot;#Fc01DF&quot;, &quot;#FFF&quot;, &quot;#ffE&quot;] 1.5.2 匹配时间 以 24 小时制为例。 要求匹配： 23:59 02:07 分析： 共 4 位数字，第一位数字可以为 [0-2]； 当第 1 位为 2 时，第2位可以为 [0-3]，其他情况时，第 2 位为 [0-9]； 第 3 位数字为 [0-5]，第 4 位为 [0-9]。 正则如下： const regex = /^([01][0-9]|[2][0-3]):[0-5][0-9]$/; console.log(regex.test('23:59')); console.log(regex.test('02:07')); // =&gt; true // =&gt; true 如果也要求匹配 7:9，也就是说时分前面的 0 可以省略。 此时正则变成： const regex = /^(0?[0-9]|1[0-9]|[2][0-3]):(0?[0-9]|[1-5][0-9])$/; console.log( regex.test('23:59') ); console.log( regex.test('02:07') ); console.log( regex.test('7:9') ); // =&gt; true // =&gt; true // =&gt; true 1.5.3 匹配日期 比如 yyyy-mm-dd 格式为例。 要求匹配： 2017-06-10 分析： 年，四位数字即可，可用 [0-9]{4}； 月，共 12 个月，分两种情况 01、02、……、09 和 10、11、12，可用 (0[1-9]|1[0-2])； 日，最大 31 天，可用 (0[1-9]|[12][0-9]|3[01])。 正则如下： const regex = /^[0-9]{4}-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])$/; console.log(regex.test('2017-06-10')); // =&gt; true 1.5.4 Window 操作系统文件路径 要求匹配： F:\\study\\javascript\\regex\\regular expression.pdf F:\\study\\javascript\\regex\\ F:\\study\\javascript -F:\\ 分析： 整体模式是: 盘符:\\文件夹\\文件夹\\文件夹\\； 其中匹配 F:\\，需要使用[a-zA-Z]:\\\\，其中盘符不区分大小写，注意 \\ 字符需要转义； 文件名或者文件夹名，不能包含一些特殊字符，此时我们需要排除字符组 [^\\\\:*&lt;&gt;|&quot;?\\r\\n/] 来表示合法字符。另外不能为空名，至少有一个字符，也就是要使用量词 +。因此匹配 &quot;文件夹&quot;，可用[^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+\\\\； 另外“文件夹\\”，可以出现任意次。也就是 ([^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+\\\\)*。其中括号提供子表达式； 路径的最后一部分可以是“文件夹”，没有 \\，因此需要添加 ([^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+)?。 最后拼接成了一个看起来比较复杂的正则： const regex = /^[a-zA-Z]:\\\\([^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+\\\\)*([^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+)?$/; console.log(regex.test('F:\\\\study\\\\javascript\\\\regex\\\\regular expression.pdf')); console.log(regex.test('F:\\\\study\\\\javascript\\\\regex\\\\')); console.log(regex.test('F:\\\\study\\\\javascript')); console.log(regex.test('F:\\\\')); // =&gt; true // =&gt; true // =&gt; true // =&gt; true 其中，JS 中字符串表示 \\ 时，也要转义。 1.5.5 匹配 id 要求从 &lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt; 提取出 id=&quot;container&quot;。 可能最开始想到的正则是： const regex = /id=&quot;.*&quot;/ const string = '&lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt;'; console.log(string.match(regex)[0]); // =&gt; id=&quot;container&quot; class=&quot;main&quot; 因为 . 是通配符，本身就匹配双引号的，而量词 * 又是贪婪的，当遇到 container 后面双引号时，不会停下来，会继续匹配，直到遇到最后一个双引号为止。 解决之道，可以使用惰性匹配： const regex = /id=&quot;.*?&quot;/ const string = '&lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt;'; console.log(string.match(regex)[0]); // =&gt; id=&quot;container&quot; 当然，这样也会有个问题。效率比较低，因为其匹配原理会涉及到“回溯”这个概念（这里也只是顺便提一下，第四章会详细说明）。可以优化如下： const regex = /id=&quot;[^&quot;]*&quot;/ const string = '&lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt;'; console.log(string.match(regex)[0]); // =&gt; id=&quot;container&quot; 第 1 章小结 字符匹配相关的案例，挺多的，不一而足。 掌握字符组和量词就能解决大部分常见的情形，也就是说，当你会了这二者，JS 正则算是入门了。 第 2 章 正则表达式位置匹配攻略 正则表达式是匹配模式，要么匹配字符，要么匹配位置。请记住这句话。 然而大部分人学习正则时，对于匹配位置的重视程度没有那么高。 本章讲讲正则匹配位置的总总。 内容包括： 什么是位置？ 如何匹配位置？ 位置的特性 几个应用实例分析 2.1 什么是位置呢？ 位置是相邻字符之间的位置。比如，下图中箭头所指的地方： 2.2. 如何匹配位置呢？ 在 ES5 中，共有 6 个锚字符：^ $ \\b \\B (?=p) (?!p)。 2.2.1 ^ 和 $ ^（脱字符）匹配开头，在多行匹配中匹配行开头； $（美元符号）匹配结尾，在多行匹配中匹配行结尾。 比如我们把字符串的开头和结尾用“#”替换（位置是可以替换成字符的！）： const result = 'hello'.replace(/^|$/g, '#'); console.log(result); // =&gt; &quot;#hello#&quot; 多行匹配模式时，二者是行的概念，这个需要我们的注意： const result = 'I\\nlove\\njavascript'.replace(/^|$/gm, '#'); console.log(result); /* #I# #love# #javascript# */ 2.2.2 \\b 和 \\B \\b 是单词边界，具体就是 \\w 和 \\W 之间的位置，也包括 \\w 和 ^ 之间的位置，也包括 \\w和 $ 之间的位置。 比如一个文件名是 &quot;[JS] Lesson_01.mp4&quot; 中的 \\b，如下： const result = '[JS] Lesson_01.mp4'.replace(/\\b/g, '#'); console.log(result); // =&gt; &quot;[#JS#] #Lesson_01#.#mp4#&quot; 为什么是这样呢？这需要仔细看看。 首先，我们知道，\\w 是字符组 [0-9a-zA-Z_] 的简写形式，即 \\w 是字母数字或者下划线的中任何一个字符。而 \\W 是排除字符组 [^0-9a-zA-Z_] 的简写形式，即 \\W 是 \\w 以外的任何一个字符。此时我们可以看看 &quot;[#JS#] #Lesson_01#.#mp4#&quot; 中的每一个 &quot;#&quot;，是怎么来的。 第一个&quot;#&quot;，两边是 &quot;[&quot;与 &quot;J&quot;，是 \\W 和 \\w 之间的位置； 第二个&quot;#&quot;，两边是 &quot;S&quot; 与 &quot;]&quot;，也就是 \\w 和 \\W 之间的位置； 第三个&quot;#&quot;，两边是空格与 &quot;L&quot;，也就是 \\W 和 \\w 之间的位置； 第四个&quot;#&quot;，两边是 &quot;1&quot; 与 &quot;.&quot;，也就是 \\w 和 \\W 之间的位置； 第五个&quot;#&quot;，两边是 &quot;.&quot;与 &quot;m&quot;，也就是 \\W 和 \\w 之间的位置； 第六个&quot;#&quot;，其对应的位置是结尾，但其前面的字符 &quot;4&quot; 是 \\w，即 \\w 和 $ 之间的位置。 知道了 \\b 的概念后，那么 \\B 也就相对好理解了。 \\B 就是 \\b 的反面的意思，非单词边界。例如在字符串中所有位置中，扣掉 \\b，剩下的都是 \\B 的。 具体说来就是 \\w 与 \\w、\\W 与 \\W、^ 与 \\W，\\W 与 $ 之间的位置。 比如上面的例子，把所有 \\B 替换成 &quot;#&quot;： const result = '[JS] Lesson_01.mp4'.replace(/\\B/g, '#'); console.log(result); // =&gt; &quot;#[J#S]# L#e#s#s#o#n#_#0#1.m#p#4&quot; 2.2.3 (?=p) 和 (?!p) (?=p)，其中 p 是一个子模式，即 p 前面的位置。 比如 (?=l)，表示 &quot;l&quot; 字符前面的位置，例如： const result = 'hello'.replace(/(?=l)/g, '#'); console.log(result); // =&gt; &quot;he#l#lo&quot; 而 (?!p) 就是 (?=p) 的反面意思，比如： const result = 'hello'.replace(/(?!l)/g, '#'); console.log(result); // =&gt; &quot;#h#ell#o#&quot; 二者的学名分别是 positive lookahead 和 negative lookahead。 中文翻译分别是正向先行断言和负向先行断言。 ES6中，还支持 positive lookbehind 和 negative lookbehind。 具体是 (?&lt;=p) 和 (?&lt;!p)。 也有书上把这四个东西，翻译成环视，即看看右边或看看左边。 但一般书上，没有很好强调这四者是个位置。 比如 (?=p)，一般都理解成：要求接下来的字符与 p 匹配，但不能包括 p 的那些字符。 而在本人看来 (?=p) 就与 ^ 一样好理解，就是 p 前面的那个位置。 2.3. 位置的特性 对于位置的理解，我们可以理解成空字符&quot;&quot;。 比如 &quot;hello&quot; 字符串等价于如下的形式： 'hello' == '' + 'h' + '' + 'e' + '' + 'l' + '' + 'l' + 'o' + ''; 也等价于： 'hello' == '' + '' + 'hello'; 因此，把 /^hello$/ 写成 /^^hello$$$/，是没有任何问题的： const result = /^^hello$$$/.test('hello'); console.log(result); // =&gt; true 甚至可以写成更复杂的： const result = /(?=he)^^he(?=\\w)llo$\\b\\b$/.test('hello'); console.log(result); // =&gt; true 也就是说字符之间的位置，可以写成多个。 把位置理解空字符，是对位置非常有效的理解方式。 2.4 相关案例 2.4.1 不匹配任何东西的正则 让你写个正则不匹配任何东西 easy，/.^/ 因为此正则要求只有一个字符，但该字符后面是开头。 2.4.2 数字的千位分隔符表示法 比如把 &quot;12345678&quot;，变成 &quot;12,345,678&quot;。 可见是需要把相应的位置替换成 &quot;,&quot;。 思路是什么呢？ 2.4.2.1 弄出最后一个逗号 使用 (?=\\d{3}$) 就可以做到： const result = '12345678'.replace(/(?=\\d{3}$)/g, ',') console.log(result); // =&gt; &quot;12345,678&quot; 2.4.2.2 弄出所有的逗号 因为逗号出现的位置，要求后面 3 个数字一组，也就是 \\d{3} 至少出现一次。 此时可以使用量词 +： const result = '12345678'.replace(/(?=(\\d{3})+$)/g, ',') console.log(result); // =&gt; &quot;12,345,678&quot; 2.4.2.3 匹配其余案例 写完正则后，要多验证几个案例，此时我们会发现问题： const result = '123456789'.replace(/(?=(\\d{3})+$)/g, ',') console.log(result); // =&gt; &quot;,123,456,789&quot; 因为上面的正则，仅仅表示把从结尾向前数，一但是 3 的倍数，就把其前面的位置替换成逗号。因此才会出现这个问题。 怎么解决呢？我们要求匹配的到这个位置不能是开头。 我们知道匹配开头可以使用 ^，但要求这个位置不是开头怎么办？easy，(?!^)，你想到了吗？测试如下： const string1 = '12345678'; const string2 = '123456789'; const reg = /(?!^)(?=(\\d{3})+$)/g; const result = string1.replace(reg, ',') console.log(result); // =&gt; &quot;12,345,678&quot; result = string2.replace(reg, ','); console.log(result); // =&gt; &quot;123,456,789&quot; 2.4.2.4 支持其他形式 如果要把 &quot;12345678 123456789&quot; 替换成 &quot;12,345,678 123,456,789&quot;。 此时我们需要修改正则，把里面的开头 ^ 和结尾 $，替换成 \\b： const string = '12345678 123456789'; const reg = /(?!\\b)(?=(\\d{3})+\\b)/g; const result = string.replace(reg, ','); console.log(result); // =&gt; &quot;12,345,678 123,456,789&quot; 其中 (?!\\b) 怎么理解呢？ 要求当前是一个位置，但不是 \\b 前面的位置，其实 (?!\\b) 说的就是 \\B。 因此最终正则变成了：/\\B(?=(\\d{3})+\\b)/g。 2.4.3 验证密码问题 密码长度 6-12 位，由数字、小写字符和大写字母组成，但必须至少包括 2 种字符。 此题，如果写成多个正则来判断，比较容易。但要写成一个正则就比较困难。 那么，我们就来挑战一下。看看我们对位置的理解是否深刻。 2.4.3.1 简化 不考虑“但必须至少包括 2 种字符”这一条件。我们可以容易写出： const reg = /^[0-9A-Za-z]{6,12}$/; 2.4.3.2 判断是否包含有某一种字符 假设，要求的必须包含数字，怎么办？此时我们可以使用 (?=.*[0-9]) 来做。 因此正则变成： const reg = /(?=.*[0-9])^[0-9A-Za-z]{6,12}$/; 2.4.3.3 同时包含具体两种字符 比如同时包含数字和小写字母，可以用 (?=.*[0-9])(?=.*[a-z]) 来做。 因此正则变成： const reg = /(?=.*[0-9])(?=.*[a-z])^[0-9A-Za-z]{6,12}$/; 2.4.3.4 解答 我们可以把原题变成下列几种情况之一： 同时包含数字和小写字母； 同时包含数字和大写字母； 同时包含小写字母和大写字母； 同时包含数字、小写字母和大写字母。 以上的 4 种情况是或的关系（实际上，可以不用第 4 条）。 最终答案是： const reg = /((?=.*[0-9])(?=.*[a-z])|(?=.*[0-9])(?=.*[A-Z])|(?=.*[a-z])(?=.*[A-Z]))^[0-9A-Za-z]{6,12}$/; console.log(reg.test('1234567')); // false 全是数字 console.log(reg.test('abcdef')); // false 全是小写字母 console.log(reg.test('ABCDEFGH')); // false 全是大写字母 console.log(reg.test('ab23C')); // false 不足 6 位 console.log(reg.test('ABCDEF234')); // true 大写字母和数字 console.log(reg.test('abcdEF234')); // true 三者都有 2.4.3.5 解惑 上面的正则看起来比较复杂，只要理解了第二步，其余就全部理解了。 /(?=.*[0-9])^[0-9A-Za-z]{6,12}$/ 对于这个正则，我们只需要弄明白 (?=.*[0-9])^即可。 分开来看就是 (?=.*[0-9]) 和 ^。 表示开头前面还有个位置（当然也是开头，即同一个位置，想想之前的空字符类比）。 (?=.*[0-9]) 表示该位置后面的字符匹配 .*[0-9]，即，有任何多个任意字符，后面再跟个数字。 翻译成大白话，就是接下来的字符，必须包含个数字。 2.4.3.6 另外一种解法 “至少包含两种字符”的意思就是说，不能全部都是数字，也不能全部都是小写字母，也不能全部都是大写字母。 那么要求“不能全部都是数字”，怎么做呢？(?!p) 出马！ 对应的正则是： const reg = /(?!^[0-9]{6,12}$)^[0-9A-Za-z]{6,12}$/; 三种“都不能”呢？ 最终答案是： const reg = /(?!^[0-9]{6,12}$)(?!^[a-z]{6,12}$)(?!^[A-Z]{6,12}$)^[0-9A-Za-z]{6,12}$/; console.log(reg.test('1234567')); // false 全是数字 console.log(reg.test('abcdef')); // false 全是小写字母 console.log(reg.test('ABCDEFGH')); // false 全是大写字母 console.log(reg.test('ab23C')); // false 不足 6 位 console.log(reg.test('ABCDEF234')); // true 大写字母和数字 console.log(reg.test('abcdEF234')); // true 三者都有 第 2 章小结 位置匹配相关的案例，挺多的，不一而足。 掌握匹配位置的这 6 个锚字符，给我们解决正则问题一个新工具。 第 3 章 正则表达式括号的作用 不管哪门语言中都有括号。正则表达式也是一门语言，而括号的存在使这门语言更为强大。 对括号的使用是否得心应手，是衡量对正则的掌握水平的一个侧面标准。 括号的作用，其实三言两语就能说明白，括号提供了分组，便于我们引用它。 引用某个分组，会有两种情形：在 JavaScript 里引用它，在正则表达式里引用它。 本章内容虽相对简单，但我也要写长点。内容包括： 分组和分支结构 引用分组 反向引用 非捕获分组 相关案例 3.1 分组和分支结构 这二者是括号最直觉的作用，也是最原始的功能。 3.1.1 分组 我们知道 /a+/ 匹配连续出现的 &quot;a&quot;，而要匹配连续出现的 &quot;ab&quot; 时，需要使用 /(ab)+/。 其中括号是提供分组功能，使量词 + 作用于 &quot;ab&quot; 这个整体，测试如下： const regex = /(ab)+/g; const string = 'ababa abbb ababab'; console.log(string.match(regex)); // =&gt; [&quot;abab&quot;, &quot;ab&quot;, &quot;ababab&quot;] 3.1.2 分支结构 而在多选分支结构 (p1|p2) 中，此处括号的作用也是不言而喻的，提供了子表达式的所有可能。 比如，要匹配如下的字符串： I love JavaScript I love Regular Expression 可以使用正则： const regex = /^I love (JavaScript|Regular Expression)$/; console.log(regex.test('I love JavaScript')); console.log(regex.test('I love Regular Expression')); // =&gt; true // =&gt; true 如果去掉正则中的括号，即 /^I love JavaScript|Regular Expression$/，匹配字符串是 &quot;I love JavaScript&quot; 和 &quot;Regular Expression&quot;，当然这不是我们想要的。 3.2 引用分组 这是括号一个重要的作用，有了它，我们就可以进行数据提取，以及更强大的替换操作。 而要使用它带来的好处，必须配合使用实现环境的 API。 以日期为例。假设格式是 yyyy-mm-dd 的，我们可以先写一个简单的正则： const regex = /\\d{4}-\\d{2}-\\d{2}/; 然后再修改成括号版的： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; 为什么要使用这个正则呢？ 3.2.1 提取数据 比如提取出年、月、日，可以这么做： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; console.log(string.match(regex)); // =&gt; [&quot;2017-06-12&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;12&quot;, index: 0, input: &quot;2017-06-12&quot;] match 返回的一个数组，第一个元素是整体匹配结果，然后是各个分组（括号里）匹配的内容，然后是匹配下标，最后是输入的文本。（注意：如果正则是否有修饰符 g，match 返回的数组格式是不一样的）。 另外也可以使用正则对象的 exec 方法： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; console.log(regex.exec(string)); // =&gt; [&quot;2017-06-12&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;12&quot;, index: 0, input: &quot;2017-06-12&quot;] 同时，也可以使用构造函数的全局属性 $1 至 $9 来获取： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; regex.test(string); // 正则操作即可，例如 //regex.exec(string); //string.match(regex); console.log(RegExp.$1); // &quot;2017&quot; console.log(RegExp.$2); // &quot;06&quot; console.log(RegExp.$3); // &quot;12&quot; 3.2.2 替换数据 比如，想把 yyyy-mm-dd 格式，替换成 mm/dd/yyyy 怎么做？ const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; const result = string.replace(regex, '$2/$3/$1'); console.log(result); // =&gt; &quot;06/12/2017&quot; 其中 replace 中的，第二个参数里用 $1、$2、$3 指代相应的分组。等价于如下的形式： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; const result = string.replace(regex, function() { return RegExp.$2 + '/' + RegExp.$3 + '/' + RegExp.$1; }); console.log(result); // =&gt; &quot;06/12/2017&quot; 也等价于： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; const result = string.replace(regex, function(match, year, month, day) { return month + '/' + day + '/' + year; }); console.log(result); // =&gt; &quot;06/12/2017&quot; 3.3 反向引用 除了使用相应 API 来引用分组，也可以在正则本身里引用分组。但只能引用之前出现的分组，即反向引用。 还是以日期为例。 比如要写一个正则支持匹配如下三种格式： 2016-06-12 2016/06/12 2016.06.12 最先可能想到的正则是： const regex = /\\d{4}(-|\\/|\\.)\\d{2}(-|\\/|\\.)\\d{2}/; const string1 = '2017-06-12'; const string2 = '2017/06/12'; const string3 = '2017.06.12'; const string4 = '2016-06/12'; console.log(regex.test(string1)); // true console.log(regex.test(string2)); // true console.log(regex.test(string3)); // true console.log(regex.test(string4)); // true 其中 / 和 . 需要转义。虽然匹配了要求的情况，但也匹配 &quot;2016-06/12&quot; 这样的数据。 假设我们想要求分割符前后一致怎么办？此时需要使用反向引用： const regex = /\\d{4}(-|\\/|\\.)\\d{2}\\1\\d{2}/; const string1 = '2017-06-12'; const string2 = '2017/06/12'; const string3 = '2017.06.12'; const string4 = '2016-06/12'; console.log(regex.test(string1)); // true console.log(regex.test(string2)); // true console.log(regex.test(string3)); // true console.log(regex.test(string4)); // false 注意里面的 \\1，表示的引用之前的那个分组 (-|\\/|\\.)。不管它匹配到什么（比如 -），\\1 都匹配那个同样的具体某个字符。 我们知道了 \\1 的含义后，那么 \\2 和 \\3 的概念也就理解了，即分别指代第二个和第三个分组。 看到这里，此时，恐怕你会有三个问题。 3.3.1 括号嵌套怎么办？ 以左括号（开括号）为准。比如： const regex = /^((\\d)(\\d(\\d)))\\1\\2\\3\\4$/; const string = '1231231233'; console.log(regex.test(string)); // true console.log(RegExp.$1); // 123 console.log(RegExp.$2 ); // 1 console.log(RegExp.$3); // 23 console.log(RegExp.$4); // 3 我们可以看看这个正则匹配模式： 第一个字符是数字，比如说 1， 第二个字符是数字，比如说 2， 第三个字符是数字，比如说 3， 接下来的是 \\1，是第一个分组内容，那么看第一个开括号对应的分组是什么，是 123， 接下来的是 \\2，找到第 2 个开括号，对应的分组，匹配的内容是 1， 接下来的是 \\3，找到第 3 个开括号，对应的分组，匹配的内容是 23， 最后的是 \\4，找到第 3 个开括号，对应的分组，匹配的内容是 3。 这个问题，估计仔细看一下，就该明白了。 3.3.2 \\10 表示什么呢？ 另外一个疑问可能是，即 \\10 是表示第 10 个分组，还是 \\1 和 0 呢？ 答案是前者，虽然一个正则里出现 \\10 比较罕见。测试如下： const regex = /(1)(2)(3)(4)(5)(6)(7)(8)(9)(#) \\10+/; const string = '123456789# ######'; console.log(regex.test(string)); // =&gt; true 3.3.3 引用不存在的分组会怎样？ 因为反向引用，是引用前面的分组，但我们在正则里引用了不存在的分组时，此时正则不会报错，只是匹配反向引用的字符本身。例如 \\2，就匹配“\\2”。注意“\\2”表示对“2”进行了转意。 const regex = /\\1\\2\\3\\4\\5\\6\\7\\8\\9/; console.log(regex.test('\\1\\2\\3\\4\\5\\6\\7\\8\\9')); console.log('\\1\\2\\3\\4\\5\\6\\7\\8\\9'.split('')); Chrome 浏览器打印的结果： Node 打印的结果： 4. 非捕获分组 之前文中出现的分组，都会捕获它们匹配到的数据，以便后续引用，因此也称他们是捕获型分组。 如果只想要括号最原始的功能，但不会引用它，即，既不在 API 里引用，也不在正则里反向引用。此时可以使用非捕获分组 (?:p)，例如本文第一个例子可以修改为： const regex = /(?:ab)+/g; const string = 'ababa abbb ababab'; console.log(string.match(regex)); // =&gt; [&quot;abab&quot;, &quot;ab&quot;, &quot;ababab&quot;] 3.5 相关案例 至此括号的作用已经讲完了，总结一句话，就是提供了可供我们使用的分组，如何用就看我们的了。 3.5.1 字符串 trim 方法模拟 trim 方法是去掉字符串的开头和结尾的空白符。有两种思路去做。 第一种，匹配到开头和结尾的空白符，然后替换成空字符。如： function trim(str) { return str.replace(/^\\s+|\\s+$/g, ''); } console.log(trim(' foobar ')); // =&gt; &quot;foobar&quot; 第二种，匹配整个字符串，然后用引用来提取出相应的数据： function trim(str) { return str.replace(/^\\s*(.*?)\\s*$/g, '$1'); } console.log(trim(' foobar ')); // =&gt; &quot;foobar&quot; 这里使用了惰性匹配 *?，不然也会匹配最后一个空格之前的所有空格的。 当然，前者效率高。 3.5.2 将每个单词的首字母转换为大写 function titleize(str) { return str.toLowerCase().replace(/(?:^|\\s)\\w/g, function(c) { return c.toUpperCase(); }); } console.log(titleize('my name is epeli')); // =&gt; &quot;My Name Is Epeli&quot; 思路是找到每个单词的首字母，当然这里不使用非捕获匹配也是可以的。 3.5.3 驼峰化 function camelize(str) { return str.replace(/[-_\\s]+(.)?/g, function(match, c) { return c ? c.toUpperCase() : ''; }); } console.log(camelize('-moz-transform')); // =&gt; &quot;MozTransform&quot; 其中分组 (.) 表示首字母。单词的界定是，前面的字符可以是多个连字符、下划线以及空白符。正则后面的 ? 的目的，是为了应对 str 尾部的字符可能不是单词字符，比如 str 是'-moz-transform'。 3.5.4 中划线化 function dasherize(str) { return str.replace(/([A-Z])/g, '-$1').replace(/[-_\\s]+/g, '-').toLowerCase(); } console.log(dasherize('MozTransform')); // =&gt; &quot;-moz-transform&quot; 驼峰化的逆过程。 3.5.5 html 转义和反转义 // 将HTML特殊字符转换成等值的实体 function escapeHTML(str) { var escapeChars = { '¢' : 'cent', '£' : 'pound', '¥' : 'yen', '€': 'euro', '©' :'copy', '®' : 'reg', '&lt;' : 'lt', '&gt;' : 'gt', '&quot;' : 'quot', '&amp;' : 'amp', '\\'' : '#39' }; return str.replace(new RegExp('[' + Object.keys(escapeChars).join('') +']', 'g'), function(match) { return '&amp;' + escapeChars[match] + ';'; }); } console.log(escapeHTML('&lt;div&gt;Blah blah blah&lt;/div&gt;')); // =&gt; &quot;&amp;lt;div&amp;gt;Blah blah blah&amp;lt;/div&amp;gt&quot;; 其中使用了用构造函数生成的正则，然后替换相应的格式就行了，这个跟本章没多大关系。 倒是它的逆过程，使用了括号，以便提供引用，也很简单，如下： // 实体字符转换为等值的HTML。 function unescapeHTML(str) { var htmlEntities = { nbsp: ' ', cent: '¢', pound: '£', yen: '¥', euro: '€', copy: '©', reg: '®', lt: '&lt;', gt: '&gt;', quot: '&quot;', amp: '&amp;', apos: '\\'' }; return str.replace(/\\&amp;([^;]+);/g, function(match, key) { if (key in htmlEntities) { return htmlEntities[key]; } return match; }); } console.log(unescapeHTML('&amp;lt;div&amp;gt;Blah blah blah&amp;lt;/div&amp;gt;')); // =&gt; &quot;&lt;div&gt;Blah blah blah&lt;/div&gt;&quot; 通过 key 获取相应的分组引用，然后作为对象的键。 3.5.6 匹配成对标签 要求匹配： &lt;title&gt;regular expression&lt;/title&gt; &lt;p&gt;laoyao bye bye&lt;/p&gt; 不匹配： &lt;title&gt;wrong!&lt;/p&gt; 匹配一个开标签，可以使用正则 &lt;[^&gt;]+&gt;， 匹配一个闭标签，可以使用 &lt;\\/[^&gt;]+&gt;， 但是要求匹配成对标签，那就需要使用反向引用，如： const regex = /&lt;([^&gt;]+)&gt;[\\d\\D]*&lt;\\/\\1&gt;/; const string1 = '&lt;title&gt;regular expression&lt;/title&gt;'; const string2 = '&lt;p&gt;laoyao bye bye&lt;/p&gt;'; const string3 = '&lt;title&gt;wrong!&lt;/p&gt;'; console.log(regex.test(string1)); // true console.log(regex.test(string2)); // true console.log(regex.test(string3)); // false 其中开标签 &lt;[^&gt;]+&gt; 改成 &lt;([^&gt;]+)&gt;，使用括号的目的是为了后面使用反向引用，而提供分组。闭标签使用了反向引用，&lt;\\/\\1&gt;。 另外 [\\d\\D] 的意思是，这个字符是数字或者不是数字，因此，也就是匹配任意字符的意思。 第 3 章小结 正则中使用括号的例子那可是太多了，不一而足。 重点理解括号可以提供分组，我们可以提取数据，应该就可以了。 例子中的代码，基本没做多少分析，相信你都能看懂的。 第 4 章 正则表达式回溯法原理 学习正则表达式，是需要懂点儿匹配原理的。 而研究匹配原理时，有两个字出现的频率比较高：“回溯”。 听起来挺高大上，确实还有很多人对此不明不白的。 因此，本章就简单扼要地说清楚回溯到底是什么东西。 内容包括： 没有回溯的匹配 有回溯的匹配 常见的回溯形式 4.1 没有回溯的匹配 假设我们的正则是 /ab{1,3}c/，其可视化形式是： 而当目标字符串是 &quot;abbbc&quot; 时，就没有所谓的“回溯”。其匹配过程是： 其中子表达式 b{1,3} 表示 &quot;b&quot;字符连续出现 1 到 3 次。 4.2 有回溯的匹配 如果目标字符串是 &quot;abbc&quot;，中间就有回溯。 图中第 5 步有红颜色，表示匹配不成功。此时 b{1,3} 已经匹配到了 2 个字符 &quot;b&quot;，准备尝试第三个时，结果发现接下来的字符是 &quot;c&quot;。那么就认为 b{1,3} 就已经匹配完毕。然后状态又回到之前的状态（即第 6 步，与第 4 步一样），最后再用子表达式 c，去匹配字符 &quot;c&quot;。当然，此时整个表达式匹配成功了。 图中的第 6 步，就是“回溯”。 你可能对此没有感觉，这里我们再举一个例子。正则是： 目标字符串是 &quot;abbbc&quot;，匹配过程是： 其中第 7 步和第 10 步是回溯。第 7 步与第 4 步一样，此时 b{1,3} 匹配了两个 &quot;b&quot;，而第 10 步与第 3 步一样，此时 b{1,3} 只匹配了一个 &quot;b&quot;，这也是 b{1,3} 的最终匹配结果。 这里再看一个清晰的回溯，正则是： 目标字符串是：&quot;acd&quot;ef，匹配过程是： 图中省略了尝试匹配双引号失败的过程。可以看出 .* 是非常影响效率的。 为了减少一些不必要的回溯，可以把正则修改为 /&quot;[^&quot;]*&quot;/。 4.3 常见的回溯形式 正则表达式匹配字符串的这种方式，有个学名，叫回溯法。 回溯法也称试探法，它的基本思想是：从问题的某一种状态（初始状态）出发，搜索从这种状态出发所能达到的所有“状态”，当一条路走到“尽头”的时候（不能再前进），再后退一步或若干步，从另一种可能“状态”出发，继续搜索，直到所有的“路径”（状态）都试探过。这种不断“前进”、不断“回溯”寻找解的方法，就称作“回溯法”。（来自百度百科）。 本质上就是深度优先搜索算法。其中退到之前的某一步这一过程，我们称为“回溯”。从上面的描述过程中，可以看出，路走不通时，就会发生“回溯”。即，尝试匹配失败时，接下来的一步通常就是回溯。 道理，我们是懂了。那么 JS 中正则表达式会产生回溯的地方都有哪些呢？ 4.3.1 贪婪量词 之前的例子都是贪婪量词相关的。比如 b{1,3}，因为其是贪婪的，尝试可能的顺序是从多往少的方向去尝试。首先会尝试 &quot;bbb&quot;，然后再看整个正则是否能匹配。不能匹配时，吐出一个 &quot;b&quot;，即在 &quot;bb&quot; 的基础上，再继续尝试。如果还不行，再吐出一个，再试。如果还不行呢？只能说明匹配失败了。 虽然局部匹配是贪婪的，但也要满足整体能正确匹配。否则，皮之不存，毛将焉附？ 此时我们不禁会问，如果当多个贪婪量词挨着存在，并相互有冲突时，此时会是怎样？ 答案是，先下手为强！因为深度优先搜索。测试如下： const string = '12345'; const regex = /(\\d{1,3})(\\d{1,3})/; console.log(string.match(regex)); // =&gt; [&quot;12345&quot;, &quot;123&quot;, &quot;45&quot;, index: 0, input: &quot;12345&quot;] 其中，前面的 \\d{1,3} 匹配的是 &quot;123&quot;，后面的 \\d{1,3} 匹配的是 &quot;45&quot;。 4.3.2 惰性量词 惰性量词就是在贪婪量词后面加个问号。表示尽可能少的匹配，比如： const string = '12345'; const regex = /(\\d{1,3}?)(\\d{1,3})/; console.log(string.match(regex)); // =&gt; [&quot;1234&quot;, &quot;1&quot;, &quot;234&quot;, index: 0, input: &quot;12345&quot;] 其中 \\d{1,3}? 只匹配到一个字符 &quot;1&quot;，而后面的 \\d{1,3} 匹配了 &quot;234&quot;。 虽然惰性量词不贪，但也会有回溯的现象。比如正则是： 目标字符串是 &quot;12345&quot;，匹配过程是： 知道你不贪、很知足，但是为了整体匹配成，没办法，也只能给你多塞点了。因此最后 \\d{1,3}? 匹配的字符是 &quot;12&quot;，是两个数字，而不是一个。 4.3.3 分支结构 我们知道分支也是惰性的，比如/can|candy/，去匹配字符串&quot;candy&quot;，得到的结果是&quot;can&quot;，因为分支会一个一个尝试，如果前面的满足了，后面就不会再试验了。 分支结构，可能前面的子模式会形成了局部匹配，如果接下来表达式整体不匹配时，仍会继续尝试剩下的分支。这种尝试也可以看成一种回溯。 比如正则： 目标字符串是 &quot;candy&quot;，匹配过程： 上面第 5 步，虽然没有回到之前的状态，但仍然回到了分支结构，尝试下一种可能。所以，可以认为它是一种回溯的。 第 4 章小结 其实回溯法，很容易掌握的。 简单总结就是，正因为有多种可能，所以要一个一个试。直到，要么到某一步时，整体匹配成功了；要么最后都试完后，发现整体匹配不成功。 贪婪量词“试”的策略是：买衣服砍价。价钱太高了，便宜点，不行，再便宜点。 惰性量词“试”的策略是：卖东西加价。给少了，再多给点行不，还有点少啊，再给点。 分支结构“试”的策略是：货比三家。这家不行，换一家吧，还不行，再换。 既然有回溯的过程，那么匹配效率肯定低一些。相对谁呢？相对那些 DFA 引擎。 而 JS 的正则引擎是 NFA，NFA 是“非确定型有限自动机”的简写。 大部分语言中的正则都是 NFA，为啥它这么流行呢？ 答：你别看我匹配慢，但是我编译快啊，而且我还有趣哦。 第 5 章 正则表达式的拆分 对于一门语言的掌握程度怎么样，可以有两个角度来衡量：读和写。 不仅要求自己能解决问题，还要看懂别人的解决方案。代码是这样，正则表达式也是这样。 正则这门语言跟其他语言有一点不同，它通常就是一大堆字符，而没有所谓“语句”的概念。 如何能正确地把一大串正则拆分成一块一块的，成为了破解“天书”的关键。 本章就解决这一问题，内容包括： 结构和操作符 注意要点 案例分析 5.1 结构和操作符 编程语言一般都有操作符。只要有操作符，就会出现一个问题。当一大堆操作在一起时，先操作谁，又后操作谁呢？为了不产生歧义，就需要语言本身定义好操作顺序，即所谓的优先级。 而在正则表达式中，操作符都体现在结构中，即由特殊字符和普通字符所代表的一个个特殊整体。 JS 正则表达式中，都有哪些结构呢？ 字符字面量，匹配一个具体字符，包括不用转义的和需要转义的。比如 a 匹配字符 &quot;a&quot;，又比如 \\n 匹配换行符，又比如 \\. 匹配小数点。 字符组，匹配一个字符，可以是多种可能之一，比如 [0-9]，表示匹配一个数字。也有 \\d 的简写形式。另外还有反义字符组，表示可以是除了特定字符之外任何一个字符，比如 [^0-9]，表示一个非数字字符，也有 \\D的简写形式。 量词，表示一个字符连续出现，比如 a{1,3}表示 &quot;a&quot; 字符连续出现 3 次。另外还有常见的简写形式，比如 a+ 表示 &quot;a&quot; 字符连续出现至少一次。 锚字符，匹配一个位置，而不是字符。比如 ^ 匹配字符串的开头，又比如 \\b 匹配单词边界，又比如 (?=\\d) 表示数字前面的位置。 分组，用括号表示一个整体，比如 (ab)+，表示 &quot;ab&quot; 两个字符连续出现多次，也可以使用非捕获分组 (?:ab)+。 选择分支，多个子表达式多选一，比如 abc|bcd，表达式匹配 &quot;abc&quot; 或者 &quot;bcd&quot; 字符子串。 反向引用，比如 \\2，表示引用第 2 个分组。 其中涉及到的操作符有： 转义符 \\ 括号和方括号 (...)、(?:...)、(?=...)、(?!...)、[...] 量词限定符 {m}、{m,n}、{m,}、?、*、+ 位置和序列 ^、$、\\ 元字符、 一般字符 管道符（竖杠）| 上面操作符的优先级从上至下，由高到低。这里，我们来分析一个正则：/ab?(c|de*)+|fg/： 由于括号的存在，所以，(c|de*) 是一个整体结构。 在 (c|de*) 中，注意其中的量词 *，因此 e* 是一个整体结构。 又因为分支结构 | 优先级最低，因此 c 是一个整体、而 de* 是另一个整体。 同理，整个正则分成了 a、b?、(...)+、f、g。而由于分支的原因，又可以分成 ab?(c|de*)+ 和 fg 这两部分。 希望你没被我绕晕，上面的分析可用其可视化形式描述如下： 5.2 注意要点 关于结构和操作符，还是有几点需要强调： 2.1 匹配字符串整体问题 因为是要匹配整个字符串，我们经常会在正则前后中加上锚字符 ^ 和 $。 比如要匹配目标字符串 &quot;abc&quot; 或者 &quot;bcd&quot; 时，如果一不小心，就会写成 /^abc|bcd$/。 而位置字符和字符序列优先级要比竖杠高，故其匹配的结构是： 应该修改成： 5.2.2 量词连缀问题 假设，要匹配这样的字符串： 每个字符为a、b、c任选其一； 字符串的长度是 3 的倍数。 此时正则不能想当然地写成 /^[abc]{3}+$/，这样会报错，说 + 前面没什么可重复的： 此时要修改成： 5.2.3 元字符转义问题 所谓元字符，就是正则中有特殊含义的字符。 所有结构里，用到的元字符总结如下：^ $ . * + ? | \\ / ( ) [ ] { } = ! : - ,。 当匹配上面的字符本身时，可以一律转义： const string = '^$.*+?|\\\\/[]{}=!:-,'; const regex = /\\^\\$\\.\\*\\+\\?\\|\\\\\\/\\[\\]\\{\\}\\=\\!\\:\\-\\,/; console.log(regex.test(string)); // =&gt; true 其中 string 中的 \\ 字符也要转义的。 另外，在 string 中，也可以把每个字符转义，当然，转义后的结果仍是本身： const string = '^$.*+?|\\\\/[]{}=!:-,'; const string2 = '\\^\\$\\.\\*\\+\\?\\|\\\\\\/\\[\\]\\{\\}\\=\\!\\:\\-\\,'; console.log(string == string2); // =&gt; true 现在的问题是，是不是每个字符都需要转义呢？否，看情况。 5.2.3.1 字符组中的元字符 跟字符组相关的元字符有 []、^、-。因此在会引起歧义的地方进行转义。例如开头的 ^ 必须转义，不然会把整个字符组，看成反义字符组。 const string = '^$.*+?|\\\\/[]{}=!:-,'; const regex = /[\\^$.*+?|\\\\/\\[\\]{}=!:\\-,]/g; console.log(string.match(regex)); // =&gt; [&quot;^&quot;, &quot;$&quot;, &quot;.&quot;, &quot;*&quot;, &quot;+&quot;, &quot;?&quot;, &quot;|&quot;, &quot;\\&quot;, &quot;/&quot;, &quot;[&quot;, &quot;]&quot;, &quot;{&quot;, &quot;}&quot;, &quot;=&quot;, &quot;!&quot;, &quot;:&quot;, &quot;-&quot;, &quot;,&quot;] 5.2.3.2 匹配 &quot;[abc]&quot; 和 &quot;{3,5}&quot; 我们知道 [abc]，是个字符组。如果要匹配字符串 &quot;[abc]&quot; 时，该怎么办？ 可以写成 /\\[abc\\]/，也可以写成 /\\[abc]/，测试如下： const string = '[abc]'; const regex = /\\[abc]/g; console.log(string.match(regex)[0]); // =&gt; &quot;[abc]&quot; 只需要在第一个方括号转义即可，因为后面的方括号构不成字符组，正则不会引发歧义，自然不需要转义。 同理，要匹配字符串 &quot;{3,5}&quot;，只需要把正则写成 /\\{3,5}/ 即可。 另外，我们知道量词有简写形式 {m,}，却没有 {,n} 的情况。虽然后者不构成量词的形式，但此时并不会报错。当然，匹配的字符串也是 &quot;{,n}&quot;，测试如下： const string = '{,3}'; const regex = /{,3}/g; console.log(string.match(regex)[0]); // =&gt; &quot;{,3}&quot; 5.2.3.3 其余情况 比如 = ! : - , 等符号，只要不在特殊结构中，也不需要转义。 但是，括号需要前后都转义的，如 /\\(123\\)/。 至于剩下的 ^ $ . * + ? | \\ / 等字符，只要不在字符组内，都需要转义的。 5.3 案例分析 接下来分析两个例子，一个简单的，一个复杂的。 5.3.1 身份证 正则表达式是：/^(\\d{15}|\\d{17}[\\dxX])$/，因为竖杠 | 的优先级最低，所以正则分成了两部分 \\d{15} 和 \\d{17}[\\dxX]。 \\d{15} 表示 15 位连续数字。 \\d{17}[\\dxX] 表示 17 位连续数字，最后一位可以是数字可以大小写字母 &quot;x&quot;。 可视化如下： 5.3.2 IPv4 地址 正则表达式是： /^((0{0,2}\\d|0?\\d{2}|1\\d{2}|2[0-4]\\d|25[0-5])\\.){3}(0{0,2}\\d|0?\\d{2}|1\\d{2}|2[0-4]\\d|25[0-5])$/ 这个正则，看起来非常吓人。但是熟悉优先级后，会立马得出如下的结构： ((...)\\.){3}(...) 上面的两个 (...) 是一样的结构。表示匹配的是 3 位数字。因此整个结构是： 3位数.3位数.3位数.3位数 然后再来分析 (...)： (0{0,2}\\d|0?\\d{2}|1\\d{2}|2[0-4]\\d|25[0-5])(0{0,2}\\d|0?\\d{2}|1\\d{2}|2[0-4]\\d|25[0-5]) 它是一个多选结构，分成 5 个部分： 0{0,2}\\d，匹配一位数，包括 0 补齐的。比如 9、09、009； 0?\\d{2}，匹配两位数，包括 0 补齐的，也包括一位数； 1\\d{2}，匹配 100 到 199; 2[0-4]\\d，匹配 200-249； 25[0-5]，匹配 250-255。 最后来看一下其可视化形式： 第 5 章小结 掌握正则表达式中的优先级后，再看任何正则应该都有信心分析下去了。 至于例子，不一而足，没有写太多。 这里稍微总结一下，竖杠的优先级最低，即最后运算。 只要知道这一点，就能读懂大部分正则。 另外关于元字符转义问题，当自己不确定与否时，尽管去转义，总之是不会错的。 第 6 章 正则表达式的构建 对于一门语言的掌握程度怎么样，可以有两个角度来衡量：读和写。 不仅要看懂别人的解决方案，也要能独立地解决问题。代码是这样，正则表达式也是这样。 与“读”相比，“写”往往更为重要，这个道理是不言而喻的。 对正则的运用，首重就是：如何针对问题，构建一个合适的正则表达式？ 本章就解决该问题，内容包括： 平衡法则 构建正则前提 准确性 效率 6.1 平衡法则 构建正则有一点非常重要，需要做到下面几点的平衡： 匹配预期的字符串 不匹配非预期的字符串 可读性和可维护性 效率 6.2 构建正则前提 6.2.1 是否能使用正则 正则太强大了，以至于我们随便遇到一个操作字符串问题时，都会下意识地去想，用正则该怎么做。但我们始终要提醒自己，正则虽然强大，但不是万能的，很多看似很简单的事情，还是做不到的。 比如匹配这样的字符串：1010010001.... 虽然很有规律，但是只靠正则就是无能为力。 6.2.2 是否有必要使用正则 要认识到正则的局限，不要去研究根本无法完成的任务。同时，也不能走入另一个极端：无所不用正则。能用字符串API解决的简单问题，就不该正则出马。 比如，从日期中提取出年月日，虽然可以使用正则： const string = '2017-07-01'; const regex = /^(\\d{4})-(\\d{2})-(\\d{2})/; console.log(string.match(regex)); // =&gt; [&quot;2017-07-01&quot;, &quot;2017&quot;, &quot;07&quot;, &quot;01&quot;, index: 0, input: &quot;2017-07-01&quot;] 其实，可以使用字符串的 split 方法来做，即可： const string = '2017-07-01'; const result = string.split('-'); console.log(result); // =&gt; [&quot;2017&quot;, &quot;07&quot;, &quot;01&quot;] 比如，判断是否有问号，虽然可以使用： const string = '?id=xx&amp;act=search'; console.log(string.search(/\\?/)); // =&gt; 0 其实，可以使用字符串的 indexOf 方法： const string = '?id=xx&amp;act=search'; console.log(string.indexOf('?')); // =&gt; 0 比如获取子串，虽然可以使用正则： const string = 'JavaScript'; console.log(string.match(/.{4}(.+)/)[1]); // =&gt; Script 其实，可以直接使用字符串的 substring 或 substr 方法来做： const string = 'JavaScript'; console.log(string.substring(4)); // =&gt; Script 6.2.3 是否有必要构建一个复杂的正则 比如密码匹配问题，要求密码长度 6-12 位，由数字、小写字符和大写字母组成，但必须至少包括 2 种字符。 在第 2 章里，我们写出了正则是：/(?!^[0-9]{6,12}$)(?!^[a-z]{6,12}$)(?!^[A-Z]{6,12}$)^[0-9A-Za-z]{6,12}$/ 其实可以使用多个小正则来做： const regex1 = /^[0-9A-Za-z]{6,12}$/; const regex2 = /^[0-9]{6,12}$/; const regex3 = /^[A-Z]{6,12}$/; const regex4 = /^[a-z]{6,12}$/; function checkPassword(string) { if (!regex1.test(string)) return false; if ( regex2.test(string)) return false; if ( regex3.test(string)) return false; if ( regex4.test(string)) return false; return true; } 6.3. 准确性 所谓准确性，就是能匹配预期的目标，并且不匹配非预期的目标。 这里提到了“预期”二字，那么我们就需要知道目标的组成规则。 不然没法界定什么样的目标字符串是符合预期的，什么样的又不是符合预期的。 下面将举例说明，当目标字符串构成比较复杂时，该如何构建正则，并考虑到哪些平衡。 6.3.1 匹配固定电话 比如要匹配如下格式的固定电话号码： 055188888888 0551-88888888 (0551)88888888 第一步，了解各部分的模式规则。 上面的电话，总体上分为区号和号码两部分（不考虑分机号和 +86 的情形）。 区号是 0 开头的 3 到 4 位数字，对应的正则是：0\\d{2,3} 号码是非 0 开头的 7 到 8 位数字，对应的正则是：[1-9]\\d{6,7} 因此，匹配 055188888888 的正则是：/^0\\d{2,3}[1-9]\\d{6,7}$/ 匹配 0551-88888888 的正则是：/^0\\d{2,3}-[1-9]\\d{6,7}$/ 匹配 (0551)88888888 的正则是：/^\\(0\\d{2,3}\\)[1-9]\\d{6,7}$/ 第二步，明确形式关系。 这三者情形是或的关系，可以构建分支： /^0\\d{2,3}[1-9]\\d{6,7}$|^0\\d{2,3}-[1-9]\\d{6,7}$|^\\(0\\d{2,3}\\)[1-9]\\d{6,7}$/ 提取公共部分： /^(0\\d{2,3}|0\\d{2,3}-|\\(0\\d{2,3}\\))[1-9]\\d{6,7}$/ 进一步简写： /^(0\\d{2,3}-?|\\(0\\d{2,3}\\))[1-9]\\d{6,7}$/ 其可视化形式： 上面的正则构建过程略显罗嗦，但是这样做，能保证正则是准确的。 上述三种情形是或的关系，这一点很重要，不然很容易按字符是否出现的情形把正则写成： /^\\(?0\\d{2,3}\\)?-?[1-9]\\d{6,7}$/ 虽然也能匹配上述目标字符串，但也会匹配 (0551-88888888 这样的字符串。当然，这不是我们想要的。 其实这个正则也不是完美的，因为现实中，并不是每个 3 位数和 4 位数都是一个真实的区号。 这就是一个平衡取舍问题，一般够用就行。 6.3.2 匹配浮点数 要求匹配如下的格式： 1.23、+1.23、-1.23 10、+10、-10 .2、+.2、-.2 可以看出正则分为三部分。 符号部分：[+-] 整数部分：\\d+ 小数部分：\\.\\d+ 上述三个部分，并不是全部都出现。如果此时很容易写出如下的正则： /^[+-]?(\\d+)?(\\.\\d+)?$/ 此正则看似没问题，但这个正则也会匹配空字符&quot;&quot;。 因为目标字符串的形式关系不是要求每部分都是可选的。 要匹配 1.23、+1.23、-1.23，可以用 /^[+-]?\\d+\\.\\d+$/ 要匹配 10、+10、-10，可以用 /^[+-]?\\d+$/ 要匹配.2、+.2、-.2，可以用 /^[+-]?\\.\\d+$/ 因此整个正则是这三者的或的关系，提取公众部分后是： /^[+-]?(\\d+\\.\\d+|\\d+|\\.\\d+)$/ 其可视化形式是： 如果要求不匹配 +.2 和 -.2，此时正则变成： /^([+-]?(\\d+\\.\\d+|\\d+)|\\.\\d+)$/ 其可视化形式是： 当然，/^[+-]?(\\d+\\.\\d+|\\d+|\\.\\d+)$/ 也不是完美的，我们也是做了些取舍，比如： 它也会匹配 012 这样以 0 开头的整数。如果要求不匹配的话，需要修改整数部分的正则。 一般进行验证操作之前，都要经过 trim 和判空。那样的话，也许那个错误正则也就够用了。 也可以进一步改写成：/^[+-]?(\\d+)?(\\.)?\\d+$/，这样我们就需要考虑可读性和可维护性了。 6.4 效率 保证了准确性后，才需要是否要考虑要优化。大多数情形是不需要优化的，除非运行的非常慢。什么情形正则表达式运行才慢呢？我们需要考察正则表达式的运行过程（原理）。 正则表达式的运行分为如下的阶段： 编译； 设定起始位置； 尝试匹配； 匹配失败的话，从下一位开始继续第 3 步； 最终结果：匹配成功或失败。 下面以代码为例，来看看这几个阶段都做了什么： const regex = /\\d+/g; console.log(regex.lastIndex, regex.exec('123abc34def')); console.log(regex.lastIndex, regex.exec('123abc34def')); console.log(regex.lastIndex, regex.exec('123abc34def')); console.log(regex.lastIndex, regex.exec('123abc34def')); // =&gt; 0 [&quot;123&quot;, index: 0, input: &quot;123abc34def&quot;] // =&gt; 3 [&quot;34&quot;, index: 6, input: &quot;123abc34def&quot;] // =&gt; 8 null // =&gt; 0 [&quot;123&quot;, index: 0, input: &quot;123abc34def&quot;] 具体分析如下： const regex = /\\d+/g; 当生成一个正则时，引擎会对其进行编译。报错与否出现这这个阶段。 regex.exec('123abc34def') 当尝试匹配时，需要确定从哪一位置开始匹配。一般情形都是字符串的开头，即第 0 位。 但当使用 test 和 exec 方法，且正则有 g 时，起始位置是从正则对象的 lastIndex 属性开始。 因此第一次 exec 是从第 0 位开始，而第二次是从 3 开始的。 设定好起始位置后，就开始尝试匹配了。 比如第一次 exec，从 0 开始，去尝试匹配，并且成功地匹配到 3 个数字。此时结束时的下标是 2，因此下一次的起始位置是 3。 而第二次，起始下标是 3，但第 3 个字符是 &quot;a&quot;，并不是数字。但此时并不会直接报匹配失败，而是移动到下一位置，即从第 4 位开始继续尝试匹配，但该字符是 b，也不是数字。再移动到下一位，是 c 仍不行，再移动一位是数字 3，此时匹配到了两位数字 34。此时，下一次匹配的位置是 d 的位置，即第 8 位。 第三次，是从第 8 位开始匹配，直到试到最后一位，也没发现匹配的，因此匹配失败，返回 null。同时设置 lastIndex 为 0，即，如要再尝试匹配的话，需从头开始。 从上面可以看出，匹配会出现效率问题，主要出现在上面的第 3 阶段和第 4 阶段。 因此，主要优化手法也是针对这两阶段的。 6.4.1 使用具体型字符组来代替通配符，来消除回溯 而在第三阶段，最大的问题就是回溯。 例如，匹配双引用号之间的字符。如，匹配字符串 123&quot;abc&quot;456 中的 &quot;abc&quot;。 如果正则用的是：/&quot;.*&quot;/，会在第 3 阶段产生 4 次回溯（粉色表示 .* 匹配的内容）： 如果正则用的是：/&quot;.*?&quot;/，会产生 2 次回溯（粉色表示 .*? 匹配的内容）： 因为回溯的存在，需要引擎保存多种可能中未尝试过的状态，以便后续回溯时使用。注定要占用一定的内存。 此时要使用具体化的字符组，来代替通配符.，以便消除不必要的字符，此时使用正则 /&quot;[^&quot;]*&quot;/，即可。 6.4.2 使用非捕获型分组 因为括号的作用之一是，可以捕获分组和分支里的数据。那么就需要内存来保存它们。 当我们不需要使用分组引用和反向引用时，此时可以使用非捕获分组。例如： /^[+-]?(\\d+\\.\\d+|\\d+|\\.\\d+)$/ 可以修改成：/^[+-]?(?:\\d+\\.\\d+|\\d+|\\.\\d+)$/ 6.4.3 独立出确定字符 例如 /a+/，可以修改成 /aa*/。 因为后者能比前者多确定了字符 a。这样会在第四步中，加快判断是否匹配失败，进而加快移位的速度。 6.4.4 提取分支公共部分 比如 /^abc|^def/，修改成 /^(?:abc|def)/。 又比如 /this|that/，修改成 /th(?:is|at)/。 这样做，可以减少匹配过程中可消除的重复。 6.4.5 减少分支的数量，缩小它们的范围 /red|read/，可以修改成 /rea?d/。此时分支和量词产生的回溯的成本是不一样的。但这样优化后，可读性会降低的。 第 6 章小结 本章涉及的内容并不多。一般情况下，针对某问题能写出一个满足需求的正则，基本上就可以了。至于准确性和效率方面的追求，纯属看个人要求了。我觉得够用就行了。关于准确性，本章关心的是最常用的解决思路：针对每种情形，分别写出正则，然用分支把他们合并在一起，再提取分支公共部分，就能得到准确的正则。至于优化，本章没有为了凑数，去写一大堆。了解了匹配原理，常见的优化手法也就这么几种。 第 7 章 正则表达式编程 什么叫知识，能指导我们实践的东西才叫知识。学习一样东西，如果不能使用，最多只能算作纸上谈兵。 正则表达式的学习，也不例外。掌握了正则表达式的语法后，下一步，也是关键的一步，就是在真实世界中使用它。那么如何使用正则表达式呢？有哪些关键的点呢？本章就解决这个问题。内容包括： 正则表达式的四种操作 相关API注意要点 真实案例 7.1 正则表达式的四种操作 正则表达式是匹配模式，不管如何使用正则表达式，万变不离其宗，都需要先“匹配”。 有了匹配这一基本操作后，才有其他的操作：验证、切分、提取、替换。 进行任何相关操作，也需要宿主引擎相关 API 的配合使用。当然，在 JS 中，相关 API 也不多。 7.1.1 验证 验证是正则表达式最直接的应用，比如表单验证。 在说验证之前，先要说清楚匹配是什么概念。 所谓匹配，就是看目标字符串里是否有满足匹配的子串。因此，“匹配”的本质就是“查找”。 有没有匹配，是不是匹配上，判断是否的操作，即称为“验证”。 这里举一个例子，来看看如何使用相关API进行验证操作的。 比如，判断一个字符串中是否有数字。 使用 search const regex = /\\d/; const string = 'abc123'; console.log(!!~string.search(regex)); // =&gt; true 使用 test const regex = /\\d/; const string = 'abc123'; console.log(regex.test(string)); // =&gt; true 使用 match const regex = /\\d/; const string = 'abc123'; console.log(!!string.match(regex)); // =&gt; true 使用 exec const regex = /\\d/; const string = 'abc123'; console.log(!!regex.exec(string)); // =&gt; true 其中，最常用的是 test。 7.1.2 切分 匹配上了，我们就可以进行一些操作，比如切分。 所谓“切分”，就是把目标字符串，切成一段一段的。在 JS 中使用的是 split。 比如，目标字符串是 &quot;html,css,javascript&quot;，按逗号来切分： const regex = /,/; const string = 'html,css,javascript'; console.log(string.split(regex)); // =&gt; [&quot;html&quot;, &quot;css&quot;, &quot;javascript&quot;] 又比如，如下的日期格式： 2017/06/26 2017.06.26 2017-06-26 可以使用 split“切出”年月日： const regex = /\\D/; console.log('2017/06/26'.split(regex)); console.log('2017.06.26'.split(regex)); console.log('2017-06-26'.split(regex)); // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;26&quot;] // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;26&quot;] // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;26&quot;] 7.1.3 提取 虽然整体匹配上了，但有时需要提取部分匹配的数据。 此时正则通常要使用分组引用（分组捕获）功能，还需要配合使用相关 API。 这里，还是以日期为例，提取出年月日。注意下面正则中的括号： match const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; console.log(string.match(regex)); // =&gt;[&quot;2017-06-26&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;26&quot;, index: 0, input: &quot;2017-06-26&quot;] exec const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; console.log(regex.exec(string)); // =&gt;[&quot;2017-06-26&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;26&quot;, index: 0, input: &quot;2017-06-26&quot;] test const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; regex.test(string); console.log(RegExp.$1, RegExp.$2, RegExp.$3); // =&gt; &quot;2017&quot; &quot;06&quot; &quot;26&quot; search const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; string.search(regex); console.log(RegExp.$1, RegExp.$2, RegExp.$3); // =&gt; &quot;2017&quot; &quot;06&quot; &quot;26&quot; replace const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; const date = []; string.replace(regex, function(match, year, month, day) { date.push(year, month, day); }); console.log(date); // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;26&quot;] 其中，最常用的是 match。 7.1.4 替换 找，往往不是目的，通常下一步是为了替换。在 JS 中，使用 replace 进行替换。 比如把日期格式，从 yyyy-mm-dd 替换成 yyyy/mm/dd： const string = '2017-06-26'; const today = new Date(string.replace(/-/g, '/')); console.log(today); // =&gt; Mon Jun 26 2017 00:00:00 GMT+0800 (中国标准时间) 这里只是简单地应用了一下 replace。但，replace 方法是强大的，是需要重点掌握的。 7.2. 相关API注意要点 从上面可以看出用于正则操作的方法，共有 6 个，字符串实例 4 个，正则实例 2 个： String#search String#split String#match String#replace RegExp#test RegExp#exec 本文不打算详细地讲解它们的方方面面细节，具体可以参考《JavaScript权威指南》的第三部分。本文重点列出一些容易忽视的地方，以飨读者。 7.2.1 search 和 match 的参数问题 我们知道字符串实例的那 4 个方法参数都支持正则和字符串。 但 search 和 match，会把字符串转换为正则的。 const string = '2017.06.27'; console.log(string.search('.')); // =&gt; 0 //需要修改成下列形式之一 console.log(string.search('\\\\.')); console.log(string.search(/\\./)); // =&gt; 4 // =&gt; 4 console.log(string.match('.')); // =&gt; [&quot;2&quot;, index: 0, input: &quot;2017.06.27&quot;] //需要修改成下列形式之一 console.log(string.match('\\\\.')); console.log(string.match(/\\./)); // =&gt; [&quot;.&quot;, index: 4, input: &quot;2017.06.27&quot;] // =&gt; [&quot;.&quot;, index: 4, input: &quot;2017.06.27&quot;] console.log(string.split('.')); // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;27&quot;] console.log(string.replace('.', '/')); // =&gt; &quot;2017/06.27&quot; 7.2.2 match 返回结果的格式问题 match 返回结果的格式，与正则对象是否有修饰符 g 有关。 const string = '2017.06.27'; const regex1 = /\\b(\\d+)\\b/; const regex2 = /\\b(\\d+)\\b/g; console.log(string.match(regex1)); console.log(string.match(regex2)); // =&gt; [&quot;2017&quot;, &quot;2017&quot;, index: 0, input: &quot;2017.06.27&quot;] // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;27&quot;] 没有 g，返回的是标准匹配格式，即，数组的第一个元素是整体匹配的内容，接下来是分组捕获的内容，然后是整体匹配的第一个下标，最后是输入的目标字符串。 有 g，返回的是所有匹配的内容。 当没有匹配时，不管有无 g，都返回 null。 7.2.3 exec比match更强大 当正则没有 g 时，使用 match 返回的信息比较多。但是有 g 后，就没有关键的信息 index 了。 而 exec 方法就能解决这个问题，它能接着上一次匹配后继续匹配： const string = '2017.06.27'; const regex2 = /\\b(\\d+)\\b/g; console.log(regex2.exec(string)); console.log(regex2.lastIndex); console.log(regex2.exec(string)); console.log(regex2.lastIndex); console.log(regex2.exec(string)); console.log(regex2.lastIndex); console.log(regex2.exec(string)); console.log(regex2.lastIndex); // =&gt; [&quot;2017&quot;, &quot;2017&quot;, index: 0, input: &quot;2017.06.27&quot;] // =&gt; 4 // =&gt; [&quot;06&quot;, &quot;06&quot;, index: 5, input: &quot;2017.06.27&quot;] // =&gt; 7 // =&gt; [&quot;27&quot;, &quot;27&quot;, index: 8, input: &quot;2017.06.27&quot;] // =&gt; 10 // =&gt; null // =&gt; 0 其中正则实例 lastIndex 属性，表示下一次匹配开始的位置。 比如第一次匹配了 &quot;2017&quot;，开始下标是 0，共 4 个字符，因此这次匹配结束的位置是 3，下一次开始匹配的位置是 4。 从上述代码看出，在使用 exec 时，经常需要配合使用 while 循环： const string = '2017.06.27'; const regex2 = /\\b(\\d+)\\b/g; const result; while (result = regex2.exec(string)) { console.log(result, regex2.lastIndex); } // =&gt; [&quot;2017&quot;, &quot;2017&quot;, index: 0, input: &quot;2017.06.27&quot;] 4 // =&gt; [&quot;06&quot;, &quot;06&quot;, index: 5, input: &quot;2017.06.27&quot;] 7 // =&gt; [&quot;27&quot;, &quot;27&quot;, index: 8, input: &quot;2017.06.27&quot;] 10 7.2.4 修饰符g，对exex和test的影响 上面提到了正则实例的 lastIndex 属性，表示尝试匹配时，从字符串的 lastIndex 位开始去匹配。 字符串的四个方法，每次匹配时，都是从 0 开始的，即 lastIndex 属性始终不变。 而正则实例的两个方法 exec、test，当正则是全局匹配时，每一次匹配完成后，都会修改 lastIndex。下面让我们以 test 为例，看看你是否会迷糊： const regex = /a/g; console.log(regex.test('a'), regex.lastIndex); console.log(regex.test('aba'), regex.lastIndex); console.log(regex.test('ababc'), regex.lastIndex); // =&gt; true 1 // =&gt; true 3 // =&gt; false 0 注意上面代码中的第三次调用 test，因为这一次尝试匹配，开始从下标 lastIndex 即 3 位置处开始查找，自然就找不到了。 如果没有 g，自然都是从字符串第 0 个字符处开始尝试匹配： const regex = /a/; console.log(regex.test('a'), regex.lastIndex); console.log(regex.test('aba'), regex.lastIndex); console.log(regex.test('ababc'), regex.lastIndex); // =&gt; true 0 // =&gt; true 0 // =&gt; true 0 7.2.5 test 整体匹配时需要使用 ^ 和 $ 这个相对容易理解，因为 test 是看目标字符串中是否有子串匹配正则，即有部分匹配即可。 如果，要整体匹配，正则前后需要添加开头和结尾： console.log(/123/.test('a123b')); // =&gt; true console.log(/^123$/.test('a123b')); // =&gt; false console.log(/^123$/.test('123')); // =&gt; true 7.2.6 split 相关注意事项 split 方法看起来不起眼，但要注意的地方有两个的。 第一，它可以有第二个参数，表示结果数组的最大长度： const string = 'html,css,javascript'; console.log(string.split(/,/, 2)); // =&gt;[&quot;html&quot;, &quot;css&quot;] 第二，正则使用分组时，结果数组中是包含分隔符的： const string = 'html,css,javascript'; console.log(string.split(/(,)/)); // =&gt;[&quot;html&quot;, &quot;,&quot;, &quot;css&quot;, &quot;,&quot;, &quot;javascript&quot;] 7.2.7 replace 是很强大的 《JavaScript权威指南》认为 exec 是这 6 个 API 中最强大的，而我始终认为 replace 才是最强大的。因为它也能拿到该拿到的信息，然后可以假借替换之名，做些其他事情。 总体来说 replace 有两种使用形式，这是因为它的第二个参数，可以是字符串，也可以是函数。 当第二个参数是字符串时，如下的字符有特殊的含义： $1,$2,...,$99 匹配第 1~99 个分组里捕获的文本 $&amp; 匹配到的子串文本 $` 匹配到的子串的左边文本 $' 匹配到的子串的右边文本 $$ 美元符号 例如，把 &quot;2,3,5&quot;，变成 &quot;5=2+3&quot;： const result = '2,3,5'.replace(/(\\d+),(\\d+),(\\d+)/, '$3=$1+$2'); console.log(result); // =&gt; &quot;5=2+3&quot; 又例如，把 &quot;2,3,5&quot;，变成 &quot;222,333,555&quot;: const result = '2,3,5'.replace(/(\\d+)/g, '$&amp;$&amp;$&amp;'); console.log(result); // =&gt; &quot;222,333,555&quot; 当第二个参数是函数时，我们需要注意该回调函数的参数具体是什么： '1234 2345 3456'.replace(/(\\d)\\d{2}(\\d)/g, function(match, $1, $2, index, input) { console.log([match, $1, $2, index, input]); }); // =&gt; [&quot;1234&quot;, &quot;1&quot;, &quot;4&quot;, 0, &quot;1234 2345 3456&quot;] // =&gt; [&quot;2345&quot;, &quot;2&quot;, &quot;5&quot;, 5, &quot;1234 2345 3456&quot;] // =&gt; [&quot;3456&quot;, &quot;3&quot;, &quot;6&quot;, 10, &quot;1234 2345 3456&quot;] 此时我们可以看到 replace 拿到的信息，并不比 exec 少。 7.2.8 使用构造函数需要注意的问题 一般不推荐使用构造函数生成正则，而应该优先使用字面量。因为用构造函数会多写很多 \\。 const string = '2017-06-27 2017.06.27 2017/06/27'; const regex = /\\d{4}(-|\\.|\\/)\\d{2}\\1\\d{2}/g; console.log(string.match(regex)); // =&gt; [&quot;2017-06-27&quot;, &quot;2017.06.27&quot;, &quot;2017/06/27&quot;] regex = new RegExp('\\\\d{4}(-|\\\\.|\\\\/)\\\\d{2}\\\\1\\\\d{2}', 'g'); console.log(string.match(regex)); // =&gt; [&quot;2017-06-27&quot;, &quot;2017.06.27&quot;, &quot;2017/06/27&quot;] 7.2.9 修饰符 ES5中修饰符，共3个： g 全局匹配，即找到所有匹配的，单词是 global i 忽略字母大小写，单词 ingoreCase m 多行匹配，只影响 ^ 和 $，二者变成行的概念，即行开头和行结尾。单词是 multiline 当然正则对象也有相应的只读属性： const regex = /\\w/img; console.log(regex.global); console.log(regex.ignoreCase); console.log(regex.multiline); // =&gt; true // =&gt; true // =&gt; true 7.2.10 source 属性 正则实例对象属性，除了 global、ingnoreCase、multiline、lastIndex 属性之外，还有一个 source 属性。 它什么时候有用呢？ 比如，在构建动态的正则表达式时，可以通过查看该属性，来确认构建出的正则到底是什么： const className = 'high'; const regex = new RegExp('(^|\\\\s)' + className + '(\\\\s|$)'); console.log(regex.source) // =&gt; (^|\\s)high(\\s|$) 即字符串&quot;(^|\\\\s)high(\\\\s|$)&quot; 7.2.11 构造函数属性 构造函数的静态属性基于所执行的最近一次正则操作而变化。除了是 $1,...,$9 之外，还有几个不太常用的属性（有兼容性问题）： RegExp.input 最近一次目标字符串，简写成 RegExp[&quot;$_&quot;] RegExp.lastMatch 最近一次匹配的文本，简写成 RegExp[&quot;$&amp;&quot;] RegExp.lastParen 最近一次捕获的文本，简写成 RegExp[&quot;$+&quot;] RegExp.leftContext 目标字符串中 lastMatch 之前的文本，简写成 RegExp[&quot;$`&quot;] RegExp.rightContext 目标字符串中 lastMatch 之后的文本，简写成 RegExp[&quot;$'&quot;] 测试代码如下： const regex = /([abc])(\\d)/g; const string = 'a1b2c3d4e5'; string.match(regex); console.log(RegExp.input); console.log(RegExp['$_']); // =&gt; &quot;a1b2c3d4e5&quot; console.log(RegExp.lastMatch); console.log(RegExp['$&amp;']); // =&gt; &quot;c3&quot; console.log(RegExp.lastParen); console.log(RegExp['$+']); // =&gt; &quot;3&quot; console.log(RegExp.leftContext); console.log(RegExp[&quot;$`&quot;]); // =&gt; &quot;a1b2&quot; console.log(RegExp.rightContext); console.log(RegExp[&quot;$'&quot;]); // =&gt; &quot;d4e5&quot; 7.3 真实案例 7.3.1 使用构造函数生成正则表达式 我们知道要优先使用字面量来创建正则，但有时正则表达式的主体是不确定的，此时可以使用构造函数来创建。模拟 getElementsByClassName 方法，就是很能说明该问题的一个例子。 这里 getElementsByClassName 函数的实现思路是： 比如要获取 className 为 &quot;high&quot; 的 dom 元素； 首先生成一个正则：/(^|\\s)high(\\s|$)/； 然后再用其逐一验证页面上的所有 dom 元素的类名，拿到满足匹配的元素即可。 代码如下(可以直接复制到本地查看运行效果)： &lt;p class=&quot;high&quot;&gt;1111&lt;/p&gt; &lt;p class=&quot;high&quot;&gt;2222&lt;/p&gt; &lt;p&gt;3333&lt;/p&gt; &lt;script&gt; function getElementsByClassName(className) { var elements = document.getElementsByTagName(&quot;*&quot;); var regex = new RegExp(&quot;(^|\\\\s)&quot; + className + &quot;(\\\\s|$)&quot;); var result = []; for (var i = 0; i &lt; elements.length; i++) { var element = elements[i]; if (regex.test(element.className)) { result.push(element) } } return result; } var highs = getElementsByClassName('high'); highs.forEach(function(item) { item.style.color = 'red'; }); &lt;/script&gt; 7.3.2 使用字符串保存数据 一般情况下，我们都愿意使用数组来保存数据。但我看到有的框架中，使用的却是字符串。 使用时，仍需要把字符串切分成数组。虽然不一定用到正则，但总感觉酷酷的，这里分享如下： const utils = {}; 'Boolean|Number|String|Function|Array|Date|RegExp|Object|Error'.split('|').forEach(function(item) { utils['is' + item] = function(obj) { return {}.toString.call(obj) == '[object ' + item + ']'; }; }); console.log( utils.isArray([1, 2, 3]) ); // =&gt; true 7.3.3 if 语句中使用正则替代 &amp;&amp; 比如，模拟 ready 函数，即加载完毕后再执行回调（不兼容 IE 的）： const readyRE = /complete|loaded|interactive/; function ready(callback) { if (readyRE.test(document.readyState) &amp;&amp; document.body) { callback() } else { document.addEventListener( 'DOMContentLoaded', function () { callback() }, false ); } }; ready(function() { alert('加载完毕！') }); 7.3.4 使用强大的 replace 因为 replace 方法比较强大，有时用它根本不是为了替换，只是拿其匹配到的信息来做文章。 这里以查询字符串（querystring）压缩技术为例，注意下面 replace 方法中，回调函数根本没有返回任何东西。 function compress(source) { var keys = {}; source.replace(/([^=&amp;]+)=([^&amp;]*)/g, function(full, key, value) { keys[key] = (keys[key] ? keys[key] + ',' : '') + value; }); var result = []; for (var key in keys) { result.push(key + '=' + keys[key]); } return result.join('&amp;'); } console.log(compress(&quot;a=1&amp;b=2&amp;a=3&amp;b=4&quot;)); // =&gt; &quot;a=1,3&amp;b=2,4&quot; 7.3.5 综合运用 最后这里再做个简单实用的正则测试器。 具体效果如下： 代码，直接贴了，相信你能看得懂： &lt;section&gt; &lt;div id=&quot;err&quot;&gt;&lt;/div&gt; &lt;input id=&quot;regex&quot; placeholder=&quot;请输入正则表达式&quot;&gt; &lt;input id=&quot;text&quot; placeholder=&quot;请输入测试文本&quot;&gt; &lt;button id=&quot;run&quot;&gt;测试一下&lt;/button&gt; &lt;div id=&quot;result&quot;&gt;&lt;/div&gt; &lt;/section&gt; &lt;style&gt; section{ display:flex; flex-direction:column; justify-content:space-around; height:300px; padding:0 200px; } section *{ min-height:30px; } #err { color:red; } #result{ line-height:30px; } .info { background:#00c5ff; padding:2px; margin:2px; display:inline-block; } &lt;/style&gt; &lt;script&gt; (function() { // 获取相应dom元素 var regexInput = document.getElementById(&quot;regex&quot;); var textInput = document.getElementById(&quot;text&quot;); var runBtn = document.getElementById(&quot;run&quot;); var errBox = document.getElementById(&quot;err&quot;); var resultBox = document.getElementById(&quot;result&quot;); // 绑定点击事件 runBtn.onclick = function() { // 清除错误和结果 errBox.innerHTML = &quot;&quot;; resultBox.innerHTML = &quot;&quot;; // 获取正则和文本 var text = textInput.value; var regex = regexInput.value; if (regex == &quot;&quot;) { errBox.innerHTML = &quot;请输入正则表达式&quot;; } else if (text == &quot;&quot;) { errBox.innerHTML = &quot;请输入测试文本&quot;; } else { regex = createRegex(regex); if (!regex) return; var result, results = []; // 没有修饰符g的话，会死循环 if (regex.global) { while(result = regex.exec(text)) { results.push(result); } } else { results.push(regex.exec(text)); } if (results[0] == null) { resultBox.innerHTML = &quot;匹配到0个结果&quot;; return; } // 倒序是有必要的 for (var i = results.length - 1; i &gt;= 0; i--) { var result = results[i]; var match = result[0]; var prefix = text.substr(0, result.index); var suffix = text.substr(result.index + match.length); text = prefix + '&lt;span class=&quot;info&quot;&gt;' + match + '&lt;/span&gt;' + suffix; } resultBox.innerHTML = &quot;匹配到&quot; + results.length + &quot;个结果:&lt;br&gt;&quot; + text; } }; // 生成正则表达式，核心函数 function createRegex(regex) { try { if (regex[0] == &quot;/&quot;) { regex = regex.split(&quot;/&quot;); regex.shift(); var flags = regex.pop(); regex = regex.join(&quot;/&quot;); regex = new RegExp(regex, flags); } else { regex = new RegExp(regex, &quot;g&quot;); } return regex; } catch(e) { errBox.innerHTML = &quot;无效的正则表达式&quot;; return false; } } })(); &lt;/script&gt; 第 7 章小结 相关API的注意点，本章基本上算是一网打尽了。 至于文中的例子，都是点睛之笔，没有详细解析。如有理解不透的，建议自己敲一敲。 后记 文章要结束了，最后还要有几点说明。 1. 需要注意的地方 本文主要讨论的是 JavaScript 的正则表达式，更精确地说是 ES5 的正则表达式。 JavaScript 的正则表达式引擎是传统型 NFA 的，因此本系列的讨论是适合任何一门正则引擎是传统型 NFA 的编程语言。当然，市面上大部分语言的正则引擎都是这种的。而 JS 里正则涉及到的所有语法要点，是这种引擎支持的核心子集。也就是说，要学正则表达式，不妨以 JS 正则为出发点。 2. 参考资料 当然本文不是无本之末。主要参考的是几本书籍。 以下书籍中核心章节都认真阅读过，甚至阅读多遍。 《JavaScript权威指南》，看完本系列，再去看书中的第 10 章，你就知道了什么叫字字珠玑。 《精通正则表达式》，权威且比较杂乱，我阅读的第一本正则表达式书籍。 《正则表达式必知必会》，这是我看的第二本正则，看完后，确定自己算是入门了。 《正则指引》，《精通正则表达式》的译者写的，相对清晰。 《正则表达式入门》，我看的是英文版的，对于已经入门的我，基本没多少收获了。 《正则表达式经典实例》，除了第 3 章，比较杂外，也有收获，以实例为主导的一本书。 《JavaScript Regular Expressions》，为数不多转讲 JS 正则的。页数不多，也有收获。 《高性能JavaScript 》第 5 章，我看的是英文版的。第 5 章，讲了回溯和优化。 《JavaScript忍者秘籍》第 7 章，大概讲了一下正则的用法，几个例子还不错。 《JavaScript高级程序设计》第 5.4 节，比较简短的介绍。 使用的工具： Regulex，一款可视化工具 ProcessOn - 免费在线作图，实时协作 LICEcap – 灵活好用，GIF 屏幕录制工具 ","link":"https://tdmaker.github.io/faded/post/regular-expression-full-tutorial/"},{"title":"正则表达式——断言人话版","content":" 这次不会说我的正则教程没写全了吧？？ 零宽断言 断言：俗话的断言就是“我断定什么什么”，而正则中的断言，就是说正则可以指明在指定内容的前面或后面会出现满足指定规则的内容，意思正则也可以像人类那样断定什么什么，比如“ss1aa2bb3”，正则可以用断言找出 aa2 前面有 bb3，也可以找出 aa2 后面有 ss1。 零宽：就是没有宽度，在正则中，断言只是匹配位置，不占字符，也就是说，匹配结果里是不会返回断言本身。 假设我们要用爬虫抓取 csdn 里的文章阅读量。通过查看源代码可以看到文章阅读量这个内容是这样的结构： &lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt; 需要获得这里边的‘641’有很多种办法，但如果使用正则应该怎么匹配呢？下面先讲一下几种类型的断言： 💡正向先行断言（正前瞻） 语法：(?=pattern)； 作用：匹配 pattern 表达式的前面内容，不返回本身。 要取到阅读量，在正则表达式中就意味着要能匹配到‘&lt;/span&gt;’前面的数字内容，按照上所说的正向先行断言可以匹配表达式前面的内容，那意思就是：(?=&lt;/span&gt;) 就可以匹配到前面的内容了。 const regExp = /.+(?=&lt;\\/span&gt;)/; const str = &quot;&lt;span class=\\&quot;read-count\\&quot;&gt;阅读数：641&lt;/span&gt;&quot; console.log(regExp.exec(str)); // 匹配结果： [ '&lt;span class=&quot;read-count&quot;&gt;阅读数：641', index: 0, input: '&lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt;', groups: undefined ] 仅匹配前面的数字： const regExp = /\\d+(?=&lt;\\/span&gt;)/; const str = &quot;&lt;span class=\\&quot;read-count\\&quot;&gt;阅读数：641&lt;/span&gt;&quot; console.log(regExp.exec(str)); // 匹配结果： [ '641', index: 29, input: '&lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt;', groups: undefined ] 💡正向后行断言（正后顾）: 语法：(?&lt;=pattern)； 作用：匹配 pattern 表达式的后面的内容，不返回本身。 有先行就有后行，先行是匹配前面的内容，那后行就是匹配后面的内容啦。上面的栗子，我们也可以用后行断言来处理。 const regExp= /(?&lt;=&lt;span class=\\&quot;read-count\\&quot;&gt;阅读数：)\\d+/; const str = &quot;&lt;span class=\\&quot;read-count\\&quot;&gt;阅读数：641&lt;/span&gt;&quot; console.log(regExp.exec(str)); // 匹配结果 [ '641', index: 29, input: '&lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt;', groups: undefined ] 💡负向先行断言（负前瞻） 语法：(?!pattern)； 作用：匹配非 pattern 表达式的前面内容，不返回本身。 有正向也有负向，负向在这里其实就是非的意思。举个栗子：比如有一句 “我爱祖国，我是祖国的花朵”，现在要找到不是 “的花朵”前面的“祖国”，用正则就可以这样写：祖国(?!的花朵)。 💡负向后行断言（负后顾） 语法：(?&lt;!pattern)； 作用：匹配非 pattern 表达式的后面内容，不返回本身。 捕获和非捕获 单纯说到捕获，他的意思是匹配表达式，但捕获通常和分组联系在一起，也就是“捕获组”。捕获组：匹配子表达式的内容，把匹配结果保存到内存中数字编号或显示命名的组里，以深度优先进行编号，之后可以通过序号或名称来使用这些匹配结果。 而根据命名方式的不同，又可以分为两种组： 💡数字编号捕获组 语法：(exp)； 解释：从表达式左侧开始，每出现一个左括号和它对应的右括号之间的内容为一个分组，在分组中，第 0 组为整个表达式，第一组开始为分组。 比如固定电话的：020-85653333，它的正则表达式为：(0\\d{2})-(\\d{8})，按照左括号的顺序，这个表达式有如下分组： 序号 编号 分组 内容 0 0 (0\\d{2})-(\\d{8}) 020-85653333 1 1 (0\\d{2}) 020 2 2 (\\d{8}) 85653333 下面来验证一下： const str = '020-85653333'; const regExp=/(0\\d{2})-(\\d{8})/; console.log(regExp.exec(str)); // 输出结果： [ '020-85653333', '020', '85653333', index: 0, input: '020-85653333', groups: undefined ] 可见，分组个数是2，但是因为第0个为整个表达式本身，因此也一起输出了。 💡命名编号捕获组： 语法：(?&lt;name&gt;exp)； 解释：分组的命名由表达式中的name指定。 比如区号也可以这样写: (?&lt;quhao&gt;\\0\\d{2})-(?&lt;haoma&gt;\\d{8})，按照左括号的顺序，这个表达式有如下分组： 序号 名称 分组 内容 0 0 (0\\d{2})-(\\d{8}) 020-85653333 1 quhao (0\\d{2}) 020 2 haoma (\\d{8}) 85653333 const str = '020-85653333'; const regExp=/(?&lt;quhao&gt;0\\d{2})-(?&lt;haoma&gt;\\d{8})/; console.log(regExp.exec(str)); // 输出结果： [ '020-85653333', '020', '85653333', index: 0, input: '020-85653333', groups: [Object: null prototype] { quhao: '020', haoma: '85653333' } ] 💡非捕获组： 语法：(?:exp)； 解释：和捕获组刚好相反，它用来标识那些不需要捕获的分组，说的通俗一点，就是你可以根据需要去保存你的分组。 比如上面的正则表达式，程序不需要用到第一个分组，那就可以这样写：1(?:\\0\\d{2})-(\\d{8})。 序号 编号 分组 内容 0 0 (0\\d{2})-(\\d{8}) 020-85653333 1 1 (\\d{8}) 85653333 const str = '020-85653333'; const regExp=/(?:0\\d{2})-(\\d{8})/; console.log(regExp.exec(str)); // 运行结果： [ '020-85653333', '85653333', index: 0, input: '020-85653333', groups: undefined ] 反向引用 上面讲到捕获，我们知道：捕获会返回一个捕获组，这个分组是保存在内存中，不仅可以在正则表达式外部通过程序进行引用，也可以在正则表达式内部进行引用，这种引用方式就是反向引用。 根据捕获组的命名规则，反向引用可分为： 数字编号组反向引用：\\k 或 \\number； 命名编号组反向引用：\\k或者 \\'name'。 捕获组通常是和反向引用一起使用的。上面说到捕获组是匹配子表达式的内容按序号或者命名保存起来以便使用。注意两个字眼：“内容” 和 “使用”，这里所说的“内容”，是匹配结果，而不是子表达式本身。这里所说的“使用”的作用主要是用来查找一些重复的内容或者做替换指定字符。 还是举栗子吧：比如要查找一串字母 &quot;aabbbbgbddesddfiid&quot; 里成对的字母，如果按照我们之前学到的正则，什么区间啊限定啊断言啊可能是办不到的，现在我们先用程序思维理一下思路： 匹配到一个字母； 匹配第下一个字母，检查是否和上一个字母是否一样； 如果一样，则匹配成功，否则失败； 这里的思路 2 中匹配下一个字母时，需要用到上一个字母，那怎么记住上一个字母呢？这下子捕获就有用处啦，我们可以利用捕获把上一个匹配成功的内容用来作为本次匹配的条件。好了，有思路就要实践，首先匹配一个字母：\\w，我们需要做成分组才能捕获，因此写成这样：(\\w)，那这个表达式就有一个捕获组：(\\w)，然后我们要用这个捕获组作为条件，那就可以：(\\w)\\1，这样就大功告成了，可能有人不明白了，\\1 是什么意思呢？ 还记得捕获组有两种命名方式吗，一种是是根据捕获分组顺序命名，一种是自定义命名来作为捕获组的命名。在默认情况下都是以数字来命名，而且数字命名的顺序是从 1 开始的。因此要引用第一个捕获组，根据反向引用的数字命名规则 就需要 \\k&lt;1&gt; 或者 \\1 当然，通常都是是后者。 我们来测试一下： const str = 'aabbbbgbddesddfiid'; const regExp=/(\\w)\\1/g; console.log(str.match(regExp)); 运行结果： [ 'aa', 'bb', 'bb', 'dd', 'dd', 'ii' ] 再举个替换的例子，假如想要把字符串中 abc 换成 a： const str = 'abcbbabcbcgbddesddfiid'; const regExp=/(a)(b)c/g; console.log(str.replace(regExp, '$1')); // 输出结果： abcbbabcbcgbddesddfiid 贪婪和非贪婪 💡贪婪 贪婪匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符，这匹配方式叫做贪婪匹配。 特性：一次性读入整个字符串进行匹配，每当不匹配就舍弃最右边一个字符，继续匹配，依次匹配和舍弃（这种匹配-舍弃的方式也叫做回溯），直到匹配成功或者把整个字符串舍弃完为止，因此它是一种最大化的数据返回，能多不会少。 前面我们讲过重复限定符，其实这些限定符就是贪婪量词，比如表达式：\\d{3,6} 用来匹配 3 到 6 位数字，在这种情况下，它是一种贪婪模式的匹配，也就是假如字符串里有 6 个数字可以匹配，那它就是全部匹配到。例如： const str = &quot;61762828 176 2991 871&quot;; const regExp=/\\d{3,6}/g; console.log(str.match(regExp)); // 输出结果： [ '617628', '176', '2991', '871' ] 由结果可见：本来字符串中的“61762828”这一段，其实只需要出现3个（617）就已经匹配成功了的，但是他并不满足，而是匹配到了最大能匹配的字符，也就是6个。 一个量词就如此贪婪了，那有人会问，如果多个贪婪量词凑在一起，那他们是如何支配自己的匹配权的呢？是这样的，多个贪婪在一起时，如果字符串能满足他们各自最大程度的匹配时，就互不干扰，但如果不能满足时，会根据深度优先原则，也就是从左到右的每一个贪婪量词，优先最大数量的满足，剩余再分配下一个量词匹配。 const str = &quot;61762828 176 2991 87321&quot;; const regExp=/(\\d{1,2})(\\d{3,4})/g; console.log(str.match(regExp)); // 输出结果： [ '617628', '2991', '87321' ] 解答： “617628” 是前面的 \\d{1,2} 匹配出了 61，后面的匹配出了 7628； “2991”是前面的 \\d{1,2} 匹配出了 2 ，后面的匹配出了 991(满足匹配优先，再最大程度的贪婪)； “87321”是前面的 \\d{1,2} 匹配出了 87，后面的匹配出了 321。 💡懒惰（非贪婪） 懒惰匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能少的字符，这匹配方式叫做懒惰匹配。 特性：从左到右，从字符串的最左边开始匹配，每次试图不读入字符匹配，匹配成功，则完成匹配，否则读入一个字符再匹配，依此循环（读入字符、匹配）直到匹配成功或者把字符串的字符匹配完为止。 懒惰量词是在贪婪量词后面加个“?”。 代码 说明 *? 重复任意次，但尽可能少重复 +? 重复 1 次或更多次，但尽可能少重复 ?? 重复 0 次或 1 次，但尽可能少重复 {n,m}? 重复 n 到 m 次，但尽可能少重复 {n,}? 重复 n 次以上，但尽可能少重复 const str = &quot;61762828 176 2991 87321&quot;; const regExp=/(\\d{1,2}?)(\\d{3,4})/g; console.log(str.match(regExp)); // 输出结果： [ '61762', '2991', '87321' ] 解答： “61762”是左边的懒惰匹配出 6，右边的贪婪匹配出 1762； “2991”是左边的懒惰匹配出 2，右边的贪婪匹配出 991； “87321”左边的懒惰匹配出 8，右边的贪婪匹配出 7321。 反义 前面说到元字符的都是要匹配什么什么，当然如果你想反着来，不想匹配某些字符，正则也提供了一些常用的反义元字符： 元字符 解释 \\W 匹配任意不是字母，数字，下划线，汉字的字符 \\S 匹配任意不是空白符的字符 \\D 匹配任意非数字的字符 \\B 匹配不是单词开头或结束的位置 [^x] 匹配除了 x 以外的任意字符 [^aeiou] 匹配除了 aeiou 这几个字母以外的任意字符 ","link":"https://tdmaker.github.io/faded/post/regular-expression-assert-mandarin/"},{"title":"正则表达式——NFA","content":" 正则表达式和NFA NFA NFA 是指 Nondeterministic Finite Automaton，非确定有限状态自动机。 目前正则表达式引擎主要有两种：NFA 和 DFA； JavaScript 采用的是 NFA 引擎。 状态机中有这样一些要素，对照上图分别说下： 开始状态：圆圈表示状态，被一个“没有起点的箭头”指向的状态，是开始状态，上例中是 S1； 最终状态：也叫接受状态，图中用双圆圈表示，这个例子中也是 S1； 输入：在一个状态下，向状态机输入的符号/信号，不同输入导致状态机产生不同的状态改变； 转换：在一个状态下，根据特定输入，改变到特定状态的过程，就是转换。 所以有限状态机的工作过程，就是从开始状态，根据不同的输入，自动进行状态转换的过程。 上图中的状态机的功能，是检测二进制数是否含有偶数个 0。从图上可以看出，输入只有 1 和 0 两种。从 S1 状态开始，只有输入 0 才会转换到 S2 状态，同样 S2 状态下只有输入 0 才会转换到 S1。所以，二进制数输入完毕，如果满足最终状态，也就是最后停在 S1 状态，那么输入的二进制数就含有偶数个 0。 正则表达式，可以认为是对一组字符串集合的描述。例如 (a+|b)c 对应的字符串集合是： ac bc aac aaac aaaac ... 有限状态机也可以用来描述字符串集合，同样是正则表达式所描述的集合，用有限状态机来表示，可以是这样的： 并且，有限状态机是可以“执行”的，给出如上的状态机之后，就可以用来对输入的字符串进行检测。如果最终匹配，也就意味着输入的字符串和正则表达式 (a+|b)c 匹配。 所以，编程语言中的正则表达式，一般是通过有限状态机来实现。正则表达式匹配字符串的过程，可以分解为： 正则表达式转换为等价的有限状态机； 有限状态机输入字符串执行。 这里再讲一下 NFA 和 DFA 的区别。DFA 是 Deterministic Finite Automaton，确定有限状态机。DFA 可以认为是一种特殊的 NFA，它最大的特点，就是确定性。它的确定性在于，在一个状态下，输入一个符号，一定是转换到确定的状态，没有其他的可能性。 举个例子，对于正则表达式 ab|ac，对应 NFA 可以是这样的： 可以看到，在状态 1 这里，如果输入 a，其实有两种可能，如果后面的符号是 b，那么可以匹配成功，后面符号是 c 也能匹配成功。所以状态机在执行过程中，可能要尝试所有的可能性。在尝试一种可能路径匹配失败后，还要回到之前的状态再尝试其他的路径，这就是“回溯”。 但是 DFA 消除了这种不确定性，所以可以想见，其执行性能应该要比 NFA 更好，因为不需要回溯。 NFA 是可以转换为等价的 DFA 的，也就是说，理论上讲，正则表达式可以用 DFA 来实现，从而获得优于 NFA 的执行性能。但是 NFA 转换 DFA 的过程，会消耗更多资源，甚至最终得到的 DFA 要占用大量存储空间（据有的资料的说法，可能会产生指数级增长）。而且，DFA 相比 NFA，在实现一些正则表达式的特性时会更复杂，成本更高。所以当前的许多编程语言，其正则表达式引擎为 NFA 模式。 /nfa|nfa not/.test('nfa not'); 用上面的正则表达式来测试字符串 nfa not，NFA 引擎在检测满足 nfa 就返回匹配成功的结果了，而 DFA 则会尝试继续查找，也就是说会得到“最长的匹配结果”。 从正则表达式到 NFA 🏈Thompson 算法 Thompson 算法用于转换正则表达式为 NFA，它并非最高效的算法，但是实用，易于理解。 Thompson 算法中使用最基本的两种转换： 普通转换就是在一个状态下，输入字符 a 后转换至另一个状态；epsilon转换则不需要有输入，就从一个状态转换至另一个状态。 正则表达式中的各种运算，可以通过组合上述两种转换实现： 组合转换 RS： 替换转换 R|S： 重复转换 R*： 上面图中的 R、S 是有开始状态和结束状态的 NFA。 以正则表达式 ab|c 为例，包括两个运算： ab 组合 ab 的结果，与 c 替换 这样我们把正则表达式视为一系列输入和运算，进行分解、组合，就可以得到最终的 NFA。 首先，我们要把正则表达式转换为方便记录输入、运算的方式。 🏈正则表达式 → 后缀表达式 后缀表达式是一种方便记录输入、运算的表达式，本身已包含了运算符的优先级，也称为逆波兰表示法（Reverse Polish Notation，简写为 RPN）。 为方便记录运算，我们为正则表达式中的组合运算也创建一个运算符“.”（本文只涉及最简单的正则表达式形式，这里的“.”不是用于匹配任意字符的特殊符号）。 正则表达式 ab|c对应的后缀表达式为 ab.c|。 这样，通过逐个扫描后缀表达式，并识别其中的运算符来执行，就可以对后缀表达式进行求解。对于正则表达式来说，则是在将其变为后缀表达式后，通过“求值”的过程来进一步构建并得到最终的 NFA。 用于创建后缀表达式的是调度场算法。 对于这里的正则表达式处理的场景，算法的大致描述如下： 创建输出队列 output 和运算符栈 ops； 依次读取输入字符串中每一个字符 ch； 如果 ch 是普通字符，追加到 output； 如果 ch 是运算符，只要 ops 栈顶的运算符优先级不低于 ch，依次出栈并追加到 output，最后将 ch 入栈 ops； 如果 ch 是“(”，入栈 ops； 如果 ch 是“)”，只要 ops 栈顶不是“(”，依次出栈并追加到 output； 将 ops 中运算符依次出栈追加到 output； 返回 output。 具体处理过程中，由于原始正则表达式中并没有组合运算符，所以需要自行判断合理的插入位置。 运算符优先级如下（由高到低）： * ? + . | ( 🏈后缀表达式 → NFA 基于后缀表达式创建 NFA，是一个由简单的 NFA 进行不断组合得到复杂 NFA 的过程。 用于表示状态 State 的数据结构为： // State { id: String, type: String, // 'n' - normal, 'e' - epsilon, 'end' symbol: String, // 普通状态对应的输入字符 out: State, // 允许的下一个状态 out1: State // 允许的下一个状态 } 每个状态可以对应最多两个 out 状态，像 a|b|c 的表达式，会被分解为 (a|b)|c，每次运算符“|”都只处理两个（子）表达式。 在构造最终 NFA 过程中，每次会创建 NFA 的片段 Fragment： // Fragment { start: State, out: State } 不管 NFA 片段内部是怎样复杂，它都只有一个入口（开始状态），一个出口（最终状态）。 处理的过程大致为： 创建用于记录 NFA 片段的栈 stack； 依次读取输入的后缀表达式的每个字符 ch； 如果 ch 是运算符，从 stack 出栈所需数目的 NFA 片段，构建新的 NFA 片段后入栈 stack； 如果 ch 是普通字符，创建新的状态，并构建只包含此状态的 NFA 片段入栈 stack； 返回 stack 栈顶的 NFA 片段，即最终结果。 以对组合运算的处理为例： const e2 = stack.pop(); const e1 = stack.pop(); e1.out.out = e2.start; stack.push(new Fragment(e1.start, e2.out)); 从 stack 出栈两个 NFA 片段，然后将其首尾相连后构建新的 NFA 片段再入栈。 NFA 的执行 NFA 的执行过程就是用当前状态来比对字符串的当前字符，如果匹配就继续比对下一个状态和下一个字符，否则匹配失败。 不过由于 NFA 的不确定性，所以可能会同时有多个匹配的状态。 总结 综上，正则表达式的执行，可以通过构建等价的 NFA，然后执行 NFA 来匹配输入的字符串。真实的 JavaScript 中的正则表达式拥有更多的特性，其正则表达式引擎也更加复杂。 简单正则表达式引擎的实现 简单的正则表达式引擎实现 🏈基本的数据结构定义 核心思路是读取正则表达式以后生成对应的NFA，NFA中有边和状态两个结构。边的结构记录了它的起点和终点，同时通过枚举类型记录匹配的其他需求。 //用于处理‘^’字符 enum { NEXCLUDED = false, EXCLUDED = true }; //用于处理预处理类型，0-128以内ASCII字符直接匹配 enum { LCASES=256, UCASES=257, NUM=258, EPSILON=259, ANY=260, WS=261 }; class Edge { public: State *start; State *end; int type; int exclude; Edge(State *s, State *e, int t, bool ex = NEXCLUDED) :start(s), end(e), type(t), exclude(ex) {}; } 状态有预备，成功和失败三种，同时每个状态维护两个向量，向量存储了出边和入边的指针。 enum { READY = -1, SUCCESS = 1, FAIL = 0}; class State { public: int status; std::list&lt;Edge *&gt; InEdges; std::list&lt;Edge *&gt; OutEdges; } NFA 类会存储一个正则表达式，同时存储 NFA 的起点和终点，并使用了两个链表来维护 NFA 的边和状态，同时用一个链表来存储匹配成功的字符串。两个静态的字符串指针用于记录文件和正则表达式字符串的读取状态，静态常量，使得最终函数只会对文件内容和正则表达式扫描一次，避免在匹配成功的字符串中再匹配子串。 char *regex; State *Start; State *End; std::list&lt;Edge *&gt; edgeList; std::list&lt;State *&gt; stateList; std::list&lt;char&gt; matchedChar; static char *regRead; static char *fileRead; } 生成NFA的过程中，通过 currentEnd 和 currentStart 两个指针分别指向当前字符读取完成后生成的最后一个状态和当前字符读取之前的开始状态，维护这两个指针的目的是为了记录 NFA 的生成过程，在处理‘*’、‘+’、‘？’等字符的时候起到了重要的作用。同时我们利用list内置的迭代器对链表进行遍历，这个方式在匹配过程中也用到了。 State *currentEnd, *currentStart; State *alternate; list&lt;Edge *&gt;::iterator itor; 🏈NFA的生成 关键的部分在于匹配字符串时采取的思路，尤其是特殊字符的生成 NFA 的方式，这个不同于课本上最开始的 NFA 生成算法，而是基于读取字符串的过程，同时避免了字符串的回退等，读取一个字符就生成一个对应的边并压入链表中，对‘*’、‘+’，‘？’和特殊符号也是如此，使得处理更加简单的同时避免生成过于冗余的状态，兼顾了时间和空间效率。以下举例说明。 🏈边和状态的生成 边的生成使用 newEdge 函数,需要记录起点和终点，以及类型，同时在生成边以后要用重载的两个 patch函数将状态和边完全连接起来。 void Nfa::newEdge(State * start, State * end, int type, int exclude = NEXCLUDED) { Edge *out = new Edge(start, end, type, exclude); end-&gt;patch(out, end); start-&gt;patch(start, out); edgeList.push_back(out); } 以普通字符的生成和‘.’字符的产生方式为例，他们都是生成一条边和一个新的状态。 case '.': /* any */ currentStart = currentEnd; currentEnd = new State(); newEdge(currentStart, currentEnd, ANY, NEXCLUDED); stateList.push_back(currentEnd); default: currentStart = currentEnd; currentEnd = new State(); newEdge(currentStart, currentEnd, *regRead, NEXCLUDED); stateList.push_back(currentEnd); break; 如下图所示： 接下来的符号处理都假定初始状态如下图所示： 🏈'|'的处理 以 currentStart 指向的状态作为子 NFA 的起点，同时将子 NFA 的终点状态和原 NFA 的终点进行合并。 case '|': // alternate regRead++; currentStart = start; alternate= regex2nfa(regRead, start); currentEnd-&gt;merge(alternate); stateList.remove(alternate); regRead--; 如下图所示： 🏈'?' &amp; '*' &amp; '+'的处理 读取到‘?’只需要在上一条边的基础上继续连接原有的边即可： case '?': // zero or one newEdge(currentStart, currentEnd, EPSILON, NEXCLUDED); break; 读取到‘\\*’后，直接将 currentStart 和 currentEnd 进行合并成环： case '*': // zero or more alternate = currentEnd; currentStart-&gt;merge(alternate); stateList.remove(alternate); currentEnd = currentStart; break; 读取到‘+’后，只需添加若干条边从 currentEnd 状态指向 currentStart 状态的下一个状态即可： case '+': /* one or more */ itor = currentStart-&gt;OutEdges.begin(); for (;itor != currentStart-&gt;OutEdges.end();itor++) newEdge(currentEnd, (*itor)-&gt;end, (*itor)-&gt;type, (*itor)-&gt;exclude); break; 如下图所示： 🏈简单的分组支持 对于中括号和括号进行了一定的支持，括号直接递归调用 NFA 的生成函数，中括号和预定义字符都有其对应的函数进行支持。 🏈NFA匹配 匹配过程采用了递归的方式，step函数调用match函数匹配边和文件字符，匹配成功后即递归调用进入下一个状态。 if (End-&gt;status == SUCCESS) return SUCCESS; for(;itor != current-&gt;OutEdges.end();itor++) { if ((*itor)-&gt;match(fileRead)) { (*itor)-&gt;end-&gt;status = SUCCESS; matchedChar.push_back(*fileRead); ++fileRead; if (step((*itor)-&gt;end)) return SUCCESS; --fileRead; matchedChar.pop_back(); } if ((*itor)-&gt;type == EPSILON &amp;&amp; step((*itor)-&gt;end)) return SUCCESS; } return FAIL; ","link":"https://tdmaker.github.io/faded/post/regular-expression-nfa/"},{"title":"正则表达式——断言","content":" 正则表达式断言 正则表达式大多数结构匹配的文本会出现在最终的匹配结果中，但也有些结构并不真正匹配文本，而只是负责判断某个位置左/右侧是否符合要求，这种结构被称为断言（assertion）。常见的断言有三类： 单词边界、行起始/结束位置、环视。本文主要简单阐述对三类断言的理解。 单词边界 单词边界顾名思义，是指单词字符 (\\w) 能匹配的字符串的左右位置。在 JavaScript、php、Python 2、Ruby 中，单词字符 (\\w) 等同于 [0-9a-zA-Z]，所以在这些语言中，给定一段文本可以用 \\b\\w+\\b 把所有单词提取出来。 例如： ('Love is composed of a single soul inhabiting two bodies.').match(/\\b\\w+\\b/g) return [&quot;Love&quot;, &quot;is&quot;, &quot;composed&quot;, &quot;of&quot;, &quot;a&quot;, &quot;single&quot;, &quot;soul&quot;, &quot;inhabiting&quot;, &quot;two&quot;, &quot;bodies&quot;] 这里值得注意的是，有些单词例如 E-mail 和组合词 I'm 这样的，\\b\\w+\\b 是无法匹配的。如要匹配，可根据需求修改为 \\b['-\\w]\\b。 单词边界记为 \\b，它能匹配的位置：一边是单词字符 \\w，一边是非单词字符 \\W。 与单词边界对应的是非单词边界 \\B，两者关系类似 \\w 与 \\W、\\d 与 \\D。 这里注意，非单词边界（\\B）和单词字符（\\w）是不一样的，因为前者是断言，而后者是普通匹配。 例如： // 式一 String(1234567890).replace(/(?=(\\B)(\\d{3})+$)/g, ',') =&gt; 1,234,567,890 // 式二 String(1234567890).replace(/(?=(\\w)(\\d{3})+$)/g, ',') =&gt; ,123,456,7890 // 附加常用例子，20180911格式化为2018-09-11 '20180911'.replace(/(?=\\B(\\d{2})+$)/g, '-').replace(/-/, '') =&gt;2018-09-11 造成差异的原因就是: 式一中的 \\B 匹配边界（是断言）。第一次匹配时，在 1234567890 中数字 1 的前方时，会环视后方进行肯定断言(?=)：后方必须是满足两个 pattern 才通过。第一个 pattern (\\B)在数字 1 的前方匹配成功；故继续在此位置匹配第二个 pattern (\\d{3})+$，发现 123456789 之后并不是结束符（结束符和开始符也是断言，下文讲述），故匹配失败。开始第二次匹配，从数字 1 和数字 2 的中间开始...最后会匹配成功三个位置：1 和 2 之间、4 和 5 之间、7 和 8 之间，再被,替换，故得到结果。 同理，式二在第一次匹配时，在数字 1 的前方环视后方进行肯定断言：后方必须是满足两个 pattern 才通过。第一个 pattern (\\w) 在数字 1 的前方匹配成功，并将匹配位置移动到 1 和 2 之间；然后继续匹配第二个pattern (\\d{3})+$...第一次匹配成功，故数字 1 前方的断言是成功的，标记该位置...最后得到三个位置：1 前方、3 和 4 之间、6 和 7 之间，再被,替换，故得到结果。 所以 \\B 只是去判断该位置左右是否只有一边有单词字符，另一边不是单词字符，且在匹配成功时，不会导致匹配位置发生改变。说起来算是一种判断吧~ 这种只是匹配某个位置而不是文本的元字符，在正则中也被称为锚点。下文继续介绍常见锚点之二：行起始/结束位置。 行起始/结束位置 ^ 与 $ 分别表示（行）起始位置和（行）结束位置，比如正则表达式 /^lu.*r$/ 只能匹配的 lu 开始并以 r 结束的字符串，例如：luwuer、lu fd --r，不能匹配 nb luwuer、lu fd --rb等。 其实行起始/结束位置断言，常用在正则表达式开启多行模式（Multiline Mode）的情况下。 例如： ('first line\\nsecond line\\nlast line').match(/^\\w+/gm) return [&quot;first&quot;, &quot;second&quot;, &quot;last&quot;] 既然是多行匹配，这里说说如何划分行。 在编辑文本时，敲回车键就向文本输入了行终止符（line terminal），表示结束当前行。这里只需注意，敲入回车时向文本中输入的行终止符在主流平台上是有差别的： Windows 的行终止符是 \\r\\n。 UNIX/Linux/Mac OS 的行终止符是 \\n。 不过正则的行起始/结束位置断言都是可以识别的哈~ 环视 环视是指在某个位置向左/向右看，保证其左/右位置必须出现某类字符（包括单词字符 \\w 和非单词字符\\W），且环视也同上两个断言，只是做一个判断（匹配一个位置，本身不匹配任何字符，但又比上两个断言灵活）。也有人称环视为零宽断言。 环视分为四种： 肯定顺序环视（正向肯定断言）positive-lookahead: ?=pattern； 否定顺序环视（正向否定断言）negative-lookahead: ?!pattern； 肯定逆序环视（反向肯定断言）positive-lookahead: ?&lt;=pattern，js不支持； 否定逆序环视（反向否定断言）negative-lookahead: ?&lt;=pattern，js不支持。 比如我们要匹配一串文字中包含在书名号《》中的书名，如不考虑环视可能需要如下实现： ('三体是刘慈欣创作的系列长篇科幻小说，由《三体》、《三体Ⅱ·黑暗森林》、《三体Ⅲ·死神永生》组成。').match(/《.*?》/g).join(',').replace(/[《》]/g, '').split(',') return [&quot;三体&quot;, &quot;三体Ⅱ·黑暗森林&quot;, &quot;三体Ⅲ·死神永生&quot;] 正则默认是贪婪模式（在整个表达式匹配成功的前提下，尽可能多的匹配），开启非贪婪模式（在整个表达式匹配成功的前提下，尽可能少的匹配）的方法：在贪婪量词 {m,n}、{m,}、?、*、+ 后加上一个 ? 号，例如 +?。 而在使用环视时会更简单： ('三体是刘慈欣创作的系列长篇科幻小说，由《三体》、《三体Ⅱ·黑暗森林》、《三体Ⅲ·死神永生》组成。').replace(/《/g,'\\n').match(/^.*?(?=》)/gm) return [&quot;三体&quot;, &quot;三体Ⅱ·黑暗森林&quot;, &quot;三体Ⅲ·死神永生&quot;] 似乎也没简单多少...当然最主要的原因是js不支持逆序环视啦啦啦 再举例，匹配6位数字构成的字符串： // 无环视 'http://luwuer.com/629212/1234567890'.match(/[^\\d]\\d{6}[^\\d]/g).join('').match(/\\d{6}/g) return [&quot;629212&quot;] // 环视 'http://luwuer.com/629212/1234567890'.match(/(?!\\d).\\d{6}(?!\\d)/g).join('').match(/\\d{6}/g) return [&quot;629212&quot;] 其实环视在js中更多的是与replace函数组合，就像在单词边界一节中最后的例子。 ","link":"https://tdmaker.github.io/faded/post/regular-expression-assert/"},{"title":"jQuery——拓展","content":"😲 extend函数 $.extend(target,[object1],[onjectN]) $.extend([deep],target,object1,[objectN]) var obj1 = { height: 100, width: 100, length: 100, div: { x: 100, y: 100 } }; var obj2 = { height: 200, width: 200, div: { x: 200 } }; $.extend(obj1, obj2); console.log(obj1.height); console.log(obj1.div.y); //result:200,undefined 当使用true参数时， var obj1 = { height: 100, width: 100, length: 100, div: { x: 100, y: 100 } }; var obj2 = { height: 200, width: 200, div: { x: 200 } }; $.extend(true, obj1, obj2); console.log(obj1.height); console.log(obj1.div.y); //result:200,100 拓展jQuery的公共函数 $.extend({ minValue: function(a, b) { return a &gt; b ? a: b } }); var a = prompt(&quot;input a&quot;); var b = prompt(&quot;input b&quot;); console.log($.minValue(a, b)); $.fn.extend() 方法可以创建 jQuery 对象方法 $.fn.extend({ test: function() { alert(&quot;click &quot; + $(this).html() + &quot; this is test function&quot;); } }); $(&quot;#fnExtend&quot;).click(function() { $(this).test(); }); 😲 自定义jQuery函数 🤗 添加新的全局函数 $.clickDiv = function(node) { console.log(node.text() + &quot; click&quot;); }; $(&quot;div&quot;).click(function() { $.clickDiv($(this)); }); 🤗 通过 extend 函数添加全局函数 $.extend({ foo: function() { alert(&quot;this is a new function 'foo()'&quot;); } }); $.foo(); 🤗 使用命名空间 $.myPluin = { ale: function() { alert(&quot;function from myPluin&quot;); } }; $.nextPluin = { ale: function() { alert(&quot;function from nextPluin&quot;); } } $.myPluin.ale(); $.nextPluin.ale(); 😲 自定义选择器 $.myPluin = { ale: function() { alert(&quot;function from myPluin&quot;); } }; $.nextPluin = { ale: function() { alert(&quot;function from nextPluin&quot;); } }; index = -1; //定义全局变量 index jQuery.expr[&quot;:&quot;].le = function(elem, i, match) { // return i&gt;match[3]-0||i==match[3] console.log(index); index++; return index &gt; match[3] - 0; // 返回索引大于 3 的元素 }; $(&quot;p:le(2)&quot;).css(&quot;color&quot;, &quot;red&quot;); // 返回元素索引值大于等于 2 的元素 $.myPluin.ale(); $.nextPluin.ale(); ","link":"https://tdmaker.github.io/faded/post/jquery-extension/"},{"title":"jQuery——选择器","content":"基本选择器 🎼 ID 选择器： // 选中 id 为 myDiv 的元素，速度最快 $(&quot;#myDiv&quot;) 🎼 类选择器： // 选中 class 属性为 red 的所有元素 $(&quot;.red&quot;) 🎼 元素选择器： // 选中所有 div 元素 $(&quot;div&quot;) 🎼 通配符选择器： // 选中所有元素 $(&quot;*&quot;) 🎼 复合选择器： // 选中所有 span 元素和所有 id 为 myDiv 的元素 $(&quot;span,#myDiv&quot;) 层次选择器 🎼 选择器1 选择器2： // 选中 body 内的所有 div 元素 $(&quot;body div&quot;) 🎼 选择器1 &gt; 选择器2： // 选中 body 内的所有直接 div 元素，不查找间接元素 $(&quot;body &gt; div&quot;) 🎼 选择器1 + 选择器2： // 选中 body 内的所有 div 元素 $(&quot;body div&quot;) 🎼 选择器1 ~ 选择器2： // 选中 body 内的所有 div 元素 $(&quot;body div&quot;) 基本过滤选择器 🎼 第一个元素选择器 // 选中第一个 div 元素 $(&quot;div:first&quot;) 🎼 最后一个元素选择器 // 选中最后一个 div 元素 $(&quot;div:last&quot;) 🎼 排除选择器 // 选中 class 不为 red 的所有 div 元素 $(&quot;div:not(.red)&quot;) 🎼 偶数选择器 // 选中索引值为偶数的 div 元素 $(&quot;div:even&quot;) 🎼 奇数选择器 // 选中索引值为奇数的 div 元素 $(&quot;div:odd&quot;) 🎼 索引值选择器 // 选中索引值为 2 的 div 元素 $(&quot;div:eq(2)&quot;) // 选中索引值大于 2 的 div 元素 $(&quot;div:gt(2)&quot;) // 选中索引值小于2的 div 元素 $(&quot;div:lt(2)&quot;) 内容过滤选择器 // 选中所有包含文本 ok 的 div 元素 $(&quot;div:contains(ok)&quot;) // 选中所有为空的 div 元素 $(&quot;div:empty&quot;) // 选中所有包含 class 为 red 的 div 元素 $(&quot;div:has(.red)&quot;) // 选中所有不为空的 div 元素 $(&quot;div:parent&quot;) 可见性过滤选择器 // 选中所有不可见的 div 元素 $(&quot;div:hidden&quot;) // 选中所有可见的 div 元素 $(&quot;div:visible&quot;) 属性过滤选择器 // 选中所有包含属性 title 的 div 元素 $(&quot;div[title]&quot;) // 选中所有属性 title 等于 ok 的 div 元素 $(&quot;div[title=ok]&quot;) // 选中所有属性 title 不等于 ok 的 div 元素 $(&quot;div[title!=ok]&quot;) // 选中所有属性 title 值以 ok 开头的 div 元素 $(&quot;div[title^=ok]&quot;) // 选中所有属性 title 值含有 ok 的 div 元素 $(&quot;div[title*=ok]&quot;) // 选中所有包含属性 id，并且属性 title 值以 ok 开头的 div 元素 $(&quot;div[id][title^=ok]&quot;) 子元素过滤选择器 // 选中所有是第二个子结点的 div 元素 $(&quot;div:nth-child(2)&quot;) // 选中所有是第一个子结点的 div 元素 $(&quot;div:first-child&quot;) // 选中所有是最后一个子结点的 div 元素 $(&quot;div:last-child&quot;) // 选中所有是唯一子结点的 div 元素 $(&quot;div:only-child&quot;) 表单属性过滤选择器 // 选中表单内可用 input $(&quot;#form1 input:enabled&quot;) // 选中表单内不可用 input $(&quot;#form1 input:disabled&quot;) // 选中表单内所有选中的元素 $(&quot;#form1 input:checked&quot;) // 选中下拉列表中选中的元素 $(&quot;select &gt; option:selected&quot;) ","link":"https://tdmaker.github.io/faded/post/jquery-selectors/"},{"title":"正则表达式——匹配","content":"💊(?:pattern) 非获取匹配，匹配 pattern 但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。 💊 (?=pattern) 非获取匹配，正向肯定预查，在任何匹配 pattern 的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如，“Windows(?=95|98|NT|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 💊 (?!pattern) 非获取匹配，正向否定预查，在任何不匹配 pattern 的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如“Windows(?!95|98|NT|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。 💊 (?&lt;=pattern) 非获取匹配，反向肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?&lt;=95|98|NT|2000)Windows”能匹配“2000Windows”中的“Windows”，但不能匹配“3.1Windows”中的“Windows”。 💊 (?&lt;!pattern) 非获取匹配，反向否定预查，与正向否定预查类似，只是方向相反。例如“(?&lt;!95|98|NT|2000)Windows”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。这个地方不正确，有问题 ","link":"https://tdmaker.github.io/faded/post/regular-expression-pattern-matching/"},{"title":"设计师网站","content":"设计师导航 网站 网址 全球100+知名设计网站 http://www.bigbigwork.com/nav/6.html CND设计网址导航 - 优秀设计网站排名大全 http://wz.cndesign.com/ 拍信 https://www.paixin.com/ 我图网 https://www.ooopic.com/ 包图网 https://ibaotu.com/ 素材天下 http://www.sucaitianxia.net/ 素材中国 http://www.sccnn.com/ 站长素材 http://sc.chinaz.com/ 红动中国 https://www.redocn.com/ 千库网 https://588ku.com/ 觅元素 http://www.51yuansu.com/ unDraw https://undraw.co/ DrawKit https://www.drawkit.io/ pngtree https://pngtree.com/ VCG https://www.vcg.com/ Textures for 3D, graphic design and Photoshop! https://www.textures.com/ 無料DTP素材 【素材ページ 】食材・料理の著作権フリー写真 http://www.sozai-page.com/index.html 免费模板网 http://www.wangjie.org/ Landing page templates for startups https://cruip.com/ Avataaars Generator https://getavataaars.com/?avatarStyle=Circle 中国色 http://zhongguose.com/ 完美对称无缝平铺背景图底纹素材 - 图鱼 https://www.hituyu.com/ 花瓣网_陪你做生活的设计师（创意灵感天堂，搜索、发现设计灵感、设计素材） https://huaban.com/ 站酷 (ZCOOL) - 设计师互动平台 - 打开站酷，发现更好的设计！ https://www.zcool.com.cn/ UI中国用户体验设计平台 https://www.ui.cn/ 68Design - 找兼职设计师就上68Design - 【设计师接单平台】 https://www.68design.net/ Flat Design Inspiration - Flat UI https://flatui.com/ UI Movement - The best UI design inspiration, every day https://uimovement.com/ Collect UI - Daily inspiration collected from daily ui archive and beyond. Based on Dribbble shots, hand picked, updating daily. http://www.collectui.com/ siteInspire - Web Design Inspiration https://www.siteinspire.com/ Dribbble - Discover the World’s Top Designers &amp; Creative Professionals https://dribbble.com/ Blocs - Fast, easy to use and powerful visual web design tool, that lets you create responsive websites without writing code. https://blocsapp.com/ UI Design Resources, UI Kits, Wireframes, Icons and More - UI8 https://ui8.net/ UI-Patterns.com https://ui-patterns.com/ 学UI网-UI设计师导航网，最专业的UI设计网站 http://hao.xueui.cn/ 优设导航 - 学设计从这里开始！ http://hao.uisdc.com/ 饭团导航 精选设计师实用工具导航 hao.psefan.com http://hao.psefan.com/ 设计导航 - 精选最好的设计网站大全 https://hao.shejidaren.com/ 优波设计 - 设计师必备网址导航 ubuuk.com https://www.ubuuk.com/ 设计订阅 - 腾讯设计导航 https://idesign.qq.com/#!index/feed http://www.bigbigwork.com/nav/6.html http://www.foolo.cn/ 工业设计网站导航 | 设计癖 http://hao.shejipi.com/ 46设计导航_设计网站大全_46design.com http://www.46design.com/2019/ UI设计师导航网 - 优阁 http://so.uigreat.com/ Canva在线平面设计软件_免费设计模板素材和海量正版图片 - Canva中文官网 https://www.canva.cn/ 创客贴_平面设计作图神器_免费设计模板_在线稿定设计印刷 https://www.chuangkit.com/ 轻量级在线平面设计工具 - 图帮主 https://www.tubangzhu.com/ 图怪兽作图神器-在线图片编辑器-PS图片制作-搞定平面设计不求人 https://818ps.com/ Fotor在线设计工具_免费设计素材和模板_在线平面设计网站 https://www.fotor.com.cn/ Presentation Software Online Presentation Tools 设计癖 | 关注设计癖 提升幸福感 http://www.shejipi.com/ xiaopiu-产品原型设计工具与团队实时协作平台 https://www.xiaopiu.com/ 燃设计-共享全球好设计_软装素材分享_软装设计灵感图库 http://www.ransheji.com/ Themes - macOS - Human Interface Guidelines - Apple Developer https://developer.apple.com/design/human-interface-guidelines/macos/overview/themes/ Overview - Atlassian Design https://atlassian.design/guidelines/product/overview 介绍 - Ant Design https://ant.design/docs/spec/introduce-cn WeUI https://weui.io/ Documentation - Materialize https://materializecss.com/ Styleguide https://www.yelp.com/styleguide/mobile 优优灵感-设计师灵感展现与启发-优优教程网 https://uiiiuiii.com/inspiration Crello — Free Graphic Design Software Create Images Online Tool 优设导航 - 学设计从这里开始！ https://hao.uisdc.com/ Creative Mass https://creativemass.cn/#/ 设计师之家 https://www.51sjsj.com/ Design Seeds for all who ♥ color The Nordnet Brand - Nordnet Brand https://brand.nordnet.se/ STUDIO Design to live website in one click. KOPPT，一个做PPT的神器！ http://koppt.cn/ 图片素材 网站 网址 Unsplash https://unsplash.com/ Pexels https://www.pexels.com/zh-cn/ Gratisography https://gratisography.com/ Beautiful free stock photos https://stocksnap.io/ Foodiesfeed https://www.foodiesfeed.com/ Freephotos https://freephotos.cc/zh Uniquely free photos. https://www.reshot.com/ Free images for creatives, by creatives https://morguefile.com/quest 沙沙野 https://www.ssyer.com/ 图虫 https://tuchong.com/ 摄图网 https://699pic.com/ 7MX——Home Business Advertising Ideas https://7mx.com/ 图品汇 https://www.88tph.com/ Free Photos for bloggers and creatives! http://photopin.com/ 花瓣美素 http://www.meisupic.com/ PAKUTASO https://www.pakutaso.com/ 懒人图库 http://www.lanrentuku.com/ SEARCH FOR CONTENT TO REUSE https://search.creativecommons.org/ Free Stock Photos by Canva https://www.canva.com/photos/free/ Creative Briefs. Request for photos https://morguefile.com/quest ImageFinder https://imagefinder.co/ 泼辣有图 http://www.polayoutu.com/collections visualhunt https://visualhunt.com/ foter https://foter.com/ Free high resolution photography - Life of Pix - Home https://www.lifeofpix.com/ New Old Stock https://nos.twnsnd.co/ 千图网 https://www.58pic.com/ Hand-picked free photos for your inspiration - Magdeleine https://magdeleine.co/ 昵图网 http://www.nipic.com/ photock https://www.photock.jp/ 免费正版高清图片素材库 https://pixabay.com/zh/ piqsels https://www.piqsels.com/zh DesignersPics http://www.designerspics.com/ freeimages https://cn.freeimages.com/ StreetWill http://www.streetwill.co/ Discover and share the world's best photos https://web.500px.com/ FREE TRAVEL PHOTOS https://www.bucketlistly.blog/photos Free Stock Photos For Commercial Use. https://www.splitshire.com/splitshire-free-stock-photos/ BURST https://burst.shopify.com/ FOCA https://focastock.com/ jay mantri https://jaymantri.com/#= LET'S FIND THE PERFECT PHOTO FOR YOU https://kaboompics.com/ A curated collection of free web design resources, all for commercial use. http://imcreator.com/free Zoommy https://zoommyapp.com/ STOKPIC - Free Stock Photos For Commercial Use https://stokpic.com/ Cupcake http://cupcake.nilssonlee.se/ Folkert Gorter Superfamous Images https://images.superfamous.com/ PICGRAPHY https://picography.co/ Free stock illustrations, Beautiful Free Art - Mixkit https://mixkit.co/free-stock-art/ Free Stock Photos https://photo-ac.com/ scrolller https://scrolller.com/art JOHN KRAUS PHOTOS https://www.johnkrausphotos.com/Portfolio/ Picrew https://picrew.me/ GENERATED FACES https://generated.photos/faces 用大作，不用翻墙和VPN秒看pixabay上的设计 http://www.bigbigwork.com/pixabay.html Awesome Wallpapers - wallhaven.cc https://wallhaven.cc/ 摄图网-正版高清图片免费下载_商用设计素材图库http://699pic.com/ 纹理 网站 网址 Subtle Patterns Free textures for your next web project 完美对称无缝平铺背景图底纹素材 - 图鱼 https://www.hituyu.com/ The Pattern Library http://thepatternlibrary.com 渐变 网站 网址 Fresh Background Gradients WebGradients.com 💎 uiGradients - Beautiful colored gradients https://uigradients.com/#TalkingToMiceElf LowPoly背景下载网站 网站 网址 uiGradients - Beautiful colored gradients https://uigradients.com/#Blu 地图生成网站 网站 网址 Pixel Map Generator amCharts 样机生成网站 网站 网址 Smartmockups - Free product mockup generator https://smartmockups.com/ Sketchsheets - Ready to print sketch sheet templates for UX designers https://sketchsheets.com/ Make Mockups, Logos, Videos and Designs in Seconds https://placeit.net/ GIF 网站 网址 With Stock Animated GIFs Crafted for Commercial Use https://cliply.co/ SOOGIF，找动图做动图.gif https://www.soogif.com/ Search all the GIFs and Stickers https://giphy.com/ LOGO 网站 网址 Instant Logo Search http://instantlogosearch.com/ Logo Maker - Create Your Own Logo, It's Free! - FreeLogoDesign https://www.freelogodesign.org/ PNG 网站 网址 free PNGs https://www.freepngs.com/search-pngs CLEAN PNG https://www.cleanpng.com/ 365psd https://cn.365psd.com/free-psd Download Free Vectors, Clipart Graphics, Vector Art &amp; Design Templates https://www.vecteezy.com/ freepik https://www.freepik.com/ humaaans https://www.humaaans.com/ illustrations 网站 网址 Free Vector Illustrations to Class up Your Project https://icons8.com/ouch IRA Design - Build your own amazing illustrations @ Creative Tim https://iradesign.io/ absurd illustrations that make sense https://absurd.design/ Illustration Gallery by ManyPixels Open-Source Editable Illustrations Free Vectors, Stock Photos &amp; PSD Downloads Freepik Illustration Gallery https://www.manypixels.co/gallery/ Illustration Gallery https://www.manypixels.co/gallery/ FREE ILLUSTRATIONS https://lukaszadam.com/illustrations 视频素材 网站 网址 Thousands of Free High-Resolution CC0 Photos and Videos https://isorepublic.com/ NASA Image and Video Library https://images.nasa.gov/ COVERR - Beautiful Free Stock Video Footage https://coverr.co/ Golden Wolf https://goldenwolf.tv/ 场库 https://www.vmovier.com/ Free stock videos · Pexels Videos https://www.pexels.com/videos/ 天空之城 https://www.skypixel.com/ Distill: Free HD Stock Video &amp; HD Video Clips https://wedistill.io/ Free Video Footage - Best Free Backgrounds Stock Video Footage https://www.free-video-footage.com/ Free Motion Backgrounds MP4, MOV video backgrounds for FREE! Free Stock Video Footage HD 4K Download Motion Graphics https://www.videvo.net/ Free Stock Footage Videos, 4k After Effects Templates and More! https://www.videezy.com/ Free 4K Stock Video | Stock Footage for Free – {Dareful} Completely Free 4K Stock Video https://www.dareful.com/ Free Stock Video Footage HD Royalty-Free Videos Download https://mazwai.com/#/ iTunes Movie Trailers https://trailers.apple.com/ Mixkit - Awesome free assets for your next video project https://mixkit.co/ XStockvideo http://www.xstockvideo.com/ ICON 网站 网址 IconMoon https://icomoon.io/ iconmonstr https://iconmonstr.com/ Zwicon – Icon set https://www.zwicon.com/cheatsheet.html Find Similar Icons http://compute.vision/nouns/index.html 图标下载，ICON(SVG/PNG/ICO/ICNS)图标搜索下载 - Easyicon http://www.easyicon.net Icon Ninja - 33350 vector icons and 700081 png icons for free download https://www.iconninja.com/ iconSweets — DesignBombs https://designbombs.com/iconsweets/ easyicon https://www.easyicon.net/ Icons for everything https://thenounproject.com/ 字体 网站 网址 iconfont https://www.iconfont.cn/ 100font.com - 免版权字体下载、免费商用字体下载网站 https://www.100font.com/ 造字工房 https://www.makefont.com/ 方正字库 http://www.foundertype.com/ 汉仪字库-用心绽放文字之美 http://www.hanyi.com.cn/ Font-To-Width http://font-to-width.com/ 字体下载-求字体网提供中文和英文字体库下载、识别与预览服务，找字体的好帮手 http://www.qiuziti.com/ ","link":"https://tdmaker.github.io/faded/post/su-cai-wang-zhan/"},{"title":"资源网站","content":"PPT 网站 网址 51PPT模板 http://www.51pptmoban.com/ 优品PPT http://www.ypppt.com/ Office PLUS http://www.officeplus.cn/Template/Home.shtml 办公资源 https://www.bangongziyuan.com/ PPT Boss https://www.pptboss.com/template-center PPT之家 https://www.52ppt.com/moban/ 第一PPT http://www.1ppt.com/ 比格PPT http://www.tretars.com/ppt-templates 叮当设计PPT http://www.dingdangsheji.com/category/ppt/ 我图网精选PPT https://www.ooopic.com/intro/kidHome/ppt/ 设计师导航 网站 网址 叮当设计 http://www.dingdangsheji.com/ ","link":"https://tdmaker.github.io/faded/post/zi-yuan-wang-zhan/"},{"title":"特色搜索","content":"网盘搜索 网站 网址 盘搜搜 https://www.pansoso.com/ 如风搜 http://www.rufengso.net/ 6miu百度云搜索 http://baiduyun.6miu.com/ 57分享百度云 https://www.57fx.com/user-drnew-daren/ 小不点搜索 https://www.xiaoso.net/ 特色搜索 网站 网址 龙轩搜索 http://ilxdh.com/ 虫部落搜索 https://www.chongbuluo.com/ neets搜索站 https://neets.cc/ 西林街搜索 https://xilinjie.cc/ 茶杯狐 https://www.cupfox.com/ 疯狂影视搜索 http://ifkdy.com/ AnywhereAnything http://lackar.com/aa/ 源代码搜索 https://publicwww.com/ 变量名搜索 https://unbug.github.io/codelf/ 比菲尔德学术搜索 https://www.base-search.net/ 吉他尤克里里谱搜索 https://sopu.52cmajor.com/ Classcentral在线课程搜索 https://www.classcentral.com/ Coursade在线课程搜索 http://www.coursade.com/ Chinese Etymology 字源 https://hanziyuan.net/ 汉典 https://www.zdic.net/ 新华字典 https://zidian.911cha.com/ 导航站 网站 网址 创造狮导航 http://chuangzaoshi.com/ 导航湾 https://www.daohangwan.com/ 好用好玩导航 http://www.haoyonghaowan.com/ 比格张 https://bigezhang.com/ Web前端导航 http://nav.web-hub.cn/ 阿猫阿狗导航 https://dh.woshipm.com/ BTMoo导航 https://www.btmoo.net/ ","link":"https://tdmaker.github.io/faded/post/te-se-sou-suo/"},{"title":"电子书下载","content":"电子书下载 网站 网址 Baen free library https://www.baen.com/allbooks/category/index/id/2012 智奇搜书 https://www.zqbook.top/ 云海电子图书馆 http://www.pdfbook.cn/ 必看网 https://www.biikan.com/ bookboon https://bookboon.com/en Free-Ebooks https://www.free-ebooks.net/ ZLibrary https://b-ok.org/ 书格 https://new.shuge.org/ Academia https://www.academia.edu/ 图灵社区 https://www.ituring.com.cn/ 书伴 https://bookfere.com/ 好读 http://haodoo.net/ ePUBee http://cn.epubee.com/books/ 三秋书屋 https://www.d4j.cn/ SoBooks https://sobooks.cc/ i-Book.in https://book.tstrs.me/ WOW! eBook https://www.wowebook.org/ 计算机书籍控 http://bestcbooks.com/ 鸠摩搜索 https://www.jiumodiary.com/ Library Genesis http://gen.lib.rus.ec/ Library Genesis 2M http://libgen.io/ 免费的计算机编程类中文书籍 https://github.com/justjavac/free-programming-books-zh_CN 国立国会图书馆 https://dl.ndl.go.jp/ ZLibrary https://b-ok.cc/s/ 电子书转换 网站 网址 在线电子书转换器 http://cn.epubee.com/ 文本或 eBook 转换为 Mobi 格式 https://ebook.online-convert.com/convert-to-mobi ","link":"https://tdmaker.github.io/faded/post/ebooks-download/"},{"title":"正则表达式——银行卡号","content":"记录中国主要银行发行的银行卡号的正则表达式 多种银行卡正则 var bankcardList = [{ bankName: &quot;中国邮政储蓄银行&quot;, bankCode: &quot;PSBC&quot;, patterns: [{ reg: /^(621096|621098|622150|622151|622181|622188|622199|955100|621095|620062|621285|621798|621799|621797|620529|621622|621599|621674|623218|623219)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(62215049|62215050|62215051|62218850|62218851|62218849)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622812|622810|622811|628310|625919)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;中国工商银行&quot;, bankCode: &quot;ICBC&quot;, patterns: [{ reg: /^(620200|620302|620402|620403|620404|620406|620407|620409|620410|620411|620412|620502|620503|620405|620408|620512|620602|620604|620607|620611|620612|620704|620706|620707|620708|620709|620710|620609|620712|620713|620714|620802|620711|620904|620905|621001|620902|621103|621105|621106|621107|621102|621203|621204|621205|621206|621207|621208|621209|621210|621302|621303|621202|621305|621306|621307|621309|621311|621313|621211|621315|621304|621402|621404|621405|621406|621407|621408|621409|621410|621502|621317|621511|621602|621603|621604|621605|621608|621609|621610|621611|621612|621613|621614|621615|621616|621617|621607|621606|621804|621807|621813|621814|621817|621901|621904|621905|621906|621907|621908|621909|621910|621911|621912|621913|621915|622002|621903|622004|622005|622006|622007|622008|622010|622011|622012|621914|622015|622016|622003|622018|622019|622020|622102|622103|622104|622105|622013|622111|622114|622017|622110|622303|622304|622305|622306|622307|622308|622309|622314|622315|622317|622302|622402|622403|622404|622313|622504|622505|622509|622513|622517|622502|622604|622605|622606|622510|622703|622715|622806|622902|622903|622706|623002|623006|623008|623011|623012|622904|623015|623100|623202|623301|623400|623500|623602|623803|623901|623014|624100|624200|624301|624402|623700|624000)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622200|622202|622203|622208|621225|620058|621281|900000|621558|621559|621722|621723|620086|621226|621618|620516|621227|621288|621721|900010|623062|621670|621720|621379|621240|621724|621762|621414|621375|622926|622927|622928|622929|622930|622931|621733|621732|621372|621369|621763)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(402791|427028|427038|548259|621376|621423|621428|621434|621761|621749|621300|621378|622944|622949|621371|621730|621734|621433|621370|621764|621464|621765|621750|621377|621367|621374|621731|621781)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(9558)\\d{15}$/g, cardType: &quot;DC&quot; }, { reg: /^(370246|370248|370249|370247|370267|374738|374739)\\d{9}$/g, cardType: &quot;CC&quot; }, { reg: /^(427010|427018|427019|427020|427029|427030|427039|438125|438126|451804|451810|451811|458071|489734|489735|489736|510529|427062|524091|427064|530970|530990|558360|524047|525498|622230|622231|622232|622233|622234|622235|622237|622239|622240|622245|622238|451804|451810|451811|458071|628288|628286|622206|526836|513685|543098|458441|622246|544210|548943|356879|356880|356881|356882|528856|625330|625331|625332|622236|524374|550213|625929|625927|625939|625987|625930|625114|622159|625021|625022|625932|622889|625900|625915|625916|622171|625931|625113|625928|625914|625986|625925|625921|625926|625942|622158|625917|625922|625934|625933|625920|625924|625017|625018|625019)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(45806|53098|45806|53098)\\d{11}$/g, cardType: &quot;CC&quot; }, { reg: /^(622210|622211|622212|622213|622214|622220|622223|622225|622229|622215|622224)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(620054|620142|620184|620030|620050|620143|620149|620124|620183|620094|620186|620148|620185)\\d{10}$/g, cardType: &quot;PC&quot; }, { reg: /^(620114|620187|620046)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;中国农业银行&quot;, bankCode: &quot;ABC&quot;, patterns: [{ reg: /^(622841|622824|622826|622848|620059|621282|622828|622823|621336|621619|622821|622822|622825|622827|622845|622849|623018|623206|621671|622840|622843|622844|622846|622847|620501)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(95595|95596|95597|95598|95599)\\d{14}$/g, cardType: &quot;DC&quot; }, { reg: /^(103)\\d{16}$/g, cardType: &quot;DC&quot; }, { reg: /^(403361|404117|404118|404119|404120|404121|463758|519412|519413|520082|520083|552599|558730|514027|622836|622837|628268|625996|625998|625997|622838|625336|625826|625827|544243|548478|628269)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622820|622830)\\d{10}$/g, cardType: &quot;SCC&quot; }] }, { bankName: &quot;中国银行&quot;, bankCode: &quot;BOC&quot;, patterns: [{ reg: /^(621660|621661|621662|621663|621665|621667|621668|621669|621666|456351|601382|621256|621212|621283|620061|621725|621330|621331|621332|621333|621297|621568|621569|621672|623208|621620|621756|621757|621758|621759|621785|621786|621787|621788|621789|621790|622273|622274|622771|622772|622770|621741|621041)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(621293|621294|621342|621343|621364|621394|621648|621248|621215|621249|621231|621638|621334|621395|623040|622348)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625908|625910|625909|356833|356835|409665|409666|409668|409669|409670|409671|409672|512315|512316|512411|512412|514957|409667|438088|552742|553131|514958|622760|628388|518377|622788|628313|628312|622750|622751|625145|622479|622480|622789|625140|622346|622347)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(518378|518379|518474|518475|518476|524865|525745|525746|547766|558868|622752|622753|622755|524864|622757|622758|622759|622761|622762|622763|622756|622754|622764|622765|558869|625905|625906|625907|625333)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(53591|49102|377677)\\d{11}$/g, cardType: &quot;SCC&quot; }, { reg: /^(620514|620025|620026|620210|620211|620019|620035|620202|620203|620048|620515|920000)\\d{10}$/g, cardType: &quot;PC&quot; }, { reg: /^(620040|620531|620513|921000|620038)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;中国建设银行&quot;, bankCode: &quot;CCB&quot;, patterns: [{ reg: /^(621284|436742|589970|620060|621081|621467|621598|621621|621700|622280|622700|623211|623668)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(421349|434061|434062|524094|526410|552245|621080|621082|621466|621488|621499|622966|622988|622382|621487|621083|621084|620107)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(436742193|622280193)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(553242)\\d{12}$/g, cardType: &quot;CC&quot; }, { reg: /^(625362|625363|628316|628317|356896|356899|356895|436718|436738|436745|436748|489592|531693|532450|532458|544887|552801|557080|558895|559051|622166|622168|622708|625964|625965|625966|628266|628366|622381|622675|622676|622677)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(5453242|5491031|5544033)\\d{11}$/g, cardType: &quot;CC&quot; }, { reg: /^(622725|622728|436728|453242|491031|544033|622707|625955|625956)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(53242|53243)\\d{11}$/g, cardType: &quot;SCC&quot; }] }, { bankName: &quot;中国交通银行&quot;, bankCode: &quot;COMM&quot;, patterns: [{ reg: /^(622261|622260|622262|621002|621069|621436|621335)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(620013)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(405512|601428|405512|601428|622258|622259|405512|601428)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(49104|53783)\\d{11}$/g, cardType: &quot;CC&quot; }, { reg: /^(434910|458123|458124|520169|522964|552853|622250|622251|521899|622253|622656|628216|622252|955590|955591|955592|955593|628218|625028|625029)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622254|622255|622256|622257|622284)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(620021|620521)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;招商银行&quot;, bankCode: &quot;CMB&quot;, patterns: [{ reg: /^(402658|410062|468203|512425|524011|622580|622588|622598|622609|95555|621286|621483|621485|621486|621299)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(690755)\\d{9}$/g, cardType: &quot;DC&quot; }, { reg: /^(690755)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(356885|356886|356887|356888|356890|439188|439227|479228|479229|521302|356889|545620|545621|545947|545948|552534|552587|622575|622576|622577|622578|622579|545619|622581|622582|545623|628290|439225|518710|518718|628362|439226|628262|625802|625803)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(370285|370286|370287|370289)\\d{9}$/g, cardType: &quot;CC&quot; }, { reg: /^(620520)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;中国民生银行&quot;, bankCode: &quot;CMBC&quot;, patterns: [{ reg: /^(622615|622616|622618|622622|622617|622619|415599|421393|421865|427570|427571|472067|472068|622620)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(545392|545393|545431|545447|356859|356857|407405|421869|421870|421871|512466|356856|528948|552288|622600|622601|622602|517636|622621|628258|556610|622603|464580|464581|523952|545217|553161|356858|622623|625912|625913|625911)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(377155|377152|377153|377158)\\d{9}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;中国光大银行&quot;, bankCode: &quot;CEB&quot;, patterns: [{ reg: /^(303)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(90030)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(620535)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(620085|622660|622662|622663|622664|622665|622666|622667|622669|622670|622671|622672|622668|622661|622674|622673|620518|621489|621492)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(356837|356838|486497|622657|622685|622659|622687|625978|625980|625981|625979|356839|356840|406252|406254|425862|481699|524090|543159|622161|622570|622650|622655|622658|625975|625977|628201|628202|625339|625976)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;中信银行&quot;, bankCode: &quot;CITIC&quot;, patterns: [{ reg: /^(433670|433680|442729|442730|620082|622690|622691|622692|622696|622698|622998|622999|433671|968807|968808|968809|621771|621767|621768|621770|621772|621773|622453|622456)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622459)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(376968|376969|376966)\\d{9}$/g, cardType: &quot;CC&quot; }, { reg: /^(400360|403391|403392|404158|404159|404171|404172|404173|404174|404157|433667|433668|433669|514906|403393|520108|433666|558916|622678|622679|622680|622688|622689|628206|556617|628209|518212|628208|356390|356391|356392|622916|622918|622919)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;华夏银行&quot;, bankCode: &quot;HXBANK&quot;, patterns: [{ reg: /^(622630|622631|622632|622633|999999|621222|623020|623021|623022|623023)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(523959|528709|539867|539868|622637|622638|628318|528708|622636|625967|625968|625969)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;深发/平安银行&quot;, bankCode: &quot;SPABANK&quot;, patterns: [{ reg: /^(621626|623058)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(602907|622986|622989|622298|627069|627068|627066|627067|412963|415752|415753|622535|622536|622538|622539|998800|412962|622983)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(531659|622157|528020|622155|622156|526855|356869|356868|625360|625361|628296|435744|435745|483536|622525|622526|998801|998802)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620010)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;兴业银行&quot;, bankCode: &quot;CIB&quot;, patterns: [{ reg: /^(438589)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(90592)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(966666|622909|438588|622908)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(461982|486493|486494|486861|523036|451289|527414|528057|622901|622902|622922|628212|451290|524070|625084|625085|625086|625087|548738|549633|552398|625082|625083|625960|625961|625962|625963)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620010)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;上海银行&quot;, bankCode: &quot;SHBANK&quot;, patterns: [{ reg: /^(621050|622172|622985|622987|620522|622267|622278|622279|622468|622892|940021)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(438600)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(356827|356828|356830|402673|402674|486466|519498|520131|524031|548838|622148|622149|622268|356829|622300|628230|622269|625099|625953)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;浦东发展银行&quot;, bankCode: &quot;SPDB&quot;, patterns: [{ reg: /^(622516|622517|622518|622521|622522|622523|984301|984303|621352|621793|621795|621796|621351|621390|621792|621791)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(84301|84336|84373|84385|84390|87000|87010|87030|87040|84380|84361|87050|84342)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(356851|356852|404738|404739|456418|498451|515672|356850|517650|525998|622177|622277|628222|622500|628221|622176|622276|622228|625957|625958|625993|625831)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622520|622519)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(620530)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;广发银行&quot;, bankCode: &quot;GDB&quot;, patterns: [{ reg: /^(622516|622517|622518|622521|622522|622523|984301|984303|621352|621793|621795|621796|621351|621390|621792|621791)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622568|6858001|6858009|621462)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(9111)\\d{15}$/g, cardType: &quot;DC&quot; }, { reg: /^(406365|406366|428911|436768|436769|436770|487013|491032|491033|491034|491035|491036|491037|491038|436771|518364|520152|520382|541709|541710|548844|552794|493427|622555|622556|622557|622558|622559|622560|528931|558894|625072|625071|628260|628259|625805|625806|625807|625808|625809|625810)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(685800|6858000)\\d{13}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;渤海银行&quot;, bankCode: &quot;BOHAIB&quot;, patterns: [{ reg: /^(621268|622684|622884|621453)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;广州银行&quot;, bankCode: &quot;GCB&quot;, patterns: [{ reg: /^(603445|622467|940016|621463)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;金华银行&quot;, bankCode: &quot;JHBANK&quot;, patterns: [{ reg: /^(622449|940051)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622450|628204)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;温州银行&quot;, bankCode: &quot;WZCB&quot;, patterns: [{ reg: /^(621977)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622868|622899|628255)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;徽商银行&quot;, bankCode: &quot;HSBANK&quot;, patterns: [{ reg: /^(622877|622879|621775|623203)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(603601|622137|622327|622340|622366)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(628251|622651|625828)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;江苏银行&quot;, bankCode: &quot;JSBANK&quot;, patterns: [{ reg: /^(621076|622173|622131|621579|622876)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(504923|622422|622447|940076)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628210|622283|625902)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;南京银行&quot;, bankCode: &quot;NJCB&quot;, patterns: [{ reg: /^(621777|622305|621259)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622303|628242|622595|622596)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;宁波银行&quot;, bankCode: &quot;NBBANK&quot;, patterns: [{ reg: /^(621279|622281|622316|940022)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621418)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625903|622778|628207|512431|520194|622282|622318)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;北京银行&quot;, bankCode: &quot;BJBANK&quot;, patterns: [{ reg: /^(623111|421317|422161|602969|422160|621030|621420|621468)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(522001|622163|622853|628203|622851|622852)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;北京农村商业银行&quot;, bankCode: &quot;BJRCB&quot;, patterns: [{ reg: /^(620088|621068|622138|621066|621560)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625526|625186|628336)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;汇丰银行&quot;, bankCode: &quot;HSBC&quot;, patterns: [{ reg: /^(622946)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622406|621442)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622407|621443)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622360|622361|625034|625096|625098)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;渣打银行&quot;, bankCode: &quot;SCB&quot;, patterns: [{ reg: /^(622948|621740|622942|622994)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622482|622483|622484)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;花旗银行&quot;, bankCode: &quot;CITI&quot;, patterns: [{ reg: /^(621062|621063)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625076|625077|625074|625075|622371|625091)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;东亚银行&quot;, bankCode: &quot;HKBEA&quot;, patterns: [{ reg: /^(622933|622938|623031|622943|621411)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622372|622471|622472|622265|622266|625972|625973)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622365)\\d{11}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;广东华兴银行&quot;, bankCode: &quot;GHB&quot;, patterns: [{ reg: /^(621469|621625)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;深圳农村商业银行&quot;, bankCode: &quot;SRCB&quot;, patterns: [{ reg: /^(622128|622129|623035)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;广州农村商业银行股份有限公司&quot;, bankCode: &quot;GZRCU&quot;, patterns: [{ reg: /^(909810|940035|621522|622439)\\d{12}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;东莞农村商业银行&quot;, bankCode: &quot;DRCBCL&quot;, patterns: [{ reg: /^(622328|940062|623038)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625288|625888)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;东莞市商业银行&quot;, bankCode: &quot;BOD&quot;, patterns: [{ reg: /^(622333|940050)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621439|623010)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622888)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;广东省农村信用社联合社&quot;, bankCode: &quot;GDRCC&quot;, patterns: [{ reg: /^(622302)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622477|622509|622510|622362|621018|621518)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;大新银行&quot;, bankCode: &quot;DSB&quot;, patterns: [{ reg: /^(622297|621277)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622375|622489)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622293|622295|622296|622373|622451|622294|625940)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;永亨银行&quot;, bankCode: &quot;WHB&quot;, patterns: [{ reg: /^(622871|622958|622963|622957|622861|622932|622862|621298)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622798|625010|622775|622785)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;星展银行香港有限公司&quot;, bankCode: &quot;DBS&quot;, patterns: [{ reg: /^(621016|621015)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622487|622490|622491|622492)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622487|622490|622491|622492|621744|621745|621746|621747)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;恒丰银行&quot;, bankCode: &quot;EGBANK&quot;, patterns: [{ reg: /^(623078)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622384|940034)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;天津市商业银行&quot;, bankCode: &quot;TCCB&quot;, patterns: [{ reg: /^(940015|622331)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(6091201)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622426|628205)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;浙商银行&quot;, bankCode: &quot;CZBANK&quot;, patterns: [{ reg: /^(621019|622309|621019)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(6223091100|6223092900|6223093310|6223093320|6223093330|6223093370|6223093380|6223096510|6223097910)\\d{9}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;南洋商业银行&quot;, bankCode: &quot;NCB&quot;, patterns: [{ reg: /^(621213|621289|621290|621291|621292|621042|621743)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(623041|622351)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625046|625044|625058|622349|622350)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620208|620209|625093|625095)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;厦门银行&quot;, bankCode: &quot;XMBANK&quot;, patterns: [{ reg: /^(622393|940023)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(6886592)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(623019|621600|)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;福建海峡银行&quot;, bankCode: &quot;FJHXBC&quot;, patterns: [{ reg: /^(622388)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621267|623063)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(620043|)\\d{12}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;吉林银行&quot;, bankCode: &quot;JLBANK&quot;, patterns: [{ reg: /^(622865|623131)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(940012)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622178|622179|628358)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;汉口银行&quot;, bankCode: &quot;HKB&quot;, patterns: [{ reg: /^(990027)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622325|623105|623029)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;盛京银行&quot;, bankCode: &quot;SJBANK&quot;, patterns: [{ reg: /^(566666)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622455|940039)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(623108|623081)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622466|628285)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;大连银行&quot;, bankCode: &quot;DLB&quot;, patterns: [{ reg: /^(603708)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622993|623069|623070|623172|623173)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622383|622385|628299)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;河北银行&quot;, bankCode: &quot;BHB&quot;, patterns: [{ reg: /^(622498|622499|623000|940046)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622921|628321)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;乌鲁木齐市商业银行&quot;, bankCode: &quot;URMQCCB&quot;, patterns: [{ reg: /^(621751|622143|940001|621754)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622476|628278)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;绍兴银行&quot;, bankCode: &quot;SXCB&quot;, patterns: [{ reg: /^(622486)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(603602|623026|623086)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(628291)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;成都商业银行&quot;, bankCode: &quot;CDCB&quot;, patterns: [{ reg: /^(622152|622154|622996|622997|940027|622153|622135|621482|621532)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;抚顺银行&quot;, bankCode: &quot;FSCB&quot;, patterns: [{ reg: /^(622442)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(940053)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622442|623099)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;郑州银行&quot;, bankCode: &quot;ZZBANK&quot;, patterns: [{ reg: /^(622421)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(940056)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(96828)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;宁夏银行&quot;, bankCode: &quot;NXBANK&quot;, patterns: [{ reg: /^(621529|622429|621417|623089|623200)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628214|625529|622428)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;重庆银行&quot;, bankCode: &quot;CQBANK&quot;, patterns: [{ reg: /^(9896)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622134|940018|623016)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;哈尔滨银行&quot;, bankCode: &quot;HRBANK&quot;, patterns: [{ reg: /^(621577|622425)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(940049)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622425)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;兰州银行&quot;, bankCode: &quot;LZYH&quot;, patterns: [{ reg: /^(622139|940040|628263)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621242|621538|621496)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;青岛银行&quot;, bankCode: &quot;QDCCB&quot;, patterns: [{ reg: /^(621252|622146|940061|628239)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621419|623170)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;秦皇岛市商业银行&quot;, bankCode: &quot;QHDCCB&quot;, patterns: [{ reg: /^(62249802|94004602)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(621237|623003)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;青海银行&quot;, bankCode: &quot;BOQH&quot;, patterns: [{ reg: /^(622310|940068)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622817|628287|625959)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(62536601)\\d{8}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;台州银行&quot;, bankCode: &quot;TZCB&quot;, patterns: [{ reg: /^(622427)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(940069)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(623039)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622321|628273)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(625001)\\d{10}$/g, cardType: &quot;SCC&quot; }] }, { bankName: &quot;长沙银行&quot;, bankCode: &quot;CSCB&quot;, patterns: [{ reg: /^(694301)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(940071|622368|621446)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625901|622898|622900|628281|628282|622806|628283)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620519)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;泉州银行&quot;, bankCode: &quot;BOQZ&quot;, patterns: [{ reg: /^(683970|940074)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622370)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(621437)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628319)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;包商银行&quot;, bankCode: &quot;BSB&quot;, patterns: [{ reg: /^(622336|621760)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622165)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622315|625950|628295)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;龙江银行&quot;, bankCode: &quot;DAQINGB&quot;, patterns: [{ reg: /^(621037|621097|621588|622977)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(62321601)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622860)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622644|628333)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;上海农商银行&quot;, bankCode: &quot;SHRCB&quot;, patterns: [{ reg: /^(622478|940013|621495)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625500)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(622611|622722|628211|625989)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;浙江泰隆商业银行&quot;, bankCode: &quot;ZJQL&quot;, patterns: [{ reg: /^(622717)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(628275|622565|622287)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;内蒙古银行&quot;, bankCode: &quot;H3CB&quot;, patterns: [{ reg: /^(622147|621633)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628252)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;广西北部湾银行&quot;, bankCode: &quot;BGB&quot;, patterns: [{ reg: /^(623001)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628227)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622335)\\d{10}$/g, cardType: &quot;CC&quot; } ] }, { bankName: &quot;桂林银行&quot;, bankCode: &quot;GLBANK&quot;, patterns: [{ reg: /^(621456)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(621562)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628219)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;龙江银行&quot;, bankCode: &quot;DAQINGB&quot;, patterns: [{ reg: /^(621037|621097|621588|622977)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(62321601)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622475|622860)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625588)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(622270|628368|625090|622644|628333)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;成都农村商业银行&quot;, bankCode: &quot;CDRCB&quot;, patterns: [{ reg: /^(623088)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622829|628301|622808|628308)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;福建省农村信用社联合社&quot;, bankCode: &quot;FJNX&quot;, patterns: [{ reg: /^(622127|622184|621701|621251|621589|623036)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628232|622802|622290)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;天津农村商业银行&quot;, bankCode: &quot;TRCB&quot;, patterns: [{ reg: /^(622531|622329)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622829|628301)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;江苏省农村信用社联合社&quot;, bankCode: &quot;JSRCU&quot;, patterns: [{ reg: /^(621578|623066|622452|622324)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622815|622816|628226)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;湖南农村信用社联合社&quot;, bankCode: &quot;SLH&quot;, patterns: [{ reg: /^(622906|628386|625519|625506)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;江西省农村信用社联合社&quot;, bankCode: &quot;JXNCX&quot;, patterns: [{ reg: /^(621592)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628392)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;商丘市商业银行&quot;, bankCode: &quot;SCBBANK&quot;, patterns: [{ reg: /^(621748)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628271)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;华融湘江银行&quot;, bankCode: &quot;HRXJB&quot;, patterns: [{ reg: /^(621366|621388)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628328)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;衡水市商业银行&quot;, bankCode: &quot;HSBK&quot;, patterns: [{ reg: /^(621239|623068)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;重庆南川石银村镇银行&quot;, bankCode: &quot;CQNCSYCZ&quot;, patterns: [{ reg: /^(621653004)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;湖南省农村信用社联合社&quot;, bankCode: &quot;HNRCC&quot;, patterns: [{ reg: /^(622169|621519|621539|623090)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;邢台银行&quot;, bankCode: &quot;XTB&quot;, patterns: [{ reg: /^(621238|620528)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;临汾市尧都区农村信用合作联社&quot;, bankCode: &quot;LPRDNCXYS&quot;, patterns: [{ reg: /^(628382|625158)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;东营银行&quot;, bankCode: &quot;DYCCB&quot;, patterns: [{ reg: /^(621004)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(628217)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;上饶银行&quot;, bankCode: &quot;SRBANK&quot;, patterns: [{ reg: /^(621416)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628217)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;德州银行&quot;, bankCode: &quot;DZBANK&quot;, patterns: [{ reg: /^(622937)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628397)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;承德银行&quot;, bankCode: &quot;CDB&quot;, patterns: [{ reg: /^(628229)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;云南省农村信用社&quot;, bankCode: &quot;YNRCC&quot;, patterns: [{ reg: /^(622469|628307)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;柳州银行&quot;, bankCode: &quot;LZCCB&quot;, patterns: [{ reg: /^(622292|622291|621412)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622880|622881)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(62829)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;威海市商业银行&quot;, bankCode: &quot;WHSYBANK&quot;, patterns: [{ reg: /^(623102)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628234)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;湖州银行&quot;, bankCode: &quot;HZBANK&quot;, patterns: [{ reg: /^(628306)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;潍坊银行&quot;, bankCode: &quot;BANKWF&quot;, patterns: [{ reg: /^(622391|940072)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628391)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;赣州银行&quot;, bankCode: &quot;GZB&quot;, patterns: [{ reg: /^(622967|940073)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628233)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;日照银行&quot;, bankCode: &quot;RZGWYBANK&quot;, patterns: [{ reg: /^(628257)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;南昌银行&quot;, bankCode: &quot;NCB&quot;, patterns: [{ reg: /^(621269|622275)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(940006)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(628305)\\d{11}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;贵阳银行&quot;, bankCode: &quot;GYCB&quot;, patterns: [{ reg: /^(622133|621735)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(888)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628213)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;锦州银行&quot;, bankCode: &quot;BOJZ&quot;, patterns: [{ reg: /^(622990|940003)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(628261)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;齐商银行&quot;, bankCode: &quot;QSBANK&quot;, patterns: [{ reg: /^(622311|940057)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(628311)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;珠海华润银行&quot;, bankCode: &quot;RBOZ&quot;, patterns: [{ reg: /^(622363|940048)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628270)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;葫芦岛市商业银行&quot;, bankCode: &quot;HLDCCB&quot;, patterns: [{ reg: /^(622398|940054)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;宜昌市商业银行&quot;, bankCode: &quot;HBC&quot;, patterns: [{ reg: /^(940055)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622397)\\d{11}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;杭州商业银行&quot;, bankCode: &quot;HZCB&quot;, patterns: [{ reg: /^(603367|622878)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622397)\\d{11}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;苏州市商业银行&quot;, bankCode: &quot;JSBANK&quot;, patterns: [{ reg: /^(603506)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;辽阳银行&quot;, bankCode: &quot;LYCB&quot;, patterns: [{ reg: /^(622399|940043)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;洛阳银行&quot;, bankCode: &quot;LYB&quot;, patterns: [{ reg: /^(622420|940041)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;焦作市商业银行&quot;, bankCode: &quot;JZCBANK&quot;, patterns: [{ reg: /^(622338)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(940032)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;镇江市商业银行&quot;, bankCode: &quot;ZJCCB&quot;, patterns: [{ reg: /^(622394|940025)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;法国兴业银行&quot;, bankCode: &quot;FGXYBANK&quot;, patterns: [{ reg: /^(621245)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;大华银行&quot;, bankCode: &quot;DYBANK&quot;, patterns: [{ reg: /^(621328)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;企业银行&quot;, bankCode: &quot;DIYEBANK&quot;, patterns: [{ reg: /^(621651)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;华侨银行&quot;, bankCode: &quot;HQBANK&quot;, patterns: [{ reg: /^(621077)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;恒生银行&quot;, bankCode: &quot;HSB&quot;, patterns: [{ reg: /^(622409|621441)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622410|621440)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622950|622951)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625026|625024|622376|622378|622377|625092)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;临沂商业银行&quot;, bankCode: &quot;LSB&quot;, patterns: [{ reg: /^(622359|940066)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;烟台商业银行&quot;, bankCode: &quot;YTCB&quot;, patterns: [{ reg: /^(622886)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;齐鲁银行&quot;, bankCode: &quot;QLB&quot;, patterns: [{ reg: /^(940008|622379)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628379)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;BC卡公司&quot;, bankCode: &quot;BCCC&quot;, patterns: [{ reg: /^(620011|620027|620031|620039|620103|620106|620120|620123|620125|620220|620278|620812|621006|621011|621012|621020|621023|621025|621027|621031|620132|621039|621078|621220|621003)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625003|625011|625012|625020|625023|625025|625027|625031|621032|625039|625078|625079|625103|625106|625006|625112|625120|625123|625125|625127|625131|625032|625139|625178|625179|625220|625320|625111|625132|625244)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;集友银行&quot;, bankCode: &quot;CYB&quot;, patterns: [{ reg: /^(622355|623042)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621043|621742)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622352|622353|625048|625053|625060)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620206|620207)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;大丰银行&quot;, bankCode: &quot;TFB&quot;, patterns: [{ reg: /^(622547|622548|622546)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625198|625196|625147)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620072)\\d{13}$/g, cardType: &quot;PC&quot; }, { reg: /^(620204|620205)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;AEON信贷财务亚洲有限公司&quot;, bankCode: &quot;AEON&quot;, patterns: [{ reg: /^(621064|622941|622974)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622493)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;澳门BDA&quot;, bankCode: &quot;MABDA&quot;, patterns: [{ reg: /^(621274|621324)\\d{13}$/g, cardType: &quot;DC&quot; }] }] //验证银行卡号 $(&quot;input[name='bankNum']&quot;).blur(function () { var num = $(this).val(); //去掉空格，因为input框中设置了自动空格，如果input框中没有设置自动空格可省略这句代码 num = num.replace(/\\s/g, &quot;&quot;); //判断卡号是否正确 for (var i = 0,len=bankcardList.length; i &lt; len; i++) { for (var j = 0,regLen = bankcardList[i].patterns.length; j &lt; regLen; j++) { var reg = bankcardList[i].patterns[j].reg.test(num); if(reg){ alert(&quot;输入的是&quot;+bankcardList[i].bankName+&quot;的卡号&quot;) return ; } } } }); ","link":"https://tdmaker.github.io/faded/post/regular-expression-band-card/"},{"title":"正则表达式——简介","content":"在自然语言处理中，很多时候我们都需要从文本或字符串中抽取出想要的信息，并进一步做语义理解或其它处理。 常用正则表达式网站 Regex Dictionary https://visca.com/regexdict/ RegExr https://regexr.com/ RegExper https://regexper.com/ Regular Expressions 101 https://regex101.com/ 基本语句 ♍锚点：^ 和 $ ^The 匹配任何以“The”开头的字符串。 end$ 匹配以“end”为结尾的字符串。 ^The end$ 匹配从“The”开始到“end”结束的字符串。 roar 匹配任何带有文本“roar”的字符串。 ♍数量符：* 和 + 和 ? 和 {} abc* 匹配在“ab”后面跟着 0 个或多个“c”的字符串。 abc+ 匹配在“ab”后面跟着 1 个或多个“c”的字符串。 abc? 匹配在“ab”后面跟着 0 个或 1 个“c”的字符串。 abc{2} 匹配在“ab”后面跟着 2 个“c”的字符串。 abc{2,} 匹配在“ab”后面跟着 2 个或更多“c”的字符串。 abc{2,5} 匹配在“ab”后面跟着 2 到 5 个“c”的字符串。 a(bc)* 匹配在“a”后面跟着 0 个或更多“bc”序列的字符串。 a(bc){2,5} 匹配在“a”后面跟着 2 到 5 个“bc”序列的字符串。 ♍或运算符：| 和 [] a(b|c) 匹配在“a”后面跟着“b”或“c”的字符串。 a[bc] 匹配在“a”后面跟着“b”或“c”的字符串。 ♍字符类：\\d 和 \\w 和 \\s 和 . \\d 匹配数字型的单个字符。 \\w 匹配单个词字（字母加下划线）。 \\s 匹配单个空格字符（包括制表符和换行符）。 . 匹配任意字符。 使用 . 运算符需要非常小心，因为常见类或排除型字符类都要更快与精确。\\d、\\w 和 \\s 同样有它们各自的排除型字符类，即 \\D、\\W 和 \\S。例如 \\D 将执行与 \\d 完全相反的匹配方法： \\D 匹配单个非数字型的字符。 为了正确地匹配，我们必须使用转义符反斜杠 \\ 定义我们需要匹配的符号 ^.[$()|*+?{\\，因为我们可能认为这些符号在原文本中有特殊的含义。 \\$\\d 匹配在单个数字前有符号“$”的字符串。 注意我们同样能匹配 non-printable 字符，例如 Tab 符 \\t、换行符 \\n 和回车符 \\r。 ♍Flags 模式的结尾我们通常可以指定以下 flag 配置或它们的组合： g（global）在第一次完成匹配后并不会返回结果，它会继续搜索剩下的文本。 m（multi line）允许使用^和$匹配一行的开始和结尾，而不是整个序列。 i（insensitive）令整个表达式不区分大小写（例如/aBc/i 将匹配 AbC）。 中级语句 ♍分组和捕获：() a(bc) 圆括弧会创建一个捕获性分组，它会捕获匹配项“bc”。 a(?:bc)* 使用“?: ”会使捕获分组失效，只需要匹配前面的“a”。 a(?&lt;foo&gt;bc) 使用“?&lt;foo&gt;”会为分组配置一个名称 。 捕获性圆括号 () 和非捕获性圆括弧 (?:) 对于从字符串或数据中抽取信息非常重要，我们可以使用 Python 等不同的编程语言实现这一功能。从多个分组中捕获的多个匹配项将以经典的数组形式展示：我们可以使用匹配结果的索引访问它们的值。如果需要为分组添加名称（使用 (?&lt;foo&gt;...)），我们就能如字典那样使用匹配结果检索分组的值，其中字典的键为分组的名称。 ♍方括弧表达式：[] [abc] 匹配带有一个“a”、“ab”或“ac”的字符串。 [a-c] 匹配带有一个“a”、“ab”或“ac”的字符串。 [a-fA-F0-9] 匹配一个代表 16 进制数字的字符串，不区分大小写。 [0-9]% 匹配在 % 符号前面带有 0 到 9 这几个字符的字符串。 [^a-zA-Z] 匹配不带 a 到 z 或 A 到 Z 的字符串，其中 ^ 为否定表达式。 记住在方括弧内，所有特殊字符（包括反斜杠 \\ ）都会失去它们应有的意义。 ♍Greedy 和 Lazy 匹配 数量符（* + {}）是一种贪心运算符，所以它们会遍历给定的文本，并尽可能匹配。例如，&lt;.+&gt; 可以匹配文本 “This is a &lt;div&gt; simple div&lt;/div&gt; test” 中的 “&lt;div&gt;simple div&lt;/div&gt;&quot;。为了仅捕获 div 标签，我们需要使用 ? 令贪心搜索变得 Lazy 一点： &lt;.+?&gt; 一次或多次匹配“&lt;”和“&gt;”里面的任何字符，可按需扩展。 注意更好的解决方案应该需要避免使用 .，这有利于实现更严格的正则表达式： &lt;[^&lt;&gt;]+&gt; 一次或多次匹配“&lt;”和“&gt;”里面的任何字符，除去“&lt;”或“&gt;”字符。 高级语句 ♍边界符：\\b 和 \\B \\babc\\b 执行整词匹配搜索。 \\b 如插入符号那样表示一个锚点（它与 $ 和 ^ 相同）来匹配位置，其中一边是一个单词符号（如 \\w），另一边不是单词符号（例如它可能是字符串的起始点或空格符号）。 它同样能表达相反的非单词边界 \\B，它会匹配 \\b 不会匹配的位置，如果我们希望找到被单词字符环绕的搜索模式，就可以使用它。 \\Babc\\B 只要是被单词字符环绕的模式就会匹配。 ♍前向匹配和后向匹配：(?=) 和 (?&lt;=) d(?=r) 只有在后面跟着“r”的时候才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分。 (?&lt;=r)d 只有在前面跟着“r”时才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分。 我们同样能使用否定运算子： d(?!r) 只有在后面不跟着“r”的时候才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分。 (?&lt;!r)d 只有在前面不跟着“r”时才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分。 结语 正如上文所示，正则表达式的应用领域非常广，很可能各位读者在开发的过程中已经遇到了它，下面是正则表达式常用的领域： 数据验证，例如检查时间字符串是否符合格式； 数据抓取，以特定顺序抓取包含特定文本或内容的网页； 数据包装，将数据从某种原格式转换为另外一种格式； 字符串解析，例如捕获所拥有 URL 的 GET 参数，或捕获一组圆括弧内的文本； 字符串替代，将字符串中的某个字符替换为其它字符。 ","link":"https://tdmaker.github.io/faded/post/regular-expression-introduction/"},{"title":"有趣的网站","content":"一些平时遇到的有用有趣的网站 网站 网址 在浏览器中运行 Linux https://bellard.org/jslinux/ 一个修改漫画的小工具 https://moeka.me/mangaEditor/ AI 人工智能图片放大 https://bigjpg.com/ 黑白照片上色 https://colourise.sg/ 在线 Photoshop https://ps.gaoding.com/#/ GIF 加字幕 http://www.yingjingtu.com/index 证件照换底色 https://www.gaoding.com/koutu 图片背景消除 https://www.remove.bg/zh 快速去掉背景色 https://bgeraser.com/index.html 网版图制作 https://xoihazard.com/tools/halftone/ 双色套效果 https://duotones.co/ SVG在线压缩合并 https://www.zhangxinxu.com/sp/svgo/ Emoji 马赛克 https://ericandrewlewis.github.io/emoji-mosaic/ CSS 动画制作 https://animista.net/ SQL 语句在线格式化 https://sqlfum.pt/ 实时在线分享代码 https://codeshare.io/ gif 制作 https://gifs.com/ 生成漂亮的代码截图 https://carbon.now.sh/ 在线文件转换 https://cn.office-converter.com/ File Converter https://cloudconvert.com/ ToolFk 在线程序员开发工具 https://www.toolfk.com/ 在线工具 https://tool.lu/ 一个工具箱 http://www.atoolbox.net/ 爱资料工具 https://www.toolnb.com/ 孟坤工具箱 http://tool.mkblog.cn/ OKTools https://oktools.net/ 在线工具 https://helloacm.com/tools/ JS/HTML格式化 https://www.zxgj.cn/g/jshtmlformat 甜言蜜语 API https://api.tryto.cn/saylove/text 甜言蜜语 API https://api.tryto.cn/djt/text 码灵程序员网址导航 https://nav.imaring.com/ CSS 剪切路径生成器 https://bennettfeely.com/clippy/ 文章生成器 https://suulnnka.github.io/BullshitGenerator/index.html 在线屏幕录制 https://www.p2hp.com/screenrecord.html 高手工具 https://c.p2hp.com/ 在线加密算法 https://www.ssleye.com/ JSON在线格式化,JSON在线解析 https://json.im/ 哈希 https://haxi.im/ 图片隐写术加密、图片隐写术解密 https://c.p2hp.com/yinxietu/ 在线代码运行时 Labstack https://code.labstack.com/dart 在线文件加密 https://hat.sh/ 在线检测浏览器版本 https://liulanmi.com/labs/core.html 糖果短语视频生成器 https://hattemi.com/ 前端网址导航 http://www.daqianduan.com/nav 背景生成器 https://bggenerator.com/zh-cn.php “爱古典”数据库 http://www.iloveclassics.icoc.cc/ Compare package download counts over time https://www.npmtrends.com/ IP反查域名 https://dns.aizhan.com/ ","link":"https://tdmaker.github.io/faded/post/you-qu-de-wang-zhan/"},{"title":"正则表达式——常用案例","content":"正则大全 https://any86.github.io/any-rule/ 火车车次 /^[GCDZTSPKXLY1-9]\\d{1,4}$/ 手机机身码(IMEI) /^\\d{15,17}$/ 必须带端口号的网址(或ip) /^(((ht|f)tps?):\\/\\/)?[\\w\\-]+(\\.[\\w\\-]+)+:\\d{0,5}\\/?/ 网址(支持端口和&quot;?+参数&quot;和&quot;#+参数) /^(((ht|f)tps?):\\/\\/)?[\\w\\-]+(\\.[\\w\\-]+)+([\\w\\-.,@?^=%&amp;:\\/~+#]*[\\w\\-@?^=%&amp;\\/~+#])?$/ 统一社会信用代码 /^[0-9A-HJ-NPQRTUWXY]{2}\\d{6}[0-9A-HJ-NPQRTUWXY]{10}$/ 迅雷链接 /^thunderx?:\\/\\/[a-zA-Z\\d]+=$/ ed2k链接(宽松匹配) /^ed2k:\\/\\/\\|file\\|.+\\|\\/$/ 磁力链接(宽松匹配) /^magnet:\\?xt=urn:btih:[0-9a-fA-F]{40,}.*$/ 子网掩码 /^(?:\\d{1,2}|1\\d\\d|2[0-4]\\d|25[0-5])(?:\\.(?:\\d{1,2}|1\\d\\d|2[0-4]\\d|25[0-5])){3}$/ Linux&quot;文件夹&quot;路径 /^\\/(\\w+\\/?)+$/ Linux&quot;文件&quot;路径 /^\\/(\\w+\\/)+\\w+\\.\\w+$/ Window下&quot;文件夹&quot;路径 /^[a-zA-Z]:\\\\(?:\\w+\\\\?)*$/ Window下&quot;文件&quot;路径 /^[a-zA-Z]:\\\\(?:\\w+\\\\)*\\w+\\.\\w+$/ A股代码 /^(s[hz]|S[HZ])(000[\\d]{3}|002[\\d]{3}|300[\\d]{3}|600[\\d]{3}|60[\\d]{4})$/ 考卷分数 /^150$|^(?:\\d|[1-9]\\d|1[0-4]\\d)(?:.5)?$/ 大于等于0, 小于等于150, 支持小数位出现5, 如145.5 校验密码强度 ^(?=.*\\\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$ 密码的强度必须是包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间。 /^(?=.*[0-9])(?=.*[a-z])(?=.*[A-Z])(?=.*\\_)\\w{8,20}$/ 只允许字母数字下划线，必须含有大小写和数字和下划线 校验中文 ^[\\\\u4e00-\\\\u9fa5]{0,}$ 由数字、26个英文字母或下划线组成的字符串 ^\\\\w+$ 校验E-Mail 地址 [\\\\w!#$%&amp;'*+/=?^_{|}~-]+(?:\\.[\\w!#$%&amp;'*+/=?^_{|}~-]+)*@(?:[\\\\w](?:[\\\\w-]*[\\\\w])?\\\\.)+[\\\\w](?:[\\\\w-]*[\\\\w])? 校验日期 ^(?:(?!0000)[0-9]{4}-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1[0-9]|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[0-9]{2}(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)-02-29)$ “yyyy-mm-dd“ 格式的日期校验，已考虑平闰年。 校验金额 ^[0-9]+(.[0-9]{2})?$ 金额校验，精确到2位小数。 判断IE的版本 ^.*MSIE [5-8](?:\\\\.[0-9]+)?(?!.*Trident\\\\/[5-9]\\\\.0).*$ 校验IPv4地址 \\\\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\b 校验IPv6地址 (([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])) 提取URL链接 ^(f|ht){1}(tp|tps):\\\\/\\\\/([\\\\w-]+\\\\.)+[\\\\w-]+(\\\\/[\\\\w- ./?%&amp;=]*)? 文件路径及扩展名校验 ^([a-zA-Z]\\\\:|\\\\\\\\)\\\\\\\\([^\\\\\\\\]+\\\\\\\\)*[^\\\\/:*?&quot;&lt;&gt;|]+\\\\.txt(l)?$ 验证windows下文件路径和扩展名（以 .txt 文件为例） 提取Color Hex Codes ^#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})$ 提取网页图片 \\\\&lt; *[img][^\\\\\\\\&gt;]*[src] *= *[\\\\&quot;\\\\']{0,1}([^\\\\&quot;\\\\'\\\\ &gt;]*) 提取页面超链接 (&lt;a\\\\s*(?!.*\\\\brel=)[^&gt;]*)(href=&quot;https?:\\\\/\\\\/)((?!(?:(?:www\\\\.)?'.implode('|(?:www\\\\.)?', $follow_list).'))[^&quot;]+)&quot;((?!.*\\\\brel=)[^&gt;]*)(?:[^&gt;]*)&gt; 查找CSS属性 ^\\\\s*[a-zA-Z\\\\-]+\\\\s*[:]{1}\\\\s[a-zA-Z0-9\\\\s.#]+[;]{1} 抽取注释 &lt;!--(.*?)--&gt; 匹配HTML标签 &lt;\\\\/?\\\\w+((\\\\s+\\\\w+(\\\\s*=\\\\s*(?:&quot;.*?&quot;|'.*?'|[\\\\^'&quot;&gt;\\\\s]+))?)+\\\\s*|\\\\s*)\\\\/?&gt; 银行卡四位一空格 str.replace(/\\s/g, '').replace(/(.{4})/g, &quot;$1 &quot;); 用户名正则 /^[a-zA-Z0-9_-]{4,16}$/ 4到16位（字母，数字，下划线，减号） 密码正则 ^[a-zA-Z]\\w{5,17}$ 以字母开头，长度在6~18之间，只能包含字母、数字和下划线 强密码正则 /^.*(?=.{6,})(?=.*\\d)(?=.*[A-Z])(?=.*[a-z])(?=.*[!@#$%^&amp;*? ]).*$/ 最少6位，包括至少1个大写字母，1个小写字母，1个数字，1个特殊字符 QQ 号正则 /^[1-9][0-9]{4,10}$/ 微信号正则 /^[a-zA-Z]([-_a-zA-Z0-9]{5,19})+$/ 6至20位，以字母开头，字母，数字，减号，下划线 特殊字符正则 /[&quot;'&lt;&gt;%;)(&amp;+]+-!！@#$~/ 域名正则 [a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.? 车牌号正则 /^[京津沪渝冀豫云辽黑湘皖鲁新苏浙赣鄂桂甘晋蒙陕吉闽贵粤青藏川宁琼使领A-Z]{1}[A-Z]{1}[A-Z0-9]{4}[A-Z0-9挂学警港澳]{1}$/ 护照正则 /^(P\\d{7}|G\\d{7,8}|TH\\d{7,8}|S\\d{7,8}|A\\d{7,8}|L\\d{7,8}|\\d{9}|D\\d+|1[4,5]\\d{7})$/ 固定电话正则 (\\(\\d{3,4}\\)|\\d{3,4}-|\\s)?\\d{8} 邮政编码正则 [1-9]{1}(\\d+){5} 经度正则 /^(\\-|\\+)?(((\\d|[1-9]\\d|1[0-7]\\d|0{1,3})\\.\\d{0,6})|(\\d|[1-9]\\d|1[0-7]\\d|0{1,3})|180\\.0{0,6}|180)$/ 维度正则 /^(\\-|\\+)?([0-8]?\\d{1}\\.\\d{0,6}|90\\.0{0,6}|[0-8]?\\d{1}|90)$/ ","link":"https://tdmaker.github.io/faded/post/regular-expression-regular-cases/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://tdmaker.github.io/faded/post/hello-gridea/"}]}