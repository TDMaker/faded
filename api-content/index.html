{"posts":[{"title":"window 对象知识总结","content":" window对象知识总结 window 对象属性 属性名 属性功能 closed 返回窗口是否已被关闭 defaultStatus 设置或返回窗口状态栏中的默认文本 document 对 document 对象的只读引用 history 对 history 对象的只读引用 innerheight 返回窗口的文档显示区的高度 innerwidth 返回窗口的文档显示区的宽度 length 设置或返回窗口中的框架数量 location 用于窗口或框架的 location 对象 name 设置或返回窗口的名称 navigator 对 navigator 对象的只读引用 opener 返回对创建此窗口的窗口的引用 outerheight 返回窗口的外部高度 outerwidth 返回窗口的外部宽度 pageXOffset 设置或返回当前页面相对于窗口显示区左上角的 X 位置 pageYOffset 设置或返回当前页面相对于窗口显示区左上角的 Y 位置 parent 返回父窗口 screen 对 screen 对象的只读引用 self 返回对当前窗口的引用。等价于 window 属性 status 设置窗口状态栏的文本 top 返回最顶层的先辈窗口 window window 属性等价于 self 属性，它包含了对窗口自身的引用 screenLeft/screenTop/screenX/screenY 只读整数。声明了窗口的左上角在屏幕上的的 x 坐标和 y 坐标。IE、Safari 和 Opera 支持 screenLeft 和 screenTop，而 Firefox 和 Safari 支持 screenX 和 screenY window 对象方法 对象名 对象功能 alert() 显示带有一段消息和一个确认按钮的警告框 blur() 把键盘焦点从顶层窗口移开 clearInterval() 取消由 setInterval() 设置的 timeout clearTimeout() 取消由 setTimeout() 方法设置的 timeout close() 关闭浏览器窗口 confirm() 显示带有一段消息以及确认按钮和取消按钮的对话框 createPopup() 创建一个 pop-up 窗口 focus() 把键盘焦点给予一个窗口 moveBy() 可相对窗口的当前坐标把它移动指定的像素 moveTo() 把窗口的左上角移动到一个指定的坐标 open() 打开一个新的浏览器窗口或查找一个已命名的窗口 print() 打印当前窗口的内容 prompt() 显示可提示用户输入的对话框 resizeBy() 按照指定的像素调整窗口的大小 resizeTo() 把窗口的大小调整到指定的宽度和高度 scrollBy() 按照指定的像素值来滚动内容 scrollTo() 把内容滚动到指定的坐标 setInterval() 按照指定的周期（以毫秒计）来调用函数或计算表达式 setTimeout() 在指定的毫秒数后调用函数或计算表达式 window 对象描述 window 对象表示一个浏览器窗口或一个框架。在客户端 JavaScript 中，window 对象是全局对象，所有的表达式都在当前的环境中计算。也就是说，要引用当前窗口根本不需要特殊的语法，可以把那个窗口的属性作为全局变量来使用。例如，可以只写 document，而不必写 window.document 同样，可以把当前窗口对象的方法当作函数来使用，如只写 alert()，而不必写 window.alert() 除了上面列出的属性和方法，window 对象还实现了核心 JavaScript 所定义的所有全局属性和方法 window 对象的 window 属性和 self 属性引用的都是它自己。当你想明确地引用当前窗口，而不仅仅是隐式地引用它时，可以使用这两个属性。除了这两个属性之外，parent 属性、top 属性以及 frame[] 数组都引用了与当前 window 对象相关的其他 window 对象 要引用窗口中的一个框架，可以使用如下语法： frame[i]：当前窗口的框架 self.frame[i]：当前窗口的框架 w.frame[i]：窗口 w 的框架 要引用一个框架的父窗口（或父框架），可以使用下面的语法： parent：当前窗口的父窗口。 self.parent：当前窗口的父窗口。 w.parent：窗口 w 的父窗口。 要从顶层窗口含有的任何一个框架中引用它，可以使用如下语法： top：当前框架的顶层窗口。 self.top：当前框架的顶层窗口。 f.top：框架 f 的顶层窗口。 新的顶层浏览器窗口由方法 window.open() 创建。当调用该方法时，应把 open() 调用的返回值存储在一个变量中，然后使用那个变量来引用新窗口。新窗口的 opener 属性反过来引用了打开它的那个窗口 一般来说，window 对象的方法都是对浏览器窗口或框架进行某种操作；而 alert() 方法、confirm() 方法和 prompt 方法则不同，它们通过简单的对话框与用户进行交互。 全局的 window 对象 JavaScript 中的任何一个全局函数或变量都是 window 的属性。 &lt;script type=&quot;text/javascript&quot;&gt; var name = &quot;aaaa&quot;; document.write(window.name); &lt;/script&gt; window 与 self 对象 self 对象与 window 对象完全相同，self 通常用于确认就是在当前的窗体内 &lt;script type=&quot;text/javascript&quot;&gt; document.write(window == self); //必须相等，永远都相等 document.write(window.top == window.self); //判断当前框架是否是主框架 &lt;/script&gt; window、self、window.self 三者是等价的。 window 的子对象 window 的主对象主要有： JavaScript document 对象 JavaScript frames 对象 JavaScript history 对象 JavaScript location 对象 JavaScript navigator 对象 JavaScript screen 对象 window 函数索引（仅对 IE 有效） 窗体控制函数 moveBy()：从当前位置水平移动窗体 x 个像素，垂直移动窗体 y 个像素，x 为负数，将向左移动窗体，y 为负数，将向上移动窗体。 moveTo()：移动窗体左上角到相对于屏幕左上角的 (x, y) 点，当使用负数做为参数时会把窗体移出屏幕的可视区域。 resizeBy()：相对窗体当前的大小，宽度调整 w 个像素，高度调整 h 个像素。如果参数为负值，将缩小窗体，反之扩大窗体。 resizeTo()：把窗体宽度调整为 w 个像素，高度调整为 h个像素。 &lt;body&gt; &lt;input type=&quot;button&quot; id=&quot;btn1&quot; value=&quot;先设置窗体固定大小！&quot; onclick=&quot;window.resizeTo(500,500);&quot; /&gt; &lt;input type=&quot;button&quot; id=&quot;btn2&quot; value=&quot;再缩小10像素！&quot; onclick=&quot;window.resizeBy(-10,-10);&quot; /&gt; &lt;input type=&quot;button&quot; id=&quot;btn2&quot; value=&quot;上！&quot; onclick=&quot;window.moveBy(0,-5);&quot; /&gt; &lt;input type=&quot;button&quot; id=&quot;btn2&quot; value=&quot;下！&quot; onclick=&quot;window.moveBy(0, 5);&quot; /&gt; &lt;input type=&quot;button&quot; id=&quot;btn2&quot; value=&quot;左！&quot; onclick=&quot;window.moveBy(-5, 0);&quot; /&gt; &lt;input type=&quot;button&quot; id=&quot;btn2&quot; value=&quot;右！&quot; onclick=&quot;window.moveBy(5, 0);&quot; /&gt; &lt;input type=&quot;button&quot; id=&quot;btn2&quot; value=&quot;距离左上角左边100像素，顶部200像素&quot; onclick=&quot;window.moveTo(100, 200);&quot; /&gt; &lt;/body&gt; 窗体滚动轴控制函数 scrollTo()：在窗体中如果有滚动条，将横向滚动条移动到相对于窗体宽度为 x 个像素的位置，将纵向滚动条移动到相对于窗体高度为 y 个像素的位置。 scrollBy()：如果有滚动条，将横向滚动条移动到相对于当前横向滚动条的 x 个像素的位置（就是向左移动 x 像素），将纵向滚动条移动到相对于当前纵向滚动条高度为 y 个像素的位置（就是向下移动 y 像素）。 注意区别，一个是相对当前窗口，一个是相当现在滚动条的位置。 &lt;div style=&quot;height:150%; width:150%; background-color:#ddd&quot;&gt; &lt;input type=&quot;button&quot; id=&quot;btn1&quot; value=&quot;移动滚动条！&quot; onclick=&quot;window.scrollTo(100,100);&quot; /&gt; //相当于设置绝对位置 &lt;input type=&quot;button&quot; id=&quot;btn1&quot; value=&quot;移动滚动条！&quot; onclick=&quot;window.scrollBy(100,100);&quot; /&gt; //相当于累加 &lt;/div&gt; 窗体焦点控制函数 focus()：使窗体或空间获得焦点。 blur()：使窗体或控件失去焦点。 &lt;div&gt; &lt;input type=&quot;button&quot; value=&quot;获得焦点&quot; onclick=&quot;document.getElementById('testInput').focus()&quot; /&gt; &lt;input type=&quot;button&quot; value=&quot;失去焦点&quot; onclick=&quot;document.getElementById('testInput').blur()&quot; /&gt; &lt;input type=&quot;text&quot; value=&quot;text&quot; id=&quot;testInput&quot; onblur=&quot;alert('我已失去焦点')&quot; /&gt; &lt;/div&gt; 新建窗体函数 open()：打开（弹出）一个新的窗体。 close()：关闭窗体。 opener：通过 opener 可以实现跨窗体之间的通讯，但是要保证是在同一域名下，而且一个窗体要包含另一个窗体的 opener。 格式：window.open(url, name, features, replace); open 函数参数说明 url：要载入窗体的 URL。 name：新建窗体的名称（也可以是 HTML target 属性的取值，目标）。 features：代表窗体特性的字符串，字符串中每个特性使用逗号分隔。 replace：一个布尔值，说明新载入的页面是否替换当前载入的页面，此参数通常不用指定。 open 方法示例 &lt;a href=&quot;2.html&quot; target=&quot;2&quot;&gt;在新窗口打开连接&lt;/a&gt; &lt;a href=&quot;#&quot; onclick=&quot;window.open('http://www.google.com','2');&quot;&gt;在已建立连接的页面打开新地址&lt;/a&gt; 首先使用普通 HTML 链接打开一个页面( target 名为 dreamdu)，之后使用 open 函数打开另一个页面，浏览器首先要查找是否有名称为 dreamdu 的窗体，如果有，就在这个窗体中加载 open 的地址。 经过设置的 open window.open ('page.html', 'newwindow', 'height=100, width=400, top=0,left=0, toolbar=no, menubar=no, scrollbars=no, resizable=no,location=no, status=no'); 弹窗方法 方法一：&lt;body onload=&quot;openwin()&quot;&gt; 浏览器读页面时弹出窗口； 方法二：&lt;body onunload=&quot;openwin()&quot;&gt; 浏览器离开页面时弹出窗口。 open 函数第三个参数 features 说明 参数名称 类型 说明 height Number 设置窗体的高度，不能小于100 left Number 说明创建窗体的左坐标，不能为负值 location Boolean 窗体是否显示地址栏，默认值为 no resizable Boolean 窗体是否允许通过拖动边线调整大小，默认值为 no scrollable Boolean 窗体中内部超出窗口可视范围时是否允许拖动，默认值为 no toolbar Boolean 窗体是否显示工具栏，默认值为 no top Number 说明创建窗体的上坐标，不能为负值 status Boolean 窗体是否显示状态栏，默认值为 no width Number 创建窗体的宽度，不能小于 100 特性字符串中的每个特性使用逗号分隔，每个特性之间不允许有空格。 window.open 函数新建立窗体后会返回新建窗体的 window 对象，通过此对象可以控制窗体（移动，改变大小，关闭）。 close 函数 &lt;input type=&quot;button&quot; value=&quot;关闭已经打开的窗体！&quot; onclick=&quot;window.close();&quot; /&gt; self.close(); 配合上 setTimeout() 可以实现，打开的窗口定时关闭的效果。 对话框函数 alert()：弹出消息对话框（对话框中有一个 OK 按钮）； confirm()：弹出消息对话框（对话框中包含一个 OK 按钮与 Cancel 按钮）；confirm() 消息对话框是排它的，也就是在用户点击对话框的按钮前，不能进行任何其它操作。 if (confirm(&quot;确定跳大？&quot;)) { alert(&quot;果断跳大&quot;); } else { alert(&quot;猥琐打钱&quot;); } ``` prompt()：弹出消息对话框（对话框中包含一个 OK 按钮、Cancel 按钮与一个文本输入框）；函数有两个参数： str1：要显示在消息对话框中的文本，不可修改； str2：文本框中的内容，可以修改。 var sResult = prompt(&quot;请在下面输入你的姓名&quot;, &quot;aaa&quot;); if (sResult != null) { alert(sResult + &quot;已经超越神的杀戮&quot;); } else { alert(&quot;无名氏已经超越神的杀戮&quot;); } 时间等待与间隔函数 setTimeout() 函数 / clearTimeout() 函数 在指定的时间后调用函数。 语法： setTimeout(fun, time);：fun：函数体或函数名，time：指定时间，单位为毫秒； clearTimeout(id);：取消指定的 setTimeout 函数将要执行的代码。 setTimeout(function () { document.write(&quot;隔3秒后触发&quot;); }, 3000) //在3秒后输出 setTimeout(fun1, 5000); //在5秒后输出 function fun1() { document.write(&quot;函数名的方式5秒后触发&quot;); } setInterval() 函数 / clearInterval() 函数 在间隔指定的事件后重复调用函数。 语法： setInterval(fun1, time)：fun：函数体或函数名，time：指定的时间，单位为毫秒。会返回一个值，这个值是统计该函数的个数用的，第一个是 1，第二个就是 2，指明是第几个 setInterval 函数。 clearInterval(value)：value：setInterval() 函数返回的值，根据这个值可以停止 setInterval() 的重复。 注意，JavaScript 是单线程的，因此，这个定时函数实际上是通过插入执行队列的方式来实现。 如下面的代码： function fn() { setTimeout(function () { alert('can you see me?'); }, 1000); while (true) { } } alert(); 永远都不会执行，因为线程一直被死循环占用了。 window.location 子对象 解析 URL 对象 location:location 对象的属性有：href，protocal，host，hostname，port，pathname，search，hash。 document.write(location.href + &quot;&lt;br/&gt;&quot;); // http://localhost:4889/javascriptTest.html document.write(location.protocol + &quot;&lt;br/&gt;&quot;); // http: document.write(location.host + &quot;&lt;br/&gt;&quot;); // localhost:4889 document.write(location.hostname + &quot;&lt;br/&gt;&quot;); // localhost document.write(location.port + &quot;&lt;br/&gt;&quot;); // 4889 document.write(location.pathname + &quot;&lt;br/&gt;&quot;); // /javascriptTest.html document.write(location.search + &quot;换行&lt;br/&gt;&quot;); //http://localhost:4889/javascriptTest.html?id=1&amp;name=张三 如果路径是这样，则输出 ?id=1&amp;name=%E5%BC%A0%E4%B8%89 document.write(location.hash); //http: //localhost:4889/javascriptTest.html#kk=你好?id=1&amp;name=张三 如果路径是这样，则输出 #kk=你好?id=1&amp;name=张三 载入新文档 location.reload() // 重新加载页面 location.replace() // 本窗口载入新文档 location.assign() // 本窗口载入新文档 location = &quot;http://www.baidu.com&quot; // 跳转到指定网址 location = &quot;search.html&quot; // 相对路径跳转 location = &quot;#top&quot; // 跳转到页面顶部 浏览历史 history 对象的 back() 与 forward()：与浏览器的“后退”，“前进”功能一样。 history.go(-2); 后退两个历史记录。 浏览器和屏幕信息 navigator.appName // Web 浏览器全称 navigator.appVersion // Web 浏览器厂商和版本的详细字符串 navigator.userAgent // 客户端绝大部分信息 navigator.platform // 浏览器运行所在的操作系统 document.write(navigator.userAgent + &quot;&lt;br/&gt;&quot;); // Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.97 Safari/537.11 document.write(navigator.appName + &quot;&lt;br/&gt;&quot;); // Netscape document.write(navigator.appVersion + &quot;&lt;br/&gt;&quot;); // 5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) document.write(navigator.platform); //Win32 窗口的关系 parent == self：只有顶级窗口才返回 true； parent 和 top 属性允许脚本引用它的窗体的祖先，通常窗体是通过元素创建的，可以用来获取顶级窗口。 event 事件对象 最有用的两个操作：阻止事件冒泡。有时 return false; 不管用，这个或许就管用了。 // IE： window.event.cancelBubble = true;//停止冒泡 window.event.returnValue = false;//阻止事件的默认行为 // Firefox： event.preventDefault(); // 取消事件的默认行为 event.stopPropagation(); // 阻止事件的传播 ","link":"https://faded.auspicious.space/post/window-object-summary/"},{"title":"KeyCode 对照表","content":" Keycode对照表 字母和数字键的键码值(keyCode) 按键 键码 按键 键码 按键 键码 按键 键码 A 65 J 74 S 83 1 49 B 66 K 75 T 84 2 50 C 67 L 76 U 85 3 51 D 68 M 77 V 86 4 52 E 69 N 78 W 87 5 53 F 70 O 79 X 88 6 54 G 71 P 80 Y 89 7 55 H 72 Q 81 Z 90 8 56 I 73 R 82 0 48 9 57 数字键盘上的键的键码值(keyCode) 按键 键码 按键 键码 0 96 8 104 1 97 9 105 2 98 * 106 3 99 + 107 4 100 Enter 108 5 101 - 109 6 102 . 110 7 103 / 111 功能键键码表(keyCode) 按键 键码 按键 键码 F1 112 F7 118 F2 113 F8 119 F3 114 F9 120 F4 115 F10 121 F5 116 F11 122 F6 117 F12 123 控制键键码表(keyCode) 按键 键码 按键 键码 按键 键码 按键 键码 BackSpace 8 Esc 27 Right Arrow 39 -_ 189 Tab 9 Spacebar 32 Dw Arrow 40 .&gt; 190 Clear 12 Page Up 33 Insert 45 /? 191 Enter 13 Page Down 34 Delete 46 `~ 192 Shift 16 End 35 Num Lock 144 [{ 219 Control 17 Home 36 ;: 186 | 220 Alt 18 Left Arrow 37 =+ 187 ]} 221 Cape Lock 20 Up Arrow 38 ,&lt; 188 '&quot; 222 多媒体键码值(keyCode) 按键 键码 音量加 175 音量减 174 停止 179 静音 173 浏览器 172 邮件 180 搜索 170 收藏 171 ","link":"https://faded.auspicious.space/post/keycode-map/"},{"title":"TCP 状态机","content":" TCP状态机 前言 本文将会首先介绍 TCP 的各个状态，然后描述 TCP 三次握手和四次挥手时的状态变化，最后重点介绍 TIME_WAIT 状态。 TCP 连接状态 一个 TCP 连接在它的生命周期内会有不同的状态。 下图说明了 TCP 连接可能会有的状态，以及基于事件的状态转换。事件中有的是应用程序的操作，有的是接收到了网络发过来的请求。 TCP状态及其描述如下表： 状态 描述 LISTEN 等待来自远程 TCP 应用程序的请求 SYN_SENT 发送连接请求后等待来自远程端点的确认。TCP 第一次握手后客户端所处的状态 SYN-RECEIVED 该端点已经接收到连接请求并发送确认。该端点正在等待最终确认。TCP 第二次握手后服务端所处的状态 ESTABLISHED 代表连接已经建立起来了。这是连接数据传输阶段的正常状态 FIN_WAIT_1 等待来自远程 TCP 的终止连接请求或终止请求的确认 FIN_WAIT_2 在此端点发送终止连接请求后，等待来自远程 TCP 的连接终止请求 CLOSE_WAIT 该端点已经收到来自远程端点的关闭请求，此 TCP 正在等待本地应用程序的连接终止请求 CLOSING 等待来自远程 TCP 的连接终止请求确认 LAST_ACK 等待先前发送到远程 TCP 的连接终止请求的确认 TIME_WAIT 等待足够的时间来确保远程 TCP 接收到其连接终止请求的确认 TCP三次握手 当一个 TCP 连接建立时，发生了以下事情： 服务端必须准备接收传入的连接。这通常通过调用 socket，bind 和 listen 来完成，称为被动打开。 客户端通过调用 connect 方法来发起一个主动的打开。客户端 TCP 会发送一个“同步”（SYN）段，它告诉服务器客户端在连接上发送的数据的初始序列号。通常情况下，SYN 没有发送数据，它只包含一个 IP 头，TCP 头和可能的 TCP 选项。 服务器必须确认（ACK）客户端的 SYN，并且服务器还必须发送自己的 SYN，其中包含服务器将在连接上发送的数据的初始序列号。 客户端必须确认服务器的 SYN。 下图显示了 TCP 三次握手的过程，以及客户端和服务端状态的变化。 TCP四次挥手 一个 TCP 连接需要四步断开： 一个应用程序首先执行 close，发送 FIN 段，这个操作被称为主动关闭，这意味着这一端完成数据的发送。 执行 FIN 的另一端执行被动关闭，该端发送 ACK，确认该 FIN。 被动关闭的一端执行 close，向主动关闭的一方发送 FIN。 主动关闭的一方确认收到的 FIN。 下图显示了一次典型的 TCP 四次挥手的过程，以及主动关闭方和被动关闭方的状态变化。在图中是客户端主动断开了连接，这里只是举个例子，服务端一样可以主动断开连接。 TIME_WAIT状态 TIME_WAIT 状态应该是最让人疑惑的一个状态了。在上图中可以看到，执行主动断开的节点最后会进入这个状态，该节点会在此状态保存 2 倍的 MSL（最大段生存期）。 TCP 的每个实现都必须为 MSL 选择一个值。RFC 1122 推荐的值为两分钟，伯克利派的实现使用 30 秒。这也就是说 TIME_WAIT 状态会维持 1 到 4 分钟。MSL 是任何 IP 数据报可以在网络中生存的最长时间。这个时间是有限制的，因为每个数据报都包含一个 8 位的跳数限制，最大值是 255。虽然这是一个跳数限制而不是一个真正的时间限制，但是根据这个限制来假设数据报的最长生命周期依然是有意义的。 网络中数据报丢失的原因通常是路由异常。一旦路由崩溃或者两个路由之间的链路断开，路由协议需要几秒或几分钟才能稳定，并找到一条备用路径。在这段时间内，可能发生路由回路。同时假设丢失是一个 TCP 数据报，则发生 TCP 超时，并且重新发送分组，重传的分组通过一些备用路径达到最终目的地。但是一段时间后（该时间小于 MSL），路由循环被更正，在循环中丢失的数据报被发送到最终目的地。这个原始的数据报被称为丢失的副本或漫游副本。TCP 协议必须处理这些数据报。 维持 TIME_WAIT 有两个原因： 可靠地实现 TCP 的全双工连接终止。 允许旧的重复数据段在网络中过期 在四次挥手中，假设最后的 ACK 丢失了，被动关闭方会重发 FIN。主动关闭端必须维护状态，来允许被动关闭方重发最后的 ACK；如果它没有维护这个状态，将会对重发 FIN 返回 RST，被动关闭方会认为这是个错误。如果 TCP 正在执行彻底终止数据流的两个方向所需的所有工作（即全双工关闭），则必须正确处理这四个段中任何一个的丢失。所以执行主动关闭的一方必须在结束时保持 TIME_WAIT 状态：因为它可能必须重传最后的 ACK。 现在来聊维持 TIME_WAIT 状态的第二个原因。假设在主机 12.106.32.254 的 1500 端口和 206.168.112.219 的 21 端口之间有一个 TCP 连接。此连接关闭后，在相通的地址和端口建立了另外一个连接。由于 IP 地址和端口相同，所以后一种连接被称为先前连接的“化身”。TCP 必须防止连接中的旧副本在稍后再次出现，并被误解为属于同一连接的新“化身”。为此，TCP 将不会启动当前处于 TIME_WAIT 状态的连接的新“化身”。由于 TIME_WAIT 状态的持续时间时两倍的 MSL，因此 TCP 允许一个方向的数据在 MSL 秒内丢失，也允许回复在一个 MSL 秒内丢失。通过强制执行此规则，可以保证当一个 TCP 连接成功建立时，来自先前连接的所有旧的副本在网络中已过期。 ","link":"https://faded.auspicious.space/post/tcp-state-machine/"},{"title":"更好的 SQL 模式的 10 条规则","content":" 更好的 SQL 模式的 10 条规则 在创建新表和数据仓库时，要做很多决定。一些在当时似乎无关紧要的地方，却让你和用户在数据库的生命期内感到痛苦。 我们和成千上万的人们以及他们的数据库一道工作，经历了长期的读写查询，我们差不多看到了每种情况。下面是创建免去痛苦模式的 10 条规则。 只使用小写字母、数字和下划线 不要在数据库、模式、表或列名中使用点（dot）、空格、或连接号【注1】。点用于标示对象，通常以 database.schema.table.column 的方式。 对象名称中包含点将引起混淆。类似地，在对象名字里使用空格将迫使你在查询语句中添加不必要的引号： SELECT &quot;user name&quot; FROM events; -- vs SELECT user_name FROM events; 如果在表或列名里有大写字母，查询语句将难以书写。如果所有字母都是小写的，人们将不必记住 users 表是 Users 还是 users。 当你最终修改数据库或把你的表复制到仓库时，你不需要记住哪个表是大小写敏感的。 使用简单的、自说明的列名 如果 users 表需要 packages 表的外键，就把键命名为 package_id。避免使用简短、晦涩的名字，比如 pkg_fk；其他人不知道它代表什么。自说明的名字让其他人更容易理解模式，随着团队规模的增加，这对于维护效率至关重要。 不要为多态的数据使用有歧义的名字。如果你发现自己创建了形如 item_type 或 item_value 的列，那么你最好使用带有具体名字的、更多的列，比如 photo_count、view_cout、transaction_price。 这样，列的内容就可以常从模式中获悉，而不用依赖于当前行的其它值。 SELECT SUM(item_value) AS photo_count FROM items WHERE item_type = 'Photo Count'; -- vs SELECT SUM(photo_count) FROM items; 不要把包含表的名字做为列名的前缀。通常，让用户表包含形如 user_birthday、user_created_at、user_name 的列，没有多少帮助。 避免使用 column、tag 和 user 之类的保留字做为列名。你将不得不在查询中使用额外的引号，不这么做将让你对错误信息感到困惑。如果保留字出现在列名应该出现的地方，数据库会极大地错误理解查询。 使用简单的、自说明的表名 如果表名由多个单词组成，就使用下划线隔开这些单词。package_deliveries 要比 packagedeliveries 更容易阅读。 如有可能，使用一个单词而不是两个单词：deliveries 更易于读。 SELECT * FROM packagedeliveries; -- vs SELECT * FROM deliveries; 不要给表加前缀来暗示模式。如果你需要把表分组为范围，就把这些表放入一个模式。store_items、store_transactions、store_coupons 之类的表名，和加了前缀的列名一样，通常不值得额外敲键盘。 我们推荐表名使用复数（例如 packages），连接表（join table）名字的两个单词都用复数（例如 packages_users）。单数的表名更有可能偶尔与保留字相撞，并且在查询语句中通常有着较低的可读性。 主键为整数 即使你在用 UUID，它也没有意义（比如对于连接表来说），添加标准的 id 列、自增整数序列。这种 key 使得某些查询更加容易，比如仅仅选取一组数据的第一行。 如果导入的任务需要复制数据，这种 key 将成为救命稻草，因为你能够删除特定行： DELETE FROM my_table WHERE id IN (SELECT ...) AS duplicated_ids; 避免多列主键。它们在尽量编写有效查询时难以推断，且难以修改。要使用整数主键、多列 unique 约束、一些单列索引代替。 与外键保持一致 有很多关于主键和外键的命名风格。我们推荐，最受欢迎的是，任何表 foo，都要拥有一个名叫 id 的主键，所有的主键命名为 foo_id。 另一种受欢迎的风格使用全局唯一键名，表 foo 有个名叫 foo_id 的主键，所有外键也叫 foo_id。如果你使用缩写（users 表的主键用 uid），会引起混淆或命名冲突，故不要缩写。 无论你选择什么风格，就保持下去。不要在有的地方使用 uid，在另外地方使用 user_id 或 users_fk。 SELECT * FROM packages JOIN users ON users.user_id = packages.uid; -- vs SELECT * FROM packages JOIN users ON users.id = packages.user_id; -- or SELECT * FROM packages JOIN users USING (user_id); 还要留意不能明显匹配表的外键。名叫 owner_id 的列名或许是 users 表的外键，或许不是。把列名取为 user_id，如有必要，取为 owner_user_id。 把时间存储为 Datetime 不要把日期保持为 Unix 时间戳或字符串：而是把它们转化为 datetime。虽然 SQL 的 date 数学函数不是最好的，但是你自己处理时间戳甚至更难。使用 SQL date 函数要求每次查询都把时间戳转化为 datetime： SELECT DATE(FROM_unixtime(created_at)) FROM packages; -- vs SELECT DATE(created_at) FROM packages; 不要在单独的列里存储年、月、日。这使得每一条时间序列【注2】查询非常难以编写，将阻碍大多数刚入门的 SQL 用户使用表格中的日期信息。 SELECT DATE(created_year || '-' || created_month || '-' || created_day); -- vs SELECT DATE(created_at); UTC，一直都是 UTC 使用某种时区而非 UTC 将引起永无止境的问题。优秀的工具（包括 Periscope）具备所有你需要的、将数据从 UTC 转换成当前时区的功能。在 Periscope 里，添加 :pst 就轻松地将 UTC 转换成 Pacific Time： SELECT [created_at:pst], email_address FROM users; 数据库的时区应该是 UTC，所有的 datetime 列应该是去除了时区的类型（没有时区的时间戳）。 如果你的数据库的时区不是 UTC，或者你的数据库既有 UTC、又有非 UTC 的 datetime，那么时间序列的分析难度将大为增加。 单一的真实数据来源 对于一条数据，应该有且只有一个真实来源【注3】。视图和汇总应该打上标签。这样，数据的使用人员将明白，在他们使用的数据和真实数据之间存在差异。 SELECT * FROM daily_usage_rollup; 留下废弃的 user_id、user_id_old、user_id_v2 之类的列，将变成混淆的、永无止境的源头。在日常维护中，要确信 drop 掉了已被抛弃的表、和弃用的列。 更喜欢没有 JSON 列的表 你肯定不想要非常宽的表。如果有很多列，且它们有的按顺序命名（比如 answer1、answer2、answer3），今后你就会痛苦。 把这种表拆分成没有重复列的模式，这种模式的形态将特别容易查询。例如，获取 survey 表的、完成的答案的数目： SELECT SUM( (CASE WHEN answer1 IS NOT NULL THEN 1 ELSE 0 END) + (CASE WHEN answer2 IS NOT NULL THEN 1 ELSE 0 END) + (CASE WHEN answer3 IS NOT NULL THEN 1 ELSE 0 END) ) AS num_answers FROM surveys WHERE id = 123; -- vs SELECT COUNT(response) FROM answers WHERE survey_id = 123; 对于分析查询，从 JSON 列提取数据，能够极大地降低查询效率。虽然在生产环境有很多理由使用 JSON 列，但那不是针对分析的。强势地把 JSON 列转换为更简单的数据类型，让分析更加容易、更加快捷。 不要过度规范化 日期、邮编和国家，不需要让它们自己的表带有主键查询。如果你带了，每次查询将包含有少量的相同连接。这会给数据库创建大量重复的 SQL，以及大量额外工作。 SELECT dates.d, COUNT(1) FROM users JOIN dates ON users.created_date_id = dates.id GROUP BY 1; -- vs SELECT DATE(created_at), COUNT(1) FROM users GROUP BY 1; 表是有着它们大量自己的数据的第一类对象。其它数据都应该是更加重要的对象上的、另外的列。 注1 连接号（－，〜），表示连接、起止、流程的符号。“两个相关的名词构成一个意义单位，中间用连接号。”、“相关的时间、地点或数目之间用连接号，表示起止。”、“相关的字母、阿拉伯数字等之间，用连接号，表示产品型号。”、“几个相关的项目表示递进式发展，中间用连接号。”http://zh.wikipedia.org/wiki/连接号 请注意：连接号和连字号是不同的：http://zh.wikipedia.org/wiki/连接号 注2 时间序列是用时间排序的一组随机变量，国内生产毛额（GDP）、消费者物价指数（CPI）、台湾加权股价指数、利率、汇率等等都是时间序列。 时间序列的时间间隔可以是分秒（如高频金融数据），可以是日、周、月、季度、年、甚至更大的时间单位。http://zh.wikipedia.org/wiki/時間序列(經濟學) 注3 In Information Systems design and theory Single Source Of Truth (SSOT) refers to the practice of structuring information models and associated schemata such that every data element is stored exactly once (e.g., in no more than a single row of a single table). http://en.wikipedia.org/wiki/Single_Source_of_Truth ","link":"https://faded.auspicious.space/post/10-rules-for-a-better-sql-schema/"},{"title":"跨页面通信的各种姿势","content":" 跨页面通信的各种姿势 将跨页面通讯类比计算机进程间的通讯，其实方法无外乎那么几种，而 Web 领域可以实现的技术方案主要是类似于以下两种原理： 获取句柄，定向通讯。 共享内存，结合轮询或者事件通知来完成业务逻辑。 由于第二种原理更利于解耦业务逻辑，具体的实现方案比较多样。以下是具体的实现方案，简单介绍下，权当科普： 获取句柄 具体方案 父页面通过 window.open(url, name) 方式打开的子页面可以获取句柄，然后通过 postMessage 完成通讯需求。 // parent.html const childPage = window.open('child.html', 'child') childPage.onload = () =&gt; { childPage.postMessage('hello', location.origin) } // child.html window.onmessage = evt =&gt; { // evt.data } Tips 当指定 window.open 的第二个 name 参数时，再次调用 window.open('****', 'child')会使之前已经打开的同 name 子页面刷新； 由于安全策略，异步请求之后再调用 window.open 会被浏览器阻止，不过可以通过句柄设置子页面的url即可实现类似效果。 // 首先先开一个空白页 const tab = window.open('about:blank') // 请求完成之后设置空白页的url fetch(/* ajax */).then(() =&gt; { tab.location.href = '****' }) 优劣 缺点是只能与自己打开的页面完成通讯，应用面相对较窄；但优点是在跨域场景中依然可以使用该方案。 LocalStorage 具体方案 设置共享区域的 storage，storage 会触发 storage 事件。 // A.html localStorage.setItem('message', 'hello') // B.html window.onstorage = evt =&gt; { // evt.key, evt.oldValue, evt.newValue } Tips 触发写入操作的页面下的 storage listener 不会被触发； storage 事件只有在发生改变的时候才会触发，即重复设置相同值不会触发 listener； safari 隐身模式下无法设置 localStorage 值。 优劣 API 简单直观，兼容性好，除了跨域场景下需要配合其他方案，无其他缺点。 BroadcastChannel 具体方案 和 localStorage 方案基本一致，额外需要初始化。 // A.html const channel = new BroadcastChannel('tabs') channel.onmessage = evt =&gt; { // evt.data } // B.html const channel = new BroadcastChannel('tabs') channel.postMessage('hello') 优劣 和 localStorage 方案没特别区别，都是同域、API 简单，BroadcastChannel 方案兼容性差些（Chrome &gt; 58），但比 localStorage 方案生命周期短（不会持久化），相对干净些。 SharedWorker 具体方案 SharedWorker 本身并不是为了解决通讯需求的，它的设计初衷应该是类似总控，将一些通用逻辑放在SharedWorker 中处理。不过因为也能实现通讯，所以一并写下： // A.html var sharedworker = new SharedWorker('worker.js') sharedworker.port.start() sharedworker.port.onmessage = evt =&gt; { // evt.data } // B.html var sharedworker = new SharedWorker('worker.js') sharedworker.port.start() sharedworker.port.postMessage('hello') // worker.js const ports = [] onconnect = e =&gt; { const port = e.ports[0] ports.push(port) port.onmessage = evt =&gt; { ports.filter(v =&gt; v!== port) // 此处为了贴近其他方案的实现，剔除自己 .forEach(p =&gt; p.postMessage(evt.data)) } } 优劣 相较于其他方案没有优势，此外，API 复杂而且调试不方便。 Cookie 具体方案 一个古老的方案，有点 localStorage 的降级兼容版，我也是整理本文的时候才发现的，思路就是往 document.cookie 写入值，由于 cookie 的改变没有事件通知，所以只能采取轮询脏检查来实现业务逻辑。 方案比较丑陋，势必被淘汰的方案，贴一下原版思路地址，我就不写 demo 了。 communication between browser windows (and tabs too) using cookies 优劣 相较于其他方案没有存在优势的地方，只能同域使用，而且污染 cookie 以后还额外增加 AJAX 的请求头内容。 Server 之前的方案都是前端自行实现，势必受到浏览器限制，比如无法做到跨浏览器的消息通讯，比如大部分方案都无法实现跨域通讯（需要增加额外的 postMessage 逻辑才能实现）。通过借助服务端，还有很多增强方案，也一并说下。 乞丐版 后端无开发量，前端定期保存，在 tab 被激活时重新获取保存的数据，可以通过校验 hash 之类的标记位来提升检查性能。 window.onvisibilitychange = () =&gt; { if (document.visibilityState === 'visible') { // AJAX } } Server-sent Events / Websocket 项目规模小型的时候可以采取这类方案，后端自行维护连接，以及后续的推送行为。 SSE // 前端 const es = new EventSource('/notification') es.onmessage = evt =&gt; { // evt.data } es.addEventListener('close', () =&gt; { es.close() }, false) // 后端，express为例 const clients = [] app.get('/notification', (req, res) =&gt; { res.setHeader('Content-Type', 'text/event-stream') clients.push(res) req.on('aborted', () =&gt; { // 清理clients }) }) app.get('/update', (req, res) =&gt; { // 广播客户端新的数据 clients.forEach(client =&gt; { client.write('data:hello\\n\\n') setTimeout(() =&gt; { client.write('event:close\\ndata:close\\n\\n') }, 500) }) res.status(200).end() }) WebSocket socket.io、sockjs 例子比较多，略 消息队列 项目规模大型时，需要消息队列集群长时间维护长链接，在需要的时候进行广播。 提供该类服务的云服务商很多，或者寻找一些开源方案自建。 例如 MQTT 协议方案（阿里云就有提供），Web 客户端本质上也是 WebSocket，需要集群同时支持ws 和 mqtt 协议，示例如下： // 前端 // 客户端使用开源的Paho // port会和mqtt协议通道不同 const client = new Paho.MQTT.Client(host, port, 'clientId') client.onMessageArrived = message =&gt; { // message. payloadString } client.connect({ onSuccess: () =&gt; { client.subscribe('notification') } }) // 抑或，借助flash（虽然快要被淘汰了）进行mqtt协议连接并订阅相应的频道，flash再通过回调抛出消息 // 后端 // 根据服务商提供的Api接口调用频道广播接口 ","link":"https://faded.auspicious.space/post/ways-to-cross-page-communication/"},{"title":"TCP 详解","content":" 计算机网络：这是一份全面 &amp; 详细 的TCP协议攻略 1 定义 Transmission Control Protocol，即传输控制协议。 属于传输层通信协议； 基于 TCP 的应用层协议有 HTTP、SMTP、FTP、Telnet 和 POP3。 2 特点 面向连接 面向字节流 全双工通信 可靠 具体介绍如下： 特点 具体描述 面向连接 使用 TCP 传输数据前，必须先建立 TCP 连接；传输完成后再释放连接（就像打电话：先拨号建立连接，打完后挂机释放连接） 全双工通信 建立 TCP 连接后，通信双方都能发送数据 可靠 通过 TCP 连接传送的数据：不丢失、无差错、不重复并且按需到达 面向字节流 数据以流的形式进行传输- 流：流入/流出进程的字符序列 - TCP 一次传输的报文长度有限制，若太大则需分块、分次传输- 但由于 TCP 连接的可靠性，接收方可按顺序接受数据块并重新组成分块之前的数据流- 所以 TCP 看起来就像直接互相传输字节流一样，即面向字节流 3 优缺点 优点：数据传输可靠。 缺点：效率慢（因需建立连接、发送确认包等）。 4 应用场景（对应的应用层协议） 要求通信数据可靠时，即数据要准确无误地传递给对方. 如：传输文件：HTTP、HTTPS、FTP 等协议；传输邮件：POP、SMTP 等协议。 万维网：HTTP 协议 文件传输：FTP 协议 电子邮件：SMTP 协议 远程终端接入：TELNET 协议 5 报文段格式 TCP 虽面向字节流，但传送的 数据单元 = 报文段； 报文段 = 首部 + 数据 2部分； TCP 的全部功能体现在它首部中各字段的作用，故下面主要讲解 TCP 报文段的首部。 首部前 20 个字符固定、后面有 4n 个字节是根据需而增加的选项，故TCP 首部最小长度 = 20字节。 字段 作用 备注 序号（报文段序号） 本报文段所发送数据的第 1 个字节的序号 4 字节 确认号（ACK） 期望收到对方下一个报文段的第一个数据字节的序号 - 4 字节- 若确认号 = N，则表明到序号 N-1 为止的所有数据都已正确收到 SYN（同步位） 连接建立时用于同步序号 - SYN = 1、ACK = 0，表明这是一个连接请求报文段- SYN = 1、ACK = 1，表明这是一个连接请求响应报文段 FIN（终止控制位） 释放连接 FIN = 1时，表明此报文段的发送方已发送数据完毕并要求释放连接 6 建立连接过程 TCP 建立连接需三次握手，具体介绍如下： 建立 TCP 连接前： TCP 客户端、服务器都处于关闭状态（CLOSED）； 直到客户端主动打开连接，服务器才被动打开连接处于监听状态（LISTEN），等待接收客户端的请求。 过程 具体描述 报文段信息 状态 第一次握手 客户端向服务器发送一个连接请求的报文段 - 同步标志位设为1：SYN = 1- 随机选择一个起始序号：seq = x- 不携带数据（因为SYN位被设置为1的报文段不能携带数据，但要消耗一个序号） 客户端进入同步已发送状态（SYN_SEND）（等待服务器的确认） 第二次握手 服务器收到请求连接报文段后，若同意建立连接，则向客户端发回连接确认的报文段（为该 TCP 连接分配 TCP 缓存、变量） - 同步标志位设为1：SYN=1- 确认标志位设为1：ACK=1- 随机选择一个起始序号：seq=y- 确认号字段设为：ack=x+1- 不携带数据（原因同上：但要消耗一个序号） 服务器进入同步已接收状态（SYN_RCVD） 第三次握手 客户端收到确认报文段后，向服务器再次发出连接确认报文段（为该 TCP 连接分配 TCP 缓存、变量） - 确认标记位设为1：ACK=1- 序号：seq=x+1- 确认号字段设为：ack=y+1- 可携带数据（因SYN无设为1，若不携带数据则不消耗序号） 客户端、服务器都进入已创建（ESTABLISHED）（可开始发送数据） 成功进行 TCP 的三次握手后，就建立起一条 TCP 连接，即可传送应用层数据 注： 因 TCP 提供的是全双工通信，故通信双方的应用进程在任何时候都能发送数据； 三次握手期间，任何 1 次未收到对面的回复，则都会重发。 特别说明：为什么TCP建立连接需三次握手？ 结论 防止服务器端因接收了早已失效的连接请求报文，从而一直等待客户端请求，最终导致形成死锁、浪费资源。 具体描述 SYN 洪泛攻击： 从上可看出：服务端的 TCP 资源分配时刻 = 完成第二次握手时；而客户端的 TCP 资源分配时刻 = 完成第三次握手时； 这就使得服务器易于受到 SYN 洪泛攻击，即同时多个客户端发起连接请求，从而需进行多个请求的 TCP 连接资源分配。 7 释放连接过程 在通信结束后，双方都可以释放连接，共需四次挥手，具体如下： 释放 TCP 连接前： TCP 客户端、服务器都处于已创建状态（ESTABLISHED）； 直到：客户端主动关闭 TCP 连接。 过程 具体描述 报文段信息 状态 第一次挥手 客户端向服务器发送一个连接释放的报文段（停止再发送数据） - 终止控制位设为1：FIN=1- 报文段序号设为前面传送数据最后一个字节的序号加1：seq=u- 可携带数据（FIN=1的报文即使不携带数据也消耗一个序号） 客户端进入终止等待1状态（FIN-WAIT-1）（等待服务器的确认） 第二次挥手 服务器收到连接释放报文段后，则向客户端发回连接释放确认的报文段 - 确认标记位设为1：ACK=1- 报文段序号设为前面传送数据最后一个字节的序号加1：seq=v- 确认号字段设为：ack=u+1 - 服务器进入关闭等待状态（CLOSE-WAIT）- 客户端收到服务器的确认后，进入终止等待2状态（FIN-WAIT-2），等待服务器发出释放连接请求- 至此，客户端→服务器的 TCP 连接已断开- 即 TCP 连接处于半关闭状态- 即客户端→服务器断开，但服务器→客户端未断开 第三次挥手 若服务器已无要向客户端发送数据，则发出释放连接的报文段 - 终止控制位设为1：FIN=1- 确认标记位设为1：ACK=1- 报文段序号：seq=w重复上次已发送的确认号字段设为：ack=u+1可携带数据（FIN=1的报文即使不携带数据也消耗一个序号） 服务器端进入最后确认状态（LAST-ACK） 第四次握手 客户端收到连接释放报文段后，则向服务器发回连接释放确认的报文段 - 确认标记位设为1：ACK=1报文段序号：seq=u+1- 确认号字段设为：ack=w+1- 可携带数据（FIN=1的报文即使不携带数据也消耗一个序号） - 客户端进入时间等待状态（TIME-WAIT） 特别说明：为什么 TCP 释放连接需四次挥手？ 结论 为了保证通信双方都能通知对方 需释放 &amp; 断开连接，即释放连接后，都无法接收 / 发送消息给对方。 具体描述 延伸疑问 为什么客户端关闭连接前要等待 2 MSL 时间？即 TIME - WAIT 状态的作用是什么？（MSL = 最长报文段寿命（Maximum Segment Lifetime）） 原因1：为了保证客户端发送的最后一个连接释放确认报文能到达服务器，从而使得服务器能正常释放连接。 原因2：防止上文提到的早已失效的连接请求报文出现在本连接中。 客户端发送了最后一个连接释放请求确认报文后，再经过 2 MSL 时间，则可使本连接持续时间内所产生的所有报文段都从网络中消失。即在下一个新的连接中就不会出现早已失效的连接请求报文 8 无差错传输 对比于 UDP，TCP 的传输是可靠的、无差错的。那么为什么 TCP 的传输为什么是可靠的、无差错的呢？下面，我将详细讲解 TCP 协议的无差错传输。 8.1 含义 无差错：即传输信道不出差错； 发送 &amp; 接收效率匹配：即无论发送方以多快的速度发送数据，接收方总来得及处理收到的数据。 8.2 基础：滑动窗口协议 先理解2个基础概念：发送窗口、接收窗口 类型 定义 作用 发送窗口 在任意时刻，发送方维持的一组连续的、允许发送帧的帧序号（发送窗口的大小：还没有收到对方确认信息的情况下发送方最多还可以发送多少个数据帧） 对发送方进行流量控制 接收窗口 任意时刻，接收方维持的一组连续的、允许接收帧的帧序号 - 控制可接收哪些数据帧和不可接收哪些数据帧- 接收方只有当收到的数据帧的序号落入接收窗口内采允许将该数据帧收下；否则一律丢弃 工作原理 对于发送端： 每收到一个确认帧，发送窗口就向前滑动一个帧的距离； 当发送窗口内无可发送的帧时（即窗口内的帧全部是已发送但未收到确认的帧），发送方就会停止发送，直到收到接收方发送的确认帧使窗口移动，窗口内有可以发送的帧，之后才开始继续发送。 具体如下图： 对于接收端： 当收到数据帧后，将窗口向前移动一个位置，并发回确认帧，若收到的数据帧落在接收窗口之外，则一律丢弃。 滑动窗口协议的重要特性 只有接收窗口向前滑动、接收方发送了确认帧时，发送窗口才有可能（只有发送方收到确认帧才是一定）向前滑动。 停止-等待协议、后退 N 帧协议和选择重传协议只是在发送窗口大小和接收窗口大小上有所差别： 停止等待协议：发送窗口大小=1，接收窗口大小=1；即单帧滑动窗口等于停止-等待协议。 后退 N 帧协议：发送窗口大小&gt;1，接收窗口大小=1。 选择重传协议：发送窗口大小&gt;1，接收窗口大小&gt;1。 当接收窗口的大小为 1 时，可保证帧有序接收。数据链路层的滑动窗口协议中，窗口的大小在传输过程中是固定的（注意要与 TCP 的滑动窗口协议区别）。 8.3 实现无差错传输的解决方案 核心思想：采用一些可靠传输协议，使得 出现差错时，让发送方重传差错数据：即出错重传； 当接收方来不及接收收到的数据时，可通知发送方降低发送数据的效率：即速度匹配。 针对上述俩个问题，分别采用的解决方案是：自动重传协议和流量控制和拥塞控制协议。 自动重传请求协议ARQ（针对出错重传） 定义：即 Auto Repeat reQuest，具体介绍如下： 类型： 类型 原理 特点 停等式 ARQ（Stop-and-Wait） （单帧滑动窗口）停止-等待协议+超时重传 发送窗口大小=1、接收窗口大小=1 后退 N 帧 ARQ（Go-Back-N） 多帧滑动窗口+累计确认+后退N帧+超时重传 发送窗口大小&gt;1、接收窗口大小=1 选择重传 ARQ（Selective Repeat） 多帧滑动窗口+累计确认+后退N帧+超时重传 发送窗口大小&gt;1、接收窗口大小&gt;1 下面，将主要讲解上述 3 类协议： 停等式ARQ（Stop-and-Wait） 原理：（单帧滑动窗口）停止 - 等待协议 + 超时重传，即 ：发送窗口大小=1、接收窗口大小=1 停止 - 等待协议的协议原理如下： 发送方每发送一帧，要等到接收方的应答信号后才能发送下一帧 接收方每接收一帧，都要反馈一个应答信号，表示可接下一帧 若接收方不反馈应答信号，则发送方必须一直等待 后退 N 帧协议 也称：连续 ARQ 协议 原理：多帧滑动窗口 + 累计确认 + 后退N帧 + 超时重传，即 ：发送窗口大小&gt;1、接收窗口大小=1 具体描述： 发送方：采用多帧滑动窗口的原理，可连续发送多个数据帧而不需等待对方确认。 接收方：采用累计确认和后退 N 帧的原理，只允许按顺序接收帧。具体原理如下： 示例讲解： 本示例 = 源站向目的站发送数据帧。具体示例如下： 选择重传 ARQ（Selective Repeat） 原理：多帧滑动窗口 + 累计确认 + 后退N帧 + 超时重传，即 ：发送窗口大小&gt;1、接收窗口大小&gt;1。类似于类型 2（后退 N 帧协议），此处仅仅是接收窗口大小的区别，故此处不作过多描述。 特点： 优：因连续发送数据帧而提高了信道的利用率； 缺：重传时又必须把原来已经传送正确的数据帧进行重传（仅因为这些数据帧前面有一个数据帧出了错），将导致传送效率降低。 由此可见，若信道传输质量很差，导致误码率较大时，后退 N 帧协议不一定优于停止-等待协议 流量控制 &amp; 拥塞控制（针对 速度匹配） 流量控制 简介： 实例： 特别注意：死锁问题 拥塞控制 定义：防止过多的数据注入到网络中，使得网络中的路由器和链路不致于过载。 拥塞：对网络中的资源需求 &gt; 该资源所能提供的部分 与 “流量控制”的区别： 类型 范围 面向对象 实际措施 拥塞控制 全局性 整个通信网络（含所有主机和路由器） 防止过多数据注入网络 流量控制 点对点、端到端 发送端 降低发送端的发送速率 具体解决方案： 共分为 2 个解决方案：慢开始和拥塞避免、快重传和快恢复。其中，涉及 4 种算法，即慢开始、拥塞避免、快重传和快恢复。 具体介绍如下： 慢开始 &amp; 拥塞避免 储备知识：拥塞窗口、慢开始算法、拥塞避免算法 拥塞窗口 发送方维持一个状态变量：拥塞窗口（cwnd， congestion window），具体介绍如下： 慢开始算法 原理：当主机开始发送数据时，由小到大逐渐增大 拥塞窗口数值（即发送窗口数值），从而由小到大逐渐增大发送报文段。 目的：开始传输时，试探网络的拥塞情况。 具体措施： 步骤 具体描述 备注 1. 开始发送报文段时 把拥塞窗口（cwnd）设置为一个最大报文段（MSS）的数值 设置得如此小的目的：试探一下网络的拥塞情况 2. 每收到一个对新的报文段的确认后 把拥塞窗口增加至多一个 MSS 的数值 逐步增大发送方的拥塞窗口 cwnd，以便分组注入到网络的速率更加合理 3. 每经过一个传输轮次 拥塞窗口（cwnd）就加倍 - 一个传输轮次：把拥塞窗口（cwnd）所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认- 一个传输轮次所经历的时间=往返时间 RTT 示意图： 特别注意： 慢开始的“慢”指：一开始发送报文段时拥塞窗口（cwnd）设置得较小（为1），使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），并不是指拥塞窗口（cwnd）的增长速率慢。 拥塞避免算法 原理：使得拥塞窗口（cwnd）按线性规律 缓慢增长：每经过一个往返时间RTT，发送方的拥塞窗口（cwnd）加1。 拥塞避免并不可避免拥塞，只是将拥塞窗口按现行规律缓慢增长，使得网络比较不容易出现拥塞 相比慢开始算法的加倍，拥塞窗口增长速率缓慢得多。 示意图： 解决方案描述（慢开始和拥塞避免） 为了防止拥塞窗口（cwnd）增长过大而引起网络拥塞，采用慢开始和拥塞避免 2 种算法，具体规则如下： 实例说明： 快重传和快恢复 快重传和快恢复的解决方案是对慢开始和拥塞避免算法的改进。 储备知识：快重传算法、快恢复算法。 快重传算法 原理： 接收方：每收到一个失序的报文段后 就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方），而不要等到自己发送数据时才进行捎带确认。 发送方只要一连收到 3 个重复确认就立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器到期。 作用： 由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约 20%。 示意图： 快恢复 当发送方连续收到 3 个重复确认后，就： 执行乘法减小算法：把慢开始门限（ssthresh）设置为出现拥塞时发送方窗口值的一半 = 拥塞窗口的一半； 将拥塞窗口（cwnd）值设置为慢开始门限 ssthresh 减半后的数值 = 拥塞窗口的一半； 执行加法增大算法：执行拥塞避免算法，使拥塞窗口缓慢地线性增大。 注： 由于跳过了拥塞窗口（cwnd）从1起始的慢开始过程，所以称为：快恢复； 此处网络不会发生网络拥塞，因若拥塞，则不会收到多个重复确认报文。 解决方案描述（快重传 &amp; 快恢复） 原理：为了优化慢开始和拥塞避免的解决方案，在上述方案中加入快重传和快恢复 两种算法，具体规则如下： 示意图： 至此，关于 TCP 无差错传输的知识讲解完毕。 9 与 UDP 协议的区别 类型 特点 性能 应用场景 首部字节 是否面向连接 传输可靠性 传输形式 传输效率 所需资源 TCP 面向连接 可靠 字节流 慢 多 要求通信数据可靠（如文件传输、邮件传输） 20-60 UDP 无连接 不可靠 数据报文段 快 少 要求通信速度高（如域名转换） 8 个字节（有 4 个字段组成） ","link":"https://faded.auspicious.space/post/tcp-full-introduction/"},{"title":"HTML5 file API 加 Canvas 实现图片前端 JS 压缩并上传","content":" HTML5 file API加canvas实现图片前端JS压缩并上传 图片上传前端压缩的现实意义 对于大尺寸图片的上传，在前端进行压缩除了省流量外，最大的意义是极大的提高了用户体验。 这种体验包括两方面： 由于上传图片尺寸比较小，因此上传速度会比较快，交互会更加流畅，同时大大降低了网络异常导致上传失败风险。 最最重要的体验改进点：省略了图片的再加工成本。很多网站的图片上传功能都会对图片的大小进行限制，尤其是头像上传，限制 5M 或者 2M 以内是非常常见的。然后现在的数码设备拍摄功能都非常出众，一张原始图片超过 2M 几乎是标配，此时如果用户想把手机或相机中的某个得意图片上传作为自己的头像，就会遇到因为图片大小限制而不能上传的窘境，不得不对图片进行再处理，而这种体验其实非常不好的。如果可以在前端进行压缩，则理论上对图片尺寸的限制是没有必要的。 HTML5 file API加canvas实现图片前端JS压缩 要想使用 JS 实现图片的压缩效果，原理其实很简单，核心 API 就是使用 canvas 的 drawImage() 方法。 canvas 的 drawImage() 方法 API 如下： context.drawImage(img, dx, dy); context.drawImage(img, dx, dy, dWidth, dHeight); context.drawImage(img, sx, sy, sWidth, sHeight, dx, dy, dWidth, dHeight); 后面最复杂的语法虽然看上去有 9 大参数，但不用慌，实际上可以看出就 3 个参数： img：就是图片对象，可以是页面上获取的 DOM 对象，也可以是虚拟 DOM 中的图片对象。 dx, dy, dWidth, dHeight：表示在 canvas 画布上规划处一片区域用来放置图片，dx，dy 为 canvas 元素的左上角坐标，dWidth，dHeight 指 canvas 元素上用在显示图片的区域大小。如果没有指定 sx，sy，sWidth，sHeight 这 4 个参数，则图片会被拉伸或缩放在这片区域内。 sx, sy, swidth, sheight：这 4 个坐标是针对图片元素的，表示图片在 canvas 画布上显示的大小和位置。sx，sy 表示图片上 sx，sy 这个坐标作为左上角，然后往右下角的 swidth，sheight 尺寸范围图片作为最终在 canvas 上显示的图片内容。 drawImage() 方法有一个非常怪异的地方，大家一定要注意，那就是 5 参数和 9 参数里面参数位置是不一样的，这个和一般的 API 有所不同。一般 API 可选参数是放在后面。但是，这里的 drawImage() 9 个参数时候，可选参数 sx，sy，swidth，sheight 是在前面的。如果不注意这一点，有些表现会让你无法理解。 下图为 MDN 上原理示意： 对于本文的图片压缩，需要用的是 5 个参数语法。举个例子，一张图片（假设图片对象是 img）的原始尺寸是 4000*3000，现在需要把尺寸限制为 400*300 大小，很简单，原理如下代码示意： var canvas = document.createElement('canvas'); var context = canvas.getContext('2d'); canvas.width = 400; canvas.height = 300; // 核心JS就这个 context.drawImage(img,0,0,400,300); 把一张大的图片，直接画在一张小小的画布上。此时大图片就天然变成了小图片，压缩就这么实现了，是不是简单的有点超乎想象。 当然，若要落地于实际开发，我们还需要做些其他的工作，就是要解决图片来源和图片去向的问题。 如何把系统中图片呈现在浏览器中 HTML5 file API 可以让图片在上传之前直接在浏览器中显示，通常使用 FileReader 方法，代码示意如下： var reader = new FileReader(), img = new Image(); // 读文件成功的回调 reader.onload = function(e) { // e.target.result就是图片的base64地址信息 img.src = e.target.result; }; eleFile.addEventListener('change', function (event) { reader.readAsDataURL(event.target.files[0]); }); 于是，包含图片信息的 context.drawImage() 方法中的 img 图片就有了。 如何把 canvas 画布转换成 img 图像 canvas 天然提供了 2 个转图片的方法，一个是： canvas.toDataURL() 语法如下： canvas.toDataURL(mimeType, qualityArgument); 可以把图片转换成 base64 格式信息，纯字符的图片表示法。 其中： mimeType 表示 canvas 导出来的 base64 图片的类型，默认是 png 格式，也即是默认值是 'image/png'，我们也可以指定为 jpg 格式 'image/jpeg' 或者 webp 等格式。file 对象中的 file.type 就是文件的 mimeType 类型，在转换时候正好可以直接拿来用（如果有 file 对象）。 qualityArgument 表示导出的图片质量，只要导出为 jpg 和 webp 格式的时候此参数才有效果，默认值是 0.92，是一个比较合理的图片质量输出参数，通常情况下，我们无需再设定。 canvas.toBlob() 语法如下： canvas.toBlob(callback, mimeType, qualityArgument) 可以把 canvas 转换成 Blob 文件，通常用在文件上传中，因为是二进制的，对后端更加友好。 和 toDataURL() 方法相比，toBlob() 方法是异步的，因此多了个 callback 参数，这个 callback 回调方法默认的第一个参数就是转换好的 blob 文件信息，本文 demo 的文件上传就是将 canvas 图片转换成二进制的 blob 文件，然后再 ajax 上传的，代码如下： // canvas转为blob并上传 canvas.toBlob(function (blob) { // 图片ajax上传 var xhr = new XMLHttpRequest(); // 开始上传 xhr.open(&quot;POST&quot;, 'upload.php', true); xhr.send(blob); }); 于是，经过“图片→canvas 压缩→图片”三步曲，我们完成了图片前端压缩并上传的功能。 更加完整的核心代码请参见demo页面的左侧，如果对其他交互代码也敢兴趣，请参考页面源代码。 结束语 就在几个月前刚写过一篇文章“使用canvas在前端实现图片水印合成”，实际上所使用的技术和套路和本文是如出一辙的，也是“图片→ canvas 水印→图片”三步曲，区别在于水印合成是连续执行两次 context.drawImage() 方法，一次是原图一次水印图片，以及最后转换成图片的时候什么是 toDataURL() 方法，其他代码逻辑和原理都是一样的。 由此及彼，利用同样的原理和代码逻辑，我们还可以实现其它很多以前前端不太好实现的功能，比方说图片的真剪裁效果，所谓“真剪裁”指不是使用个 overflow:hidden 或者 clip 这些 CSS属性的“伪剪裁”，而是真正意义上就这么大区域图片信息。甚至配合一些前端算法，我们可以直接在前端进行人脸识别，图片自动美化等一系列功能再上传等等。 原理都是一样的，都是利用 canvas 作为中间媒介进行处理。 ","link":"https://faded.auspicious.space/post/html5-canvas-image-compress-upload/"},{"title":"PNG 的故事：获取图片信息和像素内容","content":" PNG 的故事：获取图片信息和像素内容 前言 现在时富媒体时代，图片的重要性对于数十亿互联网用户来说不言而喻，图片本身就是像素点阵的合集，但是为了如何更快更好的存储图片而诞生了各种各样的图片格式：jpeg、png、gif、webp 等，而这次我们要拿来开刀的，就是 png。 简介 首先，png 是什么鬼？我们来看看 wiki 上的一句话简介： Portable Network Graphics (PNG) is a raster graphics file format that supports lossless data compression. 也就是说，png 是一种使用无损压缩的图片格式，而大家熟知的另外一种图片格式——jpeg 则是采用有损压缩的方式。用通俗易懂的方式来讲，当原图片数据被编码成 png 格式后，是可以完全还原成原本的图片数据的，而编码成 jpeg 则会损耗一部分图片数据，这是因为两者的编码方式和定位不同。jpeg 着重于人眼的观感，保留更多的亮度信息，去掉一些不影响观感的色度信息，因此是有损耗的压缩。png 则保留原始所有的颜色信息，并且支持透明／alpha 通道，然后采用无损压缩进行编码。因此对于 jpeg 来说，通常适合颜色更丰富、可以在人眼识别不了的情况下尽可能去掉冗余颜色数据的图片，比如照片之类的图片；而 png 适合需要保留原始图片信息、需要支持透明度的图片。 以下，我们来尝试获取 png 编码的图片数据： 结构 图片是属于 2 进制文件，因此在拿到 png 图片并想对其进行解析的话，就得以二进制的方式进行读取操作。png 图片包含两部分：文件头和数据块。 文件头 png 的文件头就是 png 图片的前 8 个字节，其值为 [0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A]，人们常常把这个头称之为 “魔数”。玩过 Linux 的同学估计知道，可以使用 file 命令类判断一个文件是属于格式类型，就算我们把这个文件类型的后缀改得乱七八糟也可以识别出来，用的就是判断 “魔数” 这个方法。有兴趣的同学还可以使用 String.fromCharCode 将这个 “魔数” 转成字符串看看，就知道为什么 png 会取这个值作为文件头了。 用代码来判断也很简单： // 读取指定长度字节 function readBytes(buffer, begin, length) { return Array.prototype.slice.call(buffer, begin, begin + length); } let header = readBytes(pngBuffer, 0, 8); // [0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A] 数据块 去掉了 png 图片等前 8 个字节，剩下的就是存放 png 数据的数据块，我们通常称之为 chunk。 顾名思义，数据块就是一段数据，我们按照一定规则对 png 图片（这里指的是去掉了头的 png 图片数据，下同）进行切分，其中一段数据就是一个数据块。每个数据块的长度是不定的，我们需要通过一定的方法去提取出来，不过我们要先知道有哪些类型的数据块才好判断。 数据块类型 数据块类型有很多种，但是其中大部分我们都不需要用到，因为里面没有存储我们需要用到的数据。我们需要关注的数据块只有以下四种： IHDR：存放图片信息。 PLTE：存放索引颜色。 IDAT：存放图片数据。 IEND：图片数据结束标志。 只要解析这四种数据块就可以获取图片本身的所有数据，因此我们也称这四种数据块为 “关键数据块”。 数据块格式 数据块格式如下： 描述 长度 数据块内容长度 4 字节 数据块类型 4 字节 数据块内容 不定字节 CRC 冗余校验码 4 字节 这样我们就可以轻易的指导当前数据块的长度了，即 数据块内容长度 + 12 字节，用代码实现如下： // 读取32位无符号整型数 function readInt32(buffer, offset) { offset = offset || 0; return (buffer[offset] &lt;&lt; 24) + (buffer[offset + 1] &lt;&lt; 16) + (buffer[offset + 2] &lt;&lt; 8) + (buffer[offset + 3] &lt;&lt; 0); } let length = readInt32(readBytes(4)); // 数据块内容长度 let type = readBytes(4); // 数据块类型 let chunkData = readBytes(length); // 数据块内容 let crc = readBytes(4); // CRC 冗余校验码 这里的 CRC 冗余校验码在我们解码过程中用不到，所以这里不做详解。除此之外，数据块内容长度和数据块内容好解释，不过数据块类型有何作用呢，这里我们先将这个 type 转成字符串类型： // 将buffer数组转为字符串 function bufferToString(buffer) { let str = ''; for(let i=0, len=buffer.length; i&lt;len; i++){ str += String.fromCharCode(buffer[i]); } return str; } type = bufferToString(type); 然后会发现 type 的值是四个大写英文字母，没错，这就是上面提到的数据块类型。上面还提到了我们只需要解析关键数据块，因此遇到 type 不等于 IHDR、PLTE、IDAT、IEND 中任意一个的数据块就直接舍弃好了。当我们拿到一个关键数据块，就直接解析其数据块内容就可以了，即上面代码中的 chunkData 字段。 IHDR 类型为 IHDR 的数据块用来存放图片信息，其长度为固定的 13 个字节： 描述 长度 图片宽度 4 字节 图片高度 4 字节 图像深度 1 字节 颜色类型 1 字节 压缩方法 1 字节 过滤方式 1 字节 扫描方式 1 字节 其中宽高很好解释，直接转成 32 位整数，就是这张 png 图片等宽高（以像素为单位）。压缩方法目前只支持一种（deflate/inflate 压缩算法），其值为 0；过滤方式也只有一种（包含标准的 5 种过滤类型），其值为 0；扫描方式有两种，一种是逐行扫描，值为 0，还有一种是 Adam7 隔行扫描，其值为 1，此次只针对普通的逐行扫描方式进行解析，因此暂时不考虑 Adam7 隔行扫描。 图片深度是指每个像素点中的每个通道（channel）占用的位数，只有 1、2、4、8 和 16 这 5 个值；颜色类型用来判断每个像素点中有多少个通道，只有 0、2、3、4 和 6 这 5 个值： 颜色类型的值 占用通道数 描述 0 1 灰度图像，只有 1 个灰色通道 2 3 rgb 真彩色图像，有 RGB3 色通道 3 1 索引颜色图像，只有索引值一个通道 4 2 灰度图像 + alpha 通道 PLTE 类型为 PLTE 的数据块用来存放索引颜色，我们又称之为 “调色板”。 由 IHDR 数据块解析出来的图像信息可知，图像的数据可能是以索引值的方式进行存储。当图片数据采用索引值的时候，调色板就起作用了。调色板的长度和图像深度有关，假设图像深度的值是 xxx，则其长度通常为 2x×32^x\\times 32x×3。原因是图像深度保存的就是通道占用的位数，而在使用索引颜色的时候，通道里存放的就是索引值，2x2^x2x 就表示这个通道可能存放的索引值有多少个，即调色板里的颜色数。而每个索引颜色是 RGB3 色通道存放的，因此此处还需要 ×3\\times 3×3。 通常使用索引颜色的情况下，图像深度的值即为 8，因而调色板里存放的颜色就只有 256 种颜色，长度为 256 * 3 个字节。再加上 1 位布尔值表示透明像素，这就是我们常说的 png8 图片了。 IDAT 类型为 IDAT 的数据块用来存放图像数据，跟其他关键数据块不同的是，其数量可以是连续的复数个；其他关键数据块在 1 个 png 文件里有且只有 1 个。 这里的数据得按顺序把所有连续的 IDAT 数据块全部解析并将数据联合起来才能进行最终处理，这里先略过。 let dataChunks = []; let length = 0; // 总数据长度 // ... while(/* 存在IDAT数据块 */) { dataChunks.push(chunkData); length += chunkData.length; } IEND 当解析到类型为 IEND 的数据块时，就表明所有的 IDAT 数据块已经解析完毕，我们就可以停止解析了。 IEND 整个数据块的值时固定的：[0x00, 0x00, 0x00, 0x00, 0x49, 0x45, 0x4E, 0x44, 0xAE, 0x42, 0x60, 0x82]，因为 IEND 数据块没有数据块内容，所以其数据块内容长度字段（数据块前 4 个字节）的值也是 0。 解析 解压缩 当我们收集完 IDAT 的所有数据块内容时，我们要先对其进行解压缩： const zlib = require('zlib'); let data = new Buffer(length); let index = 0; dataChunks.forEach((chunkData) =&gt; { chunkData.forEach((item) =&gt; {data[index++] = item}); }); // inflate解压缩 data = zlib.inflateSync(new Buffer(data)); 扫描 上面说过，此次我们只考虑逐行扫描的方式： // 读取8位无符号整型数 function readInt8(buffer, offset) { offset = offset || 0; return buffer[offset] &lt;&lt; 0; } let width; // 解析IHDR数据块时得到的图像宽度 let height; // 解析IHDR数据块时得到的图像高度 let colors; // 解析IHDR数据块时得到的通道数 let bitDepth; // 解析IHDR数据块时得到的图像深度 let bytesPerPixel = Math.max(1, colors * bitDepth / 8); // 每像素字节数 let bytesPerRow = bytesPerPixel * width; // 每行字节数 let pixelsBuffer = new Buffer(bytesPerPixel * width * height); // 存储过滤后的像素数据 let offset = 0; // 当前行的偏移位置 // 逐行扫描解析 for(let i=0, len=data.length; i&lt;len; i+=bytesPerRow+1) { let scanline = Array.prototype.slice.call(data, i+1, i+1+bytesPerRow); // 当前行 let args = [scanline, bytesPerPixel, bytesPerRow, offset]; // 第一个字节代表过滤类型 switch(readInt8(data, i)) { case 0: filterNone(args); break; case 1: filterSub(args); break; case 2: filterUp(args); break; case 3: filterAverage(args); break; case 4: filterPaeth(args); break; default: throw new Error('未知过滤类型！'); } offset += bytesPerRow; } 上面代码前半部分不难理解，就是通过之前解析得到的图像宽高，再加上图像深度和通道数计算得出每个像素占用的字节数和每一行数据占用的字节数。因此我们就可以拆分出每一行的数据和每一个像素的数据。 在得到每一行数据后，就要进行这个 png 编码里最关键的 1 步——过滤。 过滤 早先我们说过过滤方法只有 1 种，其中包含 5 种过滤类型，图像每一行数据里的第一个字节就表示当前行数什么过滤类型。 png 为什么要对图像数据进行过滤呢？ 大多数情况下，图像的相邻像素点的色值时很相近的，而且很容易呈现线性变化（相邻数据的值是相似或有某种规律变化的），因此借由这个特性对图像的数据进行一定程度的压缩。针对这种情况我们常常使用一种叫差分编码的编码方式，即是记录当前数据和某个标准值的差距来存储当前数据。 比如说有这么一个数组 [99, 100, 100, 102, 103]，我们可以将其转存为 [99, 1, 0, 2, 1]。转存的规则就是以数组第 1 位为标准值，标准值存储原始数据，后续均存储以前 1 位数据的差值。 当我们使用了差分编码后，再进行 deflate 压缩的话，效果会更好（deflate 压缩是 LZ77 延伸出来的一种算法，压缩频繁重复出现的数据段的效果是相当不错的，有兴趣的同学可自行去了解）。 好，回到正题来讲 png 的 5 种过滤类型，首先我们要定义几个变量以便于说明： CBAX\\begin{matrix} C &amp; B \\\\ A &amp; X \\end{matrix} CA​BX​ XXX：当前像素。 AAA：当前像素点左边的像素。 BBB：当前像素点上边的像素。 CCC：当前像素点左上边的像素。 过滤类型 0：None 这个没啥好解释的，就是完全不做任何过滤。 function filterNone(scanline, bytesPerPixel, bytesPerRow, offset) { for(let i=0; i&lt;bytesPerRow; i++) { pixelsBuffer[offset + i] = scanline[i]; } } 过滤类型 1：Sub 记录 X−AX - AX−A 的值，即当前像素和左边像素的差值。左边起第一个像素是标准值，不做任何过滤。 function filterSub(scanline, bytesPerPixel, bytesPerRow, offset) { for(let i=0; i&lt;bytesPerRow; i++) { if(i &lt; bytesPerPixel) { // 第一个像素，不作解析 pixelsBuffer[offset + i] = scanline[i]; } else { // 其他像素 let a = pixelsBuffer[offset + i - bytesPerPixel]; let value = scanline[i] + a; pixelsBuffer[offset + i] = value &amp; 0xFF; } } } 过滤类型 2：Up 记录 X−BX - BX−B 的值，即当前像素和上边像素点差值。如果当前行是第 1 行，则当前行数标准值，不做任何过滤。 function filterUp(scanline, bytesPerPixel, bytesPerRow, offset) { if(offset &lt; bytesPerRow) { // 第一行，不作解析 for(let i=0; i&lt;bytesPerRow; i++) { pixelsBuffer[offset + i] = scanline[i]; } } else { for(let i=0; i&lt;bytesPerRow; i++) { let b = pixelsBuffer[offset + i - bytesPerRow]; let value = scanline[i] + b; pixelsBuffer[offset + i] = value &amp; 0xFF; } } } 过滤类型 3：Average 记录 X−(A+B)/2X - (A + B) / 2X−(A+B)/2 的值，即当前像素与左边像素和上边像素的平均值的差值。 如果当前行数第一行：做特殊的 Sub 过滤，左边起第一个像素是标准值，不做任何过滤。其他像素记录该像素与左边像素的二分之一的值的差值。 如果当前行数不是第一行：左边起第一个像素记录该像素与上边像素的二分之一的值的差值，其他像素做正常的 Average 过滤。 function filterAverage(scanline, bytesPerPixel, bytesPerRow, offset) { if(offset &lt; bytesPerRow) { // 第一行，只做Sub for(let i=0; i&lt;bytesPerRow; i++) { if(i &lt; bytesPerPixel) { // 第一个像素，不作解析 pixelsBuffer[offset + i] = scanline[i]; } else { // 其他像素 let a = pixelsBuffer[offset + i - bytesPerPixel]; let value = scanline[i] + (a &gt;&gt; 1); // 需要除以2 pixelsBuffer[offset + i] = value &amp; 0xFF; } } } else { for(let i=0; i&lt;bytesPerRow; i++) { if(i &lt; bytesPerPixel) { // 第一个像素，只做Up let b = pixelsBuffer[offset + i - bytesPerRow]; let value = scanline[i] + (b &gt;&gt; 1); // 需要除以2 pixelsBuffer[offset + i] = value &amp; 0xFF; } else { // 其他像素 let a = pixelsBuffer[offset + i - bytesPerPixel]; let b = pixelsBuffer[offset + i - bytesPerRow]; let value = scanline[i] + ((a + b) &gt;&gt; 1); pixelsBuffer[offset + i] = value &amp; 0xFF; } } } } 过滤类型 4：Paeth 记录 X−PrX - PrX−Pr 的值，这种过滤方式比较复杂，PrPrPr 的计算方式（伪代码）如下： p = a + b - c pa = abs(p - a) pb = abs(p - b) pc = abs(p - c) if pa &lt;= pb and pa &lt;= pc then Pr = a else if pb &lt;= pc then Pr = b else Pr = c return Pr 如果当前行数第一行：做 Sub 过滤。 如果当前行数不是第一行：左边起第一个像素记录该像素与上边像素的差值，其他像素做正常的 Peath 过滤。 function filterPaeth(scanline, bytesPerPixel, bytesPerRow, offset) { if(offset &lt; bytesPerRow) { // 第一行，只做Sub for(let i=0; i&lt;bytesPerRow; i++) { if(i &lt; bytesPerPixel) { // 第一个像素，不作解析 pixelsBuffer[offset + i] = scanline[i]; } else { // 其他像素 let a = pixelsBuffer[offset + i - bytesPerPixel]; let value = scanline[i] + a; pixelsBuffer[offset + i] = value &amp; 0xFF; } } } else { for(let i=0; i&lt;bytesPerRow; i++) { if(i &lt; bytesPerPixel) { // 第一个像素，只做Up let b = pixelsBuffer[offset + i - bytesPerRow]; let value = scanline[i] + b; pixelsBuffer[offset + i] = value &amp; 0xFF; } else { // 其他像素 let a = pixelsBuffer[offset + i - bytesPerPixel]; let b = pixelsBuffer[offset + i - bytesPerRow]; let c = pixelsBuffer[offset + i - bytesPerRow - bytesPerPixel]; let p = a + b - c; let pa = Math.abs(p - a); let pb = Math.abs(p - b); let pc = Math.abs(p - c); let pr; if (pa &lt;= pb &amp;&amp; pa &lt;= pc) pr = a; else if (pb &lt;= pc) pr = b; else pr = c; let value = scanline[i] + pr; pixelsBuffer[offset + i] = value &amp; 0xFF; } } } } 获取像素 到这里，解析的工作就做完了，上面代码里的 pixelsBuffer 数组里存的就是像素的数据了，不过我们要如何获取具体某个像素的数据呢？方式可参考下面代码： let palette; // PLTE数据块内容，即调色板内容 let colorType; // 解析IHDR数据块时得到的颜色类型 let transparentPanel; // 透明像素面板，解析tRNS数据块获得 function getPixel(x, y) { if(x &lt; 0 || x &gt;= width || y &lt; 0 || y &gt;= height) { throw new Error('x或y的值超出了图像边界！'); } let bytesPerPixel = Math.max(1, colors * bitDepth / 8); // 每像素字节数 let index = bytesPerPixel * ( y * width + x); switch(colorType) { case 0: // 灰度图像 return [pixelsBuffer[index], pixelsBuffer[index], pixelsBuffer[index], 255]; case 2: // rgb真彩色图像 return [pixelsBuffer[index], pixelsBuffer[index + 1], pixelsBuffer[index + 2], 255]; case 3: // 索引颜色图像 let paletteIndex = pixelsBuffer[index]; let transparent = transparentPanel[paletteIndex] if(transparent === undefined) transparent = 255; return [palette[paletteIndex * 3 + 0], palette[paletteIndex * 3 + 1], palette[paletteIndex * 3 + 2], transparent]; case 4: // 灰度图像 + alpha通道 return [pixelsBuffer[index], pixelsBuffer[index], pixelsBuffer[index], pixelsBuffer[index + 1]]; case 6: // rgb真彩色图像 + alpha通道 return [pixelsBuffer[index], pixelsBuffer[index + 1], pixelsBuffer[index + 2], pixelsBuffer[index + 3]]; } } 此处用到了非关键数据块 tRNS 的数据，不过这里不做讲解，有兴趣的同学可去官网了解：https://www.w3.org/TR/PNG/#11tRNS（此数据块的结构相当简单） 尾声 png 的解析流程可以由这一张图简单概括： 此文只对 png 图片的格式做了简单的介绍，我们也知道如何对一张 png 图片做简单的解析。上面出现的代码只是 js 代码片段，如果对完整代码有兴趣的同学可以戳这里，虽然代码仓库还在建设过程中，不过关于简单的 png 图片解析部分已经完成。 参考资料： https://www.w3.org/TR/PNG/ http://www.libpng.org/pub/png/ https://en.wikipedia.org/wiki/Portable_Network_Graphics ","link":"https://faded.auspicious.space/post/the-story-of-png-get-images-and-pixel-content/"},{"title":"贝尔实验室的历史","content":" 贝尔实验室的历史 发明家贝尔 贝尔的全名是亚历山大·格拉厄姆·贝尔（Alexander Graham Bell） 亚历山大·贝尔（外国人常常将中间的名字略去）在 1847 年出生在苏格兰的一个声学世家， 23岁（1870年）：移民加拿大； 24岁（1871年）：又来到美国； 29岁（1876年）：试验成功了第一台可用的电话，并在同年获得电话专利； 30岁（1877年）：贝尔便创立了贝尔电话公司，公司以出租电话机收取使用费的方式盈利； 31岁（1878年）：贝尔退出了贝尔电话公司，但他所拥有的电话专利可以让他不断获得可观的专利费； 35岁（1882年）：正式加入美国国籍； 76岁（1922年）：贝尔离开了人世。 AT&amp;T AT&amp;T，即 American Telephone &amp; Telegraph Company，中文则是“美国电话电报公司”，它是当今世界五百强之一。 AT&amp;T的前身便是刚刚提到的于 1877 年创立的“贝尔电话公司”（简称贝尔公司），在经营了 18 年之后，也就是 1895 年，贝尔电话公司决定将“全美范围内的长途业务”分割出来，成立一家独立的公司，起名叫做“AT&amp;T”。AT&amp;T 发展迅猛，在 1899 年，AT&amp;T 便把其前身的贝尔电话公司整合进来，于是 AT&amp;T 便成了贝尔公司的母公司。 贝尔实验室 在 1925 年，AT&amp;T 收购了西方电子公司的研究部门，并成立了一个叫做“贝尔电话实验室公司”（简称便是贝尔实验室）的独立实体，在建立之初，贝尔实验室便致力于数学、物理学、材料科学、计算机编程、电信技术等各方面的研究。 不幸的是，在 1984 年，美国司法部依据《反托拉斯法》对如日中天的 AT&amp;T 进行拆分，形成了新的 AT&amp;T 公司及七个本地电话公司，贝尔实验室也因此缩减形成了贝尔实验室核心团队，主要负责为各个拆分后的公司提供研究开发的服务。 朗讯 在 1995 年到 1996 年间，AT&amp;T 公司又被进行了一轮拆分，贝尔实验室和设备制造部门脱离出来形成了一个新的公司，叫做朗讯科技，而 AT&amp;T 则只保留了通信服务业务，也只保留很小一批研究人员组建了AT&amp;T 实验室。 自从 1996 年从 AT&amp;T 独立出来后，朗讯（Lucent）公司以贝尔实验室作为强力后盾，一致致力于为全球最大的通信服务提供商设计和提供网络。 朗讯公司的总部位于美国新泽西州的茉莉山。 阿尔卡特 阿尔卡特（Alcatel）公司，创立于 1898 年，总部位于法国巴黎，一直专注于电信系统和设备以及相关的电缆和部件领域的研究和生产。 阿朗 在 2006 年，通信行业发生了一件大事，那就是法国阿尔卡特公司和美国朗讯公司发表联合声明，宣布了阿尔卡特公司收购朗讯公司的消息。在合并后的新公司中，阿尔卡特占据 60% 的股份，朗讯占有 40% 的股份。合并后的规模仅次于美国思科。 合并后的公司叫做阿尔卡特-朗讯（Alcatel-Lucent，简称“阿朗”），总部设在法国巴黎。 与此同时，原属朗讯科技的贝尔实验室也一并合并到阿朗。 贝尔实验室的历史 通过上面的背景知识介绍，相信你一定已经了解了贝尔实验室的发展历程，我们再来用简短的文字总结一下： 贝尔发明电话→贝尔建立贝尔电话公司→贝尔电话公司分离出 AT&amp;T 公司专门负责全美长途业务→AT&amp;T 整合原贝尔电话公司→AT&amp;T 收购西方电子研究部门并建立贝尔电话实验室（即贝尔实验室）→AT&amp;T 因垄断被拆分→AT&amp;T再次被拆分，贝尔实验室和设备制造部门被独立出来成立朗讯科技公司→阿尔卡特收购朗讯组成阿朗，贝尔实验室也一起合并→贝尔实验室现在服务于阿朗公司\\begin{aligned} \\text{贝尔发明电话} &amp;\\to \\text{贝尔建立贝尔电话公司} \\\\ &amp;\\to \\text{贝尔电话公司分离出 AT\\&amp;T 公司专门负责全美长途业务}\\\\ &amp;\\to \\text{AT\\&amp;T 整合原贝尔电话公司}\\\\ &amp;\\to \\text{AT\\&amp;T 收购西方电子研究部门并建立贝尔电话实验室（即贝尔实验室）}\\\\ &amp;\\to \\text{AT\\&amp;T 因垄断被拆分}\\\\ &amp;\\to \\text{AT\\&amp;T再次被拆分，贝尔实验室和设备制造部门被独立出来成立朗讯科技公司}\\\\ &amp;\\to \\text{阿尔卡特收购朗讯组成阿朗，贝尔实验室也一起合并}\\\\ &amp;\\to \\text{贝尔实验室现在服务于阿朗公司} \\end{aligned} 贝尔发明电话​→贝尔建立贝尔电话公司→贝尔电话公司分离出 AT&amp;T 公司专门负责全美长途业务→AT&amp;T 整合原贝尔电话公司→AT&amp;T 收购西方电子研究部门并建立贝尔电话实验室（即贝尔实验室）→AT&amp;T 因垄断被拆分→AT&amp;T再次被拆分，贝尔实验室和设备制造部门被独立出来成立朗讯科技公司→阿尔卡特收购朗讯组成阿朗，贝尔实验室也一起合并→贝尔实验室现在服务于阿朗公司​ 所以，当你进入到贝尔实验室的官方首页时，你会发现 LOGO 也是 Alcatel-Lucent 的。 ","link":"https://faded.auspicious.space/post/the-history-of-the-bell-labs/"},{"title":"浏览器 user-agent 详解","content":" 浏览器user-agent详解 特性检测并非浏览器检测 浏览器们的家族史 较古的浏览器 1993年，NCSA 发布了首款 Web 浏览器 Mosaic。它的 user-agent 字串非常简洁： Mosaic/0.9 虽然当时由于它对操作系统和平台的依赖性，但是基本格式还是很简单明了。在文本中，斜杠前面是产品名称(可能会显示为 NCSA Mosaic 或是其他类似的字)，斜杠后面是产品版本号。 Netscape Communications 开发了 Web 浏览器 Mozilla（当时号称“Mosaic 杀手”）。他们首款公开发行版本： Netscape Navigator 2 的 user-agent 字串具有如下格式： Mozilla/Version [Language] (Platform; Encryption) Netscape 按之前的做法在 user-agent 字串的前半部分使用了产品名称和产品版本，但在后面增加了下列信息： Language - 表示应用程序用的是哪个语言； Platform - 表示应用程序是在什么操作系统和/或平台中运行； Encryption - 表示应用程序包含了什么安全加密类型。其中的值可能是U（128 位加密）、I（40 位加密）、N（没加密）。 Netscape Navigator 2 的 user-agent 字串的示例： Mozilla/2.02 [fr] (WinNT; I) 上面的字串指： Netscape Navigator 2.02 、法语 、Windows NT 、40 位加密。在当时，通过 user-agent 字串中的产品名称，可以正确判断使用的是哪个 Web 浏览器。 Netscape Navigator 3 、Internet Explorer 3 1996 年，Netscape Navigator 3 发布，它远远超过 Mosaic 成为当时最流行的 Web 浏览器。而 user-agent 字串只有些小的变化：去掉了语言部分，多了个放操作系统或 CPU 的可选信息。格式如下： Mozilla/Version (Platform; Encryption [; OS-or-CPU description]) 在 Windows 系统中 Netscape Navigator 3 的 user-agent 字串的示例： Mozilla/3.0 (Win95; U) 上面的字串指：Netscape Navigator 3 、Windows 95 、128 位加密。在 Windows 系统中，字串里面不会显示 OS 或 CPU 的信息。 Netscape Navigator 3 发布不久，微软公布了它的首款 Web 浏览器： IE 3 ¹，但是 Netscape 是当时首选浏览器，大多数服务器在加载页面前都会检查 user-agent 是否为该款浏览器。IE 如果不兼容 Netscape user-agent 字串，使用 IE 的用户就根本打不开这些页面，于是造就了如下格式： Mozilla/2.0 (compatible; MSIE Version; Operating System) 在 Windows 95 中 IE 3.02 的 user-agent 字串的示例： Mozilla/2.0 (compatible; MSIE 3.02; Windows 95) 由于当时的浏览器嗅探只查 user-agent 字串中的产品名称部分，结果 IE 摇身一变被识别成了 Mozilla，伪装成 Netscape Navigator。这个做法引发了对浏览器识别的争论。从此以后，浏览器真正的版本埋没在了字串的中间。 Netscape Communicator 4 、Internet Explorer 4 至 8 1997 年8月，Netscape Communicator 4 发布（发布的名称中 Navigator 换成了 Communicator），它的 user-agent 字串格式与 3 版本一致。Windows 98 中 4 版本的 user-agent 字串如下: Mozilla/4.0 (Win98; I) Netscape 浏览器在更新时，版本也相应增加。4.79 版本的 user-agent 字串如下： Mozilla/4.79 (Win98; I) 微软发布 IE 4 时，user-agent 字串更新了版本，格式如下： Mozilla/4.0 (compatible; MSIE Version; Operating System) 在 Windows 98 中 IE 4 的 user-agent 字串的示例： Mozilla/4.0 (compatible; MSIE 4.0; Windows 98) 可以看出，Mozilla 的版本与 IE 实际的版本一致，这样就可以识别第 4 代浏览器了。但遗憾的是，不久 IE 4.5 马上就发布了(只在 Mac 平台)，虽然 Mozilla 版本仍是 4，但是 IE 的版本改成如下： Mozilla/4.0 (compatible; MSIE 4.5; Mac_PowerPC) 此后，IE 的版本一直到 7 都沿用了这个模式。 而 IE 8 的 user-agent 字串添加了呈现引擎（rendering engine）版本： Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0) 新增的呈现引擎非常重要！这样 IE8 以 MSIE 7.0 兼容模式运行时，Trident 版本保持不变，而原先 IE7 的 user-agent 字串不包括 Trident 版本。这样可以区分 IE7 与 IE8 运行的兼容模式。 注意：别指望能从 Mozilla 版本中得到什么靠谱的信息。 Gecko Gecko 是 Firefox 的呈现引擎。Gecko 首次开发是作为 Mozilla 浏览器 Netscape 6 的一部分。Netscape 6 的 user-agent 字串的结构是面向未来的，新版本反应出从 4.x 版本的简单变得较为复杂，它的格式如下： Mozilla/MozillaVersion (Platform; Encryption; OS-or-CPU; Language; PrereleaseVersion)Gecko/GeckoVersion ApplicationProduct/ApplicationProductVersion 为了更好的理解上面的 Gecko user-agent 字串格式，下面来看看各种从基于 Gecko 浏览器中取得的字串。 在 Windows XP 中的 Netscape 6.21： Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:0.9.4) Gecko/20011128 Netscape6/6.2.1 在 Linux 中的 SeaMonkey 1.1a: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.1b2) Gecko/20060823 SeaMonkey/1.1a 在 Windows XP 中的 Firefox 2.0.0.11 : Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11 Mac OS X 中的 Camino 1.5.1: Mozilla/5.0 (Macintosh; U; Intel Mac OS X; en; rv:1.8.1.6) Gecko/20070809 Camino/1.5.1 上面都是基于 Gecko 的浏览器所取得的 user-agent 字串，区别只是版本有所不同。Mozilla 版本 5.0 是自从首款基于 Gecko 发布后就一直不变，而且以后有可能也不会变²。 WebKit 2003 年，Apple 宣布发布首款他们自主开发的 Web 浏览器：Safari。它的呈现引擎叫 WebKit。它是 Linux 中的 Web 浏览器 Konqueror 呈现引擎 KHTML 的一个分支，几年后，WebKit 的开源吸引了呈现引擎的开发人员。 这款新浏览器和呈现引擎的开发人员也遇到了曾经 IE 3.0 类似的问题：怎样才能溶入主流而不被踢出局？答案是：在 user-agent 字串中放详尽的信息，以便骗取网站的信任使它与其它流行的浏览器兼容。user-agent 字串格式如下： Mozilla/5.0 (Platform; Encryption; OS-or-CPU; Language) AppleWebKit/AppleWebKitVersion (KHTML, like Gecko) Safari/SafariVersion 下面是示例： Mozilla/5.0 (Macintosh; U; PPC Mac OS X; en) AppleWebKit/124 (KHTML, like Gecko) Safari/125.1 这又是个挺长的 user-agent 字串，其中包括的信息既有 Apple WebKit 的版本，也有 Safari 的版本。凡是基于 WebKit 的浏览器都将自己伪装成了 Mozilla 5.0，与基于 Gecko 浏览器完全一样。但 Safari 的版本是浏览器的构建版本号（build number）。Safari 1.25 在 user-agent 字串中号为 125.1（如上所示）。Safari 版本 3 的 user-agent 字串包括了实际的 Safari 版本： Mozilla/5.0 (Macintosh; U; PPC Mac OS X; en) AppleWebKit/522.15.5 (KHTML, like Gecko) Version/3.0.3 Safari/522.15.5 其中的“（KHTML, like Gecko）”在 Safari 1.0 预览版本中就有了，这字串部分是最耐人寻味又饱受诟病。Apple 的野心是为了让开发人员把 Safari 当成 Gecko，所以采取了当初微软 IE user-agent 的类似做法：Safari 是兼容 Mozilla 的，否则 Safari 用户会认为用的浏览器不受支持。 而其它基于 WebKit 的浏览器与 Safari 不同的是，没有上面说的这个情况，所以检测断定浏览器是否基于 WebKit 比看有没有明确标 Safari 更有用。 Konqueror Konqueror 是款在 KDE Linux 桌面环境中的浏览器，基于 KHTML 开源呈现引擎。它只发布了在 Linux 的版本，但是拥有活跃的用户群。为了兼容性最大化，user-agent 字串的格式也紧跟 IE 的后尘： Mozilla/5.0 (compatible; Konqueror/Version; OS-or-CPU) Konqueror 3.2 为了与 WebKit user-agent 字串变化保持一致，它将 KHTML 作为它的标识： Mozilla/5.0 (compatible; Konqueror/Version; OS-or-CPU) KHTML/KHTMLVersion (like Gecko) 如下所示： Mozilla/5.0 (compatible; Konqueror/3.5; SunOS) KHTML/3.5.0 (like Gecko) Konqueror 和 KHTML 的版本号比较一致，唯一的区别就是下点处不同，比如Konquerer 3.5、KHTML 3.5.1。 Chrome Google Chrome 浏览器以 WebKit 作为呈现引擎，JavaScript 引擎却用了另一种。最初发布的版本是 0.2，它的 user-agent 字串格式是在 WebKit 信息的基础上又增加了如下： Mozilla/5.0 (Platform; Encryption; OS-or-CPU; Language) AppleWebKit/AppleWebKitVersion (KHTML, like Gecko) Chrome/ChromeVersion Safari/SafariVersion Chrome 0.2 user-agent 信息的示例如下： Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/525.13 (KHTML, like Gecko) Chrome/0.2.149.29 Safari/525.13 虽我不敢完全保证，但很可能 WebKit 版本和 Safari 版本总会保持同步。 Opera Opera 浏览器默认 user-agent 字串是现代浏览器中最合理的——正确的标识了它自己及其版本。 在 Opera 8.0 前，它的 user-agent 字串格式如下： Opera/Version (OS-or-CPU; Encryption) [Language] 在 Windows XP 中 Opera 7.54 user-agent 字串示例： Opera/7.54 (Windows NT 5.1; U) [en] Opera 8 user-agent 字串的语言部分移到了括号内。 Opera/Version (OS-or-CPU; Encryption; Language) 在 Windows XP 中 Opera 8 user-agent 字串示例： Opera/8.0 (Windows NT 5.1; U; en) 当时 Opera 做为主流浏览器之一，它的 user-agent 字串是唯一使用产品名称和版本完全真实的标识了它自己。但是由于大量的浏览器嗅探代码在 Internet 上像蝗虫飞过般只吃标 Mozilla 产品名的 user-agent 字串，造成了 Opera 的 user-agent 字串发生了完全的改变。 Opera 9 user-agent 字串有两种修改的方式：一种方式是将自己标识为 Firefox 或 IE 浏览器。在这种方式下，user-agent 字串与 Firefox 或 IE 的几乎一样，只不过末尾附加了“Opera”及版本号。如下所示： Mozilla/5.0 (Windows NT 5.1; U; en; rv:1.8.1) Gecko/20061208 Firefox/2.0.0 Opera 9.50 Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; en) Opera 9.50 前 一字串将 Opera 9.5 标识为 Firefox 2。后一字串将 Opera 9.5 标识为 IE 6，在两个字串中都带有 Opera 版本信息。虽然这种方式是作为 Firefox 或 IE 打开的，但也能识别出 Opera。另一种方法则是浏览器 user-agent 字串标识伪装成 Firefox 或 IE，同时也找不到“Opera”字串及其版本信息。这样从字面上去区分 Opera 浏览器便成了“不可能完成的任务”。³ 结论 user-agent 字串史可以说明曾对 user-agent 嗅探说不的原因：IE 想要将自己识别为 Netscape 4，Konqueror 和 WebKit 想要识别为 Firefox，Chrome 想要识别为 Safari。这样使得除 Opera 外所有浏览器的 user-agent 嗅探区别很小，想要从一堆茫茫浏览器海洋中找出有用的标识太少了。关于嗅探要记住：一款浏览器与其它浏览器是兼容的，这样造成了不能完全准确的断定是哪款 浏览器。 比如说 Chrome ，它声称任何可以在 Safari 3 访问的网站 Chrome 也都可以访问，但是对检测 Chrome 没有一点用。为了浏览器的兼容——这便是这个声明的理由。 起初前端工程师们就极力反对浏览器检测，他们认为类似 user-agent 嗅探的方法是很不好的，理由是它并不是一种面向未来的代码，无法适应新版的浏览器。更好的做法是使用特性检测，就像这样： if (navigator.userAgent.indexOf(&quot;MSIE 7&quot;) &gt; -1) { //do something } 而更好的做法是这样： if (document.all) { //do something } 这两种方式并不相同。前者是检测浏览器的特殊名称和版本；后者却是检测浏览器的特性。UA 嗅探能够精确得到浏览器的类型和版本（至少能得知浏览器类型），而特性检测却是去确定浏览器是否拥有某个对象或者支持某个方法。注意这两者是完全不同的。 因为特性检测依赖于哪些浏览器支持，当出现新版本浏览器的时候需要繁琐的确认工作。例如 DOM 标准刚出现的时候，并不是所有浏览器都支持 getElementById() 方法，所以一开始代码可能是这样： if (document.getElementById) { //DOM element = document.getElementById(id); } else if (document.all) { //IE element = document.all[id]; } else if (document.layers) { //Netscape &lt; 6 element = document.layers[id]; } 这是特性检测很好的一个例子，亮点在于当其它浏览器开始支持 getElementById() 方法时不必修改代码。 混合方式 后来前端工程师们考虑改进的写法，代码变化成这样： //AVOID!!! if (document.all) { //IE id = document.uniqueID; } else { id = Math.random(); } 这个代码的问题是通过检测 document.all 属性来确定是否是 IE。当确定是 IE 后，假定使用私有的 document.uniqueID 属性也是安全的。然而，目前所作的只是确定是否支持 document.all，并非是去辨识浏览器是否为 IE。仅仅支持 document.all 的话也不意味着 document.uniqueID 是可用的。 后来人们开始这样写，用下面那行代替上面的： var isIE = navigator.userAgent.indexOf(&quot;MSIE&quot;) &gt; -1; //下面这行代替上面那行 var isIE = !!document.all; 这些变化说明大家对“不要使用UA嗅探”存在误解——不再对浏览器的详细信息进行检测，取而代之的是通过特性的支持来推断。这种基于浏览器特性检测的方式非常不好。 后来前端们发现 document.all 并不可靠，更好的检测 IE 变为： var isIE = !!document.all &amp;&amp; document.uniqueID; 这种实现方式陷入歧途。不仅需要费时费事地去识别浏览器所增加的特性支持，另外也不能确定其它浏览器开始支持相同的特性。 如果你认为这样的代码并未被广泛使用，那么看看来自于老版本的Mootools代码片段吧： //from MooTools 1.1.2 if (window.ActiveXObject) window.ie = window[window.XMLHttpRequest ? 'ie7' : 'ie6'] = true; else if (document.childNodes &amp;&amp; !document.all &amp;&amp; !navigator.taintEnabled) window.webkit = window[window.xpath ? 'webkit420' : 'webkit419'] = true; else if (document.getBoxObjectFor != null || window.mozInnerScreenX != null) window.gecko = true; 注意它是如何使用特性检测的。我可以指出它一系列的问题，比如通过检测 window.ie 会将 IE 8 误认为 IE 7。 余波 随着浏览器的快速发展，使用特性检测变得越来越困难和不可靠。但是 Mootools 1.2.4 仍然使用这一方法，例如：getBoxObjectFor()。 //from MooTools 1.2.4 var Browser = $merge({ Engine: { name: 'unknown', version: 0 }, Platform: { name: (window.orientation != undefined) ? 'ipod' : (navigator.platform.match(/mac|win|linux/i) || ['other'])[0].toLowerCase() }, Features: { xpath: !!(document.evaluate), air: !!(window.runtime), query: !!(document.querySelector) }, Plugins: {}, Engines: { presto: function () { return (!window.opera) ? false : ((arguments.callee.caller) ? 960 : ((document.getElementsByClassName) ? 950 : 925)); }, trident: function () { return (!window.ActiveXObject) ? false : ((window.XMLHttpRequest) ? ((document.querySelectorAll) ? 6 : 5) : 4); }, webkit: function () { return (navigator.taintEnabled) ? false : ((Browser.Features.xpath) ? ((Browser.Features.query) ? 525 : 420) : 419); }, gecko: function () { return (!document.getBoxObjectFor &amp;&amp; window.mozInnerScreenX == null) ? false : ((document.getElementsByClassName) ? 19 : 18); } } }, Browser || {}); 应该怎么做？ 特性检测是个应该避免的方法，尽管直接进行特性检测是个很好的方法，并且大部分情况下能满足需求。一般只要在检测前知道这个特性是否被实现即可，而不会去考虑它们之间的关系。 我并非是说永远不使用浏览器特性检测而是基于 UA 嗅探，因为我相信它还是有很多用途的，然而我不相信它有很多合理的用途。如果你考虑 UA 嗅探的话， 请先贯彻这一思想：唯一安全的方式是针对特定浏览器的特定版本，超出范围之外都是不可靠的——例如新出的浏览器版本。其实这样做也是个明智的办法，因为相 较于向前兼容不确定的新版本而言，向后兼容老版本是最简单的做法。 ","link":"https://faded.auspicious.space/post/an-introduction-to-browser-user-agent/"},{"title":"哪些情况下必须使用 301 重定向","content":" 哪些情况下必须使用301重定向 看了一眼百度百科，301 重定向又叫做页面永久性移走，是站长必备的自动转向技术之一。你已经 get 了吗，你知道哪些情况下必须使用 301 重定向吗？ 如果你想为网站更换域名，请千万要记得利用 301 重定向将原本的域名重定向至现在的域名。 如果你想删除网站中的不合理或无意义的目录，请千万要记得利用 301 重定向到网站首页。 如果你想把其他的一些闲置域名共同指向某一个在用的网站，利用 301 重定向就能够轻松实现。 如果你想实现网站 URL 的规范化，比如 www.kangbinle.cn 和不带 www 的域名的规范化，利用 301 重定向就可以完成。 好了，以上四种情况就是必须使用 301 重定向的时候，各位站长可一定要记得呀，不要等网站的流量出现了问题再去后悔。 ","link":"https://faded.auspicious.space/post/when-should-use-301-redirect/"},{"title":"JVM—GC 垃圾回收器总结","content":" JVM—GC垃圾回收器总结 收集算法（标记-清理、复制、标记-整理、分代收集）是内存回收的方法论，垃圾收集器就是内存回收的具体实现。 主要有 7 个 GC 器，如下图。 1 Serial 收集器 1.1 介绍 Serial 收集器是单线程的收集器。 单线程：不仅仅说明它只会使用一个 CPU 或一条收集线程去完成垃圾收集工作，且在垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。 Stop the world：是 VM 在后台自动发起和自动完成的，在用户不可见情况下把用户正常工作的线程全部停掉。 1.2 缺点 由于 Stop The World，给用户带来不良体验，比如，计算机每运行一段时间就会暂停响应几分钟来处理垃圾收集。 1.3 优点 简单而高效（与其他收集器的单线程比）； 对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 1.4 应用场景 VM 运行在 Client 模式下的默认新生代收集器； 在用户的桌面应用场景中，停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，不频繁发生，是可接受的 1.5 Serial / Serial Old 收集器运行示意图 2 ParNew 收集器 2.1 介绍 ParNew 收集器是 Serial 收集器多线程版本（是 GC 线程的多线程，并行）。 并行：Parallel 指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态（多个处理器同时处理多条指令）； 并发：Concurrent 指用户线程与垃圾收集线程同时执行（但并不一定是并行的，可能交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个 CPU 上（同一时刻只能有一条指令执行，多个进程指令是交替执行）。 2.2 缺点 在单 CPU 的环境中绝对不会有比 Serial 收集器更好的效果，甚至存在线程交互的开销。 2.3 优点 除了 Serial 收集器外，只有 ParNew 收集器能与 CMS 收集器配合工作。 CMS（Concurrent Mark Sweep）第一次实现让垃圾收集线程与用户线程（基本上）同时工作。 2.4 应用场景 运行在 Server 模式下的 VM 首选新生代收集器。 2.5 ParNew / Serial Old 收集器运行示意图 2.6 参数控制 使用 -XX:+UseConcMarkSweepGC 选项后默认新生代收集器为 ParNew 收集器； 使用 -XX:+UseParNewGC 选项强制指定使用 ParNew 收集器； 使用 -XX:ParallelGCThreads 参数限制垃圾收集的线程数。 3 Parallel Scavenge 收集器 3.1 介绍 Parallel Scavenge 收集器是一个新生代收集器，使用复制算法的收集器，并行的多线程收集器。更关注吞吐量。 吞吐量：CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即： 如虚拟机总共运行 100 分钟，垃圾收集花费 1 分钟，则吞吐量是 99%；吞吐量高效率利用 CPU 时间，尽快完成程序的运算任务，主要适合后台运算而不需要太多交互的任务。 吞吐量=运行用户代码时间(运行用户代码时间+垃圾收集时间)吞吐量=\\frac{运行用户代码时间}{(运行用户代码时间+垃圾收集时间)} 吞吐量=(运行用户代码时间+垃圾收集时间)运行用户代码时间​ 停顿时间：如 CMS 等收集器关注点尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间越短就越适合需要与用户交互的程序，良好的响应速度可以提升用户体验（适合交互）。 3.2 参数控制 用户精确控制吞吐量 使用 -XX:MaxGCPauseMillis 参数：控制最大垃圾收集停顿时间； 使用 -XX:GCTimeRatio 参数：直接设置吞吐量大小； 使用 -XX:+UseAdaptiveSizePolicy 开关参数：GC 自适应的调节策略； MaxGCPauseMillis 参数允许的值是一个大于 0 的毫秒数，收集器尽可能保证内存回收时间不超过设定值。 GC 停顿时间缩短牺牲吞吐量和新生代空间——若将 MaxGCPauseMillis 该值调小带来的问题：系统把新生代调小一些，收集发生更频繁一些，吞吐量下降。 GCTimeRatio 参数值是一个大于 0 且小于 100 的整数，即垃圾收集时间占总时间的比率，相当于吞吐量的倒数。如设置为 19，则最大 GC 时间占 1/(1+19)=5%，默认值为 99。则最大允许 1/(1+99)=1% 的垃圾收集时间。 UseAdaptiveSizePolicy 开关参数：VM 会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大吞吐量。自适应调节策略是 Parallel Scavenge 收集器与 ParNew 收集器的重要区别。 3.3 应用场景 主要适合后台运算而不需要太多交互的任务。 4 Serial Old 收集器 4.1 介绍 Serial Old 收集器是 Serial 收集器的老年代版本，是一个单线程收集器，使用“标记-整理”算法。 4.2 应用场景 主要给 Client 模式下的 VM 使用； 若在 Server 模式下用，两大用途： 在 JDK1.5 及之前的版本中与 Parallel Scavenge 收集器搭配使用； 作为 CMS 收集器备选，并在 Concurrent Mode Failure 时使用。 4.3 Serial / Serial Old 收集器运行示意图 5 Parallel Old 收集器 5.1 介绍 Parallel Old 是 Parallel Scavenge 收集器的老年代版本，是一个多线程收集器，使用“标记-整理”算法。在 JDK1.6 开始提供。 5.2 应用场景 注重吞吐量以及 CPU 资源敏感的场合，优先考虑 Parallel Scavenge + Parallel Old 收集器。适合吞吐量优先。 5.3 Parallel Scavenge / Parallel Old 收集器运行示意图 6 CMS 收集器 6.1 介绍 CMS 收集器（Concurrent Mark Sweep）是一种以获取最短回收停顿时间为目标的收集器，是基于“标记-清除”算法。 6.2 CMS 的整个过程有 4 个步骤 初始标记——并发标记——重新标记——并发清除 初始标记：CMS initial mark 仅仅是标记一下 GC Roots 能直接关联的对象，速度快；需要 stop the world； 并发标记：CMS concurrent mark 是进行 GC Roots Tracing 的过程； 重新标记：CMS remark 是修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，停顿时间比初始标记长，比并发标记短；需要 stop the world； 并发清除：CMS concurrent sweep，清除算法会在收集结束时产生大量空间碎片，有可能导致没有足够大的连续空间来分配当前对象而触发一次 Full GC。 6.3 缺点 CMS 收集器对 CPU 资源非常敏感； CMS 收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败（备选用 Serial Old）而导致另一次 Full GC 的产生； CMS 是一款基于“标记-清除”算法的收集器，在收集结束后会产生大量空间碎片。 缺点具体分析： 对 CPU 资源敏感：在并发阶段会占用一部分线程而导致应用程序变慢，总吞吐量降低；（解决方法是“增量式并发收集器”，但不提倡使用，i-CMS 收集器是与单 CPU 年代 PC 机操作系统使用抢占式模拟多任务机制的思想，在并发标记、清理的时候让 GC 线程、用户线程交替执行，尽量减少 GC 线程的独占资源的时间）。 无法处理浮动垃圾：CMS 并发清理阶段用户线程还在运行，会产生新的垃圾，这部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理它们，只好留到下一次 GC 时再处理。CMS 需要预留一部分提供并发收集时的程序运行使用，CMS 收集时老年代不能填满再收集。 收集后产生大量空间碎片：“标记-清除”算法的缺点，解决方案是使用 -XX:+UseCMSCompactAtFullCollection 和 -XX:CMSFullGCsBeforeCompaction 参数。 6.4 优点 并发收集；低停顿（并发低停顿收集器）。 6.5 应用场景 在互联网站或者 B/S 系统的服务端上，重视服务的响应速度，希望系统停顿时间最短，给用户带来较好的体验。 6.6 参数控制 使用 -XX:CMSInitiatingOccupancyFraction 参数：提高触发老年代 CMS 垃圾回收的百分比； 使用 -XX:+UseCMSCompactAtFullCollection 开关参数：默认开启，用于 CMS 收集器要进行 Full GC 时开启内存碎片合并整理过程，非并发的过程； 使用 -XX:CMSFullGCsBeforeCompaction 参数：用于设置执行多少次不压缩的 Full GC 后，紧接着一次带压缩的（默认为 0，表示每次进入 Full GC 时就进行碎片整理）。 6.7 CMS 收集器运行时示意图 7 G1 收集器 7.1 介绍 G1（Garbage-First）收集器是一款面向服务端应用的垃圾收集器，为了代替 JDK1.5 中发布的 CMS 收集器。将整个 Java 堆划分为多个大小相等的独立区域。####（Region），保留新生代和老年代概念，但不再是物理隔离，是一部分 Region 的集合（不需要连续）。 7.2 优点 并发与并行、分代收集、空间整合、可预测的停顿。 并发与并行：G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个 CPU 缩短 storp-the-world 停顿时间；G1 可通过并发的方式使得 Java 程序运行； 分代收集：可以独立管理整个 GC 堆，采用不同的方式处理新创建的对象和已经存活一段时间、熬过多次GC 的旧对象以获取更好的收集效果； 空间整合：整体上基于“标记-整理”算法，局部（两个 Region 之间）基于“复制”算法，G1 运行期间不会产生内存空间碎片，收集后能提供规整的可用内存，有利于程序长时间运行，分配大对象时不会因为无法获得连续内存空间而提前触发下一次 GC； 可预测的停顿：相比于 CMS 的另一优势，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。因为可以有计划地避免在整个 Java 堆上进行全区域的垃圾收集。G1 跟踪各个 Region 内垃圾堆积的价值大小（回收所获得的空间大小+回收所需时间的经验值），在后台维护一个优先列表，根据允许的收集时间，回收价值最大的 Region（Garbage-First 的由来）。 7.3 G1 将内存“化整为零”的思路： Region 之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，VM 都是通过 Remember Set 来避免全堆扫描。G1 中每个 Region 中都有一个与之对应的 Remember Set： VM 发现程序对 Reference 类型的数据进行写操作时，会产生一个 Write Barrier 暂时中断写操作； 检查 Reference 引用的对象是否处于不同的 Region 之中；如果是，便通过 CardTable 把相关引用信息记录到被引用对象所属的 Region 的 Remember Set 之中； 当进行内存回收时，在 GC 根节点的枚举范围中加入 Remember Set 即可保证不对全堆扫描； 7.4 G1收集器运作的步骤 初始标记——并发标记——最终标记——筛选回收 初始标记：initial marking，标记一下 GC Roots 能直接关联的对象，并且修改 TAMS(Next Top at Mark Start) 的值，让下一阶段用户程序并发运行时，能在正确可用的 Region 中创建新对象，需要停顿线程，耗时短； 并发标记：concurrent marking，从 GC Root 开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时长，但可与用户程序并发执行； 最终标记：final marking，修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，对象变化记录存在线程 Remember Set Logs 中，然后把这些数据合并到 Remember Set 中，该阶段停顿线程，但是可并行执行； 筛选回收：live data counting and evacuation，对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来指定回收计划。 7.5 G1 收集器运行示意图 8 安全点 8.1 介绍 Safepoint：在 HotSpot 的实现中，使用一组称为 OopMap 的数据结构，在类加载完成的时候，HotSpot 把对象带内什么偏移量上是什么类型的数据都计算出来，在 JIT 编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用，这些特定的位置就是安全点。 程序执行时并非在所有的地方都能停顿下来开始 GC，只有到达安全点时才能暂停。 安全点的选定：标准是“是否具有让程序长时间执行的特征”，不能太少以至于让 GC 等待时间太长，也不能过于频繁以至于过分增大运行时的负荷。 8.2 安全点的停顿 如何在 GC 发生时让所有线程都“跑”到最近的安全点停顿？两种方案：抢先式中断和主动式中断。 抢先式中断 不需要线程的执行代码主动去配合，在 GC 发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上。（现在几乎不用） 主动式中断 当 GC 需要中断线程的时候，不直接对线程操作，仅仅设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。 8.3 安全点的作用 safepoint 保证程序执行时，在不太长的时间内就会遇到可进入的 GC 的 safepoint。 若程序不执行，则没有分配 CPU 时间，如线程处于 Sleep 或 Blocked 状态，无法响应 JVM 的中断请求，此时需要安全区域解决，在一段代码片段中，引用关系不会发生变化，在这个区域中的任意地方开始 GC 都是安全的。 9 垃圾收集器的参数总结 垃圾收集器总结： 9.1 GC 器的参数 参数 解释 -XX:+UseSerialGC JVM 运行在 Client 模式下的默认值，打开此开关后，使用 Serial+Serial Old 的收集器组合进行内存回收 -XX:+UseParNewGC 打开此开关后，使用 ParNew+CMS+Serial Old 的收集器进行垃圾回收 -XX:+UseConcMarkSweepGC 使用 ParNew+CMS+Serial Old 的收集器组合进行垃圾回收，Serial Old 作为 CMS 出现“Concurrent Mode Failure”失败后的后备收集器使用。 -XX:+UseParallelGC JVM 运行在 Server 模式下的默认值，打开此开关后，使用 Parallel Scavenge+Serial Old 的收集器组合进行回收 -XX:+UseParallelOldGC 使用 Parallel Scavenge + Parallel Old 的收集器组合进行回收 -XX:SurvivorRatio 新生代中 Eden 区域与 Survivor 区域的容量比值，默认为8，代表 Eden:Subrvivor = 8.1 -XX:PretenureSizeThreshold 直接晋级到老年代对象的大小，设置这个参数后，大于这个参数的对象将直接在老年代分配 -XX:MaxTenuringThreshold 晋级到老年代的对象年龄，每次 Minor GC 之后，年龄就加 1，当超过这个参数的值时进入老年代 -XX:UerAdaptiveSizePolicy 动态调整 Java 堆中各区域的大小以及进入老年代的年龄 -XX:+HandlePromotionFailure 是否允许新生代手机担保，进行一次 minor gc 后，另一块 Suvivor 空间不足时，将直接会在老年代中保留 -XX:ParallelGCThreads 设置并行 GC 进行内存回收的线程数 -XX:GCTimeRatio GC 时间占总时间的比例，默认值为 99，即允许 1% 的 GC 时间，仅在使用 Parallel Scavenge 收集器时有效 -XX:CMSInitingOccupancyFraction 设置 CMS 收集器在老年代空间被使用多少后触发垃圾收集，默认值为 68%，仅在 CMS 收集器时有效 -XX:+UseCMSCompactAtFullCollection 由于 CMS 收集器会产生碎片，此参数设置在垃圾收集器后是否需要一次内存碎片整理过程，仅在 CMS 收集器时有效 -XX:+CMSFullGCBeforeCompaction 设置 CMS 收集器在进行若干次垃圾收集后进行一次内存碎片整理过程，通常与 UseCMSCompactAtFullCollection 参数一起使用 -XX:+UseFastAccessorMethods 原始类型优化 -XX:+DisableExplicitGC 是否关闭手动 System.gc -XX:+CMSParallelRemarkEnabled 降低标记停顿 -XX:LargePageSizeInBytes 内存页的大小不可设置过大，会影响 Perm 的大小，-XX:LargePageSizeInBytes=128m 9.2 GC 器的使用 新生代 GC 老年代 -XX:+UseSerialGC Serial 串行 GC Serial Old 串行 GC -XX:+UseParallelGC Parallel Scavenge 并行回收 GC Parallel Old 并行 GC -XX:+UseConcMarkSweepGC ParNew 并行 GC CMS 并发 GC，当出现“Concurrent Mode Failure”时采用 Serial Old 串行 GC -XX:+UseParNewGC ParNew 并行 GC Serial Old 串行 GC -XX:+UseParallelOldGC Parallel Scavenge 并行回收 GC Parallel Old 并发 GC -XX:+UseConcMarkSweepGC-XX:+UseParNewGC Serial 串行 GC CMS 并发 GC 当出现“Concurrent Mode Failure”时采用 Serial Old 串行 GC ","link":"https://faded.auspicious.space/post/a-summary-to-jvm-garbage-collector/"},{"title":"六个字符构建 JavasScript 世界","content":" A Javascript journey with only six characters 前言 无用但有趣的冷知识，通过 [ ] ( ) ! + 构建 Javascript 世界，hope you enjoy it！ JavaScript 是一门非常奇怪，同时也非常棒的语言，我们可以用它写出非常疯狂但却奏效的代码，同时，它也能根据我们使用的方式进行类型转换从而辅助开发。 构建假设 如果将字符串（string）和其他类型参数相加，它会猜测我们需要文本格式，最后结果将返回 string 类型。 如果将其他类型参数加上 + 或 - 前缀，它知道我们需要一个数值类型（Number）， 如果类型转换合法，紧接着就会将参数转换成数值类型。 如果将参数取反（!），它会把类型转换成布尔值。 构建法则 下面让我们从最基础的开始，这里有几条黄金法则： 通过 ! 转换为布尔（Boolean）类型； 通过 + 转换为数值（Number）类型； 与 [] 相加转换为字符（String）类型。 通过上面的黄金法则，让我们实践几个例子： ![] === false; +[] === 0; []+[] === &quot;&quot;; 当然，聪明的你肯定知道可以通过中括号加索引的方式从字符串中获取对应位置的字符： &quot;hello&quot;[0] === &quot;h&quot;; 通过多个数值字符相加，再转换为数值类型，即可获得多位数： +(&quot;1&quot; + &quot;1&quot;) === 11 非常棒，通过上面的铺垫，现在我们已经拿到了字母 a ： ![] === false ![]+[] === &quot;false&quot; +!![] === 1 ------------------------ (![]+[])[+!![]] === &quot;a&quot; // same as &quot;false&quot;[1] 如此，通过一些简单的结合，我们还可以从单词 true 和 false 中获取到 a、e、f、l、r、s、t、u，那剩下的字母呢？ 别忘了，我们还可以通过 [][[]] 这种方式获得 undefined，复用上面的方式，我们能拿到字母 d、i、n。 [][[]] + [] === &quot;undefined&quot; 模拟构建 到目前为止，通过我们拿到的字母，已经可以拼出 fill、filter、find 这些单词，当然，你还可以组合成其他的单词，值得一提的是，上面提出三个单词都属于数组方法，这意味可以在数组实例中直接被调用，例如 [2,1].sort()。 语法上，[2,1][&quot;sort&quot;]() 是与 [2,1].sort() 等价的。 让我们继续看看，使用字母拼凑的数组方法还能得到什么，目前我们还不需要执行这些函数： [][&quot;fill&quot;] 上面的代码最终会产生 function fill() { [native code] }，通过黄金法则，我们将结果再次转换为 String 类型： [][&quot;fill&quot;]+[] === &quot;function fill() { [native code] }&quot; 现在，我们又获得了 c、o、v、(、)、{、}、（空格）。 通过新获取的 c 和 o，现在可以组合单词 constructor，constructor 是 JS 对象中返回构造函数的方法，下面就让我们通过 constructor 从已有对象类型中获取对应字符串形式的构造函数： true[&quot;constructor&quot;] + [] === &quot;function Boolean() { [native code] }&quot; 0[&quot;constructor&quot;] + [] === &quot;function Number() { [native code] }&quot; &quot;&quot;[&quot;constructor&quot;] + [] === &quot;function String() { [native code] }&quot; [][&quot;constructor&quot;] + [] === &quot;function Array() { [native code] }&quot; 通过这些构造函数，字母集合中增添了 B、N、S、A、m、g、y 现在可以构建 toString，同样，可以通过中括号使用的函数，不过这次我们要执行它： (10)[&quot;toString&quot;]() === &quot;10&quot; 但前文中我们已经通过第三条黄金法则熟练地将任何类型转换为字符串类型了，toString 的存在看起来有点鸡肋，没用了？ 别忘了，数值类型的 toString 方法还有第二个参数 radix，radix 决定了数值转换为字符串类型前被转换为的进制，举个例子： (12)[&quot;toString&quot;](10) === &quot;12&quot; // base 10 - normal to us (12)[&quot;toString&quot;](2) === &quot;1100&quot; // base 2, or binary, for 12 (12)[&quot;toString&quot;](8) === &quot;14&quot; // base 8 (octonary) for 12 (12)[&quot;toString&quot;](16) === &quot;c&quot; // hex for 12 机智的你肯定想到了，为什么只写到 16 进制？进制最大可以是 36，这可包括了 0-9、a-z 中的所有字母，现在我们可以拿到我们想要的任何字母： (10)[&quot;toString&quot;](36) === &quot;a&quot; (35)[&quot;toString&quot;](36) === &quot;z&quot; 太棒了，我们已经拿到了全部小写字母，但新问题摆在眼前，标点符号和大写字母该怎么办呢？ 根据 JS 执行的位置，它可能有权限访问特定的预定义对象或数据，如果是在浏览器中运行，那么就可以有访问到一些传统的 HTML 包装方法，例如，bold 是一个字符串方法，可以将字符串用 &lt;b&gt; 标签包裹。 &quot;test&quot;[&quot;bold&quot;]() === &quot;&lt;b&gt;test&lt;/b&gt;&quot; 这样，我们就拿到了 &lt;、&gt; 和 /。 函数运行 你可能在项目开发中使用过 escape 函数，它可以将字符串转换为浏览器可以翻译的 URI 友好格式，这个函数在我们接下来的工作中扮演了重要角色，我们需要用到它。通过拼凑字母得到这个单词，但问题是如何使其执行，它是一个全局函数，不属于任何类型。 那么函数的构造函数是什么呢？其实就是函数对象本身，function Function() { [native code] }。 [][&quot;fill&quot;][&quot;constructor&quot;] === Function 通过 Function，我们可以传入字符串来构建一个函数： Function(&quot;alert('test')&quot;); 运行得到： Function anonymous() { alert('test') } 我们只需要在末尾加上 () 就可以立即执行这个函数，如你所见，我们现在可以真正执行代码了！ 小试牛刀，运行 escape 函数： [][&quot;fill&quot;][&quot;constructor&quot;](&quot;return escape(' ')&quot;)() === &quot;%20&quot; 如果我们给 escape 函数传入 &lt;，会得到 %C，如果想获得盛夏的大写字母，这个 C 至关重要。 [][&quot;fill&quot;][&quot;constructor&quot;](&quot;return escape('&lt;')&quot;)()[2] === &quot;C&quot; 通过 C，我们可以得到 fromCharCode 函数，通过给定的十进制参数，可以得到对应的 Unicode 字符，它属于字符对象，因此调用方式可以参照前文： &quot;&quot;[&quot;constructor&quot;][&quot;fromCharCode&quot;](65) === &quot;A&quot; &quot;&quot;[&quot;constructor&quot;][&quot;fromCharCode&quot;](46) === &quot;.&quot; Javascript 世界 通过 Unicode 速查可以快速找到任何字符对应的数值。 到这里，JavaScript 世界的构建元素已经全部找齐！我们已经能拿到我们需要的任何参数，并将它们连接到一起形成代码并执行，这意味，我们仅通过 [、]、(、)、+、! 实现了 JavaScript 的图灵完备。 想证明一下？不妨在浏览器控制台里执行下面的代码： 如果你是在手机上看的，可以告诉你，上面执行的是 alert(&quot;wtf&quot;) jsFuck 可以自动转换你的代码，这里是过程介绍。 你说了这么多，有用吗？ 如果你非要问我有没有用，我只能说点儿用也没，不过 eBay 前段时间出了个 Bug，网站里允许卖家在页面中插入这些字符构成的 JS 代码，但这种攻击媒介不是很常见。有人说可以用来进行代码混淆，实际上，有更好的混淆方式。 ","link":"https://faded.auspicious.space/post/a-javascript-journey-with-only-six-characters/"},{"title":"WebSocket 协议：5 分钟从入门到精通","content":" WebSocket协议：5分钟从入门到精通 1 内容概览 WebSocket 的出现，使得浏览器具备了实时双向通信的能力。本文由浅入深，介绍了 WebSocket 如何建立连接、交换数据的细节，以及数据帧的格式。此外，还简要介绍了针对 WebSocket 的安全攻击，以及协议是如何抵御类似攻击的。 2 什么是WebSocket HTML5 开始提供的一种浏览器与服务器进行全双工通讯的网络技术，属于应用层协议。它基于 TCP 传输协议，并复用 HTTP 的握手通道。 对大部分 Web 开发者来说，上面这段描述有点枯燥，其实只要记住几点： WebSocket 可以在浏览器里使用； 支持双向通信； 使用很简单。 2.1 有哪些优点 说到优点，这里的对比参照物是 HTTP 协议，概括地说就是：支持双向通信，更灵活，更高效，可扩展性更好。 支持双向通信，实时性更强。 更好的二进制支持。 较少的控制开销。连接创建后，ws 客户端、服务端进行数据交换时，协议控制的数据包头部较小。在不包含头部的情况下，服务端到客户端的包头只有 2~10字节（取决于数据包长度），客户端到服务端的的话，需要加上额外的 4 字节的掩码。而 HTTP 协议每次通信都需要携带完整的头部。 支持扩展。ws 协议定义了扩展，用户可以扩展协议，或者实现自定义的子协议。（比如支持自定义压缩算法等） 对于后面两点，没有研究过 WebSocket 协议规范的同学可能理解起来不够直观，但不影响对 WebSocket 的学习和使用。 2.2 需要学习哪些东西 对网络应用层协议的学习来说，最重要的往往就是连接建立过程、数据交换教程。当然，数据的格式是逃不掉的，因为它直接决定了协议本身的能力。好的数据格式能让协议更高效、扩展性更好。 下文主要围绕下面几点展开： 如何建立连接； 如何交换数据； 数据帧格式； 如何维持连接。 3 入门例子 在正式介绍协议细节前，先来看一个简单的例子，有个直观感受。例子包括了WebSocket服务端、WebSocket客户端（网页端）。完整代码可以在 这里 找到。 这里服务端用了 ws 这个库。相比大家熟悉的 socket.io，ws 实现更轻量，更适合学习的目的。 3.1 服务端 代码如下，监听 8080 端口。当有新的连接请求到达时，打印日志，同时向客户端发送消息。当收到到来自客户端的消息时，同样打印日志。 var app = require('express')(); var server = require('http').Server(app); var WebSocket = require('ws'); var wss = new WebSocket.Server({ port: 8080 }); wss.on('connection', function connection(ws) { console.log('server: receive connection.'); ws.on('message', function incoming(message) { console.log('server: received: %s', message); }); ws.send('world'); }); app.get('/', function (req, res) { res.sendfile(__dirname + '/index.html'); }); app.listen(3000); 3.2 客户端 代码如下，向 8080 端口发起 WebSocket 连接。连接建立后，打印日志，同时向服务端发送消息。接收到来自服务端的消息后，同样打印日志。 &lt;script&gt; var ws = new WebSocket('ws://localhost:8080'); ws.onopen = function () { console.log('ws onopen'); ws.send('from client: hello'); }; ws.onmessage = function (e) { console.log('ws onmessage'); console.log('from server: ' + e.data); }; &lt;/script&gt; 3.3 运行结果 可分别查看服务端、客户端的日志，这里不展开。 服务端输出： server: receive connection. server: received hello 客户端输出： client: ws connection is open client: received world 4 如何建立连接 前面提到，WebSocket 复用了 HTTP 的握手通道。具体指的是，客户端通过 HTTP 请求与 WebSocket 服务端协商升级协议。协议升级完成后，后续的数据交换则遵照 WebSocket 的协议。 4.1 客户端：申请协议升级 首先，客户端发起协议升级请求。可以看到，采用的是标准的 HTTP 报文格式，且只支持 GET 方法。 GET / HTTP/1.1 Host: localhost:8080 Origin: http://127.0.0.1:3000 Connection: Upgrade Upgrade: websocket Sec-WebSocket-Version: 13 Sec-WebSocket-Key: w4v7O6xFTi36lq3RNcgctw== 重点请求首部意义如下： Connection: Upgrade：表示要升级协议 Upgrade: websocket：表示要升级到 websocket 协议。 Sec-WebSocket-Version: 13：表示 websocket 的版本。如果服务端不支持该版本，需要返回一个 Sec-WebSocket-Versionheader，里面包含服务端支持的版本号。 Sec-WebSocket-Key：与后面服务端响应首部的 Sec-WebSocket-Accept 是配套的，提供基本的防护，比如恶意的连接，或者无意的连接。 注意，上面请求省略了部分非重点请求首部。由于是标准的 HTTP请求 ，类似 Host、Origin、Cookie 等请求首部会照常发送。在握手阶段，可以通过相关请求首部进行 安全限制、权限校验等。 4.2 服务端：响应协议升级 服务端返回内容如下，状态代码 101 表示协议切换。到此完成协议升级，后续的数据交互都按照新的协议来。 HTTP/1.1 101 Switching Protocols Connection:Upgrade Upgrade: websocket Sec-WebSocket-Accept: Oy4NRAQ13jhfONC7bP8dTKb4PTU= 备注：每个 header 都以 \\r\\n 结尾，并且最后一行加上一个额外的空行 \\r\\n。此外，服务端回应的 HTTP 状态码只能在握手阶段使用。过了握手阶段后，就只能采用特定的错误码。 4.3 Sec-WebSocket-Accept 的计算 Sec-WebSocket-Accept 根据客户端请求首部的 Sec-WebSocket-Key 计算出来。 计算公式为： 将 Sec-WebSocket-Key 跟 258EAFA5-E914-47DA-95CA-C5AB0DC85B11 拼接。 通过 SHA1 计算出摘要，并转成 base64 字符串。 伪代码如下： $ toBase64( sha1( Sec-WebSocket-Key + 258EAFA5-E914-47DA-95CA-C5AB0DC85B11 ) ) 验证下前面的返回结果： const crypto = require('crypto'); const magic = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11'; const secWebSocketKey = 'w4v7O6xFTi36lq3RNcgctw=='; let secWebSocketAccept = crypto.createHash('sha1') .update(secWebSocketKey + magic) .digest('base64'); console.log(secWebSocketAccept); // Oy4NRAQ13jhfONC7bP8dTKb4PTU= 5 数据帧格式 客户端、服务端数据的交换，离不开数据帧格式的定义。因此，在实际讲解数据交换之前，我们先来看下 WebSocket 的数据帧格式。 WebSocket 客户端、服务端通信的最小单位是帧（frame），由 1 个或多个帧组成一条完整的消息（message）。 发送端：将消息切割成多个帧，并发送给服务端； 接收端：接收消息帧，并将关联的帧重新组装成完整的消息； 本节的重点，就是讲解数据帧的格式。详细定义可参考 RFC6455 5.2 节 。 5.1 数据帧格式概览 下面给出了 WebSocket 数据帧的统一格式。熟悉 TCP/IP 协议的同学对这样的图应该不陌生。 从左到右，单位是比特。比如 FIN、RSV1 各占据 1 比特，opcode 占据 4 比特。 内容包括了标识、操作代码、掩码、数据、数据长度等。（下一小节会展开） 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued, if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key, if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued ... : + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | Payload Data continued ... | +---------------------------------------------------------------+ 5.2 数据帧格式详解 针对前面的格式概览图，这里逐个字段进行讲解，如有不清楚之处，可参考协议规范，或留言交流。 FIN 1 个比特。如果是 1，表示这是消息（message）的最后一个分片（fragment），如果是 0，表示不是是消息（message）的最后一个分片（fragment）。 RSV1, RSV2, RSV3 各占 1 个比特。一般情况下全为 0。当客户端、服务端协商采用 WebSocket 扩展时，这三个标志位可以非 0，且值的含义由扩展进行定义。如果出现非零的值，且并没有采用 WebSocket 扩展，连接出错。 Opcode 4个比特。操作代码，Opcode 的值决定了应该如何解析后续的数据载荷（data payload）。如果操作代码是不认识的，那么接收端应该断开连接（fail the connection）。可选的操作代码如下： %x0：表示一个延续帧。当 Opcode 为 0 时，表示本次数据传输采用了数据分片，当前收到的数据帧为其中一个数据分片。 %x1：表示这是一个文本帧（frame）。 %x2：表示这是一个二进制帧（frame）。 %x3-7：保留的操作代码，用于后续定义的非控制帧。 %x8：表示连接断开。 %x9：表示这是一个ping操作。 %xA：表示这是一个pong操作。 %xB-F：保留的操作代码，用于后续定义的控制帧。 Mask 1 个比特。表示是否要对数据载荷进行掩码操作。从客户端向服务端发送数据时，需要对数据进行掩码操作；从服务端向客户端发送数据时，不需要对数据进行掩码操作。 如果服务端接收到的数据没有进行过掩码操作，服务端需要断开连接。 如果 Mask 是 1，那么在 Masking-key 中会定义一个掩码键（masking key），并用这个掩码键来对数据载荷进行反掩码。所有客户端发送到服务端的数据帧，Mask 都是 1。 掩码的算法、用途在下一小节讲解。 Payload length 数据载荷的长度，单位是字节。为 7 位，或 7+16 位，或 1+64 位。 假设数 Payload length === x，如果 x 为 0~126：数据的长度为 x 字节。 x 为 126：后续 2 个字节代表一个 16 位的无符号整数，该无符号整数的值为数据的长度。 x 为 127：后续 8 个字节代表一个 64 位的无符号整数（最高位为 0），该无符号整数的值为数据的长度。 此外，如果 payload length 占用了多个字节的话，payload length 的二进制表达采用网络序（big endian，重要的位在前）。 Masking-key 0 或 4字节（32位）。所有从客户端传送到服务端的数据帧，数据载荷都进行了掩码操作，Mask 为 1，且携带了 4 字节的 Masking-key。如果 Mask 为 0，则没有 Masking-key。 备注：载荷数据的长度，不包括 mask key 的长度。 Payload data (x+y) 字节。载荷数据：包括了扩展数据、应用数据。其中，扩展数据 x 字节，应用数据 y 字节。 扩展数据：如果没有协商使用扩展的话，扩展数据数据为 0 字节。所有的扩展都必须声明扩展数据的长度，或者可以如何计算出扩展数据的长度。此外，扩展如何使用必须在握手阶段就协商好。如果扩展数据存在，那么载荷数据长度必须将扩展数据的长度包含在内。 应用数据：任意的应用数据，在扩展数据之后（如果存在扩展数据），占据了数据帧剩余的位置。载荷数据长度 减去 扩展数据长度，就得到应用数据的长度。 5.3 掩码算法 掩码键（Masking-key）是由客户端挑选出来的 32 位的随机数。掩码操作不会影响数据载荷的长度。掩码、反掩码操作都采用如下算法： 首先，假设： original-octet-i：为原始数据的第i字节。 transformed-octet-i：为转换后的数据的第i字节。 j：为 i mod 4 的结果。 masking-key-octet-j：为 mask key 第 j 字节。 算法描述为：original-octet-i 与 masking-key-octet-j 异或后，得到 transformed-octet-i。 j = i MOD 4 transformed-octet-i = original-octet-i XOR masking-key-octet-j 6 数据传递 一旦 WebSocket 客户端、服务端建立连接后，后续的操作都是基于数据帧的传递。 WebSocket 根据 opcode 来区分操作的类型。比如 0x8 表示断开连接，0x0-0x2 表示数据交互。 6.1 数据分片 WebSocket 的每条消息可能被切分成多个数据帧。当 WebSocket 的接收方收到一个数据帧时，会根据 FIN 的值来判断，是否已经收到消息的最后一个数据帧。 FIN=1 表示当前数据帧为消息的最后一个数据帧，此时接收方已经收到完整的消息，可以对消息进行处理。FIN=0，则接收方还需要继续监听接收其余的数据帧。 此外，opcode 在数据交换的场景下，表示的是数据的类型。0x01 表示文本，0x02 表示二进制。而 0x00 比较特殊，表示延续帧（continuation frame），顾名思义，就是完整消息对应的数据帧还没接收完。 6.2 数据分片例子 直接看例子更形象些。下面例子来自 MDN，可以很好地演示数据的分片。客户端向服务端两次发送消息，服务端收到消息后回应客户端，这里主要看客户端往服务端发送的消息。 第一条消息 FIN=1, 表示是当前消息的最后一个数据帧。服务端收到当前数据帧后，可以处理消息。opcode=0x1，表示客户端发送的是文本类型。 第二条消息 FIN=0，opcode=0x1，表示发送的是文本类型，且消息还没发送完成，还有后续的数据帧。 FIN=0，opcode=0x0，表示消息还没发送完成，还有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。 FIN=1，opcode=0x0，表示消息已经发送完成，没有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。服务端可以将关联的数据帧组装成完整的消息。 Client: FIN=1, opcode=0x1, msg=&quot;hello&quot; Server: (process complete message immediately) Hi. Client: FIN=0, opcode=0x1, msg=&quot;and a&quot; Server: (listening, new message containing text started) Client: FIN=0, opcode=0x0, msg=&quot;happy new&quot; Server: (listening, payload concatenated to previous message) Client: FIN=1, opcode=0x0, msg=&quot;year!&quot; Server: (process complete message) Happy new year to you too! 7 连接保持+心跳 WebSocket 为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的 TCP 通道保持连接没有断开。然而，对于长时间没有数据往来的连接，如果依旧长时间保持着，可能会浪费包括的连接资源。 但不排除有些场景，客户端、服务端虽然长时间没有数据往来，但仍需要保持连接。这个时候，可以采用心跳来实现。 发送方-&gt;接收方：ping 接收方-&gt;发送方：pong ping、pong 的操作，对应的是 WebSocket 的两个控制帧，opcode 分别是 0x9、0xA。 举例，WebSocket 服务端向客户端发送 ping，只需要如下代码（采用 ws 模块） ws.ping('', false, true); 8 Sec-WebSocket-Key/Accept 前面提到了，Sec-WebSocket-Key/Sec-WebSocket-Accept 在主要作用在于提供基础的防护，减少恶意连接、意外连接。 作用大致归纳如下： 避免服务端收到非法的 websocket 连接（比如 http 客户端不小心请求连接 websocket 服务，此时服务端可以直接拒绝连接）； 确保服务端理解 websocket 连接。因为 ws 握手阶段采用的是 http 协议，因此可能 ws 连接是被一个 http 服务器处理并返回的，此时客户端可以通过 Sec-WebSocket-Key 来确保服务端认识 ws 协议。（并非百分百保险，比如总是存在那么些无聊的 http 服务器，光处理 Sec-WebSocket-Key，但并没有实现 ws 协议。。。）； 用浏览器里发起 AJAX 请求，设置 header 时，Sec-WebSocket-Key 以及其他相关的 header 是被禁止的。这样可以避免客户端发送 AJAX 请求时，意外请求协议升级（websocket upgrade）； 可以防止反向代理（不理解 ws 协议）返回错误的数据。比如反向代理前后收到两次 ws 连接的升级请求，反向代理把第一次请求的返回给 cache 住，然后第二次请求到来时直接把 cache 住的请求给返回（无意义的返回）。 Sec-WebSocket-Key 主要目的并不是确保数据的安全性，因为 Sec-WebSocket-Key、Sec-WebSocket-Accept 的转换计算公式是公开的，而且非常简单，最主要的作用是预防一些常见的意外情况（非故意的）。 |强调：Sec-WebSocket-Key/Sec-WebSocket-Accept 的换算，只能带来基本的保障，但连接是否安全、数据是否安全、客户端/服务端是否合法的 ws 客户端、ws 服务端，其实并没有实际性的保证。| |-| 9 数据掩码的作用 WebSocket 协议中，数据掩码的作用是增强协议的安全性。但数据掩码并不是为了保护数据本身，因为算法本身是公开的，运算也不复杂。除了加密通道本身，似乎没有太多有效的保护通信安全的办法。 那么为什么还要引入掩码计算呢，除了增加计算机器的运算量外似乎并没有太多的收益（这也是不少同学疑惑的点）。 答案还是两个字：安全。但并不是为了防止数据泄密，而是为了防止早期版本的协议中存在的代理缓存污染攻击（proxy cache poisoning attacks）等问题。 代理缓存污染攻击 下面摘自 2010 年关于安全的一段讲话。其中提到了代理服务器在协议实现上的缺陷可能导致的安全问题。猛击出处。 “We show, empirically, that the current version of the WebSocket consent mechanism is vulnerable to proxy cache poisoning attacks. Even though the WebSocket handshake is based on HTTP, which should be understood by most network intermediaries, the handshake uses the esoteric “Upgrade” mechanism of HTTP [5]. In our experiment, we find that many proxies do not implement the Upgrade mechanism properly, which causes the handshake to succeed even though subsequent traffic over the socket will be misinterpreted by the proxy.” [TALKING] Huang, L-S., Chen, E., Barth, A., Rescorla, E., and C. Jackson, &quot;Talking to Yourself for Fun and Profit&quot;, 2010, 在正式描述攻击步骤之前，我们假设有如下参与者： 攻击者、攻击者自己控制的服务器（简称“邪恶服务器”）、攻击者伪造的资源（简称“邪恶资源”）； 受害者、受害者想要访问的资源（简称“正义资源”）； 受害者实际想要访问的服务器（简称“正义服务器”）； 中间代理服务器。 攻击步骤一 攻击者 浏览器 向 邪恶服务器 发起 WebSocket 连接。根据前文，首先是一个协议升级请求。 协议升级请求 实际到达 代理服务器。 代理服务器 将协议升级请求转发到 邪恶服务器。 邪恶服务器 同意连接，代理服务器 将响应转发给 攻击者。 由于 upgrade 的实现上有缺陷，代理服务器 以为之前转发的是普通的 HTTP 消息。因此，当 协议服务器 同意连接，代理服务器 以为本次会话已经结束。 攻击步骤二 攻击者 在之前建立的连接上，通过 WebSocket 的接口向 邪恶服务器 发送数据，且数据是精心构造的HTTP格式的文本。其中包含了 正义资源 的地址，以及一个伪造的 host（指向 正义服务器）。（见后面报文） 请求到达 代理服务器 。虽然复用了之前的TCP连接，但 代理服务器 以为是新的HTTP请求。 代理服务器 向 邪恶服务器 请求 邪恶资源。 邪恶服务器 返回 邪恶资源。代理服务器 缓存住 邪恶资源（url 是对的，但 host 是 正义服务器 的地址）。 受害者 到这里，受害者可以登场了： 受害者 通过 代理服务器 访问 正义服务器 的 正义资源。 代理服务器 检查该资源的 url、host，发现本地有一份缓存（伪造的）。 代理服务器 将 邪恶资源 返回给 受害者。 受害者 卒。 附：前面提到的精心构造的“HTTP 请求报文”。 Client → Server: POST /path/of/attackers/choice HTTP/1.1 Host: host-of-attackers-choice.com Sec-WebSocket-Key: &lt;connection-key&gt; Server → Client: HTTP/1.1 200 OK Sec-WebSocket-Accept: &lt;connection-key&gt; 当前解决方案 最初的提案是对数据进行加密处理。基于安全、效率的考虑，最终采用了折中的方案：对数据载荷进行掩码处理。 需要注意的是，这里只是限制了浏览器对数据载荷进行掩码处理，但是坏人完全可以实现自己的 WebSocket 客户端、服务端，不按规则来，攻击可以照常进行。 但是对浏览器加上这个限制后，可以大大增加攻击的难度，以及攻击的影响范围。如果没有这个限制，只需要在网上放个钓鱼网站骗人去访问，一下子就可以在短时间内展开大范围的攻击。 10 写在后面 WebSocket 可写的东西还挺多，比如 WebSocket 扩展。客户端、服务端之间是如何协商、使用扩展的。WebSocket 扩展可以给协议本身增加很多能力和想象空间，比如数据的压缩、加密，以及多路复用等。 篇幅所限，这里先不展开，感兴趣的同学可以留言交流。文章如有错漏，敬请指出。 11 相关链接 RFC6455：websocket规范 - https://tools.ietf.org/html/rfc6455 规范：数据帧掩码细节 - https://tools.ietf.org/html/rfc6455#section-5.3 规范：数据帧格式 - https://tools.ietf.org/html/rfc6455#section-5.1 server-example - https://github.com/websockets/ws#server-example 编写websocket服务器 - https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_servers 对网络基础设施的攻击（数据掩码操作所要预防的事情）- https://tools.ietf.org/html/rfc6455#section-10.3 Talking to Yourself for Fun and Profit（含有攻击描述） - http://w2spconf.com/2011/papers/websocket.pdf What is Sec-WebSocket-Key for? - https://stackoverflow.com/questions/18265128/what-is-sec-websocket-key-for 10.3. Attacks On Infrastructure (Masking) - https://tools.ietf.org/html/rfc6455#section-10.3 Talking to Yourself for Fun and Profit - http://w2spconf.com/2011/papers/websocket.pdf Why are WebSockets masked? - https://stackoverflow.com/questions/33250207/why-are-websockets-masked How does websocket frame masking protect against cache poisoning? - https://security.stackexchange.com/questions/36930/how-does-websocket-frame-masking-protect-against-cache-poisoning What is the mask in a WebSocket frame? - https://stackoverflow.com/questions/14174184/what-is-the-mask-in-a-websocket-frame ","link":"https://faded.auspicious.space/post/websocket-deep-in/"},{"title":"英特尔至强处理器技术简介","content":" 英特尔至强处理器技术简介 1 至强处理器介绍 至强（Xeon）是英特尔针对服务器和工作站市场的处理器品牌，但也有某些超级计算机采用此处理器。Xeon 采用 x86 架构和（或）x86-64 架构，和采用 IA-64 架构的 Itanium 不同。 至强处理器与常规桌面级 CPU 相采用同一套微结构（微内核），但更关注于核心数量而非时钟频率，并增加了针对服务器和工作站的高级功能，例如 ECC 内存，更多的内核数量，更大的 RAM 和高速缓存，提供企业级的可靠性，可用性和可维护性的 Machine Check Architecture (MCA) 异常处理机制等。此外，某些型号还支持 QPI（快速通道互联）和 UPI（超级通道互联）总线，从而将多个 CPU 连接在一起，从而提供 2 路、4 路、8 路等多路处理能力。 至强（Xeon）处理器目前主要有 6 个系列： 1.1 E3 系列 针对入门级工作站、移动工作站、小型企业服务器等应用的单路处理器，通常为 2/4/8 核，提供必要的性能和视觉功能，处理器架构每年跟随消费级处理器同步更新； 1.2 E5 系列 针对高端工作站的双路 / 四路处理器，最高 22 核，支持 4 通道内存技术和 QPI (快速通道互联)，提供大幅增强的性能和功能，专为下一代数据中心的架构而设计，每年更新，处理器架构落后 E3 一代； 1.3 E7 系列 面向数据要求苛刻的关键任务和数据中心的双路 / 四路 / 八路处理器，最高 24 核，支持 4 通道内存技术和 QPI (快速通道互联)，提供实时分析、任务关键型业务处理以及大数据洞察能力，强调可靠性、可用性和可服务性（RAS）； 1.4 可扩展处理器系列 分为铜牌、银牌、金牌、铂金 4 个等级，分别对应于 E5 和 E7 的不同产品定位，最高 28 核，支持 4 通道内存技术和 UPI（超级通道互联）； 1.5 D 系列 用于空间和功率受限环境的片上系统 (SoC)，最高 16 核，将可扩展平台架构创新引入到片上系统（SoC）处理器，以支持低功耗、高密度解决方案，且集成了基本网络以及安全和加速功能； 1.6 W 系列 针对主流工作站，最高 28 核，基于可扩展平台架构，提供硬件增强的工作负载性能、安全性和可靠性。 此外，至强还包含至强融核系列处理器，目前最新的 Xeon PHI 处理器基于英特尔®集成众核架构（MIC 架构），能为要求最苛刻的高性能计算应用程序提供大规模并行处理和矢量化服务，最高支持 72 核，36M L2 Cache。 2 至强处理器核心技术介绍 2.1 多路互联技术 多路互联技术用于在单块主板上安装多块互相连接的处理器，主要包括: 2.1.1 Intel 的 QPI（快速通道互联）/ UPI（超级通道互联）技术 由英特尔开发并使用的用于替代 FSB（前端总线）并与 AMD 的 HT（HyperTransport）技术竞争的点对点处理器互联架构，最高速度 9.6 GT/s（38.4 GB/s）；2017 年，英特尔通过 SkyLake 微架构发布了基于 QPI 的 UPI（超级通道互联）技术，采用共享地地址空间技术和基于目录的一致性 snoop 协议，通过新的封包格式提高传输效率，最高速度可达 10.4 GT/s（41.6 GB/s），支持低功耗模式，并且不再要求资源预分配； 2.1.2 HT 联盟的 HT（HyperTransport）技术 曾被称作“闪电数据传输”（Lightning Data Transport，LDT），是一种高速、双向、低延时、点对点（P2P）、串行或者并行的高带宽连接总线技术，1999 年由 AMD 提出并发起成立 HyperTransport 开放联盟，于 2001 年 4 月 2 日开始投入使用，广泛用于 AMD、IBM、苹果、Nvidia、MIPS、龙芯、思科、Broadcom 等厂商的处理器上，目前有 1.x，2.0，3.0 和 3.1 等版本，最高速度 51.2 GB/s，支持电源管理； 2.1.3 Nvidia 的 NVLink 技术 NVIDIA 开发并推出的一种串行点对点总线和通信协议，主要使用在 Nvidia GPU 和 IBM Power 处理器上，最高速率为单通道 25 GT/s（25 GB/s），在 IBM Power 9 的 6 通道模式下可达 300 GB/s。 2.2 众核处理器 众核（Manycore）处理器是专为高度并行处理而设计的专用多核处理器，不追求流水线深度、超线程等计数来提高单核性能，而是包含大量简单独立的处理器内核，因此具有更高的吞吐量或更低的功耗，但是具有更高的延迟和较低的单线程性能。 Cache 一致性是限制多核处理器扩展的难点。众核处理器通过消息传递，暂存式内存，DMA，分区化的全局地址空间（Partitioned global address space，PGAS），只读 / 非一致性高速缓存等技巧绕过这个难点。GPU 实际上可以认为是具有多个着色器处理单元的众核处理器。 2.3 多通道内存技术 多通道内存技术是一种可以提升内存数据发送性能的技术，通过在 DRAM 和内存控制器 / 芯片组之间，增加更多的并行通信通道以增加数据发送的带宽。理论上每增加一条通道，数据发送性能相较于单通道而言会增加一倍。通常情况下，多通道对内存的规格和插槽都有要求，只要满足要求才能使能多通道模式。 目前常见的多通道技术多为双通道的设置，例如两组 64-bit DDR 提供 128 位的 DDR 通道。支持四通道技术的处理器包括 Intel / AMD 的高端处理器、包含 ARM CoreLink CCI-500 技术的 Cortex-A72 等处理器，以及高通和三星的高端处理器等。支持八通道技术的有 AMD EPYC、Cavium ThunderX2 等服务器处理器。此外，英特尔 2012 年展示的 Haswell-EX 架构也支持八通道 DDR4。 2.4 多线程技术 多线程技术包括同时多线程（SMT）和时间多线程： 2.4.1 同时多线程 同时多线程（Simultaneous multithreading，SMT）：也称同步多线程，即在一个时钟周期中发出多个线程的多个指令。支持 SMT 计数的处理器包括 IBM Power、MIPS、SUN / Oracle / 富士通Sparc、AMD Bulldozer / Zen微架构等处理器；超线程（HT, Hyper-Threading）是英特尔专有的同步多线程（SMT）实现，通过在 CPU 内部仅复制必要的资源让两个线程可同时运行，从而在同一周期内处理两个线程的工作，模拟实体双核心、双线程运作。 2.4.2 时间多线程 时间多线程（Temporal multithreading）也称交叉多线程，即在一个时钟周期中发出一个指令，交错发出不同线程的多个指令。时间多线程目前仅在 CDC 6000（1960s）、Tera MTA（1988）、XMOS XCore XS1（2007）等 Barrel（桶）处理器上出现。 2.5 MCA 异常处理机制 Intel 服务器处理器提供的硬件错误检测和报告机制，包括系统总线错误，ECC 错误，奇偶校验错误，Cache 错误、TLB 错误等，包括一组用于设置 MCA（Machine Check Architecture） 的 MSR 寄存器和记录硬件错误的附加 MSR 寄存器。 2.6 ECC 内存 在 ECC 技术出现之前，内存中应用最多的另外一种错误检查技术，是奇偶校验位（Parity）技术，仅能发现错误而不能纠正错误。 ECC 内存够实现错误检查和自动纠正技术的内存，可以自动检测和纠正最常见的内部数据损坏，使系统得以正常的操作，不致因错误而中断。通常情况下，ECC 内存保持一个内存系统不受单一位错误的影响，即使用 5 位 ECC 码纠正 8 位数据中的 1 位错误。数据位每增加一倍，ECC 只增加 1 位检验位，即数据位为 16 位时 ECC 位为 6 位，32 位时 ECC 位为 7 位，数据位为 64 位时 ECC 位为 8 位，依此类推。 2.7 向量处理技术 向量处理技术能够直接操作一维数组（向量），与一次只能处理一个数据的标量处理正好相反。向量处理技术可以在特定工作环境中极大地提升性能，尤其是在数值模拟或者相似领域。向量处理技术最早出现于 20 世纪 70 年代早期，并在 70 年代到 90 年代期间成为超级计算机设计的主导方向。由于常规处理器设计性价比的快速下降，基于向量处理的超级计算机在 90 年代末逐渐让出了主导地位。现在，绝大多数商业化 CPU 实现都能够提供某种形式的向量处理指令，用来处理多个向量化的数据集，也就是所谓的 SIMD（单一指令多重数据）。此外，还有多重指令处理多重向量化数据集的 MIMD（多重指令多重数据）技术。 ","link":"https://faded.auspicious.space/post/a-brief-introduction-to-intel-xeon-processor /"},{"title":"TCP 请求头","content":" TCP 请求头 TCP 请求头结构： Source Port：源端口号 （占用 16 位），发送端程序端口。 Destination Port：目的端口号（占用 16 位），接收端程序端口。 Sequence Number：发送数据序号，用来标识从 TCP 发端向 TCP 收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节在数据流中的序号；主要用来解决网络报乱序的问题；（占用 32 位）。 Acknowledgment Number：ACK 确认号，32 位确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加 1。不过，只有当标志位中的 ACK 标志（下面介绍）为 1 时该确认序列号的字段才有效。主要用来解决不丢包的问题； 例如：传输一个文件，文件比较大的 TCP 会把该文件拆成多段进行发送， 假如每段1000个字节，第一次的时候 Sequence Number 会随机一个 int 数值，假如为1。 第一次发送 Sequence Number=1， 第一次响应 Acknowledgment Number = 1001 第二次发送 Sequence Number=1001 第二次响应 Acknowledgment Number = 2001 ... ... Data Offset： 数据偏移量（4 位）给出首部中 32 bit 字的数目，需要这个值是因为任选字段的长度是可变的。这个字段占 4 bit（最多能表示 15 个 32 bit 的的字，即 4*15 = 60 个字节的首部长度），因此 TCP 最多有 60 字节的首部。然而，没有任选字段，正常的长度是 20 字节； 如果有额外的 TCP 的 option 选项，还得加上 option 的长度。 Reserved：保留字段，目前还没有使用。 TCP Flags：TCP 控制位（6 位），每一位代表一个控制位，它们中的多个可同时被设置为 1，主要是用于操控 TCP 的状态机的，依次为 URG，ACK，PSH，RST，SYN，FIN。每个标志位的意思如下： URG：此标志表示 TCP 包的紧急指针域（后面马上就要说到）有效，用来保证 TCP 连接不被中断，并且督促中间层设备要尽快处理这些数据； ACK：此标志表示应答域有效，就是说前面所说的 TCP 应答号将会包含在 TCP 数据包中；有两个取值：0 和 1，为 1 的时候表示应答域有效，反之为 0； PSH：这个标志位表示 Push 操作。所谓 Push 操作就是指在数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队； RST：这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包； SYN：表示同步序号，用来建立连接。SYN 标志位和 ACK 标志位搭配使用，当连接请求的时候，SYN = 1，ACK = 0；连接被响应的时候，SYN = 1，ACK = 1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有 SYN 的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行 TCP 三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行 TCP 的三次握手； FIN： 表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送 FIN 标志位的 TCP 数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描。 Window：窗口大小（16 位），表示接收端可用缓冲区大小，根据缓冲区大小和每次包大小，就可以计算出同时处理的 TCP 包的个数。同时处理的包个数越多，则网速越快。 Checksum：校验和，用来检查 TCP 包是否完整（16 位）。 Urgent Pointer：紧急指针，表示应紧急处理的数据位置（16 位）。路由器可以把紧急的数据包优先处理。 Options：可选字段，可变长度，最长为 40 字节。（因为 Data Offset 最多能表示 60 个字节长度的 TCP 头信息，固定的 TCP 头部为 20 字节）。 Padding：填充位。因为 Data Offset 只能表示 TCP 头部的长度 必须是 4 字节的整倍数。如果 Options 选项不足 4 字节的整倍数，就需要 Padding 填充为 4 字节的整倍数。 ","link":"https://faded.auspicious.space/post/tcp-request-header/"},{"title":"HTTP 状态码详解","content":" HTTP协议状态码详解（HTTP Status Code） 1xx（临时响应） 表示临时响应并需要请求者继续执行操作的状态代码。 100（继续） 请求者应当继续提出请求。 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。 101（切换协议） 请求者已要求服务器切换协议，服务器已确认并准备切换。 2xx （成功） 表示成功处理了请求的状态代码。 200（成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。 201（已创建） 请求成功并且服务器创建了新的资源。 202（已接受） 服务器已接受请求，但尚未处理。 203（非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。 204（无内容） 服务器成功处理了请求，但没有返回任何内容。 205（重置内容） 服务器成功处理了请求，但没有返回任何内容。 206（部分内容） 服务器成功处理了部分 GET 请求。 3xx （重定向） 表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。 300（多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。 301（永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。 302（临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 303（查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。 304（未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。 305（使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。 307（临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 4xx（请求错误） 这些状态代码表示请求可能出错，妨碍了服务器的处理。 400（错误请求） 服务器不理解请求的语法。 401（未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。 403（禁止） 服务器拒绝请求。 404（未找到） 服务器找不到请求的网页。 405（方法禁用） 禁用请求中指定的方法。 406（不接受） 无法使用请求的内容特性响应请求的网页。 407（需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。 408（请求超时） 服务器等候请求时发生超时。 409（冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。 410（已删除） 如果请求的资源已永久删除，服务器就会返回此响应。 411（需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。 412（未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。 413（请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 414（请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。 415（不支持的媒体类型） 请求的格式不受请求页面的支持。 416（请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。 417（未满足期望值） 服务器未满足“期望”请求标头字段的要求。 5xx（服务器错误） 这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。 500（服务器内部错误） 服务器遇到错误，无法完成请求。 501（尚未实施） 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。 502（错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。 503（服务不可用） 服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。 504（网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。 505（HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。 4 个新的 HTTP 状态码 RFC 6585 最近刚刚发布，该文档描述了 4 个新的 HTTP 状态码。 HTTP 协议还在变化？是的，HTTP 协议一直在演变，新的状态码对于开发 REST 服务或者说是基于 HTTP 的服务非常有用，下面我们为你详细介绍这四个新的状态码以及是否应该使用。 428 Precondition Required (要求先决条件) 先决条件是客户端发送 HTTP 请求时，如果想要请求能成功必须满足一些预设的条件。 一个好的例子就是 If-None-Match 头，经常在 GET 请求中使用，如果指定了 If-None-Match，那么客户端只在响应中的 ETag 改变后才会重新接收回应。 先决条件的另外一个例子就是 If-Match 头，这个一般用在 PUT 请求上用于指示只更新没被改变的资源，这在多个客户端使用 HTTP 服务时用来防止彼此间不会覆盖相同内容。 当服务器端使用 428 Precondition Required 状态码时，表示客户端必须发送上述的请求头才能执行请求，这个方法为服务器提供一种有效的方法来阻止 'lost update' 问题。 429 Too Many Requests (太多请求) 当你需要限制客户端请求某个服务数量时，该状态码就很有用，也就是请求速度限制。 在此之前，有一些类似的状态码，例如 '509 Bandwidth Limit Exceeded'. Twitter 使用 420 （这不是HTTP定义的状态码） 如果你希望限制客户端对服务的请求数，可使用 429 状态码，同时包含一个 Retry-After 响应头用于告诉客户端多长时间后可以再次请求服务。 431 Request Header Fields Too Large (请求头字段太大) 某些情况下，客户端发送 HTTP 请求头会变得很大，那么服务器可发送 431 Request Header Fields Too Large 来指明该问题。 我不太清楚为什么没有 430 状态码，而是直接从 429 跳到 431，我尝试搜索但没有结果。唯一的猜测是 430 Forbidden 跟 403 Forbidden 太像了，为了避免混淆才这么做的，天知道！ 511 Network Authentication Required (要求网络认证) 对我来说这个状态码很有趣，如果你在开发一个 HTTP 服务器，你不一定需要处理该状态码，但如果你在编写 HTTP 客户端，那这个状态码就非常重要。 如果你频繁使用笔记本和智能手机，你可能会注意到大量的公用 WiFi 服务要求你必须接受一些协议或者必须登录后才能使用。 这是通过拦截 HTTP 流量，当用户试图访问网络返回一个重定向和登录，这很讨厌，但是实际情况就是这样的。 使用这些“拦截”客户端，会有一些讨厌的副作用。在 RFC 中有提到这两个的例子： 如果你在登录 WIFI 前访问某个网站，网络设备将会拦截首个请求，这些设备往往也有自己的网站图标 ‘favicon.ico'。登录后您会发现，有一段时间内你访问的网站图标一直是WIFI登录网站的图标。 如果客户端使用 HTTP 请求来查找文档（可能是 JSON），网络将会响应一个登录页，这样你的客户端就会解析错误并导致客户端运行异常，在现实中这种问题非常常见。 因此 511 状态码的提出就是为了解决这个问题。 如果你正在编写 HTTP 的客户端，你最好还是检查 511 状态码以确认是否需要认证后才能访问。 英文原文 ","link":"https://faded.auspicious.space/post/http-detailed-introduction-to-status-code/"},{"title":"HTTP 协议中 GET 和 POST 的区别","content":" HTTP协议中GET和POST的区别 不完全正确的网红答案 GET 的 URL 会有长度上的限制，则 POST 的数据则可以非常大。 POST 比 GET 安全，GET 请求的数据会附在 URL 之后，POST 把提交的数据则放置在是 HTTP 包的包体中。 为什么是不完全正确的答案 HTTP 协议对 GET 和 POST 都没有对长度的限制：HTTP 协议没有对传输的数据大小进行限制，HTTP 协议规范也没有对 URL 长度进行限制。 而在实际开发中存在的限制主要有： GET：特定浏览器和服务器对 URL 长度有限制，例如 IE 对 URL 长度的限制是 2083 字节(2K+35)。对于其他浏览器，如 Netscape、FireFox 等，理论上没有长度限制，其限制取决于操作系统的支持。因此对于 GET 提交时，传输数据就会受到 URL 长度的限制。 POST：由于不是通过 URL 传值，理论上数据不受 限。但实际各个 WEB 服务器会规定对 POST 提交数据大小进行限制，Apache、IIS6 都有各自的配置。 安全性意义不同：通过 GET 提交数据，用户名和密码将明文出现在 URL 上，因为登录页面有可能被浏览器缓存，其他人查看浏览器的历史纪录，那么别人就可以拿到你的账号和密码了。POST 一般来说都不会被缓存，但有很多抓包工具也是可以窥探到你的数据，真的要安全那就要把传输的信息加密。但这不是 HTTP 协议对 GET 和 POST 做的的安全性区别，是浏览器使用的具体表现出来的。GET 在 HTTP 协议中用于获取数据，POST 在 HTTP 协议中用于修改数据。 在 HTTP 中 GET 和 POST 的原理区别 HTTP 定义了与服务器交互的不同方法，最基本的方法有 4 种，分别是 GET，POST，PUT，DELETE URL 全称是资源定位符，我们可以这样认为：一个 URL 地址，它用于描述一个网络上的资源，而 HTTP 中的 GET，POST，PUT，DELETE 就对应着对这个资源的查 ，改 ，增 ，删 4 个操作。到这里，大家应该有个大概的了解了，GET 一般用于获取 / 查询资源信息，而 POST 一般用于更新资源信息。 根据 HTTP 规范，GET 用于信息获取，而且应该是安全的和幂等的。 GET—安全 所谓安全的意味着该操作用于获取信息而非修改信息。换句话说，GET 请求一般不应产生副作用。就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。 注意：这里安全的含义仅仅是指是非修改信息。 GET—幂等 幂等的意味着对同一 URL 的多个请求应该返回同样的结果。幂等（idempotent、idempotence）是一个数学或计算机学概念，常见于抽象代数中。 幂等有以下几种定义： 对于单目运算，如果一个运算对于在范围内的所有的一个数多次进行该运算所得的结果和进行一次该运算所得的结果是一样的，那么我们就称该运算是幂等的。 比如绝对值运算就是一个例子，在实数集中，有 abs(a) = abs(abs(a)) 。 对于双目运算，则要求当参与运算的两个值是等值的情况下，如果满足运算结果与参与运算的两个值相等，则称该运算幂等，如求两个数的最大值的函数，有在实数集中幂等，即 max(x, x) = x。看完上述解释后，应该可以理解 GET 幂等的含义了。 但在实际应用中，以上 2 条规定并没有这么严格。引用别人文章的例子：比如，新闻站点的头版不断更新。虽然第二次请求会返回不同的一批新闻，该操作仍然被认为是安全的和幂等的，因为它总是返回当前的新闻。从根本上说，如果目标是当用户打开一个链接时，他可以确信从自身的角度来看没有改变资源即可。 根据 HTTP 规范，POST 表示可能修改变服务器上的资源的请求。继续引用上面的例子：还是新闻以网站为例，读者对新闻发表自己的评论应该通过 POST 实现，因为在评论提交后站点的资源已经不同了，或者说资源被修改了。 上面大概说了一下 HTTP 规范中，GET 和 POST 的一些原理性的问题。但在实际的做的时候，很多人却没有按照 HTTP 规范去做，导致这个问题的原因有很多，比如说： 很多人贪方便，更新资源时用了 GET，因为用 POST 必须要到 FORM（表单），这样会麻烦一点。 对资源的增，删，改，查操作，其实都可以通过 GET/POST 完成，不需要用到 PUT 和 DELETE。 另外一个是，早期的但是 Web MVC 框架设计者们并没有有意识地将 URL 当作抽象的资源来看待和设计。还有一个较为严重的问题是传统的 Web MVC 框架基本上都只支持 GET 和 POST 两种 HTTP 方法，而不支持 PUT 和 DELETE 方法。 为什么要使用 GET 答案就是：因为 GET 比 POST 更快。 请求过程区别 POST 请求的过程，会先将请求头发送给服务器进行确认，然后才真正发送数据；而 GET 请求的过程，会在连接建立后会将请求头和请求数据一起发送。 POST 请求的过程： 浏览器请求 TCP 连接（第一次握手）； 服务器答应进行 TCP 连接（第二次握手）； 浏览器确认，并发送 POST 请求头（第三次握手，这个报文比较小，所以 HTTP 会在此时进行第一次据发送）； 服务器返回 100 CONTINUE 响应； 浏览器开始发送数据； 服务器返回 200 OK 响应。 GET 请求的过程： 浏览器请求 TCP 连接（第一次握手）； 服务器答应进行 TCP 连接（第二次握手）； 浏览器确认，并发送 GET 请求头和数据（第三次握手，这个报文比较小，所以 HTTP 会在此时进行第一次数据发送）； 服务器返回 200 OK 响应； 也就是说，目测 GET 的总耗是 POST 的 2/3 左右。 GET 会将数据缓存起来，而 POST 不会 可以做个简短的测试，使用 AJAX 采用 GET 方式请求静态数据（比如 HTML 页面，图片）的时候，如果两次传输的数据相同，第二次以后耗费的时间将在 10ms 以内（Chrome 测试），而 POST 每次耗费的时间都差不多。经测试，Chrome 下和 FireFox 下如果检测到 GET 请求的是静态资源，则会缓存，如果是数据，则不缓存，但是 IE 都会缓存起来。 POST 不能进行管道化传输 HTTP 在的一次会话需要先建立 TCP 连接然后才能通信，如果每次连接都只进行一次 HTTP 会话，那这个连接过程占的比例太大了！ 于是出现了持久连接：在 http/1.0+ 中是 connection 首部中添加 keep-alive 值，在 http/1.1 中是在 connection 首部中添加 persistent 值，当然两者不仅仅是命名上的差别，http/1.1 中，持久连接是默认的，除非显示在 connection 中添加 close，否则持久连接不会关闭，而 http/1.0+ 中则恰好相反，除非显示在 connection 首部中添加 keep-alive，否则在接收数据包后连接就断开了。 出现了持久连接还不够，在 http/1.1 中，还有一种称为管道通信的方式进行速度优化：把需要发送到服务器上的所有请求放到输出队列中，在第一个请求发送出去后，不等到收到服务器的应答，第二个请求紧接着就发送出去，但是这样的方式有一个问题：不安全，如果一个管道中有 10 个连接，在发送出 9 个后，突然服务器告诉你，连接关闭了，此时客户端即使收到了前 9 个请求的答复，也会将这 9 个请求的内容清空，也就是说，白忙活了……此时，客户端的这 9 个请求需要重新发送。这对于幂等请求还好（比如 GET，多发送几次都没关系，每次都是相同的结果），如果是 POST 这样的非幂等请求（比如支付的时候，多发送几次就惨了），肯定是行不通的。所以，POST 请求不能通过管道的方式进行通信！ 管道化传输在浏览器端的实现还需考证，貌似默认情况下大部分浏览器（除了 Opera）是不进行管道化传输的，除非手动开启！ 所以，在可以使用 GET 请求通信的时候，不要使用 POST 请求，这样用户体验会更好，当然，如果有安全性要求的话，POST 会更好。 ","link":"https://faded.auspicious.space/post/the-difference-between-get-and-post-in-http/"},{"title":"TCP——发送窗口","content":" 理解TCP发送窗口 窗口是 TCP 中一个极为重要的概念，它直接关系到 TCP 的一个关键功能——流量控制。今天我简单介绍下 TCP 发送窗口，从较为微观的角度去理解 TCP 是如何限制发送端可发送的数据量的。 我们知道 TCP header 中有一个 Window Size 字段，它其实是指接收端的窗口，即接收窗口，用来告知发送端自己所能接收的数据量，从而达到一部分流控的目的。假设你现在有 10MB 的数据要通过 TCP 发送，或许你点个按钮就开始发送了，然后就认为 TCP 仅仅是简单的把数据从一端挪到另一端（宏观上的确如此）。其实 TCP 在整个发送过程中，也在度量当前的网络状态，目的是为了维持一个健康稳定的发送过程。因此，这 10MB 数据是在某些机制的控制下进行传输的，其中一种重要机制就是窗口机制。发送端的发送窗口是基于接收端的接收窗口来计算的，我们可以把这 10MB 数据分为如下四类来看（见图）： 已发送且已应答（Sent / Acked）； 已发送但尚未应答（Send / UnAcked）； 未发送，但位于当前发送窗口之内（Unsent / Inside）； 未发送，但位于当前发送窗口之外（Unsent / Outside）。 已发送且已应答（Sent / Acked） Sent/Acked 数据的第一个字节是 ISN+1，ISN 是指在 TCP 建立连接时由 SYN 分段所选择的第一个编号。SYN Flag 被当作是一个字节的数据，特地会被应答一次。因此，TCP 连接上发送的数据的第一个字节编号就是 ISN+1，被应答的数据的最后一个字节编号为【ACK编号-1】。例如，A 发送 1000 个字节给 B，假设 ISN=1，则所要发送数据的第一个字节的编号为 2，全部发送到 B 之后，B 会应答 1002，意思是说前 1001（包括 ISN）个字节我都收到了，请给我第 1002 个字节。所以，被应答的数据的最后一个字节的编号为 1001。 已发送但尚未应答（Send / UnAcked） Send/UnAcked 数据的状态可能是正在传输的过程中，或是被网络丢弃了，或是已到达接收端但应答尚未被发送（因为 Delayed-Ack），又或是应答正在传输过程中。 为了区分 Sent/UnAcked 数据和 Unsent/Inside 数据，TCP 维护一个叫做 SND.NEXT 的变量，它是下一个即将被发送的字节的编号。所以 SND.NEXT 的值将是下一个即将被发送的 TCP 分段的 Sequence Number 字段的值。Send/UnAcked 数据的第一个字节是接收端上一次接受的应答分段的 Acknowledge Number 字段的值。 未发送，但位于当前发送窗口之内（Unsent / Inside） Unsent/Inside 数据是接收端允许发送端发送的数据，发送端可以发送窗口内的所有数据，无需等待应答以及窗口更新。换句话说，如果发送端停止发送并等待应答，那就说明已经没有 Unsent/Inside 的数据了。 然而，如果遇到拥塞，发送端的流控机制，即 slow start 和 congestion avoidance 会阻止发送端发送所有位于接收窗口内的数据。在这种情况下，这些机制会主宰等待应答之前的可发送数据量。 未发送，但位于当前发送窗口之外（Unsent / Outside） Unsent/Outside 数据是位于当前发送窗口意外的数据，代表将来要发送的数据，但根据目前的接收窗口它们是不允许被发送的。接收端会丢弃无法保存在接收缓存区中的数据，并用当前的应答编号来应答发送端。 发送窗口的移动 发送窗口有一个左侧边缘和一个右边边缘。当收到一个带有更高 Ack number 的应答时，发送窗口的左侧边缘就会向右移动（close）。当收到的应答的 Ack number + Window &gt; 之前的 Ack number + Window 时，发送窗口的右侧边缘会向右移动（open）。 另外，发送窗口仅 close 但不 open 也是有可能的。比如发送端收到一个应答，它的 Ack number 增加了，但是窗口变小了，最终 Ack number + Window 并没有变化。这种情况发生在接收端收到了数据，但还没有把数据给应用层，因此 Ack number 会增加，但是窗口大小会减少同样多的值。 ","link":"https://faded.auspicious.space/post/tcp-slide-window/"},{"title":"Git——原理","content":" 聊聊Git原理 Git 给自己的定义是一套内存寻址文件系统，当你在一个目录下执行 git init 命令时，会生成一个 .git 目录，它的目录结构是这样的： .git/ ├── branches ├── config ├── description ├── HEAD ├── hooks │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── prepare-commit-msg.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ └── update.sample ├── info │ └── exclude ├── objects │ ├── info │ └── pack └── refs ├── heads └── tags 其中 branches 目录已经不再使用，description 文件仅供 GitWeb 程序使用，config 文件保存了项目的配置。 需要我们重点关注的是 HEAD 和 index 文件以及 objects 和 refs 目录。其中 index 中保存了暂存区的一些信息，这里不做过多介绍。 objects 目录 这个目录是用来存储 Git 对象的（包括 tree 对象、commit 对象和 blob 对象），对于一个初始的 Git 仓库，objects 目录下只有 info 和 pack 两个子目录，并没有常规文件。随着项目的进行，我们创建的文件，以及一些操作记录，都会作为 Git 对象被存储在这个目录下。 在该目录下，所有对象都会生成一个文件，并且有对应的 SHA-1 校验和，Git 会创建以校验和前两位为名称的子目录，并以剩下的 38 位为名称来保存文件。 接下来让我们一起看一下当我们进行一次提交时，Git 具体做了哪些事情。 $ echo 'test content'&gt;test.txt $ git add . 执行上述命令后，objects 目录结构如下： .git/objects/ ├── d6 │ └── 70460b4b4aece5915caf5c68d12f560a9fe3e4 ├── info └── pack 这里多了一个文件夹，如上面所述，这个就是 Git 为我们创建的一个对象，我们可以使用底层命令来看一下这个对象的类型以及它存储的是什么。 $ git cat-file -t d670460b4b4aece5915caf5c68d12f560a9fe3e4 blob $ git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4 test content 可以看到，这是一个 blob 对象，存储内容就是我们刚刚创建的文件的内容。接下来继续执行提交操作。 $ git commit -m 'test message' [master (root-commit) 2b00dca] test message 1 file changed, 1 insertion(+) create mode 100644 test.txt $ tree .git/objects/ .git/objects/ ├── 2b │ └── 00dcae50af70bb5722033b3fe75281206c74da ├── 80 │ └── 865964295ae2f11d27383e5f9c0b58a8ef21da ├── d6 │ └── 70460b4b4aece5915caf5c68d12f560a9fe3e4 ├── info └── pack 此时 objects 目录下又多了两个对象。再用 cat-file 命令来查看一下这两个文件。 $ git cat-file -t 2b00dcae50af70bb5722033b3fe75281206c74da commit $ git cat-file -p 2b00dcae50af70bb5722033b3fe75281206c74da tree 80865964295ae2f11d27383e5f9c0b58a8ef21da author jackeyzhe &lt;jackeyzhe59@163.com&gt; 1534670725 +0800 committer jackeyzhe &lt;jackeyzhe59@163.com&gt; 1534670725 +0800 test message $ git cat-file -t 80865964295ae2f11d27383e5f9c0b58a8ef21da tree $ git cat-file -p 80865964295ae2f11d27383e5f9c0b58a8ef21da 100644 blob d670460b4b4aece5915caf5c68d12f560a9fe3e4 test.txt 可以看到一个是 commit 对象，一个是 tree 对象。commit 对象通常包括 4 部分内容： 工作目录快照的 Hash，即 tree 的值； 提交的说明信息； 提交者的信息； 父提交的 Hash 值； 由于我是第一次提交，所以这里没有父提交的 Hash 值。 tree 对象可以理解为 UNIX 文件系统中的目录，保存了工作目录的 tree 对象和 blob 对象的信息。接下来我们再来看一下 Git 是如何进行版本控制的。 echo 'version1'&gt;version.txt $ git add . $ git commit -m 'first version' [master 702193d] first version 1 file changed, 1 insertion(+) create mode 100644 version.txt $ echo 'version2'&gt;version.txt $ git add . $ git commit -m 'second version' [master 5333a75] second version 1 file changed, 1 insertion(+), 1 deletion(-) $ tree .git/objects/ .git/objects/ ├── 1f │ └── a5aab2a3cf025d06479b9eab9a7f66f60dbfc1 ├── 29 │ └── 13bfa5cf9fb6f893bec60ac11d86129d56fcbe ├── 2b │ └── 00dcae50af70bb5722033b3fe75281206c74da ├── 53 │ └── 33a759c4bdcdc6095b4caac19743d9445ca516 ├── 5b │ └── dcfc19f119febc749eef9a9551bc335cb965e2 ├── 70 │ └── 2193d62ffd797155e4e21eede20897890da12a ├── 80 │ └── 865964295ae2f11d27383e5f9c0b58a8ef21da ├── d6 │ └── 70460b4b4aece5915caf5c68d12f560a9fe3e4 ├── df │ └── 7af2c382e49245443687973ceb711b2b74cb4a ├── info └── pack $ git cat-file -p 1fa5aab2a3cf025d06479b9eab9a7f66f60dbfc1 100644 blob d670460b4b4aece5915caf5c68d12f560a9fe3e4 test.txt 100644 blob 5bdcfc19f119febc749eef9a9551bc335cb965e2 version.txt $ git cat-file -p 2913bfa5cf9fb6f893bec60ac11d86129d56fcbe 100644 blob d670460b4b4aece5915caf5c68d12f560a9fe3e4 test.txt 100644 blob df7af2c382e49245443687973ceb711b2b74cb4a version.txt Git 将没有改变的文件的 Hash 值直接存入 tree 对象，对于有修改的文件，则会生成一个新的对象，将新的对象存入 tree 对象。我们再来看一下 commit 对象的信息。 $ git cat-file -p 5333a759c4bdcdc6095b4caac19743d9445ca516 tree 2913bfa5cf9fb6f893bec60ac11d86129d56fcbe parent 702193d62ffd797155e4e21eede20897890da12a author jackeyzhe &lt;jackeyzhe59@163.com&gt; 1534672270 +0800 committer jackeyzhe &lt;jackeyzhe59@163.com&gt; 1534672270 +0800 second version $ git cat-file -p 702193d62ffd797155e4e21eede20897890da12a tree 1fa5aab2a3cf025d06479b9eab9a7f66f60dbfc1 parent 2b00dcae50af70bb5722033b3fe75281206c74da author jackeyzhe &lt;jackeyzhe59@163.com&gt; 1534672248 +0800 committer jackeyzhe &lt;jackeyzhe59@163.com&gt; 1534672248 +0800 first version 此时的 commit 对象已经有 parent 信息了，这样我们就可以顺着 parent 一步步往回进行版本回退了。不过这样是比较麻烦的，我们一般习惯用的是 git log 查看提交记录。 refs 目录 在介绍 refs目录之前，我们还是先来看一下该目录结构： $ tree .git/refs/ .git/refs/ ├── heads │ └── master └── tags 2 directories, 1 file $ cat .git/refs/heads/master 5333a759c4bdcdc6095b4caac19743d9445ca516 在一个刚刚被初始化的 Git 仓库中，refs 目录下只有 heads 和 tags 两个子目录，由于我们刚刚有过提交操作，所以 git 为我们自动生成了一个名为 master 的引用。master 的内容是最后一次提交对象的 Hash 值。看到这里大家一定在想，如果我们对每次提交都创建一个这样的引用，不就不需要记住每次提交的 Hash 值了，只要看看引用的值，复制过来就可以退回到对应版本了。没错，这样是可以方便的退回，但是这样做的意义不大，因为我们并不需要频繁的退回，特别是比较古老的版本，退回的概率更是趋近于 0。Git 用这个引用做了更有意义的事，那就是分支。 当我新建一个分支时，git 就会在 .git/refs/heads 目录下新建一个文件。当然新建的引用还是指向当前工作目录的最后一次提交，一般情况下我们不会主动去修改这些引用文件，不过如果一定要修改，Git 为我们提供了一个 update-ref 命令。可以改变引用的值，使其指向不同的 commit 对象。 tags 目录下的文件存储的是标签对应的 commit，当为某次提交打上一个 tag 时，tags 目录下就会被创建出一个命名为 tag 名的文件，值是此次提交的 Hash 值。 HEAD 新建分支的时候，Git 是怎么知道我们当前是在哪个分支的，Git 又是如何实现分支切换的呢？答案就在 HEAD 这个文件中。 $ cat .git/HEAD ref: refs/heads/master $ git checkout test Switched to branch 'test' $ cat .git/HEAD ref: refs/heads/test 很明显，HEAD 文件存储的就是我们当前分支的引用，当我们切换分支后再次进行提交操作时，Git 就会读取 HEAD 对应引用的值，作为此次 commit 的 parent。我们也可以通过 symbolic-ref 命令手动设置 HEAD 的值，但是不能设置 refs 以外的形式。 Packfiles 到这里我们在文章开头所说的重点关注的目录和文件都介绍完毕了。但是作为一个文件系统，还存在一个问题，那就是空间。前文介绍过，当文件修改后进行提交时，Git 会创建一份新的快照。这样长久下去，必定会占用很大的存储空间。而比较古老的版本的价值已经不大，所以要想办法清理出足够的空间供用户使用。 好消息是，Git 拥有自己的 gc（垃圾回收）方法。当仓库中有太多松散对象时，Git 会调用 git gc 命令（当然我们也可以手动调用这个命令），将这些对象进行打包。打包后会出现两个新文件：一个 idx 索引文件和一个 pack 文件。索引文件包含了 packfile 的偏移信息，可以快速定位到文件。打包后，每个文件最新的版本的对象存的是完整的文件内容。而之前的版本只保存差异。这样就达到了压缩空间的目的。 ","link":"https://faded.auspicious.space/post/git-principle/"},{"title":"为什么 Nginx 的性能要比 Apache 高得多","content":" 为什么Nginx的性能要比Apache高得多 这得益于 Nginx 使用了最新的 epoll（Linux 2.6 内核）和 kqueue（freebsd）网络 I/O 模型， 而 Apache 则使用的是传统的 select 模型。目前 Linux 下能够承受高并发访问的 Squid、Memcached 都采用的是 epoll 网络 I/O 模型。 处理大量的连接的读写，Apache 所采用的 select 网络 I/O 模型非常低效。 下面用一个比喻来解析 Apache 采用的 select 模型和 Nginx 采用的 epoll 模型进行之间的区别： 假设你在大学读书，住的宿舍楼有很多间房间，你的朋友要来找你。select 版宿管大妈就会带着你的朋友挨个房间去找，直到找到你为止。而 epoll 版宿管大妈会先记下每位同学的房间号，你的朋友来时，只需告诉你的朋友你住在哪个房间即可，不用亲自带着你的朋友满大楼找人。如果来了 10000 个人，都要找自己住这栋楼的同学时，select 版和 epoll 版宿管大妈，谁的效率更高，不言自明。同理，在高并发服务器中，轮询 I/O 是最耗时间的操作之一，select 和 epoll 的性能谁的性能更高，同样十分明了。 epoll - I/O event notification facility 在 Linux 的网络编程中，很长的时间都在使用 select 来做事件触发。在 Linux 新的内核中，有了一种替换它的机制，就是epoll。相比于 select，epoll 最大的好处在于它不会随着监听 fd 数目的增长而降低效率。因为在内核中的 select 实现中，它是采用轮询来处理的，轮询的 fd 数目越多，自然耗时越多。并且，在 linux/posix_types.h 头文件有这样的声明： #define __FD_SETSIZE 1024 表示 select 最多同时监听 1024 个 fd，当然，可以通过修改头文件再重编译内核来扩大这个数目，但这似乎并不治本。 epoll 的接口非常简单，一共就三个函数： int epoll_create(int size); 创建一个 epoll 的句柄，size 用来告诉内核这个监听的数目一共有多大。这个参数不同于 select() 中的第一个参数，给出最大监听的 fd+1 的值。 需要注意的是，当创建好 epoll 句柄后，它就是会占用一个 fd 值，在 Linux 下如果查看 /proc/进程id/fd/，是能够看到这个 fd 的，所以在使用完 epoll 后，必须调用 close() 关闭，否则可能导致 fd 被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); epoll 的事件注册函数，它不同于 select() 是在监听事件时告诉内核要监听什么类型的事件， 而是在这里先注册要监听的事件类型。第一个参数是 epoll_create() 的返回值，第二个参数表示动作，用三个宏来表示： EPOLL_CTL_ADD：注册新的 fd 到 epfd 中； EPOLL_CTL_MOD：修改已经注册的 fd 的监听事件； EPOLL_CTL_DEL：从 epfd 中删除一个 fd； 第三个参数是需要监听的 fd，第四个参数是告诉内核需要监听什么事，struct epoll_event 结构如下： typedef union epoll_data { void *ptr; int fd; __uint32_t u32; __uint64_t u64; } epoll_data_t; struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; events 可以是以下几个宏的集合： EPOLLIN：表示对应的文件描述符可以读（包括对端 SOCKET 正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将 EPOLL 设为边缘触发（Edge Triggered）模式，这是相对于水平触发（Level Triggered）来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个 socket 的话，需要再次把这个 socket 加入到 EPOLL 队列里。 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 等待事件的产生，类似于 select() 调用。参数 events 用来从内核得到事件的集合，maxevents 告之内核这个 events 有多大，这个 maxevents 的值不能大于创建 epoll_create() 时的 size，参数 timeout 是超时时间（毫秒，0 会立即返回，-1 将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回 0 表示已超时。 关于 ET、LT 两种工作模式： 可以得出这样的结论: ET 模式仅当状态发生变化的时候才获得通知,这里所谓的状态的变化并不包括缓冲区中还有未处理的数据, 也就是说,如果要采用 ET 模式,需要一直 read/write 直到出错为止，很多人反映为什么采用 ET 模式只接收了一部分数据就再也得不到通知了,大多因为这样；而 LT 模式是只要有数据没有处理就会一直通知下去的。 那么究竟如何来使用 epoll 呢？其实非常简单。 通过在包含一个头文件 #include &lt;sys/epoll.h&gt; 以及几个简单的 API 将可以大大的提高你的网络服务器的支持人数。 首先通过 create_epoll(int maxfds) 来创建一个 epoll 的句柄，其中 maxfds 为你 epoll 所支持的最大句柄数。这个函数会返回一个新的 epoll句柄，之后的所有操作将通过这个句柄来进行操作。在用完之后，记得用 close() 来关闭这个创建出来的 epoll 句柄。 之后在你的网络主循环里面，每一帧的调用 epoll_wait(int epfd, epoll_event events, int max events, int timeout) 来查询所有的网络接口，看哪一个可以读，哪一个可以写了。基本的语法为： nfds = epoll_wait(kdpfd, events, maxevents, -1); 其中 kdpfd 为用 epoll_create 创建之后的句柄，events 是一个 epoll_event* 的指针，当 epoll_wait 这个函数操作成功之后，epoll_events 里面将储存所有的读写事件。max_events 是当前需要监听的所有 socket 句柄数。最后一个 timeout 是 epoll_wait 的超时，为 0 的时候表示马上返回，为 -1 的时候表示一直等下去，直到有事件范围，为任意正整数的时候表示等这么长的时间，如果一直没有事件，则范围。一般如果网络主循环是单独的线程的话，可以用 -1 来等，这样可以保证一些效率，如果是和主逻辑在同一个线程的话，则可以用 0 来保证主循环的效率。epoll_wait 范围之后应该是一个循环，遍利所有的事件。 几乎所有的 epoll 程序都使用下面的框架： for( ; ; ) { nfds = epoll_wait(epfd,events,20,500); for(i=0;i&lt;nfds;++i) { if(events[i].data.fd==listenfd) //有新的连接 { connfd = accept(listenfd,(sockaddr *)&amp;clientaddr, &amp;clilen); //accept这个连接 ev.data.fd=connfd; ev.events=EPOLLIN|EPOLLET; epoll_ctl(epfd,EPOLL_CTL_ADD,connfd,&amp;ev); //将新的fd添加到epoll的监听队列中 } else if( events[i].events&amp;EPOLLIN ) //接收到数据，读socket { n = read(sockfd, line, MAXLINE)) &lt; 0 //读 ev.data.ptr = md; //md为自定义类型，添加数据 ev.events=EPOLLOUT|EPOLLET; epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&amp;ev);//修改标识符，等待下一个循环时发送数据，异步处理的精髓 } else if(events[i].events&amp;EPOLLOUT) //有数据待发送，写socket { struct myepoll_data* md = (myepoll_data*)events[i].data.ptr; //取数据 sockfd = md-&gt;fd; send( sockfd, md-&gt;ptr, strlen((char*)md-&gt;ptr), 0 ); //发送数据 ev.data.fd=sockfd; ev.events=EPOLLIN|EPOLLET; epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&amp;ev); //修改标识符，等待下一个循环时接收数据 } else { //其他的处理 } } } ","link":"https://faded.auspicious.space/post/why-nginx-outperform-apache/"},{"title":"TCP——三次握手和四次挥手","content":" TCP 三次握手 和 四次挥手 概述 我们都知道 TCP 是 可靠的数据传输协议，UDP 是不可靠传输，那么 TCP 它是怎么保证可靠传输的呢？那我们就不得不提 TCP 的三次握手和四次挥手。 三次握手 下图为三次握手的流程图： 下面通过我们 Wireshark 抓包工具来分析三次握手： 第一次握手 建立连接。客户端发送连接请求报文段，将 SYN 位置为 1，Sequence Number 为 x；（x 是随机生成的一个 int 数值）然后，客户端进入 SYN_SEND 状态，等待服务器的确认； 第二次握手 服务器收到 SYN 报文段。服务器收到客户端的 SYN 报文段，需要对这个 SYN 报文段进行确认，设置 Acknowledgment Number 为 x+1(Sequence Number+1)；同时，自己自己还要发送 SYN 请求信息，将 SYN 位置为1，Sequence Number 为 y （y 是随机生存的一个 int 数值）；服务器端将上述所有信息放到一个报文段（即 SYN + ACK 报文段）中，一并发送给客户端，此时服务器进入 SYN_RECV 状态； 第三次握手 客户端收到服务器的 SYN + ACK 报文段。然后将 Acknowledgment Number 设置为 y + 1，向服务器发送 ACK 报文段，这个报文段发送完毕以后，客户端和服务器端都进入 ESTABLISHED 状态，完成 TCP 三次握手。 四次挥手 第一次挥手 Client（可以使客户端，也可以是服务器端），设置 Sequence Number 和 Acknowledgment Number，向 Server 发送一个 FIN 报文段；此时，Client 进入 FIN_WAIT_1 状态；这表示 Client 没有数据要发送给 Server 了； 客户端发送第一次挥手后，就不能在向服务端发送数据了。 第二次挥手 Server 收到了 Client 发送的 FIN 报文段，向 Client 回一个 ACK 报文段，Acknowledgment Number 为 Sequence Number 加 1；Client 进入 FIN_WAIT_2 状态；Server 告诉 Client ，我“同意”你的关闭请求； Server 第一次响应后，还可以继续向 Client 发送数据，这里只是告诉 Client ，我收到你发送的关闭请求。 第三次挥手 Server 向 Client 发送 FIN 报文段，请求关闭连接，同时 Server 进入 CLOSE_WAIT 状态； 当 Server 的数据响应完成后，再告诉 Client，我这边也可以关闭请求了， 这时 Server 就不能再向 Client 发送数据了。 第四次挥手 Client 收到 Server 发送的 FIN 报文段，向 Server 发送 ACK 报文段，然后 Client 进入 TIME_WAIT 状态；Server 收到 Client 的 ACK 报文段以后，就关闭连接；此时，Client 等待 2 MSL 后依然没有收到回复，则证明 Server 端已正常关闭，那好，Client 也可以关闭连接了。 什么是 MSL MSL 是 Maximum Segment Lifetime 英文的缩写，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文（segment）是 IP 数据报（datagram）的数据部分，具体称谓请参见《数据在网络各层中的称呼》一文，而 IP 头中有一个 TTL 域，TTL 是 Time To Live 的缩写，中文可以译为“生存时间”，这个生存时间是由源主机设置初始值但不是存的具体时间，而是存储了一个 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。RFC 793 中规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟和 2 分钟等。 2 MSL 即两倍的 MSL，TCP 的 TIME_WAIT 状态也称为 2 MSL 等待状态，当 TCP 的一端发起主动关闭，在发出最后一个 ACK 包后，即第 3 次握手完成后发送了第四次握手的 ACK 包后就进入了 TIME_WAIT 状态，必须在此状态上停留两倍的 MSL 时间，等待 2 MSL 时间主要目的是怕最后一个 ACK 包对方没收到，那么对方在超时后将重发第三次握手的 FIN 包，主动关闭端接到重发的 FIN 包后可以再发一个 ACK 应答包。在 TIME_WAIT 状态时两端的端口不能使用，要等到 2 MSL 时间结束才可继续使用。当连接处于 2 MSL 等待阶段时任何迟到的报文段都将被丢弃。不过在实际应用中可以通过设置 SO_REUSEADDR 选项达到不必等待 2 MSL 时间结束再使用此端口。 TTL 与 MSL 是有关系的但不是简单的相等的关系，MSL 要大于等于 TTL。 为什么要三次握手？ TCP 建立连接，其实通过两次握手就可以建立连接了，为什么要三次呢？是不是多此一举呢？ 《计算机网络》中是这样说的 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。在书中同时举了一个例子，如下：“已失效的连接请求报文段”的产生在这样一种情况下： Client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 Server。本来这是一个早已失效的报文段。但 Server 收到此失效的连接请求报文段后，就误认为是 Client 再次发出的一个新的连接请求。于是就向 Client 发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要 Server 发出确认，新的连接就建立了。由于现在 Client 并没有发出建立连接的请求，因此不会理睬 Server 的确认，也不会向 Server 发送数据。但 Server 却以为新的运输连接已经建立，并一直等待 Client 发来数据。这样， Server 的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况， Client 不会向 Server 的确认发出确认。 Server 由于收不到确认，就知道 Client 并没有要求建立连接。” 网络故障 比如，现在网络出现了故障，只能发请求数据包，而接收不到响应数据包，那么只要发送一次请求，服务器就建立请求，这样肯定也是不对的，网络请求有来有回才能完成通讯。所以三次握手是必不可少的。 为什么要四次挥手呢？ TCP 协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP 是全双工模式，这就意味着，当 Client 发出 FIN 报文段时，只是表示 Client 已经没有数据要发送了，Client 告诉 Server，它的数据已经全部发送完毕了；但是，这个时候 Client 还是可以接受来自 Server 的数据；当 Server 返回 ACK 报文段时，表示它已经知道 Client 没有数据发送了，但是 Server 还是可以发送数据到 Client 的；当 Server 也发送了 FIN 报文段时，这个时候就表示 Server 也没有数据要发送了，就会告诉 Client，我也没有数据要发送了，之后彼此就会愉快的中断这次 TCP 连接。如果要正确的理解四次分手的原理，就需要了解四次分手过程中的状态变化。 ","link":"https://faded.auspicious.space/post/tcp-three-handshake-and-four-waves/"},{"title":"芙蓉女儿诔","content":" 芙蓉女儿诔---注音版 芙蓉女儿诔（lěi） 贾宝玉（《红楼梦》第七十八回） 维太平不易之元，蓉桂竞芳之月，无可奈何之日，怡红院浊玉，谨以群花之蕊，冰鲛之縠（hú），沁芳之泉，枫露之茗（míng），四者虽微，聊以达诚申信，乃致祭于白帝宫中抚司秋艳芙蓉女儿之前曰： 窃思女儿自临浊世，迄今凡十有六载。其先之乡籍姓氏，湮（yān）沦（lún）而莫能考者久矣。而玉得于衾（qīn）枕栉（zhì）沐（mù）之间，栖息宴游之夕，亲昵（nì）狎（xiá）亵（xiè），相与共处者，仅五年八月有（yòu）奇（jī）。 忆女儿曩（nǎng）生之昔，其为质则金玉不足喻其贵，其为性则冰雪不足喻其洁，其为神则星日不足喻其精，其为貌则花月不足喻其色。姊妹悉慕媖（yīng）娴（xián），妪（yù）媪（ǎo）咸仰惠德。 孰料鸠（jiū）鸩（zhèn）恶（wù）其高，鹰鸷（zhì）翻遭罦（fú）罬（zhuó）；薋（cí）葹（shī）妒其臭（xiù），茝（chǎi）兰竟被芟（shān）鉏（chú）！花原自怯，岂奈狂飙（biāo）？柳本多愁，何禁骤雨？偶遭蛊（gǔ）虿（chài）之谗，遂抱膏肓（huāng）之疚（jiù）。故而樱唇红褪，韵吐呻吟；杏脸香枯，色陈顑（kǎn）颔（hàn）。诼（zhuó）谣謑（xī）诟（gòu），出自屏帏（wéi）；荆棘蓬榛（zhēn），蔓延户牖（yǒu）。岂招尤则替，实攘诟而终。既忳（tún）幽沉于不尽，复含罔屈于无穷。高标见嫉，闺（guī）帏（wéi）恨比长沙；直烈遭危，巾帼惨于羽野。自蓄辛酸，谁怜夭折？仙云既散，芳趾难寻。洲迷聚窟，何来却死之香？海失灵槎（chá），不获回生之药。 眉黛烟青，昨犹我画；指环玉冷，今倩谁温？鼎炉之剩药犹存，襟泪之余痕尚渍（zì）。镜分鸾（luán）别，愁开麝月之奁（lián）；梳化龙飞，哀折檀（tán）云之齿。委金钿（diàn）于草莽，拾翠盒（è 盍代勺中之丶）于尘埃。楼空鳷（zhī）鹊，徒悬七夕之针；带断鸳鸯，谁续五丝之缕？ 况乃金天属节，白帝司时，孤衾（qīn）有梦，空室无人。桐阶月暗，芳魂与倩影同销；蓉帐香残，娇喘共细言皆绝。连天衰草，岂独蒹（jiān）葭（jiā）；匝（zā）地悲声，无非蟋蟀。露苔晚砌，穿帘不度寒砧（zhēn）；雨荔秋垣（yuán），隔院希闻怨笛。芳名未泯（mǐn），檐前鹦鹉犹呼；艳质将亡，槛外海棠预老。捉迷屏后，莲瓣无声；斗草庭前，兰芳枉（wǎng）待。抛残绣线，银笺（jiān）彩缕谁裁？摺（zhé）断冰丝，金斗御香未熨。 昨承严命，既趋车而远涉芳园；今犯慈威，复拄杖而近抛孤柩（jiù）。及闻槥（huì）棺被燹（xiǎn），惭违共穴之盟；石椁（guǒ）成灾，愧迨（dài）同灰之诮（qiào）。 尔乃西风古寺，淹滞青燐（lín），落日荒丘，零星白骨。楸（qiū）榆飒（sà）飒（sà），蓬艾萧萧。隔雾圹（kuàng）以啼猿，绕烟塍（chéng）而泣鬼。自为红绡（xiāo）帐里，公子情深；始信黄土陇（lǒng）中，女儿命薄！汝南泪血，斑斑洒向西风；梓（zǐ）泽馀（yú）衷，默默诉凭冷月。 呜呼！固鬼蜮（yù）之为灾，岂神灵而亦妒。箝诐（bì）奴之口，讨岂从宽？剖（pōu）悍妇之心，忿犹未释！在君之尘缘虽浅，然玉之鄙意岂终。因蓄惓（quán）惓（quán）之思，不禁谆（zhūn）谆（zhūn）之问。 始知上帝垂旌（jīng），花宫待诏（zhào），生侪（chái）兰蕙（huì），死辖芙蓉。听小婢（bì）之言，似涉无稽（jī）；据浊玉之思，则深为有据。何也？昔叶法善摄魂以撰碑，李长吉被诏而为记，事虽殊，其理则一也。故相物以配才，苟非其人，恶乃滥乎其位？始信上帝委托权衡，可谓至洽至协，庶不负其所秉赋也。因希其不昧之灵，或陟（zhì）降（jiàng）于兹（zī），特不揣（chuǎi）鄙俗之词，有污慧听。乃歌而招之曰： 天何如是之苍苍兮，乘玉虬（qiú）以游乎穹（qióng）窿（lóng）耶？ 地何如是之茫茫兮，驾瑶（yáo）象以降乎泉壤耶？ 望伞盖之陆离兮，抑箕（jī）尾之光耶？ 列羽葆（bǎo）而为前导兮，卫危虚于傍耶？ 驱丰隆以为比从兮，望舒月以临耶？ 听车轨而伊轧兮，御鸾（luán）鹥（yī）以征耶？ 闻馥郁而薆（ài）然兮，纫（rèn）蘅杜以为纕（xiāng）耶？ 炫裙裾（jū）之烁（shuò）烁（shuò）兮，镂明月以为珰（dāng）耶？ 籍葳（wēi）蕤（ruí）而成坛畤（zhì）兮，檠（qíng）莲焰以烛兰膏耶？ 文瓟（bó）瓠（hú）以为觯（zhì）斝（jiǎ）兮，漉醽（líng）醁（lù）以浮桂醑（xǔ）耶？ 瞻云气而凝盼兮，仿佛有所觇（chān）耶？ 俯窈窕而属耳兮，恍惚有所闻耶？ 期汗漫而无夭阏（yān）兮，忍捐弃余于尘埃耶？ 倩风廉之为余驱车兮，冀联辔（pèi）而携归耶？ 余中心为之慨然兮，徒噭（jiào）噭（jiào）而何为耶？ 君偃（yǎn）然而长寝（qǐn）兮，岂天运之变于斯耶？ 既窀（zhūn）穸（xī）且安稳兮，反其真而复奚（xī）化耶？ 余犹桎（zhì）梏（gù）而悬附兮，灵格余以嗟（jiē）来耶？ 来兮止兮，君其来耶！ 若夫鸿蒙而居，寂静以处，虽临于兹，余亦莫睹。搴（qiān）烟萝而为步幛（zhàng），列枪蒲而森行伍。警柳眼之贪眠，释莲心之味苦。素女约于桂岩，宓（fú）妃迎于兰渚（zhǔ）。弄玉吹笙（shēng），寒簧击敔（yǔ）。征嵩（sōng）岳之妃，启骊（lí）山之姥（mǔ）。龟呈洛浦之灵，兽作咸池之舞。潜赤水兮龙吟，集珠林兮凤翥（zhù）。爰（yuán）格爰（yuán）诚，匪簠（fǔ）匪筥（jǔ）。发轫（rèn）乎霞城，返旌（jīng）乎玄圃。既显微而若通，复氤（yīn）氲（yūn）而倏阻。离合兮烟云，空蒙兮雾雨。尘霾（mái）敛兮星高，溪山丽兮月午。何心意之忡忡，若寤（wù）寐（mèi）之栩栩？余乃欷（xī）歔（xū）怅望，泣涕彷徨。人语兮寂历，天籁兮篔（yún）筜（dāng）。鸟惊散而飞，鱼唼（shà）喋（zhá）以响。志哀兮是祷（dǎo），成礼兮期祥。呜呼哀哉！尚飨（xiǎng）！ ","link":"https://faded.auspicious.space/post/hibiscus-girl-dirge/"},{"title":"在网页上使用 jpg、png、gif 和 svg","content":" 在网页上使用JPG、PNG和SVG：新手指南 | Cheesecake Labs 如今，图像已经成为网络不可或缺的一部分。但情况并非一贯如此。直到 1993 年，Mosaic 浏览器才在网页内容中中加入图像。有些图像格式像 GIF 和 JPEG 当时已经存在，而 PNG 和 SVG 直到 90 年代才出现。图像用途多样，如：显示图片、品牌、插图、图表以及许多其他内容。 由于多样的使用情况和图片格式，有时选择正确的格式可能会令人困惑。标志应该是 SVG 还是 PNG？截图呢？JPEG 还是 PNG？在不生成过大文件的前提下，文件质量能有多高？了解每个图像格式如何工作还有它们各自的利弊可以帮助回答这些问题。 在过去几年中，通过数字设计和前端开发，研究和测试不同的工具帮助我澄清了这些问题。在本文中，我将展示一下每种格式如何工作、它们在哪个方面存在优势，以及在网页使用时的压缩与保存方法。 JPEG JEPG 由联合图像专家小组（Joint Photographic Experts Group）于 1992 年创建，并以创建者命名。JPEG 是一种有损光栅图像格式，这意味着每次保存被压缩的 JPEG 时，一些信息将被不可逆转地丢失。 JPEG 利用人眼感知的缺陷——对亮度比对颜色更敏感——使用了一种压缩算法来丢弃我们不太擅长获取的信息，因此被命名为“有损格式”。应用于给定图像的压缩量将直接与所得文件的质量和大小相关。 JPEG 压缩的技术方面远远不止这些，如果你想更深入，请查看这篇文章 作者：大卫·奥斯丁（David Austin）。 JPEG 的用途 因为 JPEG 适用于亮度和色彩压缩，所以在照片，以及其他写实或者带阴影的图像（如绘画和 3D 渲染）上使用效果良好。这就是为什么它是多年来最流行的存储图片的格式。出于同样的原因，JPEG 不适宜用在矢量图片，如徽标，几何图形，截图等方面。 照片，以及复杂的或带阴影的图像，如绘画，是使用 JPEG 的很好的例子。 压缩 JPEG 作为有损格式，JPEG 文件的压缩级别与最终图像质量直接相反。在像 Photoshop 这样的工具中保存 JPEG 时，你会看到一个从 0 到 100 的质量设置。Photoshop 设置了一些图像质量范围： 低 — 10% 中 — 30% 高 — 60% 非常高 — 80% 最佳 — 100% 最佳 100% (61 KB)，非常高 80% (29 KB)。 高 60% (16 KB)，中 30% (7 KB)。 低 10% (6 KB)，最低 0% (3 KB)。 网络建议使用在 50％ 到 60％ 质量之间的 JPEG，因为它能保证不错的图像质量和较小的文件尺寸。从 JPEG 资源中删除元数据也可以减少文件大小。还有如 TinyJPG 的在线工具，以及桌面应用程序如 ImageOptim (Mac) 和 RIOT (Windows)都可以用来压缩图片。在 Photoshop 里，可以通过在“导出”中选择“元数据：无”或“存储为 Web 所用格式（旧版）”来完成压缩。模糊图像或图像部分区域也会产生较小的文件可在此处查看。 请注意，由于 JPEG 的有损方式，即使以 100％ 的质量保存相同的文件，因为压缩算法会在同一图像上一次又一次地应用，多次之后也会导致图像质量的降低。但这一变化可能不会显示在文件大小的改变上。 PNG 可移植网络图形（Portable Network Graphics）也是一种自 1995 年以来就一直存在的光栅图像格式。它与 JPEG 不同，因为它是一种无损格式，并且是目前网络上最常见的无损格式。这意味着由于它的压缩算法，当文件被保存和压缩时，不会丢失任何信息。 PNG 有很多很酷的特性，如： Alpha 透明度——意味着每个像素可以具有不同的透明度； 8 位文件可以使用基于调色板的颜色模型（也称为索引颜色）——这意味着如果减少颜色数量，文件可能更小； 依据 libPNG 的说法，PNG 压缩效率比 GIF 高 25％； 二维隔行扫描——图像会在加载过程中逐步显现，而不是只有当图像完全加载时，才能显示图像。必须谨慎使用此选项，因为它会增加文件大小。 有关 PNG 更多特性、历史和技术信息的完整列表，请查看 libpng 的页面。 PNG 的用途 PNG 对于线条图，徽标，图标和只有几种颜色的图像非常好用。另一方面，用在大量颜色的照片和图像时，将生成巨大的文件。PNG 的另一个好用的地方是透明背景。在这种情况下，即使是复杂的图片仍然可以使用 PNG，因为 JPEG 中不存在透明度功能。 PNG 可以很好地用在线条作品，徽标和图标上。 (漫画作者：xkcd) 压缩 PNG 因为 PNG 中的压缩算法是无损的，你可以选择性地减少它的颜色，从而通过外部工具减小图片尺寸。 Pngquant 就是一个很好的工具，它可以在保持 Alpha 水平的同时减少文件大小。请注意，这一过程会创建一个 8 位文件，即该文件最多可以有 256 种颜色。可能看起来不多，但是用这么多颜色足以获得很好的效果。 左边的 24 位图像 (149 KB) 和右边 8 位，256 色图像 (54 KB)——缩小了 63.7% 对于大多数 PNG 使用场景（线图，图形，图标），256色是足够的。因此，可以通过减少调色板中的颜色数量来进一步减少文件大小。 使用 GUI 工具是个不错的选择，如 Pngyu 或 ImageAlpha，这些工具允许你预览生成的文件。 下面的例子显示了如何在不会显著影响质量的前提下，将调色板减少到 32 种颜色。在类似的例子中，图像很难被自动化地压缩——因为需要不断预览和测试来达到最佳效果——同时使用最少的颜色和产生最小的文件尺寸。就像 JPEG 一样，也有用于压缩 PNG 的在线工具，如：TinyPNG。 在这个示例中，徽标可以从原始的 24 位 PNG（10 KB）减少到 8 位，32 色版本（2 KB，缩减 80％），并且没有丢失任何明显的细节。 GIF 图形交换格式（Graphics Interchange Format）也是一种位图格式，并且比本文中提到的其它格式都出现地更早。它在 1989 年由 Steve Wilhite 创建, 它在 PNG 创建前都是最流行的 8 位图像格式。GIF 与 PNG 具有类似的特性，但有一些缺点： 仅支持 256 种颜色； 一维交错——图像边加载边现实，但不够平滑； 与 PNG 相比压缩性差； “非此即彼”透明度——像素只能是 100％ 透明或 100％ 可见； 有歧义的发音？ SVG 可伸缩矢量图形（Scalable Vector Graphics）与前面的两个栅格格式不同，顾名思义，它是矢量格式。这意味着它不会存储基于像素的数据，而是协调生成图形的信息。 SVG 矢量使用带有标签的基于 XML 的结构，就像 HTML 一样。由于此标签结构，你可以通过 ID 识别 SVG 元素，并操纵它们。这带来了很多可能性，例如使用 JavaScript 和 CSS 修改和动画化元素或创建响应式图形。 请看这个例子：#1 – 咖啡机 – CSS3制作SVG动画 ，作者乔纳森·席尔瓦（Jonathan Silva）(@jonathansilva) 发表于 CodePen。 就像其它矢量格式，SVG 图片能不丢失任何细节或像素化地放大到任何大小。打个比方，同一个图标，可以以多种尺寸使用，并且在任何屏幕分辨率（比如 Retina 显示器）中都将看起来很清晰，而不需要存成多个文件。 矢量图片（右）能够在保持图片的质量的前提下任意放大。 SVG 的用途 SVG 在线条艺术，标志，图标，插画和数据可视化方面发挥出色。但它不适用于写实图像和有许多细节的复杂图片。在一些情况下，SVG 和 PNG 都能很好地达到同一个目的。对于线条艺术，SVG 通常能生成较小的文件。但是这不是必然的，实际情况会根据矢量图像究竟有多少个锚点，它甚至可能会生成比 PNG 更大的文件。 SVG 真正出色的地方是数据可视化。由于可以使用 JavaScript 来操纵和创建矢量动画，诸如 D3 之类的库提供了无限的可能性。 徽标，图标和数据可视化是 SVG 使用的优秀范例。 压缩 SVG 大多数情况下，在网页上使用工具如 SVGz（GZipped SVG）来压缩 SVG 文件是不必要的。你可以（并且应该）在服务器上应用此 Gzipping，但也是多此一举。能做的应该是通过清除 SVG 文件里矢量图形中不必要的锚点、元素和属性来减少文件大小。锚点绘制了矢量图像，因此，你需要确保已移除的锚点不会影响矢量图形的最终形状。如果您使用 Adobe Illustrator 编辑 SVG，请确保使用 导出&gt;导出为... 而不是 文件&gt;另存为... 进行保存，因为这样才能生成一个最小化的文件，其它优点。在 Sketch 里, 注意不要使用不必要的文件夹，因为它们也会作为额外的标签被 SVG 保存。 清理不必要的节点是缩减 SVG 尺寸的一种途径。 元素是包含在 SVG 文件内的所有内容，包括开始和结束标签。矢量编辑软件，如 Adobe Illustrator 和 Sketch 可能会到处含有非必要元素和属性的 SVG。SVG 压缩器可用于删除这种多余的信息。Compressor 和 SVGOMG 等在线工具可以完成此工作。如果你是开发人员，而且不习惯清理和压缩 SVG，可以用自动执行工具 SVGO，如果你是设计师，请与该项目的开发人员谈谈 SVG 的最小化，以避免进行将这一项可以轻松自动化的工作手动完成。 在下面的例子里，这个从 Sketch 里导出的图标有 1,364 B。同一个图标在清理和压缩后，就只剩 460 B——缩小了 66%。 请看这个例子：来自 Sketch 的 SVG 作者布鲁诺·穆勒（Bruno Müller）(@brunomuler) on CodePen。 对比：优化后的 SVG。 文末思考 如同任何其他技术一般，图像格式也在不断发展。作为网页设计师和开发人员，我们的主要限制是浏览器支持。几年前，在 IE6 为主流浏览器的时代，PNG 还不能使用 Alpha 透明度。在不久的将来，也许我们会使用新的格式，如 Google's Webp 或者其它仍未被创建出来的图片格式。 了解如何使用和优化每种图片格式将确保更好的用户体验。因为用户将能够更早地预览和接收内容，减少带宽的使用。它还将为设计人员提供了动画和响应式页面的新机会。 我希望这篇文章有助于澄清一些网络上关于图像格式的诸多不确定性的问题。如果你还有任何问题或建议，请在下方发表评论或与我联系。另外，如果觉得本文对你有帮助，不要忘了分享。 ","link":"https://faded.auspicious.space/post/jpg-png-gif-and-svg-on-the-web-a-beginner-guide/"},{"title":"进程间通信—IPC","content":" 看图理解进程间通信IPC 什么是进程间通讯 进程间通信（Inter-Process Communication 或 Interprocess Communication，简写 IPC）是指两个或两个以上进程（或线程）之间进行数据或信号交互的技术方案。 通常，IPC 一般包含客户端和服务器，客户端请求数据，服务器响应请求（比如分布式计算中就是这样）。 有哪些 IPC 方法 IPC 方法适用的环境 IPC 方法 操作系统或环境 文件（File） 多数操作系统 信号（Singal） 多数操作系统 套接字（Socket） 多数操作系统 Unix 域套接字（Unix domain socket） 所有 POSIX 操作系统 消息队列（Message queue） 多数操作系统 管道（Pipe） 所有 POSIX 系统，Windows 命名管道（Named pipe 或 FIFO） 所有 POSIX 系统，Windows，Amiga OS 2.0+ 共享内存（Shared memory） 所有 POSIX 系统，Windows 消息传递（Message passing） 用于 RPC、RMI、MPI 规范、Java RMI、CORBA、DDS、MSMQ、MailSlots、QNX 等 内存映射文件（Memory-mapped file） 所有 POSIX 系统，Windows 文件（File） 存储在磁盘上的记录，或由文件服务器按需合成的记录，可以由多个进程访问。 信号（Signal） 系统消息从一个进程发送到另一个进程，一般不用于传输数据，而是用于远程传输命令。 套接字（Socket） 通过网络接口将数据量发送到本机的不同进程或远程计算机。 Unix域套接字（Unix domain socket） 用于在同一台机器上运行的进程之间的通信。虽然因特网域套接字可用于同一目的，但 Unix 域套接字的效率更高。Unix 域套接字仅仅复制数据；它们并不执行协议处理，不需要添加或删除网络报头，无需计算检验和，不要产生顺序号，无需发送确认报文。 消息队列（Message queue） 类似于套接字的数据流，但消息有自己的结构，它允许多个进程只需要读写消息队列，而不需要直接相互连接。 管道（Pipe） 管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 命名管道（Named pipe 或 FIFO） 命名管道可在同一台计算机的不同进程之间或在跨越一个网络的不同计算机的不同进程之间，支持可靠的、单向或双向的数据通信。 共享内存（Shared memory） 允许多个进程访问同一个内存块，该内存块作为一个共享缓冲区，供进程间相互通信。 消息传递（Message passing） 一般在并发模型中，允许多个程序使用消息队列或者托管通道通信。 内存映射文件（Memory-mapped file） 类似于标准的文件，内存映射文件映射到 RAM，可以直接对内存地址进行更改，而不是更改输出流。 ","link":"https://faded.auspicious.space/post/inter-process-communication/"},{"title":"MBR、开机流程与主引导分区","content":" MBR、开机流程与主引导分区 预备知识 CMOS：主板上记录了硬件参数的储存器。 BIOS：写入到主板 ROM 中的程序，开机时执行的第一个程序。 MBR：可引导设备的第一个扇区（一般情况下是硬盘中的第一扇区）中的主引导分区。 Boot loader：读取操作系统内核文件来执行的程序。 开始 学过计算机的肯定都知道操作系统是一个软件，我们平时用的软件都是基于操作系统提供的接口运行的。那么操作系统又是怎么运行的呢？ Step 1: BIOS 在预备知识中我们就知道了，开机运行的第一个程序就是 BIOS，那么开机引导操作系统的切入点也肯定是它了。 BIOS 识别 CMOS 读取硬件信息，从中找出可开机设备，一般自然是硬盘了。 当然，可开机设备不一定是硬盘，或者说你有两个硬盘，这里就不做讨论了。 Step 2: MBR &amp; Boot loader BIOS 找到第一个扇区之后就查找 MBR 的位置，这是最基本的引导程序（Boot loader），这个程序一旦启动，BIOS 的任务才算圆满。 MBR 中的引导程序运行，这个时候用户可以对开机选项进行操作，例如转交引导加载的任务给其他引导程序（之后还会提到）。 Step 3: Operating System 什么都做完了，当然该操作系统登场，负责提供其基本功能。 补充 磁盘分区表 Step 2 中提到了第一个扇区。实际上，这个扇区不止包含 MBR，它还包含了一个分区表，用来对硬盘进行分割，文件系统的最小单位是柱面，所以它是以记录柱面号来分割硬盘的。 例如第一分区是 1~100 柱面，那么分区记录项第一个的内容就是 1 和 100，其他以此类推。 我们所谓的&quot;分区&quot;实际上就是对这个分区表的记录进行修改。 由于分区表只有 64 bytes，所以最多只能有 4 个分区，这四个分区被称为主（Primary）分区。 那么你肯定要有疑问：分区可不一定只有 4 个啊。 是的，这种情况下就有一个相对于主引导分区的概念——扩展（Extended）分区。 如果我们拿主分区的其中一个存放另外一个分区表储存更多的分区信息，那我们就可以拥有更多分区。不是么。有时间理解一下下图吧。 这里需要注意的地方是，如果有 4 个主分区，我们就再也没有办法存放另外的分区信息，所以一般情况下会留下一个分区存放扩展分区信息，主分区因此最多只有 3 个。 扩展分区只能有一个（操作系统限制），扩展分区持续切割，形成新的分区，这就是逻辑分区（logical partition）。我们平时能作为数据访问的分区是主分区和逻辑分区，扩展分区不能格式化。 多重引导 这里需要说明一下，每个分区都拥有自己的启动扇区，可以用来存放引导程序，并且该引导程序可以将管理权交给另一引导程序（其他分区的引导扇区）或者自己引导所在的分区，是的，可开机的内核文件不是在引导扇区内，而是在各分区内。 意思就是，你可以引导不止一种操作系统，根据你在 boot menu 的选择，可以引导任何在 MBR 指向中的系统。 Linux 安装的时候可以选择安装在分区的启动扇区，或者 MBR，Linux 的 Loader 可以手动转换引导程序。 Windows 会覆盖掉 MBR 和自己所在的分区。你没有办法保留之前 MBR 中对 Linux 引导程序的指向。 上述两个原因表明了为何需要先安装 Windows 操作系统，再安装 Linux，否则将不会在开机的时候看到 Linux 引导选项。 GUID 分区方案 相对于 MBR 分区方案，GUID有以下优点： 支持 2TB 以上的大硬盘。 每个磁盘的分区个数几乎没有限制。为什么说“几乎”呢？是因为 Windows 系统最多只允许划分 128 个分区。不过也完全够用了。 分区大小几乎没有限制。又是一个“几乎”。因为它用 64 位的整数表示扇区号，即 0 ~18,446,744,073,709,551,616。夸张一点说，一个 64 位整数能代表的分区大小已经是个“天文数字”了，若干年内你都无法见到这样大小的硬盘，更不用说分区了。 分区表自带备份。在磁盘的首尾部分分别保存了一份相同的分区表。其中一份被破坏后，可以通过另一份恢复。 每个分区可以有一个名称（不同于卷标）。 GUID 扩展了分区表头，并且兼容了 MBR（第一扇区还是留有 MBR 的空间，为了兼容不支持 GUID 的硬盘），分区信息存放于分区表中，由 GUID HEADER 中的信息标识引导程序 efi 所在的分区。 开机过程（以下是我个人的理解，欢迎指正）： BIOS 过程同 MBR 分区方案一致。 之后在 GUID HEADER 中查找 .efi 引导程序。 主引导程序扫描所有分区的引导扇区并运行其中的分区引导程序。 分区引导程序读取分区内容并引导操作系统。 ","link":"https://faded.auspicious.space/post/mbr-and-boot-loader/"},{"title":"如何优雅地链式取值","content":" 如何优雅地链式取值 开发中，链式取值是非常正常的操作，如： res.data.goods.list[0].price 但是对于这种操作报出类似于 Uncaught TypeError: Cannot read property 'goods' of undefined 这种错误也是再正常不过了，如果说是 res 数据是自己定义，那么可控性会大一些，但是如果这些数据来自于不同端（如前后端），那么这种数据对于我们来说我们都是不可控的，因此为了保证程序能够正常运行下去，我们需要对此校验： if (res.data.goods.list[0] &amp;&amp; res.data.goods.list[0].price) { // your code } 如果再精细一点，对于所有都进行校验的话，就会像这样： if (res &amp;&amp; res.data &amp;&amp; res.data.goods &amp;&amp; res.data.goods.list &amp;&amp; res.data.goods.list[0] &amp;&amp; res.data.goods.list[0].price){ // your code } 不敢想象，如果数据的层级再深一点会怎样，这种实现实在是非常不优雅，那么如果优雅地来实现链式取值呢？ optional chaining 这是一个出于 stage 2 的 ecma 新语法，目前已经有了 babel 的插件 babel-plugin-transform-optional-chaining，这种语法在 swift 中有，可以看下官方给的实例： a?.b // undefined if `a` is null/undefined, `a.b` otherwise. a == null ? undefined : a.b a?.[x] // undefined if `a` is null/undefined, `a[x]` otherwise. a == null ? undefined : a[x] a?.b() // undefined if `a` is null/undefined a == null ? undefined : a.b() // throws a TypeError if `a.b` is not a function // otherwise, evaluates to `a.b()` a?.() // undefined if `a` is null/undefined a == null ? undefined : a() // throws a TypeError if `a` is neither null/undefined, nor a function // invokes the function `a` otherwise 通过函数解析字符串 我们可以通过函数解析字符串来解决这个问题，这种实现就是 lodash 的 _.get 方法。 var object = { a: [{ b: { c: 3 } }] }; var result = _.get(object, 'a[0].b.c', 1); console.log(result); // output: 3 实现起来也非常简单，只是简单的字符串解析而已： function get (obj, props, def) { if((obj == null) || obj == null || typeof props !== 'string') return def; const temp = props.split('.'); const fieldArr = [].concat(temp); temp.forEach((e, i) =&gt; { if(/^(\\w+)\\[(\\w+)\\]$/.test(e)) { const matchs = e.match(/^(\\w+)\\[(\\w+)\\]$/); const field1 = matchs[1]; const field2 = matchs[2]; const index = fieldArr.indexOf(e); fieldArr.splice(index, 1, field1, field2); } }) return fieldArr.reduce((pre, cur) =&gt; { const target = pre[cur] || def; if(target instanceof Array) { return [].concat(target); } if(target instanceof Object) { return Object.assign({}, target) } return target; }, obj) } var c = {a: {b : [1,2,3] }} get(c ,'a.b') // [1,2,3] get(c, 'a.b[1]') // 2 get(c, 'a.d', 12) // 12 使用解构赋值 这个思路是来自 github 上 You-Dont-Need-Lodash-Underscore 这个仓库，看到这个的时候真的佩服。 const c = {a:{b: [1,2,3,4]}} const { a: result } = c; // result : {b: [1,2,3,4]} const {a: { c: result = 12 }} = c // result: 12 当然，这个时候为了保证不报 uncaught Typeerror，我们仍然需要定义默认值， 就像这样, 貌似如果不加 lint 可读性堪忧。 const {a: {c: {d: result2} = {}}} = c 使用 Proxy 这个是组内同事提到的，一个简单实现如下： function pointer(obj, path = []) { return new Proxy(() =&gt; {}, { get (target, property) { return pointer(obj, path.concat(property)) }, apply (target, self, args) { let val = obj; let parent; for(let i = 0; i &lt; path.length; i++) { if(val === null || val === undefined) break; parent = val; val = val[path[i]] } if(val === null || val === undefined) { val = args[0] } return val; } }) } 我们可以这样使用： let c = {a: {b: [1, ,2 ,3]}} pointer(c).a(); // {b: [1,2,3]} pointer(c).a.b(); // [1,2,3] pointer(d).a.b.d('default value'); // default value 这差不多就是心中所谓的优雅了。 综上，在实际工作中，使用方法四会是最优雅，可读性也非常强，但考虑到浏览器的话，可能方法二会更加常用，当然，如果你所要取的值层级不是太深，你组内的同事要严格的 lint，方法三也不失为一种好的选择。 ","link":"https://faded.auspicious.space/post/how-to-elegantly-optional-chaining/"},{"title":"& * # 这三个是什么符号？","content":"&amp; 这个符号的名字是 ampersand，含义就是“and”。听到这个词，要意识到老师在说啥。 * 这个符号的名是 asterisk，一种符号，在文章中一般表示，底下有脚注。 # 这个符号的名字是 hash，是不是很难受的感觉，在英文里的意思是表示数字，比如我家住 18 号 401，写地址可以写成 #18, 401，另外在美国还用于表示磅这个重量单位，比如 2# of sugar，大概两斤糖； ～ 这个符号的名字最难找，叫 tilde，从西班牙语或者葡萄牙语过来的名字，参看维基百科； ` 这个符号，我一般念做 back tick，不过我也没查到，我看百科里叫 back quote； ^ 这个符号，叫 caret，在 ASCII 里面是一个Space Symbol。 ","link":"https://faded.auspicious.space/post/names-of-three-sign/"},{"title":"TCP——套接口编程","content":" 值得收藏的TCP套接口编程文章 TCP 客户端-服务器典型事件 下图是 TCP 客户端与服务器之间交互的一系列典型事件时间表： 首先启动服务器，等待客户端连接。 启动客户端，连接到服务器。 客户端发送一个请求给服务器，服务器处理请求，响应客户端。 循环步骤3。 客户端给服务器发一个文件结束符，关闭客户端连接。 服务器也关闭连接。 套接口编程基本函数 socket 函数 为了执行网络 I/O，一个进程（无论是服务端还是客户端）必须做的第一件事情就是调用 socket 函数。 #include &lt;sys/socket.h&gt; /* basic socket definitions */ int socket(int family, int type, int protocol);/* 返回：非负描述字——成功，-1——出错 */ family——协议族 族 解释 AF_INET IPv4 协议 AF_INET6 IPv6 协议 AF_LOCAL Unix 域协议 AF_ROUTE 路由套接口 AF_KEY 密钥套接口 type——套接口类型 类型 解释 SOCK_STREAM 字节流套接口 SOCK_DGRAM 数据报套接口 SOCK_RAW 原始套接口 有效的 family 和 type 组合（简略版） AF_INET AF_INET6 SOCK_STREAM TCP TCP SOCK_DGRAM UDP UDP SOCK_RAW IPv4 IPv6 socket 函数返回一个套接口描述字，简称套接字（sockfd）。获取套接字无需指定地址，只需要指定协议族和套接口类型（如上表中的组合）。 connect 函数 TCP 客户用 connect 函数来建立一个与 TCP 服务器的连接。 #include &lt;sys/socket.h&gt; /* basic socket definitions */ int connect(int sockfd, const struct sockaddr * servaddr, socklen_t addrlen);/* 返回：0——成功，-1——出错 */ 参数 sockfd 便是 socket 函数返回的套接口描述字。 套接口地址结构 servaddr 必须包含服务器的 IP 地址和端口号。 客户端不必非要绑定一个端口（调用 bind 函数），内核会选择源 IP 和一个临时端口。 connect 函数会触发 TCP 三次握手。有可能出现下面的错误情况： 客户端未收到 SYN 分节的响应： 第一次发出未收到，间隔 6s 再发一次，再没收到，隔 24s 再发一次，总共等待 75s 还没收到则返回错误（ETIMEDOUT）。可以用时间日期程序验证一下： 查看本地网络信息： JACKIELUO-MC0:intro jackieluo$ ifconfig en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 ether f4:0f:24:2a:72:a6 inet6 fe80::1830:dbd:1b29:2989%en0 prefixlen 64 secured scopeid 0x6 inet 192.168.0.101 netmask 0xffffff00 broadcast 192.168.0.255 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect status: active 将程序指向本地地址 192.168.0.101（确保时间日期服务器程序已运行），成功： JACKIELUO-MC0:intro jackieluo$ ./daytimetcpcli 192.168.0.101 Sat Oct 6 17:06:55 2018 将程序指向本地子网地址 192.168.0.102，其主机ID（102）不存在，等待几分钟后超时返回： JACKIELUO-MC0:intro jackieluo$ ./daytimetcpcli 192.168.0.102 connect error: Operation timed out 收到 RST： 即服务器主机在指定端口上没有等待连接的进程，这称为“hard error”，客户端一接收到 RST，马上返回错误（ECONNREFUSED）。验证： 关闭之前本机运行的 daytimetcpsrv 进程 将程序指向本地地址192.168.0.101： JACKIELUO-MC0:intro jackieluo$ ./daytimetcpcli 192.168.0.101 connect error: Connection refused 发出的 SYN 在路由器上引发了目的不可达 ICMP 错误： 这个错误被称为“soft error”，最终返回 EHOSTUNREACH 或者 ENETUNREACH。 bind 函数 函数 bind 为套接口分配一个本地协议地址，包括 IP 地址和端口号。 #include &lt;sys/socket.h&gt; /* basic socket definitions */ int bind(int sockfd, const struct sockaddr * servaddr, socklen_t addrlen);/* 返回：0——成功，-1——出错 */ 客户端可以不调用这个函数，由内核选择一个本地 IP 的临时端口就好。 服务器一般都会调用 bind 函数绑定 IP 地址和端口，供客户端调用。一个例外是 RPC（远程过程调用）服务器，它由内核为其选择临时端口。然后通过 RPC 端口映射器进行注册，客户端与该服务器连接之前，先通过端口映射器获取服务器的端口。 进程可以把一个特定的 IP 地址捆绑到它的套接口上。对于客户端，它发送的请求，源IP地址就是这个地址；对于服务器，如果绑定了 IP 地址，则只接受目的地为此 IP 地址的客户连接。 如果服务器不把 IP 地址绑定到套接口上，那么内核把客户端发送 SYN 所在分组的目的 IP 地址作为服务器的源 IP 地址。（即服务器收到 SYN 的 IP） 给函数 bind 指定用于捆绑的 IP 地址和 / 或端口号的结果： IP地址 端口 结果 0 内核选择 IP 地址和端口 非 0 内核选择 IP 地址，进程指定端口 本地 IP 地址 0 进程选择 IP 地址，内核指定端口 本地 IP 地址 非 0 进程选择 IP 地址和端口 listen 函数 函数 listen 仅被 TCP 服务器调用。 #include &lt;sys/socket.h&gt; /* basic socket definitions */ int listen(int sockfd, int backlog);/* 返回：0——成功，-1——出错 */ 调用函数 socket 函数创建的套接口，默认是主动方，下一步应是调用 connect，CLOSED 的下一个状态是 SYN_SENT（见 TCP 状态转换图）。而函数 listen 将套接口转换成被动方，告诉内核，应接受指向此套接口的连接请求，CLOSED 状态变成 LISTEN。 函数 listen 的第二个参数 backlog 表示内核为此套接口排队的最大连接数。对于给定的监听套接口，内核会维护两个队列： 未完成连接队列（incomplete connection queue）SYN 分节已由客户发出，到达服务器，正在进行 TCP 的三路握手。此时这些套接口处于 SYN_RCVD 状态。 已完成连接队列（completed connection queue）SYN 分节已由客户发出，到达服务器，并且已完成三路握手。此时这些套接口处于 ESTABLISHED 状态。 当来自客户的 SYN 到达时，TCP 在未完成连接队列中创建一个新条目，直到三路握手中，第三个分节（客户对服务 SYN 的 ACK）到达，这个条目移到已完成连接队列的队尾。 当进程调用 accept 函数时，已完成连接队列的头部条目返回给进程。 两个队列之和不能超过 backlog。 当一个客户 SYN 到达时，若这两个队列都是满的，TCP 就忽略此分节，且不发送 RST。客户 TCP 将重发 SYN，期望不久就能在队列中找到空闲位置。 TCP 为监听套接口维护的两个队列。 accept 函数 函数 accept 由 TCP 服务器调用，从已完成连接队列头部返回下一个已完成连接，若该队列为空，则进程睡眠（假定套接口为默认的阻塞方式）。 #include &lt;sys/socket.h&gt; /* basic socket definitions */ int accept(int sockfd, struct sockaddr *cliaddr, socklen_t *addrlen);/* 返回：非负描述字——成功，-1——出错 */ 函数 accept 的第一个参数和返回值都是套接口描述字。其中， 第一个参数，称为监听套接口描述字，即由函数 socket 返回，也用于 bind，listen 的第一个参数。 返回值，称为已连接套接口描述字。 通常一个服务器，只生成一个监听套接口描述字，直到其关闭。而内核为每个被接受的客户连接，创建一个已连接套接口，当客户连接完成时，关闭该已连接套接口。 注意到 intro/daytimetcpsrv.c 中，后两个参数传的都是空指针，这是因为我们不关注客户的身份，无需知道客户的协议地址。 connfd = Accept(listenfd, (SA *) NULL, NULL); 稍作修改，不再传入空指针，见 intro/daytimetcpsrv1.c： socklen_t len; struct sockaddr_in servaddr, cliaddr; ... connfd = Accept(listenfd, (SA *) &amp;cliaddr, &amp;len); printf(&quot;connection from %s, port %d\\n&quot;, Inet_ntop(AF_INET, &amp;cliaddr.sin_addr, buff, sizeof(buff)), ntohs(cliaddr.sin_port)); kill 掉之前的 daytimetcpsrv 进程： $ sudo lsof -i -P | grep -i &quot;listen&quot; daytimetc 80986 root 3u IPv4 0xae12d925e4528793 0t0 TCP *:13 (LISTEN) $ sudo kill -9 80986 编译运行新的服务端程序： $ make daytimetcpsrv1.c daytimetcpsrv1 $ ./daytimetcpsrv1 重复执行客户端程序，发几个请求： $ ./daytimetcpcli 127.0.0.1 Wed Sep 26 14:11:20 2018 $ ./daytimetcpcli 127.0.0.1 Wed Sep 26 14:17:06 2018 查看服务端打印： connection from 127.0.0.1, port 58201 connection from 127.0.0.1, port 58342 注意到，由于客户端程序没有调用 bind 函数，内核为它的协议地址选择了源 ip 作为 IP 地址，临时端口号也发生了变化。 fork 和 exec 函数 #include &lt;unistd.h&gt; pid_t fork(void);/* 返回：在子进程中为0，在父进程中为子进程ID，-1——出错 */ fork 函数调用一次，却返回两次。 在调用它的进程（即父进程），它返回一次，返回值是派生出来的子进程的进程 ID。 父进程可能有很多子进程，必须通过返回值跟踪记录子进程 ID。 在子进程，它还返回一次，返回值为 0。 子进程只有一个父进程，总可以通过 getppid 来得到父进程的 ID。 通过返回值可以判断当前进程是子进程还是父进程。 父进程在调用 fork 之前打开的所有描述字在函数 fork 返回后都是共享的。网络服务器会利用这一特性： 父进程调用 accept。 父进程调用 fork，已连接套接口就在父进程与子进程间共享。（一般来说就是子进程读、写已连接套接口，而父进程关闭已连接套接口）。 fork 有两个典型应用： 一个进程为自己派生一个拷贝，并发执行任务，这也是典型的并发网络服务器模型。 一个进程想执行其他的程序，于是调用 fork 生成一个拷贝，利用子进程调用 exec 来执行新的程序。典型应用是 shell。 以文件形式存储在硬盘上的可执行程序若要被执行，需要由一个现有进程调用 exec 函数。我们将调用 exec 的进程称为调用进程，新程序的进程 ID 并不改变，仍处于当前进程。 小结 客户和服务器，从调用 socket 开始，返回一个套接口描述字。客户调用 connect，服务器调用 bind、listen、accept。最后套接口由 close 关闭。 多数 TCP 服务器是调用 fork 来实现并发处理多客户请求的。多数 UDP 服务器则是迭代的。 ","link":"https://faded.auspicious.space/post/tcp-suite-programming/"},{"title":"Git——超详实教程与命令大全","content":" 超详实Git简明教程与命令大全 Git（wiki: en chs ）是一个免费开源的分布式版本控制系统，由 Linux 内核作者 Linus Torvalds 开发，大型开源项目 Linux Kernel、Android、Chromium、Mono、DotNet、UE4 等都使用 Git 管理项目著名 github 网站使用 Git 托管所有项目代码，Git 的代码也托管在 github 上，链接为：github.com/git 与集中式版本控制系统（开源软件：SVN；免费软件：CVS；商业软件：微软的 VSS、IBM 的 Rational ClearCase）相比。 Git 优点： 本地是版本库的完整镜像，因此支持离线工作； 绝大多数操作都只需要访问本地文件和资源，而且与每个提交都是所有文件的完整副本，因此速度非常快； 强大快捷的分支功能，非常适合非线性开发过程。 Git 缺点： 只能全量整体，而不能以子目录和分支为单位进行更新、提交等操作； 子目录和分支不能单独进行权限控制； 由于每个提交都是所有文件的完整副本，因此更占磁盘空间。 注：SVN 等集中式版本控制系统存储每个文件与初始化版本的差异。 注：Git 每个提交都是所有文件的完整副本，使得 Git 在回溯到某个提交时，不会对所有文件执行差异计算还原，因此速度会非常快。 这使得源代码、配置文件等更适合用 Git 来管理，而资源等较大的二进制文件则容易导致版本库体积膨胀。 在项目实践中，对于资源等较大的二进制文件可以采用 Git-LFS 来管理，UE4 则是使用自己开发的 GitDependencies 来管理。 基本概念 origin：默认远程版本库名。 master：默认分支名。 origin/master：远程默认分支名。 HEAD：当前分支顶端 Commit 的别名，即当前分支最近的一个提交的 SHA-1 哈希值。 ORIG_HEAD：上次 HEAD 指针的位置。注：当执行 git reset / git pull / git merge 命令时，git 会把老的 HEAD 拷贝到文件 .git/ORIG_HEAD 中，在后续命令中可以使用 ORIG_HEAD 引用这个提交。 commit（提交）：每个 commit 都是全部文件的完整快照，并用一个 commitID（基于文件的内容或目录结构计算出来的 40 位十六进制的 SHA-1 哈希值） 来唯一标志。从某个角度上来说，Git 维护的就是一个 commitID 有向无环图。 detached HEAD：HEAD 没有指向任何分支的状态。一般有以下几种情况会出现这种情况： 使用 checkout 命令跳到某个没有分支指着的 commit 时； rebase 处理冲突时所处的状态； 切换到某个远程分支 cache 上时。 在 Git 中，在执行命令时，一定要清楚：你在哪？对谁执行这个命令？ 本文使用 git 版本为：git version 2.13.0.windows 运行命令行建议使用：git bash（可通过右键菜单 Git Bash here 来启动），主要有3个原因： 在 Windows 的 cmd 下执行 git log 等需要显示多页内容的命令时，会导致 cmd 卡死（有时按 Q 键也没法退出）； git bash 中可以使用 MinGW 中自带的 Linux 环境下常用的命令工具； git bash 着色做得更好，利于阅读。 图解常见操作 Working Directory：即工作区。操作系统层面的目录树结构，也可以理解为一个 tree 目录对象。 Stage(Index)：即暂存区，为等待 Commit 的文件列表。是以扁平的文件清单实现的，不过从理解层面上也可以理解为 tree 目录对象。 Local Repository(History)：本地版本库。有向无环图，其每一个节点都是一个 tree 目录对象。 Remote Repository：远程版本库。有向无环图，其每一个节点都是一个 tree目录对象。 注：图中 git checkout -- &lt;file&gt; 1、2 步骤的含义是当在暂存区中有修改时，优先使用暂存区中的修改覆盖工作区。 SVN 命令对比一览 svn git 说明 svn checkout git clone 检出项目 svn update git fetchgit pull 更新 svn commit git commitgit push 提交 svn add git add 添加 svn mv git mv 移动 svn rm git rm 删除 svn status git status 查看状态 svn log git log 查看 log svn diff git diff 查看差异 svn revert git checkoutgit resetgit revert 撤销、丢弃修改 svn copy git checkout -b/-Bgit branch 创建分支 svn switch git checkout 切换分支 svn copy git tag 创建tag svn merge git mergegit rebase 分支合并 文件存储机制 Git 存储使用的是一个内容寻址的文件系统，其核心部分是一个简单的键值对（key-value）数据库，当向数据库中插入任意类型的内容，它会返回一个 40 位十六进制的 SHA-1 哈希值用作索引。在版本库中，Git 维护的数据结构有：以下 4 种对象及索引，并通过保存 commitID 有向无环图的 log 日志来维护与管理项目的修订版本和历史信息。 blob — 1 个 blob 保存 1 个文件的 1 个版本的数据。 tree — 表示 1 个目录，记录着目录里所有文件 blob 哈希值、文件名子目录名及其他元数据。通过递归引用其他目录树，从而建立一个包含文件和子目录的完整层次结构。 commit — 1 个提交对象保存版本库中每一次变化的元数据，每个提交对象指向一个版本的 git 目录树对象。 tag — 分为轻量标签和附注标签。轻量标签实际上是一个特定提交的引用，附注标签是存储在 git 中的一个完整可被校验的对象（保存在 .git/refs/tags 中），还包含打标签者的名字、E-mail、日志、注释等信息。 git 使用 zlib 将头部信息（对象类型：blob 或 tree 或 commit + 1 个空格 + 数据内容长度 + 1 个空字节）和对象数据拼接一起的内容进行压缩存储成一个文件。 压缩的文件被十六进制的 SHA-1 哈希值命名，该文件可以用 pigz.exe -dz &lt;文件路径&gt; 来解压查看。注：Windows 版的 pigz.exe 可以从这儿下载。 40 位十六进制的 SHA-1 哈希值 = sha1(&quot;blob/tree/commit &quot; + filesize + &quot;\\0&quot; + data)， 如：sha1(&quot;blob 7\\0foobar\\n&quot;) = &quot;323fae03f4606ea9991df8befbb2fca795e648fa&quot; 注：\\n 的二进制为 0a。 底层命令—剖析 Git 对象 find .git/objects -type f // 用 find 命令查看 .git/objects 目录（递归子目录）中的所有文件。 git rev-list --objects --all // 查看所有 git 对象的 SHA-1 哈希值与文件名的对应关系。 git rev-list --objects --all | grep 83c4fbc43a6f187d4e8a247a1c9aced872b2315d // 查看 SHA-1 哈希值为 83c4fbc43a6f187d4e8a247a1c9aced872b2315d 的文件名。 echo &quot;Hello World!&quot; | git hash-object --stdin // 计算内容为 Hello World! 文件的 SHA-1 哈希值。 echo &quot;Hello World!&quot; | git hash-object -w --stdin // 计算内容为 Hello World! 文件的 SHA-1 哈希值并写入到当前 git 本地版本库中。 git hash-object README.txt // 查看 README.txt 的 SHA-1 哈希值。 git hash-object -w README.txt // 查看 README.txt 的 SHA-1 哈希值并写入到当前 git 本地版本库中。 git cat-file -p master^^{tree} // 查看 master 分支 HEAD 指针 git 目录（tree 对象）下的各子目录（tree 对象）和文件（blob 对象）的 SHA-1 哈希值。 100644 blob 7abd3a56703ad4a7120571967f5d06607b5e5502 README.txt 040000 tree 9f448c40e684dc38109574007c661277c815fb7e ss 注：040000：表示目录；100644：表示一般文件；100755：表示可执行文件；120000：表示符号链接。 git cat-file -p 7abd3a56703ad4a7120571967f5d06607b5e5502 // 查看 SHA-1 哈希值为 7abd3a56703ad4a7120571967f5d06607b5e5502 文件的内容。 git show 7abd3a56703ad4a7120571967f5d06607b5e5502 // 查看 SHA-1 哈希值为 7abd3a56703ad4a7120571967f5d06607b5e5502 文件的内容。 git cat-file -t f3961f5 // 查看 f3961f5 提交对象的类型：显示为 commit。 git cat-file -p f3961f5 // 查看 f3961f5 提交对象的信息：包含 git 目录（tree 对象）、上次提交对象的 SHA-1 哈希值及提交时 Author、Date 和注释信息。 tree ead34240822030a3f71df4fc351057d80d7d83f8 parent 33d5bbc5d61b024aab5078e40548c4e3da808e0e author nicochen &lt;nicochen@tencent.com&gt; 1537258258 +0800 committer nicochen &lt;nicochen@tencent.com&gt; 1537258258 +0800 123 desc txt git cat-file -p tag1.0 // 查看轻量标签或附注标签 tag1.0 信息。 git cat-file tag tag1.0 // 查看附注标签 tag1.0 信息。 git ls-tree ead34240822030a3f71df4fc351057d80d7d83f8 // 查看 tree 目录对象 ead34240822030a3f71df4fc351057d80d7d83f8 中包含的 blob 文件对象和 tree 目录对象。 git ls-tree HEAD // 查看 HEAD 所指向 tree 目录对象中包含的 blob 文件对象和 tree 目录对象。 git verify-pack -v .git/objects/pack/pack-a9282552b62cbe3f255fbb20374695a17c1ba2a2.idx // 查看pack-a9282552b62cbe3f255fbb20374695a17c1ba2a2.pack 压缩包中的内容。 git update-index n.txt // 将修改状态的 n.txt 文件添加到暂存区。 git update-index --add n.txt // 将未追踪状态或修改状态的 n.txt 文件添加到暂存区。 git update-index --add --cacheinfo 100644 5d11580eed65ffd34b6786274a60460b3582aa7d n.txt // 使用类型为 100644、SHA-1 哈希值为 5d11580eed65ffd34b6786274a60460b3582aa7d 的信息将追踪状态或修改状态的 n.txt 添加到暂存区。 git write-tree // 将整个暂存区内容生成一个 tree 对象，并输出其 SHA-1 哈希值。 echo &quot;add n.txt&quot; | git commit-tree 31b7ca405196ca9e8fb4d5404b315bef9f2c841f -p HEAD // 用 git write-tree 得到的31b7ca405196ca9e8fb4d5404b315bef9f2c841f 树对象创建一个注释为 add n.txt 的提交对象，并将提交对象的父亲设置为当前 HEAD。 git update-ref refs/heads/master 372aa8e425b57ca30e2974b8e7737133caaa0b7f // 若当前分支为 master，更新 HEAD 指向上面 git commit-tree 命令得到的 372aa8e425b57ca30e2974b8e7737133caaa0b7f 提交对象，此时用 git log 就可以看到这条 commit 记录。 git write-tree --prefix=ss // 将暂存区中 ss 目录下的内容生成一个 tree 对象，并输出其 SHA-1 哈希值。 git update-ref -d refs/remotes/origin/v1.0 // 删除 v1.0 远程分支 cache。 git update-index --chmod=+x engine_mac.sh // 为 engine_mac.sh 增加可执行权限（Linux、Unix、Mac OS X 系统上需要）。 命令大全 查看命令帮助 git config --help // 查看 git config 命令详细用法 git help config // 功能同上 配置 git config --global user.name &quot;kekec&quot; // 配置提交用户名。 git config --global user.email &quot;kekec@qq.com&quot; // 配置 E-mail 信息。 git config --global core.editor vim // 配置默认文本编辑器，当 Git 需要你输入信息时会调用它。 git config --global alias.st status // 为 status 配置别名 st，这样 git status 就可以写成 git st。 git config --list // 查看当前仓库的所有配置信息（包括分支相关的信息） git config user.name // 查看当前仓库的用户名信息 git config -e --global // 编辑全局配置文件（用户名和 E-mail 信息就记录在其中） 所在目录：c:/users/&lt;用户名&gt;/.gitconfig。 git config -e // 编辑当前仓库的配置文件 所在目录：.git\\config。 创建版本库 git init // 在当前目录创建一个空的 git 代码库。 git init MyGame // 在当前目录创建一个名为 MyGame 的文件夹，然后在其中创建一个空的 git 代码库。 .git目录结构如下： hooks：不同操作时执行的 hook 脚本。 info/exclude：与 .gitignore 文件（该文件需放在 .git 文件夹的同级目录中，Windows 下可通过命令行 type nul &gt; .gitignore 来创建）一样，用作文件过滤。不同的是：该文件不会提交到版本库，因此过滤只对本地生效，不影响其他人。 # 忽略所有.so 结尾的文件 *.so # 但 game.so 除外 !game.so # 仅仅忽略项目根目录下的 README.md 文件，不包括 subdir/README.md /README.md # 忽略 .svn/ 目录下的所有文件 .svn/ # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt doc/*.txt # 忽略 doc/ 目录下所有扩展名为 txt 的文件 doc/**/*.txt logs/refs/heads：各个本地分支的版本 log 记录。 logs/refs/remotes：各个远程分支 cache 的 log 记录。 logs/refs/stash：储藏区数据。 logs/HEAD：git 操作记录。 objects：2 级文件索引（把 SHA-1 哈希值拆成了：2位+38位），存储 commit 数据、blob 文件数据和 tree 目录数据。 objects/pack：pack 文件为存储 commit、tree 目录及 blob 文件的压缩数据；idx 文件为 pack 文件中各数据对象的索引。 objects/info/packs：该文件记录所有 git 库的 pack 文件列表。 refs/heads：各个本地分支 HEAD。 refs/remotes：各个远程分支 cache 的 HEAD。 refs/tags：各个附注标签的信息。 COMMIT_EDITMSG：上一次提交的注释。 config：版本库相关的配置信息。 description：仓库描述信息，供 gitweb 程序使用。 index：暂存区相关的信息。 HEAD：指向当前分支的最近提交（如：ref: refs/heads/master）。 ORIG_HEAD：执行 git merge / git pull / git reset 操作时，会把调整为新值之前的先前版本的 HEAD 记录到 OERG_HEAD 中，用于恢复或回滚之前的状态。 FETCH_HEAD：git fech 将所有抓取分支的 HEAD 记录到 .git/FETCH_HEAD 中。 MERGEHEAD：正在合并进 HEAD 的 commit id。 packed-refs：远程版本库 cache 和远程标签 cache。 日志与文件状态 git reflog // 查看操作记录。 注：每条操作记录使用 HEAD@{n} 来标识。 git show HEAD@{5} // 查看索引为 5 的操作记录的详细信息。 git status // 查看当前所处的分支暂存区和工作区的文件（会显示当前所处分支）。 注1：处于暂存区的文件状态:：staged（已暂存）；处于工作区的文件状态:：untrack（未跟踪）、modified（已修改）； 注2：工作区中的空目录不会被 git 追踪。 git status -s --ignored // 以简洁模式查看暂存区和工作区的文件（全部显示，不执行文件过滤）。 git status -uno // 查看暂存区和工作区的非 untrack（未跟踪）状态文件。 git status -uall // 查看暂存区和工作区的状态文件（递归子目录显示出里面的文件）。 git log // 查看本地版本库提交记录（会显示当前所处分支，HEAD 指针指向哪个分支的哪条提交）。 git log --stat // 查看本地版本库提交记录（会显示当前所处分支，HEAD 指针指向哪个分支的哪条提交和每次提交的文件变更简略统计信息）。 git log -- README.md // 查看 README.md 文件的本地版本库提交记录。 git log --graph -- README.md // 以图形化方式查看 README.md 文件的本地版本库提交记录。 git log -p README.md // 查看 README.md 文件的本地版本库提交记录（显示出每次的修改内容）。 git log --grep &quot;test&quot; // 显示注释中含有 test 字符串的提交。 git log --author=kekec // 查看本地版本库中作者为 kekec 的提交记录。 git log -S &quot;SplitPath(FString&amp; str)&quot; // 查看 SplitPath(FString&amp; str) 内容是什么时候加到项目中那些文件中去的。 git log --since=2.weeks // 查看最近 2 周的提交记录。 git log --since=&quot;2 weeks 3 days 2 hours 30 minutes 59 seconds ago&quot; // 查看 2 周 3 天 2 小时 30 分 59 秒以前的提交记录。 git log --after=&quot;2018-10-7&quot; --before=&quot;2018-10-12&quot; // 查看 2018.10.7~2018.10.12 之间的提交记录。 git log --since=&quot;2018-10-7&quot; --until=&quot;2018-10-12&quot; // 功能同上：git log --after=&quot;2018-10-7&quot; --before=&quot;2018-10-12&quot;。 注：--since、--until 标记和 --after、--before 标记分别是等价的。 git whatchanged README.md // 查看 README.md 文件的本地版本库提交记录（包括文件改名）。 git log --follow README.md // 功能同上：git whatchanged README.md。 git log -3 // 查看最近 3 条本地版本库提交记录。 git log -3 --pretty --oneline // 查看最近 3 条本地版本库提交记录（简洁模式，一行显示一个提交）。 git log --graph --oneline // 以图形化简洁模式查看当前分支的本地版本库提交记录。 git log release --graph --oneline // 以图形化简洁模式查看 release 分支的本地版本库提交记录。 git log --graph --oneline --no-merges // 以图形化简洁模式查看当前分支的本地版本库提交记录（过滤 merge 过来的提交）。 git log --graph --oneline --merges // 以图形化简洁模式查看当前分支的本地版本库提交记录（只显示有 2 个及以上父亲节点的提交）。 git log --graph --oneline --name-only // 以图形化简洁模式查看当前分支的本地版本库提交记录（并显示每次提交的文件名称清单）。 git log --graph --oneline --name-status // 以图形化简洁模式查看当前分支的本地版本库提交记录（并显示每次提交的文件状态、名称清单）。 git log --graph --oneline --stat // 以图形化简洁模式查看当前分支的本地版本库提交记录（并显示每次提交的文件变化统计、各文件名及增删记录）。 git log --graph --oneline --shortstat // 以图形化简洁模式查看当前分支的本地版本库提交记录（并显示每次提交的文件变化统计及增删记录）。 git log --graph --oneline --decorate --all // 以图形化简洁模式查看所有分支的本地版本库提交记录树。 git log --graph --pretty=format:&quot;%H - %an, %ad : %s&quot; // 自定义格式图形化查看所有分支的本地版本库提交记录树。 %H 提交对象（commit）的完整哈希字串； %h 提交对象的简短哈希字串； %T 树对象（tree）的完整哈希字串； %t 树对象的简短哈希字串； %P 父对象（parent）的完整哈希字串； %p 父对象的简短哈希字串； %an 作者（author）的名字； %ae 作者的电子邮件地址； %ad 作者修订日期（可以用 --date= 选项定制格式）； %ar 作者修订日期，按多久以前的方式显示； %cn 提交者（committer）的名字； %ce 提交者的电子邮件地址； %cd 提交日期； %cr 提交日期，按多久以前的方式显示； %s 提交说明； git log master..v5.0 // 查看 v5.0 分支还未合并到 master 分支上的提交记录列表。 git log v5.0..master // 查看 master 分支还未合并到 v5.0 分支上的提交记录列表。 git log master...v5.0 // git log master..v5.0 + git log v5.0..master。 git shortlog -sn // 统计各个提交者的次数。 git blame README.md // 显示 README.md 最近一次的修改信息。 git show 3a6c702376168aa15a2f3d7bc98000d07a70d023 README.md // 查看 README.md 文件的 3a6c702376168aa15a2f3d7bc98000d07a70d023 提交的修改内容。 git show HEAD // 查看最近一次提交的修改内容。 git show --name-only HEAD // 查看最近一次提交的文件列表（不显示具体的修改内容）。 标签（查看/新建/切换/删除） git tag // 列出所有的标签。 git tag -l 'tag1*' // 列出所有 tag1 开头的标签。 git tag tag1.0 // 创建名为 tag1.0 的轻量标签。 git tag -a tag1.0 -m &quot;tag1.0 desc&quot; // 添加 tag1.0 desc 注释并创建名为 tag1.0 的附注标签。 git tag tag2.0 abffefc5d82078cbaea7fcbb5106ab0c21cbeba9 // 在 abffefc5d82078cbaea7fcbb5106ab0c21cbeba9 提交处创建名为 tag2.0 的轻量标签。 git tag -a tag2.0 -m &quot;tag2.0 desc&quot; abffefc // 在 abffefc 提交处创建名为 tag2.0 的附注标签。 git tag -d tag2.0 // 删除名为 tag2.0 的标签。 git show tag1.0 // 查看名为 tag1.0 相关的信息。 git ls-remote --tags // 查看所有远端的标签。 分支（查看/新建/切换/删除） git branch // 列出所有本地分支。 git branch -r // 列出所有远程分支 cache。 git branch -a // 列出所有本地分支和远程分支 cache。 git branch -av // 列出所有本地分支和远程分支 cache（含简单说明）。 git branch -vv // 查看所有本地分支和远程分支 cache 之间的追踪关系。 git branch v1.0 // 在当前分支的 HAED 指针下创建名为 v1.0 的分支（创建完不会切到 v1.0 分支上）。 git branch --track v1.0 origin/v1.0 // 若 v1.0 分支不存在则先新建，然后将其与远程分支 origin/v1.0 建立追踪关系。 远程分支 origin/v1.0 要存在，否则命令执行失败。 执行完不会切到 v1.0 分支上。 git branch v2.0 372aa8e425b57ca30e2974b8e7737133caaa0b7f // 在 372aa8e425b57ca30e2974b8e7737133caaa0b7f 提交处创建名为 v2.0 的分支（创建完不会切到 v2.0 分支上）。 git branch -m v1.0 x1.0 // 将分支 v1.0 重命名为 x1.0。 git checkout v1.0 // 切换到 v1.0 分支上（v1.0 分支不存在则命令执行失败）。 git checkout -b v1.0 // 创建并切换到 v1.0 分支上（v1.0 分支存在则命令执行失败）。 git checkout -B v1.0 // 不存在则创建，并切换到 v1.0 分支上。 git checkout -b v1.0 5a95f2d // 在 5a95f2d 提交处创建并切换到 v1.0 的分支上。 git checkout -b v1.0 tag1.0 // 在标签 tag1.0 处创建并切换到 v1.0 的分支上。 git checkout -t origin/v1.0 // 创建并切换到 origin/v1.0 远程分支 cache 的名为 v1.0 本地分支上，并建立两者追踪关系（本地分支 v1.0 存在则命令执行失败）。 git checkout -b x1.0 -t origin/v1.0 // 创建并切换到 origin/v1.0 远程分支 cache 的名为 x1.0 本地分支上，并建立两者追踪关系（本地分支 x1.0 存在则命令执行失败） 注1：切换分支前，必须处理工作区（未追踪的文件不用处理）和暂存区的修改才能切换成功 注2：切换成功后，工作区会被设置成分支的内容 注3：不允许在远程分支 cache 上提交，需要创建对应关联的本地分支，然后在本地分支上进行提交。 git checkout -f v1.0 // 强制切换到 v1.0 分支上，丢弃暂存区和工作区中的所有文件的修改（工作区中未追踪的文件不受影响）。 git checkout -f -B v1.0 origin/v1.0 // 不存在则创建，强制切换到 v1.0 分支上，丢弃暂存区和工作区中的所有文件的修改，并将 HEAD 指向 origin/v1.0 处（工作区中未追踪的文件不受影响）。 git checkout - // 切换到上一次分支。 git branch -d v2.0 // 删除名为 v2.0 的分支（必须先切到其他分支上才能执行删除操作）。 git branch -D v2.0 // 强制删除名为 v2.0 的分支（必须先切到其他分支上才能执行删除操作）。 git branch -dr origin/v2.0 // 删除远程分支 origin/v2.0 cache。 文件（增加/删除/提交/撤销） git add README.md // 将当前目录下的 README.md 文件加入到暂存区。 git add . // 将当前目录下（递归子目录）所有文件加入到暂存区。 git add -u . // 将当前目录下（递归子目录）所有追踪状态的文件加入到暂存区。 git add Doc/\\*.txt // 将当前目录的 Doc 文件夹下（递归子目录）所有 txt 后缀的文件加入到暂存区。 git rm README.md // 删除工作区文件，并且将这次删除放入暂存区（若 README.md 在工作区或暂存区中有修改，命令会执行失败）。 git rm -f README.md // 强制删除工作区文件，并且将这次删除放入暂存区（即使 README.md 在工作区或暂存区中有修改，也会执行删除操作）。 git rm --cached README.md // 不删除工作区对应的文件，只将 README.md 删除放入暂存区以供提交。 git mv README.md test.md // 将 README.md 改名为 test.md，并且将这个改名放入暂存区。 git commit -m &quot;desc&quot; // 添加 desc 注释并将暂存区中的所有修改提交到本地仓库。 git commit README.md -m &quot;desc&quot; // 添加 desc 注释并将暂存区中的 README.md 的修改提交到本地仓库。 git commit --amend -m &quot;desc&quot; // 添加 desc 注释使用当前提交覆盖上一次的提交（若上一次提交包含 1.txt 和 2.txt 的修改，当前提交只包含 1.txt 的修改；执行命令后，本地版本库中为本次的 1.txt 和上一次 2.txt）。若没有提交内容，则用来改写上一次提交的日志信息。 git commit -m &quot;desc&quot; --amend README.txt // 添加 desc 注释使用 README.txt 的当前提交覆盖上一次的提交。 git commit -a -m &quot;desc&quot; // 添加 desc 注释并将工作区和暂存区中的所有修改提交到本地仓库。 git commit -am &quot;desc&quot; // 功能同上。 git commit -c b5cad94d229e72bd7aff5fe2c6f022b29c30e7a8 // 拿 372aa8e425b57ca30e2974b8e7737133caaa0b7f 提交的信息（作者、提交者、注释、时间戳等）来提交当前修改。 git reset -- README.md // 丢弃暂存区中的 README.md 文件的修改。 git reset README.md // 功能如上，丢弃暂存区中的 README.md 文件的修改。 git reset b5cad94 README.md // 使用本地版本库 b5cad94 提交处的 README.md 版本覆盖暂存区中的 README.md。 git reset // 丢弃暂存区中的所有文件的修改（工作区不受影响）。 git reset --mixed // --mixed 为缺省参数，命令与上面 git reset 一样。 git reset --hard // 丢弃暂存区和工作区中的所有文件的修改（工作区中未追踪的文件不受影响）。 git reset --soft b5cad94d229e72bd7aff5fe2c6f022b29c30e7a8 // 仅将当前分支的。HEAD 指向 372aa8e425b57ca30e2974b8e7737133caaa0b7f 提交（暂存区和工作区中的所有文件的修改都不丢弃）。 git reset --soft HEAD~ // 仅将当前分支的 HEAD 指向上一次提交（暂存区和工作区中的所有文件的修改都不丢弃）。 git reset --soft HEAD~2 // 仅将当前分支的 HEAD 指向上两次提交（暂存区和工作区中的所有文件的修改都不丢弃）。 git reset --merge &lt;commit&gt; // 在被污染的工作区中回滚 merge 或者 pull。 $ git pull (1) Auto-merging nitfol Merge made by recursive. nitfol | 20 +++++---- ... $ git reset --merge ORIG_HEAD (2) 即便你已经在本地更改了一些你的工作区，你也可安全的 git pull，前提是你知道将要 pull 的内容不会覆盖你的工作区中的内容。 git pull 完后，你发现这次 pull 下来的修改不满意，想要回滚到 pull 之前的状态，我们可以执行 git reset --hard ORIG_HEAD，但是这个命令有个副作用就是清空你的工作区，即丢弃你的本地未 add 的那些改变。 为了避免丢弃工作区中的内容，可以使用 git reset --merge ORIG_HEAD，注意其中的--hard 换成了 --merge，这样就可以避免在回滚时清除工作区。 git reset --keep &lt;commit&gt; // 保留工作区并丢弃一些之前的提交。 假设你正在编辑一些文件，并且已经提交，接着继续工作，但是现在你发现当前在工作区中的内容应该属于另一个分支，与之前的提交没有什么关系。此时，可以开启一个新的分支，并且保留着工作区中的内容。 $ git tag start $ git checkout -b branch1 $ edit $ git commit ... (1) $ edit $ git checkout -b branch2 (2) $ git reset --keep start (3) 这次是把在 branch1 中的改变提交了。 此时发现，之前的提交不属于这个分支，此时新建了 branch2 分支，并切换到了 branch2 上。 此时可以用 reset --keep 把在 start 之后的提交清除掉，但是保持工作区不变。 git checkout -- README.md // -- 符号非常重要，否则就变成了切换到 README.md 分支了。 // 当 README.md 在暂存区中有修改时，使用暂存区中的修改覆盖工作区中的 README.md。 // 当 README.md 不在暂存区中时，使用本地版本库中的 HEAD 指针处的修改覆盖工作区中的 README.md。 git checkout -- . // 使用暂存区和本地版本库来恢复当前目录（递归子目录）下的所有文件。 注：若暂存区中有修改，优先使用暂存区。 git checkout HEAD README.md // 使用本地版本库中的 HEAD 处提交覆盖暂存区和工作区中的 README.md。 git checkout 9a387f22ff949fa16336508adc2284384bd6a890 README.md // 使用本地版本库中的 9a387f22ff949fa16336508adc2284384bd6a890 修改覆盖暂存区和工作区中的 README.md。 git checkout -b v2.0 tag2.0 // 在名为 tag2.0 的提交处创建并切换到 v2.0 分支上（v2.0 分支存在则命令执行失败）。 git revert --no-edit 3a6c702376168aa15a2f3d7bc98000d07a70d023 // 回滚 3a6c702376168aa15a2f3d7bc98000d07a70d023 提交，然后提交到本地仓库。 git revert HEAD~ // 回滚 HEAD 的上一次提交，然后会弹出 vim 环境编辑注释（输入 :q 直接使用默认注释内容、输入 :q! 放弃修改使用默认注释内容、输入 :x 或 :wq 保存当前修改的注释内容），然后提交到本地仓库。 git revert -n HEAD~3 // 回滚掉 HEAD~3 处的提交，不自动提交到本地仓库。 git revert -n HEAD~2..HEAD // 回滚掉 (HEAD~2, HEAD] 之间的 2 次提交，不自动提交到本地仓库。 注：git reset 是把 HEAD 向后移动来删除提交，而 git revert 是用一次新的提交来回滚之前的提交（HEAD 会继续前进）。 查看差异 git diff README.md // 查看当前目录下的 README.md 在工作区和暂存区之间的差异。 git diff --cached README.md // 查看当前目录下的 README.md 在暂存区和本地仓库最后一次提交之间的差异。 git diff --cached 372aa8e425b57ca30e2974b8e7737133caaa0b7f README.md // 查看当前目录下的 README.md 在暂存区和本地仓库的 372aa8e425b57ca30e2974b8e7737133caaa0b7f 提交之间的差异。 git diff HEAD README.md // 查看当前目录下的 README.md 在工作区和本地仓库 HEAD 指针处提交之间的差异。 git diff 372aa8e425b57ca30e2974b8e7737133caaa0b7f README.md // 查看当前目录下的 README.md 在工作区和本地仓库的 372aa8e425b57ca30e2974b8e7737133caaa0b7f 提交之间的差异。 git diff 372aa8e425b57ca30e2974b8e7737133caaa0b7f HEAD README.md // 查看当前目录下的 README.md 在本地仓库的 372aa8e425b57ca30e2974b8e7737133caaa0b7f 提交和最后一次提交之间的差异。 git diff 372aa8e425b57ca30e2974b8e7737133caaa0b7f HEAD // 查看本地仓库的 372aa8e425b57ca30e2974b8e7737133caaa0b7f 提交和最后一次提交之间的差异。 git diff 372aa8e b5cad94 README.md // 查看当前目录下的 README.md 在本地仓库的 372aa8e 提交和 b5cad94 提交之间的差异 注：可以将 git diff 换成 git difftool 来使用外部 diff 工具（可以在 c:/users/&lt;用户名&gt;/.gitconfig 文件配置 beyond compare 作为默认的 difftool 和 mergetool）来查看差异。[diff] tool = bc3 [difftool] prompt = false [difftool &quot;bc3&quot;] cmd = &quot;\\&quot;e:/program files (x86)/beyond compare 3/bcomp.exe\\&quot; \\&quot;$LOCAL\\&quot; \\&quot;$REMOTE\\&quot;&quot; 分支合并 git merge-base Master Feature // 查看 Master 和 Feature 分支的最优共同 commit 父节点。 git merge Feature // 将 Feature 分支 merge 合并到当前分支 Master（无冲突时会直接提交）。 git merge -m &quot;merge test&quot; Feature // 将 Feature 分支 merge 合并到当前分支 Master（无冲突时使用 merge test 注释直接提交）。 git merge --no-commit Feature // 将 Feature 分支 merge 合并到当前分支 Master（不自动提交）。 git rebase Feature // 将 Feature 分支 rebase 合并到当前分支 Master。 注1：git rebase 会先找出共同的祖先节点，从祖先节点把 Feature 分支的提交记录全都剪切下来，然后合到 Master 分支（合并前后 commitID 会不一样）。 注2：相对来说，git merge 处理冲突更直接，但会增加一些冗余的提交记录；而 git rebase 能够保证清晰线性的提交记录，但这也将合并的操作没有被记录下来。 注3：最好是用 git rebase 合并远程分支到本地，git merge 合并 Feature 分支到 Master 分支。 注4：在合并 Feature 分支到 Master 分支前，务必先执行 git pull -r origin Feature 来进行远程分支与本地分支的 rebase 合并。 注5：处于冲突状态（conflict）的文件为 UU（可通过 git status -s --ignored 来查找），手动处理完冲突后，然后使用 git add 该文件，最后继续执行 git merge/rebase --continue 来完成合并的提交工作。 注6：README.md 文件冲突内容如下&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD 123 456 789 000 111 222 333 444 555 ss // 当前分支的内容 ======= 123 456 789 000 ss tt // Feature 分支的内容 &gt;&gt;&gt;&gt;&gt;&gt;&gt; Feature 注7：可以使用 git mergetool 来使用外部 merge 工具（可以在 c:/users/&lt;用户名&gt;/.gitconfig 文件配置 beyond compare 作为默认的 mergetool）来处理冲突。 修改完当前文件后，可再次调用 git mergetool 来处理下一个冲突，直至全部处理完毕，然后使用 git add 该文件，最后继续执行 git merge/rebase --continue 来完成合并的提交工作。[merge] tool = bc3 [mergetool] prompt = false [mergetool &quot;bc3&quot;] cmd = &quot;\\&quot;e:/program files (x86)/beyond compare 3/bcomp.exe\\&quot; \\&quot;$LOCAL\\&quot; \\&quot;$REMOTE\\&quot; \\&quot;$BASE\\&quot; \\&quot;$MERGED\\&quot;&quot; git rebase /i Feature // 将 Feature 分支采用手动交互方式 rebase 合并到当前分支 Master。 pick 07c5abd Introduce OpenPGP and teach basic usage pick de9b1eb Fix PostChecker::Post#urls pick 3e7ee36 Hey kids, stop all the highlighting pick fa20af3 git interactive rebase, squash, amend # Rebase 8db7e8b..fa20af3 onto 8db7e8b # # Commands: # p, pick = use commit # r, reword = use commit, but edit the commit message # e, edit = use commit, but stop for amending # s, squash = use commit, but meld into previous commit # f, fixup = like &quot;squash&quot;, but discard this commit's log message # x, exec = run command (the rest of the line) using shell # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out git merge/rebase --abort // 撤销当前 merge 或 rebase 操作。 git merge/rebase --skip // 强制使用 Feature 分支的内容。 git merge/rebase --continue // 手动处理完冲突后使用 git add 该文件，最后继续执行 git merge/rebase --continue 来完成合并的提交工作。 git merge origin/master // fetch 完之后，可以将远程分支 cache master 分支 merge 合并到当前分支上。 git rebase origin/master // fetch 完之后，可以将远程分支 cache master 分支 rebase 合并到当前分支上。 git rebase --onto master 76cada~ // 将当前分支从 [76cada, HEAD] 区间段的提交 rebase 合并到 master 上。 git cherry-pick 9a341e // 将 9a341e 提交合入当前分支。若不冲突，则直接使用 9a341e 的提交信息进行 commit，否则要先进行冲突处理，然后继续执行 git cherry-pick --continue 来完成合并的提交工作。 git cherry-pick 371c2…971209 // 将 (371c2, 971209] 提交合入当前分支（每个提交都会在当前分支上创建一个 commit）。 git cherry-pick 371c2~…971209 // 将 [371c2, 971209] 提交合入当前分支（每个提交都会在当前分支上创建一个 commit）。 git cherry-pick -n 9a341e d2f99e // 将 9a341e 和 d2f99e 提交合入当前分支（不提交），后续需要手动 commit。 git cherry-pick --abort // 撤销当前 cherry-pick 操作。 git cherry-pick --quit // 清理当前操作状态，不撤销修改强制退出 cherry-pick 操作过程。 git cherry-pick --continue // 手动处理完冲突后，最后继续执行 git cherry-pick --continue 来完成合并的提交工作。 查看远程版本库 git remote -v // 显示远程仓库的 URL。 注：由于 git 是分布式的，所有远程仓库可能有很多个origin https://github.com/kekec/Test.git (fetch) origin https://github.com/kekec/Test.git (push) git remote -ls // 查看远程仓库 URL 和分支信息From https://github.com/kekec/Test.git fae0fc82d711425daa897a63137d7e1af09512ba HEAD fae0fc82d711425daa897a63137d7e1af09512ba refs/heads/master git remote // 查看远程仓库名称，一般为 origin。 git remote rename origin test // 将远程仓库名称从 origin 修改为 test。 git remote show origin // 显示远程仓库的信息。* remote origin Fetch URL: https://github.com/kekec/Test.git Push URL: https://github.com/kekec/Test.git HEAD branch: master Remote branches: master tracked v3.1 tracked Local branch configured for 'git pull': master merges with remote master Local refs configured for 'git push': master pushes to master (fast-forwardable) v3.1 pushes to v3.1 (up to date) git remote rm origin // 删除 .git/config 文件中添加 remote origin 相关的信息。 git remote add origin https://github.com/kekec/Test.git // 在 .git/config 文件中添加 remote origin 指向的远程仓库 URL（若已存在，则命令执行失败）。[remote &quot;origin&quot;] url = https://github.com/kekec/Test.git fetch = +refs/heads/*:refs/remotes/origin/* git remote set-url origin https://github.com/kekec/Test.git // 修改 .git/config 文件中添加 remote origin 指向的远程仓库 URL。 git remote prune origin // 对于远程仓库不存在的分支，清除对应的远程分支 cache。 远程操作 git clone https://github.com/kekec/Test.git // 将 https://github.com/kekec/Test.git 上的当前分支克隆到本地（会创建一个名为 Test 目录，远程仓库名称使用默认名 origin）。 git clone https://github.com/kekec/Test.git MyProject // 将 https://github.com/kekec/Test.git 上的当前分支克隆到本地（会创建一个名为 MyProject 目录，远程仓库名称使用默认名 origin）。 git clone -b v1.0 https://github.com/kekec/Test.git // 将 https://github.com/kekec/Test.git 上的 v1.0 分支克隆到本地（会创建一个名为 Test 目录，远程仓库名称使用默认名 origin）。 git clone -b v1.0 https://github.com/kekec/Test.git d:\\MyGame // 将 https://github.com/kekec/Test.git 上的 v1.0 分支克隆到 d:\\MyGame 目录（会在 d:\\MyGame 中创建一个名为 Test 目录，远程仓库名称使用默认名 origin）。 git clone -o TestPrj https://github.com/kekec/Test.git // 将 https://github.com/kekec/Test.git 上的当前分支克隆到本地（会创建一个名为 Test 目录，并将远程仓库名称设置为 TestPrj）。 git fetch origin master // 从远程仓库拉取 master 分支状态的变化信息（工作区文件不会更新）。 git fetch // 从远程仓库拉取所有分支和 tag 状态的变化信息（工作区文件不会更新）。 git fetch -p // 从远程仓库拉取所有分支和 tag 状态的变化信息，并清除已被删除的远程分支和 tag 在本地的缓存（工作区文件不会更新）。 git fetch origin --tags // 从远程仓库拉取所有 tag 到本地（工作区文件不会更新）。 git pull &lt;远程仓库名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;。 git pull origin master // 先执行 fetch，然后将远程 origin/master 分支 merge 合并到当前分支（最后会更新 origin/master，origin/HEAD 指针到最新提交）。 git pull https://github.com/kekec/Test.git master // 先执行 fetch，将远程 origin/master 分支 merge 合并到当前分支（最后不会更新 origin/master，origin/HEAD 指针到最新提交）。 git pull origin v1.0:master // 先执行 fetch，然后将远程 origin/v1.0 分支 merge 合并到本地 master 分支。 git pull origin // 先执行 fetch，然后将对应的远程分支 merge 合并到当前分支（当前分支需要预存远程分支的追踪关系）。 git pull // 先执行 fetch，然后将对应的远程分支 merge 合并到当前分支（当前分支需要预存远程分支的追踪关系，而且当前分支只有一个远程仓库）。 git pull -p // 先执行 fetch，然后将对应的远程分支 merge 合并到当前分支，并清除已被删除的远程分支和 tag 在本地的缓存。 git pull -r origin master // 先执行 fetch，然后将远程 origin/master 分支 rebase 合并到 master 分支。 git push &lt;远程仓库名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;。 git push -u origin master // 将本地仓库的修改 push 到 origin 所指向的远程仓库 URL 的 master 分支上，并在 .git/config 文件中记录当前分支与远程分支 master 的对应关系。 git push origin // 将当前分支更新推送给对应的远端分支。 git push // 将当前分支更新推送给对应的远端分支（当前分支只有一个远程仓库，可以省略仓库名 origin）。 git push origin -f // 使用当前分支更新强行覆盖对应的远端分支（合入远端分支有冲突时，也使用当前分支更新）。 git push origin v1.0 // 将本地分支 v1.0 更新推送给对应的远端分支 remotes/origin/v1.0。 git push origin --all // 将本地所有分支更新推送给各自对应的远端分支。 git push origin tag1.0 // 将本地标签 tag1.0 更新到远端标签 tag1.0。 git push origin --tags // 将本地所有标签更新到对应的远端标签。 git push origin :v1.0 // 删除远端分支 v1.0。 git push origin :refs/tags/tag1.0 // 删除远程标签 tag1.0。 git push origin -d v1.0 // 删除远端分支 v1.0 功能同上。 储藏区 git stash // 将工作区中所有文件的修改备份压栈到储藏区，然后丢弃工作区与暂存区的所有文件的修改。 git stash pop // 使用储藏区的栈顶处备份（stash@{0}）来恢复当前分支的工作区，并将栈顶备份移除。 git stash apply stash@{1} // 使用储藏区的栈顶下面一个备份（stash@{1}）来恢复当前分支的工作区，但不移除储藏区中任何备份。 git stash list // 查看储藏区栈列表。 git stash show -p stash@{0} // 查看储藏区的栈顶处备份中各个文件的内容。 git stash drop // 直接移除储藏区的栈顶处备份（不用于恢复当前分支的工作区）。 git stash clear // 清除储藏区栈列表。 工作区 git clean -nd // 探测工作区中哪些文件和目录（未追踪状态）会被删除。 git clean -fd // 删除工作区中未追踪状态的文件和目录。 暂存区 git ls-files // 查询暂存区中的文件列表（递归子目录）。 git ls-files -s // 查看暂存区中所有文件的 blob 数据块信息。 git ls-files -s -- README.md // 查看暂存区中的 README.md 文件的 blob 数据块信息。 其他命令 git fsck --full // 列出所有未引用的 blob、tree、commit 对象。 git archive --format zip --output d:/file.zip master // 将当前 master 分支所有文件使用 zip 压缩方式打包到 d:/file.zip。 Git 瘦身 git count-objects -v // 查看 git 对象的统计信息。 find .git/objects -type f -print0 | xargs -0 du -hk | sort -nr | head -5 // 查找 git 库中最大的 5 个文件（du -hk 中的 k 代表单位为 KB）。 find .git/objects -type f -size +1M -print0 | xargs -0 du -hm | sort -nr | head -5 // 查找 git 库中 size 超过 1M 的最大的 5 个文件（du -hm 中的 m 代表单位为 MB）。 git verify-pack -v .git/objects/pack/pack-b340eea7566df839294b71ec91a327ca2ece0b94.idx | sort -k 3 -nr | head -5 // 对压缩存储的 git 库查找最大的 5 个文件。 git filter-branch --force --index-filter 'git rm --cached --ignore-unmatch FramePro.cpp' --prune-empty --tag-name-filter cat -- --all // 从 git 库的历史记录中彻底清理 FramePro.cpp。 git for-each-ref --format='delete %(refname)' refs/original | git update-ref --stdin // 清理所有废弃的 ref 引用。 git gc --prune=now 将所有的对象压缩存储到 pack 二进制文件中，以节省空间和提高效率。 移除与任何提交都不相关的陈旧对象。 git reflog expire --expire=now --all // 清除所有操作记录日志。 除了使用 git 原生命令外，可以使用专门的工具 BFG（Java 实现）来对 Git 库瘦身。 经典 Gitflow master 分支存储了正式发布的历史（master 分支上的所有提交都会分配一个版本号）。 develop 分支作为功能的集成分支。 每个新功能位于一个自己的 Feature 分支，该分支使用 develop 分支作为父分支。当新功能完成时，合并回 develop 分支。新功能提交应该从不直接与 master 分支交互。 一旦 develop 分支上有了做一次发布（或者说快到了既定的发布日）的足够功能，就从 develop 分支上 fork 一个 release分支。 新建的分支用于开始发布循环，所以从这个时间点开始之后新的功能不能再加到这个分支上。 这个分支只应该做 Bug 修复、文档生成和其它面向发布任务。 对外发布的工作完成后，发布分支会合并到 master 分支并分配一个版本号打好 Tag。另外，这些从新建发布分支以来的做的修改要合并回 develop 分支。 hotfix 分支用于生成快速给产品发布版本（production releases）打补丁，修复完成，修改应该马上合并回 master 分支（打好 Tag）和 develop 分支（当前的发布分支）。 参考 Pro Git 第二版pdf Git 原理入门 常用 Git 命令清单 Git 远程操作详解 Git 工作流程 Git 使用规范流程 Git 分支管理策略 GIT 基本概念和用法总结 Git 工作流指南：Gitflow 工作流 ","link":"https://faded.auspicious.space/post/git-super-detailed-tutorials-and-commands/"},{"title":"Git——25个进阶技巧","content":" 25个 Git 进阶技巧 基本技巧 1. 安装后的第一步 在安装好 git 后，你第一件该做的事是设置你的名字和电子邮箱，因为每次提交都要用到这些信息： $ git config --global user.name &quot;Some One&quot; $ git config --global user.email &quot;someone@gmail.com&quot; 2. Git 是基于指针的 保存在 git 里的一切都是文件。当你创建一个提交的时候，会建立一个包含你的提交信息和相关数据（名字，邮件地址，日期/时间，前一个提交，等等）的文件，并把它链接到一个树文件中。这个树文件中包含了对象或其他树的列表。这里的提到的对象（或二进制大对象）是和本次提交相关的实际内容（它也是一个文件，另外，尽管文件名并没有包含在对象里，但是存储在树中）。所有这些文件都使用对象的 SHA-1 哈希值作为文件名。 用这种方式，分支和标签就是简单的文件（基本上是这样），包含指向该提交的 SHA-1 哈希值。使用这些索引会带来优秀的灵活性和速度，比如创建一个新分支就是简单地用分支名字和所分出的那个提交的 SHA-1 索引来创建一个文件。当然，你不需要自己做这些，而只要使用 Git 命令行工具（或者 GUI），但是实际上就是这么简单。 你也许听说过叫 HEAD 的索引。这只是简单的一个文件，包含了你当前指向的那个提交的 SHA-1 索引值。如果你正在解决一次合并冲突然后看到了 HEAD，这并不是一个特别的分支或分支上的一个必需的特殊位置，只是标明你当前所在位置。 所有的分支指针都保存在 .git/refs/heads 里，HEAD 在 .git/HEAD 里，而标签保存在 .git/refs/tags 里——自己可以随便进去看看。 3. 两个爸爸（父节点） - 你没看错！ 在历史中查看一个合并提交的信息时，你将看到有两个父节点（不同于工作副本上的常规提交的情况）。第一个父节点是你所在的分支，第二个是你合并过来的分支。 4. 合并冲突 目前我相信你碰到过合并冲突并且解决过。通常是编辑一下文件，去掉 &lt;&lt;&lt;&lt;，====，&gt;&gt;&gt;&gt; 标志，保留需要留下的代码。有时能够看到这两个修改之前的代码会很不错，比如，在这两个现在冲突的分支之前的改动。下面是一种方式： $ git diff --merge diff --cc dummy.rb index 5175dde,0c65895..4a00477 --- a/dummy.rb +++ b/dummy.rb @@@ -1,5 -1,5 +1,5 @@@ class MyFoo def say - puts &quot;Bonjour&quot; - puts &quot;Hello world&quot; ++ puts &quot;Annyong Haseyo&quot; end end 如果是二进制文件，比较差异就没那么简单了...通常你要做的就是测试这个二进制文件的两个版本来决定保留哪个（或者在二进制文件编辑器里手工复制冲突部分）。从一个特定分支获取文件拷贝（比如说你在合并 master 和 feature123 两个分支）： $ git checkout master flash/foo.fla # 或者... $ git checkout feature132 flash/foo.fla $ # 然后... $ git add flash/foo.fla 另一种方式是通过 git 输出文件——你可以输出到另外的文件名，然后当你决定了要用哪个后，再将选定的正确文件复制为正常的文件名： $ git show master:flash/foo.fla &gt; master-foo.fla $ git show feature132:flash/foo.fla &gt; feature132-foo.fla $ # 检出master-foo.fla和feature132-foo.fla $ # 假如说我们决定来自feature132的文件是正确的 $ rm flash/foo.fla $ mv feature132-foo.fla flash/foo.fla $ rm master-foo.fla $ git add flash/foo.fla 更新：感谢 Carl 在原博客文章上评论里的提醒，你实际上可以用 git checkout —ours flash/foo.fla 和 git checkout —theirs flash/foo.fla 来检出特定版本的文件，而不用记住你在合并的分支名字。就我个人来说喜欢更精确一点，但这也是一种方式... 记着在解决完冲突后要将文件加入提交（像我上面做的那样）。 服务器，分支和标签 5. 远端服务器 git 的一个超强大的功能就是可以有不止一个远端服务器（实际上你一直都在一个本地仓库上工作）。你并不是一定都要有这些服务器的写权限，你可以有多个可以读取的服务器（用来合并他们的工作）然后写入到另外一个仓库。添加一个新的远端服务器很简单： $ git remote add john git@github.com:johnsomeone/someproject.git 如果你想查看远端服务器的信息可以这样做： # 显示每个远端服务器的URL $ git remote -v # 提供更多详细信息 $ git remote show name 你随时都可以查看本地分支和远端分支的差异： $ git diff master..john/master 你也可以查看没有在远端分支上的 HEAD 的改动： $ git log remote/branch.. # 注意：..后面没有结束的特定引用 6. 标签 在 git 里有两种类型的标签——轻量级标签和带注释标签。记住技巧 2 里说过 git 是基于指针的，这两者之间的差异也很简单。轻量级标签只是一个简单的指向一次提交的带名字指针。你随时都可以将它指向另一个提交。带注释标签是一个指向标签对象的带名字指针，带有自己的信息和历史。因为有自己的信息，它可以根据需要用 GPG 签名。 建立这两种类型的标签都很简单（只有一个命令行开关的差异） $ git tag to-be-tested $ git tag -a v1.1.0 # 会提示输入标签的信息 7. 建立分支 在 git 里建立分支非常简单（而且像闪电一样快，因为它只需要创建一个小于 100 字节的文件）。用普通方式建立新分支并切换过去： $ git branch feature132 $ git checkout feature132 当然，如果你确定自己直接切换到新建的分支，可以用一个命令实现： $ git checkout -b feature132 如果你想重命名一个本地分支也很简单（可以显示发生了什么的较长的方式）： $ git checkout -b twitter-experiment feature132 $ git branch -d feature132 更新：你也可以（像 Brian Palmer 在原博客文章的评论里提出的）只用 git branch 的 -m 开关在一个命令里实现（像 Mike 提出的，如果你只指定了一个分支参数，就会重命名当前分支）： $ git branch -m twitter-experiment $ git branch -m feature132 twitter-experiment 8. 合并分支 也许在将来的某个时候，你希望将改动合并。有两种方式： $ git checkout master $ git merge feature83 # 或者... $ git rebase feature83 merge 和 rebase 之间的差别是 merge 会尝试处理改动并建立一个新的混合了两者的提交。rebase 会尝试把你从一个分支最后一次分离后的所有改动，一个个加到该分支的 HEAD 上。不过，在已经将分支推到远端服务器后不要再 rebase 了 - 这会引起冲突/问题。 如果你不确定在哪些分支上还有独有的工作——所以你也不知道哪些分支需要合并而哪些可以删除，git branch 有两个开关可以帮你： # 显示已经全部合并到当前分支的分支 $ git branch --merged # 显示没有合并到当前分支的分支 $ git branch --no-merged 9. 远端分支 如果你在本地有一个分支希望推到远端服务器上，你可以用一行命令推送上去： $ git push origin twitter-experiment:refs/heads/twitter-experiment # origin是我们服务器的名字，而twitter-experiment是分支名字 更新：感谢 Erlend 在原博客文章上的评论——这个实际上和 git push origin twitter-experiment 效果一样，不过使用完整的语法，你可以在两者之间使用不同的分支名（这样本地分支可以是 add-ssl-support 而远端是 issue-1723）。 如果你想在远端服务器上删除一个分支（注意分支名前面的冒号）： $ git push origin :twitter-experiment 如果你想查看所有远端分支的状态可以这样做： $ git remote show origin 这个命令可能会列出服务器上一些以前有过但现在已经不在了的分支。如果碰到这种情况你可以用下面的命令从你本地分支里清理掉： $ git remote prune 最后，如果你想在本地跟踪一个远端分支，普通的方式是： $ git branch --track myfeature origin/myfeature $ git checkout myfeature 不过，新版的 git 在使用 -b 标记检出分支时会自动设定跟踪： $ git checkout -b myfeature origin/myfeature 在储藏点，索引和文件系统中保存内容 10. 储藏 在 git 里你可以把当前工作状态放进一个储藏堆栈中，然后可以再取出来。最简单的情形是下面这样： $ git stash # 做点其他事情... $ git stash pop 许多人建议使用 git stash apply 来代替 pop，不过如果这样做的话最后会遗留一个很长的储藏列表。而 pop 会在全部加载后自动从堆栈中移除。如果使用过 git stash apply，你也可以使用下面的命令从堆栈上移除最后一项： $ git stash drop git 会基于当前的提交信息自动创建评论。如果你更希望有自定义信息的话（因为它可能和前一个提交没有任何联系）： $ git stash save &quot;My stash message&quot; 如果你希望从列表中取出一个特定的储藏点（不一定非得是最后一个）可以先列出它们然后用下面的方式取出： $ git stash list stash@{0}: On master: Changed to German stash@{1}: On master: Language is now Italian $ git stash apply stash@{1} 11. 交互式添加 在 subversion 的世界里你只能修改文件然后提交所有改动。而在 git 里你有强大得多的方式来提交部分文件或者甚至是部分补丁。提交部分文件或文件中的部分改动你需要进入交互式模式： $ git add -i staged unstaged path *** Commands *** 1: status 2: update 3: revert 4: add untracked 5: patch 6: diff 7: quit 8: help What now&gt; 这会让你进入一个基于菜单的交互式提示。你可以使用命令中的数字或高亮的字母（如果你在终端里打开了高亮的话）来进入相应的模式。然后就只是输入你希望操作的文件的数字了（你可以使用这样的格式，1 或者 1-4 或 2,4,7）。 如果你想进入补丁模式（交互式模式下按 p 或 5），你也可以直接进入： $ git add -p diff --git a/dummy.rb b/dummy.rb index 4a00477..f856fb0 100644 --- a/dummy.rb +++ b/dummy.rb @@ -1,5 +1,5 @@ class MyFoo def say - puts &quot;Annyong Haseyo&quot; + puts &quot;Guten Tag&quot; end end Stage this hunk [y,n,q,a,d,/,e,?]? 你可以看到下方会有一些选项供选择用来添加该文件的这个改动、该文件的所有改动，等等。使用 ? 命令可以详细解释这些选项。 12. 从文件系统里保存/取回改动 有些项目（比如 Git 项目本身）在 git 文件系统中直接保存额外文件而并没有将它们加入到版本控制中。 让我们从在 git 中存储一个随机文件开始： $ echo &quot;Foo&quot; | git hash-object -w --stdin 51fc03a9bb365fae74fd2bf66517b30bf48020cb 这样这个目标文件就已经保存到数据库中了，但是如果你没有设定一个指向它的指针的话它会被当做垃圾回收。最简单的方式是设定一个标签： $ git tag myfile 51fc03a9bb365fae74fd2bf66517b30bf48020cb 注意这里我们使用了标签 myfile。当我们需要使用这个文件的时候可以这样做： $ git cat-file blob myfile 这个对于一些工具文件很有用，开发者可能会用到（密码，GPG 密钥，等等）但是又不希望每次都检出到硬盘（尤其是在实际工作中）。 日志以及有哪些改动？ 13. 查看日志 长时间使用 Git 的话，不会没用过 git log 来查看最近的提交。不过，有一些技巧来更好地应用。比如，你可以使用下面的命令来查看每次提交的具体改动： $ git log -p 或者你可以仅仅查看有哪些文件改动： $ git log --stat 有个很不错的别名你可以试试，会显示简短提交名和一个不错的分支图并在一行里显示提交信息（有点像 gitk，但是是在命令行下）： $ git config --global alias.lol &quot;log --pretty=oneline --abbrev-commit --graph --decorate&quot; $ git lol * 4d2409a (master) Oops, meant that to be in Korean * 169b845 Hello world 14. 搜索日志 如果你想找特定提交者可以这样做： $ git log --author=Andy 更新：感谢 Johannes 的评论，我已经去掉了之前这里的一些有混淆的地方。 或者你想在提交信息里找一些相关字段： $ git log --grep=&quot;Something in the message&quot; 也有一个更强大的叫做 pickaxe 的命令用来查找包含了删除或添加的某个特定内容的提交（比如，该内容第一次出现或被删除）。这可以告诉你什么时候增加了一行（但这一行里的某个字符后面被改动过就不行了）： $ git log -S &quot;TODO: Check for admin status&quot; 假如你改动了一个特定的文件，比如 lib/foo.rb $ git log lib/foo.rb 比如说你有一个 feature/132 分支和 feature/145 分支，然后你想看看这两个分支上不在 master 分支里的提交（注意符号 ^ 是不在的意思）： $ git log feature/132 feature/145 ^master 你也可以使用 ActiveSupport 格式的日期来缩小到某个日期范围： $ git log --since=2.months.ago --until=1.day.ago 默认情况下会用 OR 来组合查询，但你可以轻易地改为 AND（如果你有超过一条的查询标准） $ git log --since=2.months.ago --until=1.day.ago --author=andy -S &quot;something&quot; --all-match 15. 查看/修改版本 有很多方式可以用来引用一个版本，看你记得哪个： $ git show 12a86bc38 # 根据版本 $ git show v1.0.1 # 根据标签 $ git show feature132 # 根据分支名 $ git show 12a86bc38^ # 一次提交的父节点 $ git show 12a86bc38~2 # 一次提交的祖父节点 $ git show feature132@{yesterday} # 时间相关 $ git show feature132@{2.hours.ago} # 时间相关 注意和之前部分有些不同，末尾 ^ 的意思是该提交的父节点——开始位置 ^ 的意思是不在这个分支。 16. 选择范围 最简单的方式： $ git log origin/master..new # [old]..[new] - 所有你还没有推送的提交 你也可以省略 [new]，将使用当前的 HEAD。 时光回溯和后悔药 17. 重置改动 如果你还没有提交的话可以用下面的命令轻松地取消改动： $ git reset HEAD lib/foo.rb 通常会使用 unstage 的别名，因为上面的看上去有些不直观。 $ git config --global alias.unstage &quot;reset HEAD&quot; $ git unstage lib/foo.rb 如果你已经提交了该文件，你可以做两件事 - 如果是最后一次提交你还可以改正： $ git commit --amend 这会取消最后一次提交，把工作分支回退到提交前标记了所有改动的状态，而且提交信息也都准备好可以修改或直接提交。 如果你已经提交过多次而且希望全部回退，你可以将分支重置到合适的位置。 $ git checkout feature132 $ git reset --hard HEAD~2 如果你实际上希望将分支指向一个完全不同的 SHA1（也许你要将一个分支的 HEAD 替换到另一个分支，或者之后的某次提交）你可以使用下面的较长的方式： $ git checkout FOO $ git reset --hard SHA 实际上有一个快速的方式（不需要先把你的工作分支切换到 FOO 再前进到 SHA）： $ git update-ref refs/heads/FOO SHA 18. 提交到了错误的分支 好吧，假如说你已经提交到了 master，但却应该创建一个叫 experimental 的主题分支更合适。要移动这些改动，你可以在当前位置创建分支，回退 HEAD 再检出新分支： $ git branch experimental # 创建一个指向当前master的位置的指针 $ git reset --hard master~3 # 移动master分支的指针到3个版本之前 $ git checkout experimental 如果你的改动是在分支的分支的分支上会更复杂。那样你需要做的是将分支基础切换到其他地方： $ git branch newtopic STARTPOINT $ git rebase oldtopic --onto newtopic 19. 交互式切换基础 这是一个我之前看过展示却没真正理解过的很赞的功能，现在觉得它就很简单了。假如说你提交了3次但是你希望更改顺序或编辑（或者合并）： $ git rebase -i master~3 然后这会启动你的编辑器并带有一些指令。你所要做的就是修改这些指令来选择/插入/编辑（或者删除）提交和保存/退出。然后在编辑完后你可以用 git rebase --continue 命令来让每一条指令生效。 如果你有修改，将会切换到你提交时所处的状态，之后你需要使用命令 git commit --amend 来编辑。 注意：在 rebase 的时候千万不要提交 - 只能先添加然后使用参数 --continue，--skip 或 --abort。 20. 清理 如果你提交了一些内容到你的分支（也许你从 SVN 导入了一些旧仓库），然后你希望把某个文件从历史记录中全部删掉： $ git filter-branch --tree-filter 'rm -f *.class' HEAD 如果你已经推送到 origin 了，但之后提交了一些垃圾改动，你也可以在推送前在本地系统里这样做： $ git filter-branch --tree-filter 'rm -f *.class' origin/master..HEAD 其他技巧 21. 你查看过的前一个引用 如果你知道自己之前查看过一个 SHA-1，但是随后做了一些重置/回退的操作，你可以使用 reflog 命令来列出最近查看过的 SHA-1 记录： $ git reflog $ git log -g # 和上面一样，但是使用'log'格式输出 22. 分支命名 一个可爱的小技巧 - 别忘了分支名并不限于 a-z 和 0-9。名字中可以用/和.将非常方便用来建立伪命名空间或版本，例如： $ # 生成版本132的改动历史 $ git shortlog release/132 ^release/131 $ # 贴上v1.0.1的标签 $ git tag v1.0.1 release/132 23. 找出谁是凶手 通常找出来谁改动了某个文件里的某行代码会很有用。实现这个功能的最简单命令是： $ git blame FILE 有时候这些改动来自其他文件（如果你合并了两个文件，或者你移动了某个函数）所以你可以使用下面的命令： $ # 显示内容来自哪个文件 $ git blame -C FILE 有时候通过点击各个改动然后回到很早很早以前来跟踪改动会很不错。有一个很好的内建 GUI 命令来做这个： $ git gui blame FILE 24. 数据维护 通常 git 不需要经常维护，它把自己照顾的很好。不过，你可以通过下面的命令查看数据统计： $ git count-objects -v 如果占用很多空间的话，你可以选择在你的本地仓库做垃圾回收。这不会影响推送或其他人，却会让一些命令运行更快而且减少空间占用： $ git gc 经常运行完整性检查也很有意义： $ git fsck --full 你也可以在末尾加上 --auto 参数（如果你在服务器上通过 crontab 经常/每天都运行这个命令的话），然后它只会在必要的时候才执行 fsck` 动作。 在检查的时候，看到 dangling 或 unreachable 是正常的，通常这是由回退 HEAD 或切换基础的结果。而看到 missing 或 sha1 mismatch 就不对了...找专业人士帮忙吧！ 25. 恢复遗失的分支 如果你使用 -D 参数删除了 experimental 分支，可以用下面的命令重新建立： $ git branch experimental SHA1_OF_HASH 如果你最近访问过的话，你通常可以用 git reflog 来找到 SHA1 哈希值。 另一种方式是使用 git fsck —lost-found。其中一个 dangling 的提交就是丢失的 HEAD（它只是已删除分支的 HEAD，而 HEAD 被引用为当前的 HEAD 所以它并不处于 dangling 状态）。 ","link":"https://faded.auspicious.space/post/git-25-advanced-skills/"},{"title":"Git——4 个阶段的撤销更改","content":"错误修改了代码不要紧，这里教你如何恢复以前的正确代码。 Git的4个阶段的撤销更改 虽然 git 诞生距今已有 12 年之久，网上各种关于 git 的介绍文章数不胜数，但是依然有很多人（包括我自己在内）对于它的功能不能完全掌握。以下的介绍只是基于我个人对于 git 的理解，并且可能生编硬造了一些不完全符合 git 说法的词语。目的只是为了让 git 通俗化，使初学者也能大概了解如何快速上手 git。同时，下面所有讨论，我们都假设只使用一个分支，也就是主分支 master 的情况，虽然这种作法并不符合 git 规范，但是现实情况中绝大部分用户是直接在 master 分支上进行工作的，所以在这里我们不去引入更加复杂的各种分支的情况，也不涉及标签 tag 的操作，只讲在最简单的主分支上如何回退。 基本概念 3 个步骤 正常情况下，我们的工作流就是 3 个步骤，对应上图中的 3 个箭头线： git add . git commit -m &quot;comment&quot; git push git add . 把所有文件放入暂存区； git commit 把所有文件从暂存区提交进本地仓库； git push 把所有文件从本地仓库推送进远程仓库。 4 个区 git 之所以令人费解，主要是它相比于 svn 等等传统的版本管理工具，多引入了一个暂存区（Stage）的概念，就因为多了这一个概念，而使很多人疑惑。其实，在初学者来说，每个区具体怎么工作的，我们完全不需要关心，而只要知道有这么 4 个区就够了： 工作区（Working Area） 暂存区（Stage） 本地仓库（Local Repository） 远程仓库（Remote Repository） 5 种状态 以上 4 个区，进入每一个区成功之后会产生一个状态，再加上最初始的一个状态，一共是 5 种状态。以下我们把这 5 种状态分别命名为： 未修改（Origin） 已修改（Modified） 已暂存（Staged） 已提交（Committed） 已推送（Pushed） 检查修改 了解了基本概念之后，我们来谈一谈犯错误之后如何撤销的问题。首先，我们要了解如何检查这 3 个步骤当中每一个步骤修改了什么，然后才好判断有没有修改成功。检查修改的二级命令都相同，都是 diff，只是参数有所不同。 已修改，未暂存 git diff 首先，我们来看一下，如果我们只是简单地在浏览器里保存了一下文件，但是还没有做 git add . 之前，我们如何检查有哪些修改。我们先随便拿一个文件来做一下实验： 我们在文件开头的第 2 行胡乱加了 4 个数字 1234，存盘，这时文件进入了已修改状态，但是还没有进入暂存区，我们运行 git diff，结果如下： diff --git a/index.md b/index.md index 73ff1ba..1066758 100644 --- a/index.md +++ b/index.md @@ -1,5 +1,5 @@ --- -layout: main +1234layout: main color: black --- git diff 的结果告诉我们哪些文件已经做了哪些修改。 已暂存，未提交 git diff --cached 现在我们把修改放入暂存区看一下。先执行 git add .，然后执行 git diff，你会发现没有任何结果： 这说明 git diff 这个命令只检查我们的工作区和暂存区之间的差异，如果我们想看到暂存区和本地仓库之间的差异，就需要加一个参数 git diff --cached： diff --git a/index.md b/index.md index 73ff1ba..1066758 100644 --- a/index.md +++ b/index.md @@ -1,5 +1,5 @@ --- -layout: main +1234layout: main color: black --- 这时候我们看到的差异是暂存区和本地仓库之间的差异。 已提交，未推送 git diff master origin/master 现在，我们把修改从暂存区提交到本地仓库，再看一下差异。先执行 git commit，然后再执行 git diff --cached，没有差异，执行 git diff master origin/master，可以看到差异： 在这里，master 就是你的本地仓库，而 origin/master 就是你的远程仓库，master 是主分支的意思，因为我们都在主分支上工作，所以这里两边都是 master，而 origin 就代表远程。 撤销修改 了解清楚如何检查各种修改之后，我们开始尝试各种撤销操作。 恢复已修改，未暂存 如果我们只是在编辑器里修改了文件，但还没有执行 git add .，这时候我们的文件还在工作区，并没有进入暂存区，我们可以用： git checkout . 或者 git reset --hard 来进行撤销操作。 可以看到，在执行完 git checkout . 之后，修改已被撤销，git diff 没有任何内容了。 一对反义词 &gt; git add . 的反义词是 git checkout .。做完修改之后，如果你想向前走一步，让修改进入暂存区，就执行 git add .，如果你想向后退一步，撤销刚才的修改，就执行 git checkout .。 恢复已暂存，未提交 你已经执行了 git add .，但还没有执行 git commit -m &quot;comment&quot;。这时候你意识到了错误，想要撤销，你可以执行： git reset git checkout . 或者 git reset --hard git reset 只是把修改退回到了 git add . 之前的状态，也就是说文件本身还处于已修改未暂存状态，你如果想退回未修改状态，还需要执行 git checkout .。 或许你已经注意到了，以上两个步骤都可以用同一个命令 git reset --hard 来完成。是的，就是这个强大的命令，可以一步到位地把你的修改完全恢复到未修改的状态。 恢复已提交，未推送 你的手太快，你既执行了 git add .，又执行了 git commit，这时候你的代码已经进入了你的本地仓库，然而你后悔了，怎么办？不要着急，还有办法。 git reset --hard origin/master 还是这个 git reset --hard 命令，只不过这次多了一个参数 origin/master，正如我们上面讲过的，origin/master 代表远程仓库，既然你已经污染了你的本地仓库，那么就从远程仓库把代码取回来吧。 已推送 很不幸，你的手实在是太快了，你既 git add 了，又 git commit 了，并且还 git push 了，这时你的代码已经进入远程仓库。如果你想恢复的话，还好，由于你的本地仓库和远程仓库是等价的，你只需要先恢复本地仓库，再强制 push 到远程仓库就好了： git reset --hard HEAD^ git push -f 总结 以上 4 种状态的撤销我们都用到了同一个命令 git reset --hard，前 2 种状态的用法甚至完全一样，所以只要掌握了 git reset --hard 这个命令的用法，从此你再也不用担心提交错误了。 ","link":"https://faded.auspicious.space/post/git-four-stages-of-reset/"},{"title":"JavaScript——发现闭包的强大威力","content":" [译]发现 JavaScript 中闭包的强大威力 闭包是一个可以访问外部作用域的内部函数，即使这个外部作用域已经执行结束。 1 作用域 作用域决定这个变量的生命周期及其可见性。 当我们创建了一个函数或者 {} 块，就会生成一个新的作用域。需要注意的是，通过 var 创建的变量只有函数作用域，而通过 let 和 const 创建的变量既有函数作用域，也有块作用域。 2 嵌套作用域 在 JavasScript 中函数里面可以嵌套函数，如下： (function autorun(){ let x = 1; function log(){ console.log(x); } log(); })(); log() 即是一个嵌套在 autorun() 函数里面的函数。在 log() 函数里面可以通过外部函数访问到变量 x。此时，log() 函数就是一个闭包。 闭包就是内部函数，我们可以通过在一个函数内部或者 {} 块里面定义一个函数来创建闭包。 2.1 外部函数作用域 内部函数可以访问外部函数中定义的变量，即使外部函数已经执行完毕。如下： (function autorun(){ let x = 1; setTimeout(function log(){ console.log(x); }, 10000); })(); 并且，内部函数还可以访问外部函数中定义的形参，如下： (function autorun(p){ let x = 1; setTimeout(function log(){ console.log(x);//1 console.log(p);//10 }, 10000); })(10); 2.2 外部块作用域 内部函数可以访问外部块中定义的变量，即使外部块已执行完毕，如下： { let x = 1; setTimeout(function log(){ console.log(x); }, 10000); } 3 词法作用域 词法作用域是指内部函数在定义的时候就决定了其外部作用域。 看如下代码： (function autorun(){ let x = 1; function log(){ console.log(x); }; function run(fn){ let x = 100; fn(); } run(log);//1 })(); log() 函数是一个闭包，它在这里访问的是 autorun() 函数中的 x 变量，而不是 run 函数中的变量。 ❗️闭包的外部作用域是在其定义的时候已决定，而不是执行的时候。 autorun() 的函数作用域即是 log() 函数的词法作用域。 4 作用域链 每一个作用域都有对其父作用域的引用。当我们使用一个变量的时候，JavaScript 引擎 会通过变量名在当前作用域查找，若没有查找到，会一直沿着作用域链一直向上查找，直到 global 全局作用域。 示例如下： let x0 = 0; (function autorun1(){ let x1 = 1; (function autorun2(){ let x2 = 2; (function autorun3(){ let x3 = 3; console.log(x0 + &quot; &quot; + x1 + &quot; &quot; + x2 + &quot; &quot; + x3);//0 1 2 3 })(); })(); })(); 我们可以看到，autorun3() 这个内部函数可以访问其自身局部变量 x3 ，也可以访问外部作用域中的 x1 和 x2 变量，以及全局作用域中的 x0 变量。即：闭包可以访问其外部（父）作用域中的定义的所有变量。 4.1 外部作用域执行完毕后 当外部作用域执行完毕后，内部函数还存活（仍在其他地方被引用）时，闭包才真正发挥其作用。譬如以下几种情况： 在异步任务例如 timer 定时器，事件处理，Ajax 请求中被作为回调。 被外部函数作为返回结果返回，或者返回结果对象中引用该内部函数。 考虑如下的几个示例： 4.1.1 Timer (function autorun(){ let x = 1; setTimeout(function log(){ console.log(x); }, 10000); })(); 变量 x 将一直存活着直到定时器的回调执行或者 clearTimeout() 被调用。 如果这里使用的是 setInterval()，那么变量 x 将一直存活到 clearInterval() 被调用。 译者注：原文中说变量 x 一直存活到 setTimeout() 或者 setInterval() 被调用是错误的。 4.1.2 Event (function autorun(){ let x = 1; $(&quot;#btn&quot;).on(&quot;click&quot;, function log(){ console.log(x); }); })(); 当变量 x 在事件处理函数中被使用时，它将一直存活直到该事件处理函数被移除。 4.1.3 Ajax (function autorun(){ let x = 1; fetch(&quot;http://&quot;).then(function log(){ console.log(x); }); })(); 变量 x 将一直存活到接收到后端返回结果，回调函数被执行。 在已上几个示例中，我们可以看到，log() 函数在父函数执行完毕后还一直存活着，log() 函数就是一个闭包。 除了 timer 定时器，事件处理，Ajax 请求等比较常见的异步任务，还有其他的一些异步 API 比如 HTML5 Geolocation，WebSockets，requestAnimationFrame() 也将使用到闭包的这一特性。 变量的生命周期取决于闭包的生命周期。被闭包引用的外部作用域中的变量将一直存活直到闭包函数被销毁。如果一个变量被多个闭包所引用，那么直到所有的闭包被垃圾回收后，该变量才会被销毁。 5 闭包与循环 闭包只存储外部变量的引用，而不会拷贝这些外部变量的值。 查看如下示例： function initEvents(){ for(var i=1; i&lt;=3; i++){ $(&quot;#btn&quot; + i).click(function showNumber(){ alert(i);//4 }); } } initEvents(); 在这个示例中，我们创建了 3 个闭包，皆引用了同一个变量 i，且这三个闭包都是事件处理函数。由于变量 i 随着循环自增，因此最终输出的都是同样的值。 修复这个问题最简单的方法是在 for 语句块中使用 let 变量声明，这将在每次循环中为 for 语句块创建一个新的局部变量。如下： function initEvents(){ for(let i=1; i&lt;=3; i++){ $(&quot;#btn&quot; + i).click(function showNumber(){ alert(i); // 1 2 3 }); } } initEvents(); 但是，如果变量声明在 for 语句块之外的话，即使用了 let 变量声明，所有的闭包还是会引用同一个变量，最终输出的还是同一个值。 6 闭包与封装性 封装性意味着信息隐藏。 6.1 函数与私有状态 通过闭包，我们可以创建拥有私有状态的函数，闭包使得状态被封装起来。 6.2 工厂模式与私有原型对象 我们先来看一个通过原型创建对象的常规方式，如下： let todoPrototype = { toString : function() { return this.id + &quot; &quot; + this.userName + &quot;: &quot; + this.title; } } function Todo(todo){ let newTodo = Object.create(todoPrototype); Object.assign(newTodo, todo); return newTodo; } 在这个例子中，todoPrototype 原型对象是一个全局对象。 我们可以通过闭包，只用创建原型对象一次，也能够被所有 Todo 函数调用所公用，并且保证其私有性。示例如下： let Todo = (function createTodoFactory(){ let todoPrototype = { toString : function() { return this.id + &quot; &quot; + this.userName + &quot;: &quot; + this.title; } } return function(todo){ let newTodo = Object.create(todoPrototype); Object.assign(newTodo, todo); return newTodo; } })(); let todo = Todo({id : 1, title: &quot;This is a title&quot;, userName: &quot;Cristi&quot;, completed: false }); 这里，Todo() 就是一个拥有私有状态的函数。 6.3 工厂模式与私有构造函数 查看如下代码： let Todo = (function createTodoFactory(){ function Todo(spec){ Object.assign(this, spec); } return function(spec){ let todo = new Todo(spec); return Object.freeze(todo); } })(); 这里，Todo() 工厂函数就是一个闭包。通过它，不管是否使用 new，我们都可以创建不可变对象，原型对象也只用创建一次，并且它是私有的。 let todo = Todo({title : &quot;A description&quot;}); todo.title = &quot;Another description&quot;; // Cannot assign to read only property 'title' of object todo.toString = function() {}; //Cannot assign to read only property 'toString' of object 而且，在内存快照中，我们可以通过构造函数名来识别这些示例对象。 6.4 翻译功能与私有 map 通过闭包，我们可以创建一个 map，在所有翻译调用中被使用，且是私有的。 示例如下： let translate = (function(){ let translations = {}; translations[&quot;yes&quot;] = &quot;oui&quot;; translations[&quot;no&quot;] = &quot;non&quot;; return function(key){ return translations[key]; } })(); translate(&quot;yes&quot;); //oui 6.5 自增生成器函数 通过闭包，我们可以创建自增生成器函数。同样，内部状态是私有的。示例如下： function createAGenerate(count, increment) { return function(){ count += increment; return count; } } let generateNextNumber = createAGenerate(0, 1); console.log(generateNextNumber()); //1 console.log(generateNextNumber()); //2 console.log(generateNextNumber()); //3 let generateMultipleOfTen = createAGenerate(0, 10); console.log(generateMultipleOfTen()); //10 console.log(generateMultipleOfTen()); //20 console.log(generateMultipleOfTen()); //30 译者注：原文中依次输出0,1,2,0,10,20是有误的，感谢@Round的指正 6.6 对象与私有状态 以上示例中，我们可以创建一个拥有私有状态的函数。同时，我们也可以创建多个拥有同一私有状态的函数。基于此，我们还可以创建一个拥有私有状态的对象。 示例如下： function TodoStore(){ let todos = []; function add(todo){ todos.push(todo); } function get(){ return todos.filter(isPriorityTodo).map(toTodoViewModel); } function isPriorityTodo(todo){ return task.type === &quot;RE&quot; &amp;&amp; !task.completed; } function toTodoViewModel(todo) { return { id : todo.id, title : todo.title }; } return Object.freeze({ add, get }); } TodoStore() 函数返回了一个拥有私有状态的对象。在外部，我们无法访问私有的 todos 变量，并且 add 和 get 这两个闭包拥有相同的私有状态。在这里，TodoStore() 是一个工厂函数。 6.7 闭包 vs 纯函数 闭包就是那些引用了外部作用域中变量的函数。 为了更好的理解，我们将内部函数拆成闭包和纯函数两个方面： 闭包是那些引用了外部作用域中变量的函数。 纯函数是那些没有引用外部作用域中变量的函数，它们通常返回一个值并且没有副作用。 在上述例子中，add() 和 get() 函数是闭包，而 isPriorityTodo() 和 toTodoViewModel() 则是纯函数。 7 闭包在函数式编程中的应用 闭包在函数式编程中也应用广泛。譬如，underscore 源码中 函数相关小节 中的所有函数都利用了闭包这一特性。 A function decorator is a higher-order function that takes one function as an argument and returns another function, and the returned function is a variation of the argument function — Javascript Allongé 装饰器函数也使用了闭包的特性。 我们来看如下 not 这个简单的装饰器函数： function not(fn){ return function decorator(...args){ return !fn.apply(this, args); } } decorator() 函数引用了外部作用域的 fn 变量，因此它是一个闭包。 如果你想知道更多关于装饰器相关的知识，可以查看这篇文章。 8 垃圾回收 在 JavaScript 中，局部变量会随着函数的执行完毕而被销毁，除非还有指向他们的引用。当闭包本身也被垃圾回收之后，这些闭包中的私有状态随后也会被垃圾回收。通常我们可以通过切断闭包的引用来达到这一目的。 在这个例子中，我们首先创建了一个 add() 闭包。 let add = (function createAddClosure(){ let arr = []; return function(obj){ arr.push(obj); } })(); 随后，我们又定义了两个函数： addALotOfObjects() 往闭包变量 arr 中加入对象。 clearAllObjects() 将闭包函数置为 null 。 并且两个函数皆作为事件处理函数： function addALotOfObjects(){ for(let i=1; i&lt;=10000;i++) { add(new Todo(i)); } } function clearAllObjects(){ if(add){ add = null; } } $(&quot;#add&quot;).click(addALotOfObjects); $(&quot;#clear&quot;).click(clearAllObjects); 当我点击 Add 按钮时，将往闭包变量 arr 中加入 10000 个 todo 对象，内存快照如下： 当我点击 Clear 按钮时，我们将闭包引用置为 null。随后，闭包变量 arr 将被垃圾回收，内存快照如下： 9 避免全局变量 在 JavaScript 中，我们很容易创建出全局变量。任何定义在函数和 {} 块之外的变量都是全局的，定义在全局作用域中的函数也是全局的。 这里以定义创建不同对象的工厂函数为例。为了避免将所有的工厂函数都放在全局作用域下，最简单的方法就是将他们挂在 app 全局变量下。 示例如下： let app = Loader(); app.factory(function DataService(args){ return {}}); app.factory(function Helper(args){ return {}}); app.factory(function Mapper(args){ return {}}); app.factory(function Model(args){}); app.factory() 方法还可以将不同的工厂函数归类到不同的模块中。下面这个示例就是将 Timer 工厂函数归类到 tools 模块下。 app.factory(&quot;tools&quot;)(function Timer(args){ return {}}); 我们可以在 app 对象上暴露一个 start 方法来作为应用的入口点，通过回调函数中 factories 参数来访问这些工厂函数。这里 start() 函数只能被调用一次，如下： app.start(function startApplication(factories){ let helper = factories.Helper(); let dataService = factories.DataService(); let model = factories.Model({ dataService : dataService, helper : helper, timer : factories.tools.Timer() }); }); A Composition Root is a (preferably) unique location in an application where modules are composed together—Mark Seemann 9.1 loader 对象 让我们来将 app 完善为一个 loader 对象，示例如下： function Loader(){ let modules = Object.create(null); let started = false; function getNamespaceModule(modulesText){ let parent = modules; if(modulesText){ let parts = modulesText.split('.'); for(let i=0; i&lt;parts.length; i++){ let part = parts[i]; if (typeof parent[part] === &quot;undefined&quot;) { parent[part] = Object.create(null); } parent = parent[part]; } } return parent; } function addFunction(namespace, fn){ if(typeof(fn) !== &quot;function&quot;) { throw &quot;Only functions can be added&quot;; } let module = getNamespaceModule(namespace); let fnName = fn.name; module[fnName] = fn; } function addNamespace(namespace){ return function(fn){ addFunction(namespace, fn) } } function factory(){ if(typeof(arguments[0]) === &quot;string&quot;){ return addNamespace(arguments[0]); } else { return addFunction(null, arguments[0]); } } function start(startApplication){ if(started){ throw &quot;App can be started only once&quot;; } startApplication(Object.freeze(modules)); started = true; } return Object.freeze({ factory, start }); }; let app = Loader(); factory() 方法用于添加新的工厂函数到内部变量 modules 中。 start() 方法则会调用回调函数，在回调函数中访问内部变量。 通过 factory() 定义工厂函数，将 start() 作为整个应用中调用各种工厂函数生成不同对象的唯一入口点，这是如此简洁优雅的方式。 在这里，factory 和 start 都是闭包。 10 总结 闭包是一个可以访问外部作用域中变量的内部函数。 这些被引用的变量直到闭包被销毁时才会被销毁。 闭包使得 timer 定时器，事件处理，Ajax 请求等异步任务更加容易。 可以通过闭包来达到封装性。 最后，想获得更多关于 JavaScript 函数相关知识，可以查看以下文章： Discover Functional Programming in JavaScript with this thorough introduction Discover the power of first class functions How point-free composition will make you a better functional programmer Here are a few function decorators you can write from scratch Make your code easier to read with Functional Programming ","link":"https://faded.auspicious.space/post/javascript-discover-the-power-of-closures/"},{"title":"忘记 jQuery 使用原生接口","content":"jQuery VS JavaScript原生API 1 选择元素 // jQuery var els = $('.el'); //==========================================================// // 原生方法 var els = document.querySelectorAll('.el'); // 函数法 var $ = function (el) { return document.querySelectorAll(el); } var els = $('.el'); 2 创建元素 // jQuery var newEl = $('&lt;div/&gt;'); //==========================================================// // 原生方法 var newEl = document.createElement('div'); 3 添加 / 移除 / 切换类 // jQuery $('.el').addClass('class'); $('.el').removeClass('class'); $('.el').toggleClass('class'); //==========================================================// // 原生方法 document.querySelector('.el').classList.add('class'); document.querySelector('.el').classList.remove('class'); document.querySelector('.el').classList.toggle('class'); 4 判断是否包含类 // jQuery $('.el').hasClass('className'); $('.el').has('.className'); //也可以用来 判断是否包含某个元素 //==========================================================// // 原生方法(1) _hasClass(document.querySelector('.el'), className); function _hasClass( elements,cName ){ return !!elements.className.match( new RegExp( &quot;(\\\\s|^)&quot; + cName + &quot;(\\\\s|$)&quot;) ); }; // 原生方法(2) if(el.classList.contains(&quot;someClass&quot;)){} 5 添加事件监听器 // jQuery $('.el').on('event', function() { }); //==========================================================// // 原生方法 [].forEach.call(document.querySelectorAll('.el'), function (el) { el.addEventListener('event', function() { }, false); }); 原生－DOM绑定事件－优化1 参考HERE //DOM绑定事件-之自执行 var BindEvent = (function () { if ('addEventListener' in document) { return function (dom, event, handle, ex) { dom.addEventListener(event, handle, ex || false); } } else if ('attachEvent' in document) { return function (dom, event, handle) { dom.attachEvent('on' + event, handle); } } else { return function (dom, event, handle) { dom['on' + event] = handle; } } })();``` ## 原生－DOM绑定事件－优化2 ```javascript //DOM绑定事件-之惰性加载(调用方去触发BindEvent之时才去做初始化)// var BindEvent = function (dom, event, handle, ex) { if ('addEventListener' in document) { BindEvent = function (dom, event, handle, ex) { dom.addEventListener(event, handle, ex || false); } } else if ('attachEvent' in document) { trueBindEvent = function (dom, event, handle) { dom.attachEvent('on' + event, handle); } } else { BindEvent = function (dom, event, handle) { dom['on' + event] = handle; } } BindEvent(dom, event, handle, ex); }; 6 设置 / 获取属性 // jQuery $('.el').filter(':first').attr('key', 'value'); $('.el').filter(':first').attr('key'); //==========================================================// // 原生方法 document.querySelector('.el').setAttribute('key', 'value'); document.querySelector('.el').getAttribute('key'); 7 附加内容（Append） // jQuery $('.el').append($('&lt;div/&gt;')); //==========================================================// // 原生方法 document.querySelector('.el').appendChild(document.createElement('div')); 8 克隆元素 // jQuery var clonedEl = $('.el').clone(); //==========================================================// // 原生方法 var clonedEl = document.querySelector('.el').cloneNode(true); 9 移除元素 // jQuery $('.el').remove(); //==========================================================// // 原生方法 remove('.el'); function remove(el) { var toRemove = document.querySelector(el); toRemove.parentNode.removeChild(toRemove); } 10 获取父元素 // jQuery $('.el').parent(); //==========================================================// // 原生方法 document.querySelector('.el').parentNode; 11 上一个 / 下一个元素 // jQuery $('.el').prev(); $('.el').next(); //==========================================================// // 原生方法 document.querySelector('.el').previousElementSibling; document.querySelector('.el').nextElementSibling; 12 修改CSS属性 总是通过 Javascript 修改和检索 CSS 属性，这样会比使用 jQuery CSS 函数更加简单快速，并且没有任何不必要的代码。 //----设置CSS属性---- /* jQuery */ $(el).css({ background: &quot;#FF0000&quot;, &quot;box-shadow&quot;: &quot;1px 1px 5px 5px red&quot;, width: &quot;100px&quot;, height: &quot;100px&quot;, display: &quot;block&quot; }); //==========================================================// /* 原生 */ var el = document.querySelector(&quot;.main-content&quot;); el.style.background = &quot;#FF0000&quot;; el.style.width = &quot;100px&quot;; el.style.height = &quot;100px&quot;; el.style.display = &quot;block&quot;; el.style.boxShadow = &quot;1px 1px 5px 5px red&quot;; 13 XHR 或 Ajax // jQuery $.get('url', function (data) { }); $.post('url', {data: data}, function (data) { }); //==========================================================// // 原生方法 // get var xhr = new XMLHttpRequest(); xhr.open('GET', url); xhr.onreadystatechange = function (data) { } xhr.send(); // post var xhr = new XMLHttpRequest() xhr.open('POST', url); xhr.onreadystatechange = function (data) { } xhr.send({data: data}); ","link":"https://faded.auspicious.space/post/how-to-forget-about-jquery-and-start-using-native/"},{"title":"JavaScript——闭包实际场景应用","content":"1. 函数防抖 比如要缩放窗口 触发 onresize 事件 需要在这时候做一件事情,但是我们希望拖动的时候只触发一次,比如： window.onresize = function () { console.log('onresize')//只想触发一次 } 一般方法 window.onresize = function () { debounce(fn, 1000) } var fn = function () { console.log('fn') } var time = '' function debounce(fn, timeLong) { if (time) { clearTimeout(time) time = '' } time = setTimeout(function () { fn() }, timeLong) } 闭包 window.onresize = debounce(fn, 500) function debounce(fn) { var timer = null return function () { if (timer) { //timer第一次执行后会保存在内存里 永远都是执行器 直到最后被触发 clearTimeout(timer) timer = null } timer = setTimeout(function () { fn() }, 1000) } } var fn = function () { console.log('fn') } 2 使用闭包设计单例模式 class CreateUser { constructor(name) { this.name = name; this.getName(); } getName() { return this.name; } } // 代理实现单例模式 var ProxyMode = (function () { var instance = null; return function (name) { if (!instance) { instance = new CreateUser(name); } return instance; } })(); // 测试单体模式的实例 var a = ProxyMode(&quot;aaa&quot;); var b = ProxyMode(&quot;bbb&quot;); // 因为单体模式是只实例化一次，所以下面的实例是相等的 console.log(a === b); //true 3 为多个组件独立属性 假如我现在要在页面中使用 Echarts画 6 个线状图，需要 6 个容器。需要为每个容器元素声明一个独立 id，不然会混乱。 constructor(){ this.state = { id: &quot;EchartsLine&quot; + Util.clourse() }; } componentDidMount() { this.myEChart = echarts.init(document.getElementById(this.state.id));//不同 id } &lt;div id={this.state.id} className='echarts-line'&gt;&lt;/div&gt; clourse(){ let clourse = (function () { var a = 1; return function () { return a++; } })(this); this.clourse = clourse; } //使用数字命名 不用害怕被篡改 4 设置私有变量 内部属性在 Java 里使用 private 就可以，但是 JS 还没有这个东东。 let _width = Symbol(); class Private { constructor(s) { this[_width] = s } foo() { console.log(this[_width]) } } var p = new Private(&quot;50&quot;); p.foo(); console.log(p[_width]); //可以拿到 // 赋值到闭包里 let sque = (function () { let _width = Symbol(); class Squery { constructor(s) { this[_width] = s } foo() { console.log(this[_width]) } } return Squery })(); let ss = new sque(20); ss.foo(); console.log(ss[_width]) 5 拿到正确的值 for (var i = 0; i &lt; 10; i++) { setTimeout(function () { console.log(i) // 10 个 10 }, 1000) } 遇到这种问题 如何用解决呢？ for (var i = 0; i &lt; 10; i++) { ((j) =&gt; { setTimeout(function () { console.log(j)//1-10 }, 1000) })(i) } 原理是 声明了10个自执行函数，保存当时的值到内部。 ","link":"https://faded.auspicious.space/post/javascript-closure-application-scenarios/"},{"title":"JavaScript——闭包简介","content":" 闭包详解一 一、什么是闭包 《JavaScript高级程序设计》这样描述： 闭包是指有权访问另一个函数作用域中的变量的函数； 《JavaScript权威指南》这样描述： 从技术的角度讲，所有的JavaScript函数都是闭包：它们都是对象，它们都关联到作用域链。 《你不知道的JavaScript》这样描述： 当函数可以记住并访问所在的词法作用域时，就产生了闭包，即使函数是在当前词法作用域之外执行。 我最认同的是《你不知道的JavaScript》中的描述，虽然前面的两种说法都没有错，但闭包应该是基于词法作用域书写代码时产生的自然结果，是一种现象！你也不用为了利用闭包而特意的创建，因为闭包的在你的代码中随处可见，只是你还不知道当时你写的那一段代码其实就产生了闭包。 二、讲解闭包 上面已经说到，当函数可以记住并访问所在的词法作用域时，就产生了闭包，即使函数是在当前词法作用域之外执行。 看一段代码 function fn1() { var name = 'iceman'; function fn2() { console.log(name); } fn2(); } fn1(); 如果是根据《JavaScript高级程序设计》和《JavaScript权威指南》来说，上面的代码已经产生闭包了。fn2 访问到了 fn1 的变量，满足了条件“有权访问另一个函数作用域中的变量的函数”，fn2 本身是个函数，所以满足了条件“所有的JavaScript函数都是闭包”。 这的确是闭包，但是这种方式定义的闭包不太好观察。 再看一段代码： function fn1() { var name = 'iceman'; function fn2() { console.log(name); } return fn2; } var fn3 = fn1(); fn3(); 这样就清晰地展示了闭包： fn2 的词法作用域能访问 fn1的作用域； 将 fn2 当做一个值返回； fn1 执行后，将 fn2 的引用赋值给 fn3； 执行 fn3，输出了变量 name。 我们知道通过引用的关系，fn3 就是 fn2 函数本身。执行 fn3 能正常输出 name，这不就是 fn2 能记住并访问它所在的词法作用域，而且 fn2 函数的运行还是在当前词法作用域之外了。 正常来说，当 fn1 函数执行完毕之后，其作用域是会被销毁的，然后垃圾回收器会释放那段内存空间。而闭包却很神奇的将 fn1 的作用域存活了下来，fn2 依然持有该作用域的引用，这个引用就是闭包。 总结：某个函数在定义时的词法作用域之外的地方被调用，闭包可以使该函数极限访问定义时的词法作用域。 注意：对函数值的传递可以通过其他的方式，并不一定值有返回该函数这一条路，比如可以用回调函数： function fn1() { var name = 'iceman'; function fn2() { console.log(name); } fn3(fn2); } function fn3(fn) { fn(); } fn1(); 本例中，将内部函数 fn2 传递给 fn3，当它在 fn3 中被运行时，它是可以访问到 name变量的。 所以无论通过哪种方式将内部的函数传递到所在的词法作用域以外，它都回持有对原始作用域的引用，无论在何处执行这个函数都会使用闭包。 三、再次解释闭包 以上的例子会让人觉得有点学院派了，但是闭包绝不仅仅是一个无用的概念，你写过的代码当中肯定有闭包的身影，比如类似如下的代码： function waitSomeTime(msg, time) { setTimeout(function () { console.log(msg) }, time); } waitSomeTime('hello', 1000); 定时器中有一个匿名函数，该匿名函数就有涵盖 waitSomeTime 函数作用域的闭包，因此当 1 秒之后，该匿名函数能输出 msg。 另一个很经典的例子就是 for 循环中使用定时器延迟打印的问题： for (var i = 1; i &lt;= 10; i++) { setTimeout(function () { console.log(i); }, 1000); } 在这段代码中，我们对其的预期是输出 1~10，但却输出 10 次 11。这是因为 setTimeout 中的匿名函数执行的时候，for 循环都已经结束了，for 循环结束的条件是 i 大于 10，所以当然是输出 10 次 11 咯。 究其原因：i 是声明在全局作用中的，定时器中的匿名函数也是执行在全局作用域中，那当然是每次都输出 11 了。 原因知道了，解决起来就简单了，我们可以让i在每次迭代的时候，都产生一个私有的作用域，在这个私有的作用域中保存当前i的值。 for (var i = 1; i &lt;= 10; i++) { (function () { var j = i; setTimeout(function () { console.log(j); }, 1000); })(); } 这样就达到我们的预期了呀，让我们用一种比较优雅的写法改造一些，将每次迭代的i作为实参传递给自执行函数，自执行函数中用变量去接收： for (var i = 1; i &lt;= 10; i++) { (function (j) { setTimeout(function () { console.log(j); }, 1000); })(i); } 四、闭包的应用 闭包的应用比较典型是定义模块，我们将操作函数暴露给外部，而细节隐藏在模块内部： function module() { var arr = []; function add(val) { if (typeof val == 'number') { arr.push(val); } } function get(index) { if (index &lt; arr.length) { return arr[index] } else { return null; } } return { add: add, get: get } } var mod1 = module(); mod1.add(1); mod1.add(2); mod1.add('xxx'); console.log(mod1.get(2)); ","link":"https://faded.auspicious.space/post/javascript-closure-introduction/"},{"title":"JavaScript——7 个角度吃透 Lodash 防抖节流原理","content":" 浅出篇 7 个角度吃透 Lodash 防抖节流原理 节流函数 Throttle 我们先来看一张图，这张图充分说明了 Throttle（节流）和 Debounce（防抖）的区别，以及在不同配置下产生的不同效果，其中 mousemove 事件每 50 ms 触发一次，即下图中的每一小隔是 50 ms。今天这篇文章就从下面这张图开始介绍。 角度 1 lodash.throttle(fn, 200, {leading: true, trailing: true}) mousemove 第一次触发 先来看下 throttle 源码 function throttle(func, wait, options) { // 首尾调用默认为 true let leading = true let trailing = true if (typeof func !== 'function') { throw new TypeError('Expected a function') } // options 是否是对象 if (isObject(options)) { leading = 'leading' in options ? !!options.leading : leading trailing = 'trailing' in options ? !!options.trailing : trailing } // maxWait 为 wait 的防抖函数 return debounce(func, wait, { leading, trailing, 'maxWait': wait, }) } 所以 throttle(fn, 200, {leading: true, trailing: true}) 返回内容是 debounce(fn, 200, {leading: true, trailing: true, maxWait: 200})，多了 maxWait: 200 这部分。 先打个预防针，后面即将开始比较难的部分，看下 debounce 入口函数。 // 入口函数，返回此函数 function debounced(...args) { // 获取当前时间 const time = Date.now() // 判断此时是否应该执行 func 函数 const isInvoking = shouldInvoke(time) // 赋值给闭包，用于其他函数调用 lastArgs = args lastThis = this lastCallTime = time // 执行 if (isInvoking) { // 无 timerId 的情况有两种： // 1、首次调用 // 2、trailingEdge 执行过函数 if (timerId === undefined) { return leadingEdge(lastCallTime) } // 如果设置了最大等待时间，则立即执行 func // 1、开启定时器，到时间后触发 trailingEdge 这个函数。 // 2、执行 func，并返回结果 if (maxing) { // 循环定时器中处理调用 timerId = startTimer(timerExpired, wait) return invokeFunc(lastCallTime) } } // 一种特殊情况，trailing 设置为 true 时，前一个 wait 的 trailingEdge 已经执行了函数 // 此时函数被调用时 shouldInvoke 返回 false，所以要开启定时器 if (timerId === undefined) { timerId = startTimer(timerExpired, wait) } // 不需要执行时，返回结果 return result } 对于 debounce(fn, 200, {leading: true, trailing: true, maxWait: 200}) 来说，会经历如下过程。 shouldInvoke(time) 中，因为满足条件 lastCallTime === undefined，所以返回 true。 lastCallTime = time，所以 lastCallTime 等于当前时间，假设为 0。 timerId === undefined 满足，执行 leadingEdge(lastCallTime) 方法。 // 执行连续事件刚开始的那次回调 function leadingEdge(time) { // 1、设置上一次执行 func 的时间 lastInvokeTime = time // 2、开启定时器，为了事件结束后的那次回调 timerId = startTimer(timerExpired, wait) // 3、如果配置了 leading 执行传入函数 func // leading 来源自 !!options.leading return leading ? invokeFunc(time) : result } 在 leadingEdge(time) 中，设置 lastInvokeTime 为当前时间即 0，开启 200 毫秒定时器，执行 invokeFunc(time) 并返回。 // 执行 Func 函数 function invokeFunc(time) { // 获取上一次执行 debounced 的参数 const args = lastArgs // 获取上一次的 this const thisArg = lastThis // 重置 lastArgs = lastThis = undefined lastInvokeTime = time result = func.apply(thisArg, args) return result } 在 invokeFunc(time) 中，执行 func.apply(thisArg, args)，即 fn 函数第一次执行，并把结果赋值给 result，便于后续触发时直接返回。同时重置 lastInvokeTime 为当前时间即 0，清空 lastArgs 和 lastThis。 第一次触发已经完成，注意此时 lastCallTime 和 lastInvokeTime 都为 0，200 毫秒的定时器还在运行中。 mousemove 第二次触发 50 毫秒后第二次触发到来，此时当前时间 time 为 50，wait 为 200， maxWait 为 200，maxing 为 true，lastCallTime 和 lastInvokeTime 都为 0，timerId 定时器存在，我们来看下执行步骤。 function shouldInvoke(time) { // 当前时间距离上一次调用 debounce 的时间差 const timeSinceLastCall = time - lastCallTime // 当前时间距离上一次执行 func 的时间差 const timeSinceLastInvoke = time - lastInvokeTime // 下述 4 种情况返回 true return ( lastCallTime === undefined || (timeSinceLastCall &gt;= wait) || (timeSinceLastCall &lt; 0) || (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait) ) } shouldInvoke(time) 中，timeSinceLastCall 为 50，timeSinceLastInvoke 为 50，4 种条件都不满足，返回 false。 此时 isInvoking 为 false，同时 timerId === undefined 不满足，直接返回第一次触发时的 result。 第二次触发完成，并不会执行 fn，只会返回上次执行的结果 result。 第三次和第四次触发时，效果一样，就不再重复了。 mousemove 第五次触发 距第一次触发 200 毫秒后第五次触发到来，此时当前时间 time 为 200，wait 为 200， maxWait 为 200，maxing 为 true，lastCallTime 为 150，lastInvokeTime 为 0，timerId 定时器存在，我们来看下执行步骤。 shouldInvoke(time) 中，timeSinceLastInvoke 为 200，满足 (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait)，所以返回 true。 // debounced 方法中执行到这部分 if (maxing) { // 循环定时器中处理调用 timerId = startTimer(timerExpired, wait) return invokeFunc(lastCallTime) } 满足 maxing 条件，重新开启 200 毫秒的定时器，并执行 invokeFunc(lastCallTime) 函数。 invokeFunc(time) 中，重置 lastInvokeTime 为当前时间即 200，清空 lastArgs 和 lastThis。 第六、七、八次触发时，同第二次触发效果一致，就不再重复了。 mousemove 停止触发 假设第八次触发之后就停止了滚动，在第八次触发时 time 为 350，所以如果有第九次触发，那么此时是应该执行 fn 的，但是此时 mousemove 已经停止了触发，那么还会执行 fn 吗？答案是依旧执行，因为最开始设置了 {trailing: true}。 // 开启定时器 function startTimer(pendingFunc, wait) { // 没传 wait 时调用 window.requestAnimationFrame() if (useRAF) { // 若想在浏览器下次重绘之前继续更新下一帧动画 // 那么回调函数自身必须再次调用 window.requestAnimationFrame() root.cancelAnimationFrame(timerId); return root.requestAnimationFrame(pendingFunc) } // 不使用 RAF 时开启定时器 return setTimeout(pendingFunc, wait) } 在第五次触发时开启了 200 毫秒的定时器，所以在时间 time 到 400 时会执行 pendingFunc，此时的 pendingFunc 就是 timerExpired 函数，来看下具体的代码。 // 定时器回调函数，表示定时结束后的操作 function timerExpired() { const time = Date.now() // 1、是否需要执行 // 执行事件结束后的那次回调，否则重启定时器 if (shouldInvoke(time)) { return trailingEdge(time) } // 2、否则 计算剩余等待时间，重启定时器，保证下一次时延的末尾触发 timerId = startTimer(timerExpired, remainingWait(time)) } 此时在 shouldInvoke(time) 中，time 为 400，lastInvokeTime 为 200，timeSinceLastInvoke 为 200，满足 (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait)，所以返回 true。 // 执行连续事件结束后的那次回调 function trailingEdge(time) { // 清空定时器 timerId = undefined // trailing 和 lastArgs 两者同时存在时执行 // trailing 来源自 'trailing' in options ? !!options.trailing : trailing // lastArgs 标记位的作用，意味着 debounce 至少执行过一次 if (trailing &amp;&amp; lastArgs) { return invokeFunc(time) } // 清空参数 lastArgs = lastThis = undefined return result } 之后执行 trailingEdge(time)，在这个函数中判断 trailing 和 lastArgs，此时这两个条件都是 true，所以会执行 invokeFunc(time)，最终执行函数 fn。 这里需要说明以下两点： 如果设置了 {trailing: false}，那么最后一次是不会执行的。对于 throttle 和 debounce 来说，默认值是 true，所以如果没有特意指定 trailing，那么最后一次是一定会执行的。 对于 lastArgs 来说，执行 debounced 时会赋值，即每次触发都会重新赋值一次，那什么时候清空呢，在 invokeFunc(time) 中执行 fn 函数时重置为 undefined，所以如果 debounced 只触发了一次，即使设置了 {trailing: true} 那也不会再执行 fn 函数，这个就解答了上篇文章留下的第一道思考题。 角度 2 lodash.throttle(fn, 200, {leading: true, trailing: false}) 在角度 1 之 mousemove 停止触发这部分中说到，如果不设置 trailing 和设置 {trailing: true} 效果是一样的，事件回调结束后都会再执行一次传入函数 fn，但是如果设置了 {trailing: false}，那么事件回调结束后是不会再执行 fn 的。 此时的配置对比角度 1 来说，区别在于设置了 {trailing: false}，所以实际效果对比 1 来说，就是最后不会额外再执行一次，效果见第一张图。 角度 3 lodash.throttle(fn, 200, {leading: false, trailing: true}) 此时的配置和角度 1 相比，区别在于设置了 {leading: false}，所以直接看 leadingEdge(time) 方法就可以了。 // 执行连续事件刚开始的那次回调 function leadingEdge(time) { // 1、设置上一次执行 func 的时间 lastInvokeTime = time // 2、开启定时器，为了事件结束后的那次回调 timerId = startTimer(timerExpired, wait) // 3、如果配置了 leading 执行传入函数 func // leading 来源自 !!options.leading return leading ? invokeFunc(time) : result } 在这里，会开启 200 毫秒的定时器，同时因为 leading 为 false，所以并不会执行 invokeFunc(time)，只会返回 result，此时的 result 值是 undefined。 这里开启一个定时器的目的是为了事件结束后的那次回调，即如果设置了 {trailing: true} 那么最后一次回调将执行传入函数 fn，哪怕 debounced 函数只触发一次。 这里指定了 {leading: false}，那么 leading 的初始值是什么呢？在 debounce 中是 false，在 throttle 中是 true。所以在 throttle 中不需要刚开始就触发时，必须指定 {leading: false}，在 debounce 中就不需要了，默认不触发。 防抖函数 Debounce 角度 4 lodash.debounce(fn, 200, {leading: false, trailing: true}) 此时相比较 throttle 来说，缺少了 maxWait 值，所以具体触发过程中的判断就不一样了，来详细看一遍。 在入口函数 debounced 中，执行 shouldInvoke(time)，前面讨论过因为第一次触发所以会返回 true，之后执行 leadingEdge(lastCallTime)。 // 执行连续事件刚开始的那次回调 function leadingEdge(time) { // 1、设置上一次执行 func 的时间 lastInvokeTime = time // 2、开启定时器，为了事件结束后的那次回调 timerId = startTimer(timerExpired, wait) // 3、如果配置了 leading 执行传入函数 func // leading 来源自 !!options.leading return leading ? invokeFunc(time) : result } 在 leadingEdge 中，因为 leading 为 false，所以并不执行 fn，只开启 200 毫秒的定时器，并返回 undefined。此时 lastInvokeTime 为当前时间，假设为 0。 // 判断此时是否应该执行 func 函数 function shouldInvoke(time) { // 当前时间距离上一次调用 debounce 的时间差 const timeSinceLastCall = time - lastCallTime // 当前时间距离上一次执行 func 的时间差 const timeSinceLastInvoke = time - lastInvokeTime // 下述 4 种情况返回 true return ( lastCallTime === undefined || (timeSinceLastCall &gt;= wait) || (timeSinceLastCall &lt; 0) || (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait) ) } 之后每次触发时，timeSinceLastCall 总是为 50 毫秒，maxing 为 false，所以 shouldInvoke(time) 总是返回 false，并不会执行传入函数 fn，只返回 result，即为 undefined。 到现在为止，fn 一次还没有执行，200 毫秒后，定时器回调函数触发，执行 timerExpired 函数。 // 定时器回调函数，表示定时结束后的操作 function timerExpired() { const time = Date.now() // 1、是否需要执行 // 执行事件结束后的那次回调，否则重启定时器 if (shouldInvoke(time)) { return trailingEdge(time) } // 2、否则 计算剩余等待时间，重启定时器，保证下一次时延的末尾触发 timerId = startTimer(timerExpired, remainingWait(time)) } 此时存在两种情况，第一种是 mousemove 事件一直在触发，根据前面介绍 shouldInvoke(time) 会返回 false，之后就将计算剩余等待时间，重启定时器。时间计算公式为 wait - (time - lastCallTime)，即 200 - 50，所以只要 shouldInvoke(time) 返回 false，就每隔 150 毫秒后执行一次 timerExpired()。 第二种情况是 mousemove 事件不再触发，因为 timerExpired() 在循环执行，所以肯定会存在一种情况满足 timeSinceLastCall &gt;= wait，即 shouldInvoke(time) 返回 true，终结 timerExpired() 的循环，并执行 trailingEdge(time)。 // 执行连续事件结束后的那次回调 function trailingEdge(time) { // 清空定时器 timerId = undefined // trailing 和 lastArgs 两者同时存在时执行 // trailing 来源自 'trailing' in options ? !!options.trailing : trailing // lastArgs 标记位的作用，意味着 debounce 至少执行过一次 if (trailing &amp;&amp; lastArgs) { return invokeFunc(time) } // 清空参数 lastArgs = lastThis = undefined return result } 在 trailingEdge 中 trailing 和 lastArgs 都是 true，所以会执行 invokeFunc(time)，即执行传入函数 fn。 所以整个过程中只在最后执行一次传入函数 fn，效果同上面第一张图所示。 角度 5 lodash.debounce(fn, 200, {leading: true, trailing: false}) 此时相比角度 4 来说，差异在于 {leading: true, trailing: false}，但是 wait 和 maxWait 都和角度 4 一致，所以只存在下面 2 种区别，效果同上面第一张图所示。 区别 1：leadingEdge 中会执行传入函数 fn 区别 2：trailingEdge 中不再执行传入函数 fn 角度 6 lodash.debounce(fn, 200, {leading: true, trailing: true}) 此时相比角度 4 来说，差异仅仅在于设置了 {leading: true}，所以只存在一个区别，那就是在 leadingEdge 中会执行传入函数 fn，当然在 trailingEdge 中依旧执行传入函数 fn，所以会出现在 mousemove 事件触发过程中首尾都会执行的情况，效果同上面第一张图所示。 当然一种情况除外，那就是 mousemove 事件永远只触发一次的情况，关键在于 lastArgs 变量。 对于 lastArgs 变量来说，在入口函数 debounced 中赋值，即每次触发都会重新赋值一次，那什么时候清空呢，在 invokeFunc(time) 中重置为 undefined，所以如果 debounced 只触发了一次，而且在 {leading: true} 时执行过一次 fn，那么即使设置了 {trailing: true} 也不会再执行传入函数 fn。 角度 7 lodash.debounce(fn, 200, {leading: false, trailing: true, maxWait: 400}) 此时 wait 为 200，maxWait 为 400，maxing 为 true，我们来看下执行过程。 第一次触发时，因为 {leading: false}，所以肯定不会执行 fn，此时开启了一个 200 毫秒的定时器。 // 判断此时是否应该执行 func 函数 function shouldInvoke(time) { // 当前时间距离上一次调用 debounce 的时间差 const timeSinceLastCall = time - lastCallTime // 当前时间距离上一次执行 func 的时间差 const timeSinceLastInvoke = time - lastInvokeTime // 下述 4 种情况返回 true return ( lastCallTime === undefined || (timeSinceLastCall &gt;= wait) || (timeSinceLastCall &lt; 0) || (maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait) ) } 之后每隔 50 毫秒触发一次，每次都会执行 shouldInvoke(time) 函数，只有在第 400 毫秒时，才会满足 maxing &amp;&amp; timeSinceLastInvoke &gt;= maxWait，返回 true。 // 计算仍需等待的时间 function remainingWait(time) { // 当前时间距离上一次调用 debounce 的时间差 const timeSinceLastCall = time - lastCallTime // 当前时间距离上一次执行 func 的时间差 const timeSinceLastInvoke = time - lastInvokeTime // 剩余等待时间 const timeWaiting = wait - timeSinceLastCall // 是否设置了最大等待时间 // 是（节流）：返回「剩余等待时间」和「距上次执行 func 的剩余等待时间」中的最小值 // 否：返回剩余等待时间 return maxing ? Math.min(timeWaiting, maxWait - timeSinceLastInvoke) : timeWaiting } 但是在这之前的第 200 毫秒，定时器触发回调函数，执行 timerExpired，因为此时 shouldInvoke(time) 返回 false，所以会重新计算剩余等待时间并重启计时器，其中 timeWaiting 是 150 毫秒，maxWait - timeSinceLastInvoke 是 200 毫秒，所以计算结果是 150 毫秒。 150 毫秒之后，即自开始之后的第 350 毫秒时，会重新计算时间，其中 timeWaiting 依旧是 150 毫秒，maxWait - timeSinceLastInvoke 是 50 毫秒，所以重新开启 50 毫秒的定时器，即在第 400 毫秒时触发。 此时会发现定时器触发的时间是第 400 毫秒，shouldInvoke(time) 中返回 true 的时间也是在第 400 毫秒，为什么要这样呢？这样会冲突吗？首先定时器剩余时间判断和 shouldInvoke(time) 判断中，只要有一处满足执行 fn 条件，就会立马执行，同时 lastInvokeTime 值也会发生改变，所以另一处判断就不会生效了。另外本身定时器是不精准的，所以通过 Math.min(timeWaiting, maxWait - timeSinceLastInvoke) 取最小值的方式来减少误差。 于此同时，需要在 debounced 入口函数添加这么一句 if (timerId === undefined) {timerId = startTimer(timerExpired, wait)}，避免 trailingEdge 执行后定时器被清空。 最终效果和节流是一样的，只是时间间隔变大了而已，具体效果同第一张图所示。 ","link":"https://faded.auspicious.space/post/javascript-a-simple-explanation-to-debounce-and-throttle-in-lodash/"},{"title":"JavaScript——防抖和节流","content":" JS简单实现防抖和节流 1 防抖 - debounce 其中一种解决方案就是每次用户停止输入后，延迟超过 500ms 时，才去搜索此时的 string，这就是防抖。 1.1 原理 将若干个函数调用合成为一次，并在给定时间过去之后仅被调用一次。 1.2 代码实现 function debounce(fn, delay) { // 维护一个 timer，用来记录当前执行函数状态 let timer = null; return function() { // 通过 'this' 和 'arguments' 获取函数的作用域和变量 let context = this; let args = arguments; // 清理掉正在执行的函数，并重新执行 clearTimeout(timer); timer = setTimeout(function() { fn.apply(context, args); }, delay); } } let flag = 0; // 记录当前函数调用次数 // 当用户滚动时被调用的函数 function foo() { flag++; console.log('Number of calls: %d', flag); } // 在 debounce 中包装我们的函数，过 2 秒触发一次 document.body.addEventListener('scroll', debounce(foo, 2000)); 1.3 解释 debounce 函数封装后，返回内部函数。 每一次事件被触发，都会清除当前的 timer 然后重新设置超时并调用。这会导致每一次高频事件都会取消前一次的超时调用，导致事件处理程序不能被触发。 只有当高频事件停止，最后一次事件触发的超时调用才能在 delay 时间后执行。 2 节流 - throttle 另一种解决方案比防抖要宽松些，这时我们不想用户一味的输入，而是给用户一些搜索提示，所以在当中限制每过 500ms 就查询一次此时的 string，这就是节流。 2.1 原理 节流函数不管事件触发有多频繁，都会保证在规定时间内一定会执行一次真正的事件处理函数。 2.2 代码实现 代码实现有两种，一种是时间戳，另一种是定时器。 2.2.1 时间戳实现 function throttle(func, delay){ let prev = Date.now(); return function(){ const context = this; const args = arguments; const now = Date.now(); if(now - prev &gt;= delay){ func.apply(context, args); prev = Date.now(); } } } 当高频事件触发时，第一次应该会立即执行（给事件绑定函数与真正触发事件的间隔如果大于 delay 的话），而后再怎么频繁触发事件，也都是会每 delay 秒才执行一次。而当最后一次事件触发完毕后，事件也不会再被执行了。 2.2.2 定时器实现 当触发事件的时候，我们设置一个定时器，再触发事件的时候，如果定时器存在，就不执行；直到 delay 秒后，定时器执行执行函数，清空定时器，这样就可以设置下个定时器。 fucntion throttle(func, delay){ let timer = null; return funtion(){ let context = this; let args = arguments; if(!timer){ timer = setTimeout(function(){ func.apply(context, args); timer = null; }, delay); } } } 当第一次触发事件时，肯定不会立即执行函数，而是在 delay 秒后才执行。 之后连续不断触发事件，也会每 delay 秒执行一次。 当最后一次停止触发后，由于定时器的 delay 延迟，可能还会执行一次函数。 2.2.3 综合使用时间戳与定时器 完成一个事件触发时立即执行，触发完毕还能执行一次的节流函数。 function throttle(func, delay){ let timer = null; let startTime = Date.now(); return function(){ let curTime = Date.now(); let remaining = delay - (curTime - startTime); const context = this; const args = arguments; clearTimeout(timer); if(remaining &lt;= 0){ func.apply(context,args); startTime = Date.now(); }else{ timer = setTimeout(func, remaining); } } } 需要在每个 delay 时间中一定会执行一次函数，因此在节流函数内部使用开始时间、当前时间与 delay 来计算 remaining，当 remaining &lt;= 0 时表示该执行函数了，如果还没到时间的话就设定在 remaining 时间后再触发。当然在 remaining 这段时间中如果又一次发生事件，那么会取消当前的计时器，并重新计算一个 remaining 来判断当前状态。 ","link":"https://faded.auspicious.space/post/javascript-debounce-throttle/"},{"title":"什么是 P 问题、NP 问题和 NPC 问题","content":" 什么是P问题、NP问题和NPC问题 [转载] 什么是P问题、NP问题和NPC问题 1 总结 Problem Introduction P 能在多项式时间里找到一个解决算法 NP 能在多项式时间里验证一个解是否正确 NPC 1. 首先必须是一个NP问题 2. 所有的NP问题都能 reduce 成该问题 NP-Hard 只需要满足 NPC 问题的第二个条件即可 下面的一些说法或许是众多 OIer 最大的误区之一。 你会经常看到网上出现“这怎么做，这不是 NP 问题吗”、“这个只有搜了，这已经被证明是 NP 问题了”之类的话。你要知道，大多数人此时所说的 NP 问题其实都是指的 NPC 问题。他们没有搞清楚 NP 问题和 NPC 问题的概念。NP 问题并不是那种“只有搜才行”的问题，NPC 问题才是。好，行了，基本上这个误解已经被澄清了。下面的内容都是在讲什么是 P 问题，什么是 NP 问题，什么是 NPC 问题，你如果不是很感兴趣就可以不看了。接下来你可以看到，把 NP 问题当成是 NPC 问题是一个多大的错误。 2 时间复杂度 还是先用几句话简单说明一下时间复杂度。时间复杂度并不是表示一个程序解决问题需要花多少时间，而是当问题规模扩大后，程序需要的时间长度增长得有多快。也就是说，对于高速处理数据的计算机来说，处理某一个特定数据的效率不能衡量一个程序的好坏，而应该看当这个数据的规模变大到数百倍后，程序运行时间是否还是一样，或者也跟着慢了数百倍，或者变慢了数万倍。不管数据有多大，程序处理花的时间始终是那么多的，我们就说这个程序很好，具有 O(1)O(1)O(1) 的时间复杂度，也称常数级复杂度；数据规模变得有多大，花的时间也跟着变得有多长，这个程序的时间复杂度就是 O(n)O(n)O(n)，比如找 nnn 个数中的最大值；而像冒泡排序、插入排序等，数据扩大 2 倍，时间变慢 4 倍的，属于 O(n2)O(n^2)O(n2) 的复杂度。还有一些穷举类的算法，所需时间长度成几何阶数上涨，这就是 O(an)O(a^n)O(an) 的指数级复杂度，甚至 O(n!)O(n!)O(n!) 的阶乘级复杂度。不会存在 O(2n2)O(2n^2)O(2n2) 的复杂度，因为前面的那个“2”是系数，根本不会影响到整个程序的时间增长。同样地，O(n3+n2)O(n^3+n^2)O(n3+n2) 的复杂度也就是 O(n3)O(n^3)O(n3) 的复杂度。因此，我们会说，一个 O(0.01∗n3)O(0.01*n^3)O(0.01∗n3) 的程序的效率比 O(100n2)O(100n^2)O(100n2) 的效率低，尽管在 nnn 很小的时候，前者优于后者，但后者时间随数据规模增长得慢，最终 O(n3)O(n^3)O(n3) 的复杂度将远远超过 O(n2)O(n^2)O(n2)。我们也说，O(n100)O(n^{100})O(n100) 的复杂度小于 O(1.01n)O(1.01^n)O(1.01n) 的复杂度。 容易看出，前面的几类复杂度被分为两种级别，其中后者的复杂度无论如何都远远大于前者：一种是 O(1)O(1)O(1)，O(log⁡(n))O(\\log(n))O(log(n))，O(na)O(n^a)O(na)等，我们把它叫做多项式级的复杂度，因为它的规模 n 出现在底数的位置；另一种是 O(an)O(a^n)O(an) 和 O(n!)O(n!)O(n!) 型复杂度，它是非多项式级的，其复杂度计算机往往不能承受。当我们在解决一个问题时，我们选择的算法通常都需要是多项式级的复杂度，非多项式级的复杂度需要的时间太多，往往会超时，除非是数据规模非常小。 自然地，人们会想到一个问题：会不会所有的问题都可以找到复杂度为多项式级的算法呢？很遗憾，答案是否定的。有些问题甚至根本不可能找到一个正确的算法来，这称之为“不可解问题”(Undecidable Decision Problem)。The Halting Problem 就是一个著名的不可解问题，在我的 Blog 上有过专门的介绍和证明。再比如，输出从 1 到 n 这 n 个数的全排列。不管你用什么方法，你的复杂度都是阶乘级，因为你总得用阶乘级的时间打印出结果来。有人说，这样的“问题”不是一个“正规”的问题，正规的问题是让程序解决一个问题，输出一个“YES”或“NO”（这被称为判定性问题），或者一个什么什么的最优值（这被称为最优化问题）。那么，根据这个定义，我也能举出一个不大可能会有多项式级算法的问题来：Hamilton 回路。问题是这样的：给你一个图，问你能否找到一条经过每个顶点一次且恰好一次（不遗漏也不重复）最后又走回来的路（满足这个条件的路径叫做 Hamilton 回路）。这个问题现在还没有找到多项式级的算法。事实上，这个问题就是我们后面要说的 NPC 问题。 3 P 问题 下面引入 P 类问题的概念：如果一个问题可以找到一个能在多项式的时间里解决它的算法，那么这个问题就属于 P 问题。P 是英文单词多项式的第一个字母。哪些问题是 P 类问题呢？通常 NOI 和 NOIP 不会出不属于 P 类问题的题目。我们常见到的一些信息奥赛的题目都是 P 问题。道理很简单，一个用穷举换来的非多项式级时间的超时程序不会涵盖任何有价值的算法。 4 NP 问题 接下来引入 NP 问题的概念。这个就有点难理解了，或者说容易理解错误。在这里强调（回到我竭力想澄清的误区上），NP 问题不是非 P 类问题。NP 问题是指可以在多项式的时间里验证一个解的问题。NP 问题的另一个定义是，可以在多项式的时间里猜出一个解的问题。比方说，我 RP 很好，在程序中需要枚举时，我可以一猜一个准。现在某人拿到了一个求最短路径的问题，问从起点到终点是否有一条小于 100 个单位长度的路线。它根据数据画好了图，但怎么也算不出来，于是来问我：你看怎么选条路走得最少？我说，我 RP 很好，肯定能随便给你指条很短的路出来。然后我就胡乱画了几条线，说就这条吧。那人按我指的这条把权值加起来一看，嘿，神了，路径长度 98，比 100 小。于是答案出来了，存在比 100 小的路径。别人会问他这题怎么做出来的，他就可以说，因为我找到了一个比 100 小的解。在这个题中，找一个解很困难，但验证一个解很容易。验证一个解只需要 O(n)O(n)O(n) 的时间复杂度，也就是说我可以花 O(n)O(n)O(n) 的时间把我猜的路径的长度加出来。那么，只要我 RP 好，猜得准，我一定能在多项式的时间里解决这个问题。我猜到的方案总是最优的，不满足题意的方案也不会来骗我去选它。这就是 NP 问题。当然有不是 NP 问题的问题，即你猜到了解但是没用，因为你不能在多项式的时间里去验证它。下面我要举的例子是一个经典的例子，它指出了一个目前还没有办法在多项式的时间里验证一个解的问题。很显然，前面所说的 Hamilton 回路是 NP 问题，因为验证一条路是否恰好经过了每一个顶点非常容易。但我要把问题换成这样：试问一个图中是否不存在 Hamilton 回路。这样问题就没法在多项式的时间里进行验证了，因为除非你试过所有的路，否则你不敢断定它“没有 Hamilton 回路”。 之所以要定义 NP 问题，是因为通常只有 NP 问题才可能找到多项式的算法。我们不会指望一个连多项式地验证一个解都不行的问题存在一个解决它的多项式级的算法。相信读者很快明白，信息学中的号称最困难的问题——“NP 问题”，实际上是在探讨 NP 问题与 P 类问题的关系。 很显然，所有的 P 类问题都是 NP 问题。也就是说，能多项式地解决一个问题，必然能多项式地验证一个问题的解——既然正解都出来了，验证任意给定的解也只需要比较一下就可以了。关键是，人们想知道，是否所有的 NP 问题都是 P 类问题。我们可以再用集合的观点来说明。如果把所有 P 类问题归为一个集合 P 中，把所有 NP 问题划进另一个集合 NP 中，那么，显然有 P 属于 NP。现在，所有对 NP 问题的研究都集中在一个问题上，即究竟是否有 P=NP ？通常所谓的“NP 问题”，其实就一句话：证明或推翻 P=NP。 NP 问题一直都是信息学的巅峰。巅峰，意即很引人注目但难以解决。在信息学研究中，这是一个耗费了很多时间和精力也没有解决的终极问题，好比物理学中的大统一和数学中的歌德巴赫猜想等。 目前为止这个问题还“啃不动”。但是，一个总的趋势、一个大方向是有的。人们普遍认为，P=NP 不成立，也就是说，多数人相信，存在至少一个不可能有多项式级复杂度的算法的 NP 问题。人们如此坚信 P≠NP 是有原因的，就是在研究 NP 问题的过程中找出了一类非常特殊的 NP 问题叫做 NP-完全问题，也即所谓的 NPC 问题。C 是英文单词“完全”的第一个字母。正是 NPC 问题的存在，使人们相信 P≠NP。下文将花大量篇幅介绍 NPC 问题，你从中可以体会到 NPC 问题使 P=NP 变得多么不可思议。 5 规约 为了说明 NPC 问题，我们先引入一个概念——约化(Reducibility，有的资料上叫“归约”)。 简单地说，一个问题 A 可以约化为问题 B 的含义即是，可以用问题 B 的解法解决问题 A，或者说，问题 A 可以“变成”问题 B。《算法导论》上举了这么一个例子。比如说，现在有两个问题：求解一个一元一次方程和求解一个一元二次方程。那么我们说，前者可以约化为后者，意即知道如何解一个一元二次方程那么一定能解出一元一次方程。我们可以写出两个程序分别对应两个问题，那么我们能找到一个“规则”，按照这个规则把解一元一次方程程序的输入数据变一下，用在解一元二次方程的程序上，两个程序总能得到一样的结果。这个规则即是：两个方程的对应项系数不变，一元二次方程的二次项系数为 0。按照这个规则把前一个问题转换成后一个问题，两个问题就等价了。同样地，我们可以说，Hamilton 回路可以约化为 TSP(Travelling Salesman Problem，旅行商问题)：在Hamilton 回路问题中，两点相连即这两点距离为 0，两点不直接相连则令其距离为 1，于是问题转化为在 TSP 中，是否存在一条长为 0 的路径。Hamilton 回路存在当且仅当 TSP 中存在长为 0 的回路。 “问题 A 可约化为问题 B”有一个重要的直观意义：B 的时间复杂度高于或者等于 A 的时间复杂度。也就是说，问题 A 不比问题 B 难。这很容易理解。既然问题 A 能用问题 B 来解决，倘若 B 的时间复杂度比 A 的时间复杂度还低了，那 A 的算法就可以改进为 B 的算法，两者的时间复杂度还是相同。正如解一元二次方程比解一元一次方程难，因为解决前者的方法可以用来解决后者。 很显然，约化具有一项重要的性质：约化具有传递性。如果问题 A 可约化为问题 B，问题 B 可约化为问题 C，则问题 A 一定可约化为问题 C。这个道理非常简单，就不必阐述了。 现在再来说一下约化的标准概念就不难理解了：如果能找到这样一个变化法则，对任意一个程序 A 的输入，都能按这个法则变换成程序 B 的输入，使两程序的输出相同，那么我们说，问题 A 可约化为问题 B。 当然，我们所说的“可约化”是指的可“多项式地”约化(Polynomial-time Reducible)，即变换输入的方法是能在多项式的时间里完成的。约化的过程只有用多项式的时间完成才有意义。 好了，从约化的定义中我们看到，一个问题约化为另一个问题，时间复杂度增加了，问题的应用范围也增大了。通过对某些问题的不断约化，我们能够不断寻找复杂度更高，但应用范围更广的算法来代替复杂度虽然低，但只能用于很小的一类问题的算法。再回想前面讲的 P 和 NP 问题，联想起约化的传递性，自然地，我们会想问，如果不断地约化上去，不断找到能“通吃”若干小 NP 问题的一个稍复杂的大 NP 问题，那么最后是否有可能找到一个时间复杂度最高，并且能“通吃”所有的 NP 问题的这样一个超级 NP 问题？答案居然是肯定的。也就是说，存在这样一个 NP 问题，所有的 NP 问题都可以约化成它。换句话说，只要解决了这个问题，那么所有的 NP 问题都解决了。这种问题的存在难以置信，并且更加不可思议的是，这种问题不只一个，它有很多个，它是一类问题。这一类问题就是传说中的 NPC 问题，也就是 NP-完全问题。NPC 问题的出现使整个 NP 问题的研究得到了飞跃式的发展。我们有理由相信，NPC 问题是最复杂的问题。再次回到全文开头，我们可以看到，人们想表达一个问题不存在多项式的高效算法时应该说它“属于 NPC 问题”。此时，我的目的终于达到了，我已经把 NP 问题和 NPC 问题区别开了。到此为止，本文已经写了近 5000 字了，我佩服你还能看到这里来，同时也佩服一下自己能写到这里来。 6 NPC 问题 NPC 问题的定义非常简单。同时满足下面两个条件的问题就是 NPC 问题。 首先，它得是一个 NP 问题； 然后，所有的 NP 问题都可以约化到它。 证明一个问题是 NPC 问题也很简单。先证明它至少是一个 NP 问题，再证明其中一个已知的 NPC 问题能约化到它（由约化的传递性，则 NPC 问题定义的第二条也得以满足；至于第一个 NPC 问题是怎么来的，下文将介绍），这样就可以说它是 NPC 问题了。 既然所有的 NP 问题都能约化成 NPC 问题，那么只要任意一个 NPC 问题找到了一个多项式的算法，那么所有的 NP 问题都能用这个算法解决了，NP 也就等于 P 了。因此，给 NPC 找一个多项式算法太不可思议了。因此，前文才说，“正是 NPC 问题的存在，使人们相信 P≠NP”。我们可以就此直观地理解，NPC 问题目前没有多项式的有效算法，只能用指数级甚至阶乘级复杂度的搜索。 7 NP-Hard 问题 顺便讲一下 NP-Hard 问题。NP-Hard 问题是这样一种问题，它满足 NPC 问题定义的第二条但不一定要满足第一条（就是说，NP-Hard 问题要比 NPC 问题的范围广）。NP-Hard 问题同样难以找到多项式的算法，但它不列入我们的研究范围，因为它不一定是 NP 问题。即使 NPC 问题发现了多项式级的算法，NP-Hard 问题有可能仍然无法得到多项式级的算法。事实上，由于 NP-Hard 放宽了限定条件，它将有可能比所有的 NPC 问题的时间复杂度更高从而更难以解决。 8 NPC 问题示例 不要以为 NPC 问题是一纸空谈。NPC 问题是存在的。确实有这么一个非常具体的问题属于 NPC 问题。下文即将介绍它。 下文即将介绍逻辑电路问题。这是第一个 NPC 问题。其它的 NPC 问题都是由这个问题约化而来的。因此，逻辑电路问题是 NPC 类问题的“鼻祖”。 逻辑电路问题是指的这样一个问题：给定一个逻辑电路，问是否存在一种输入使输出为 True。 什么叫做逻辑电路呢？一个逻辑电路由若干个输入，一个输出，若干“逻辑门”和密密麻麻的线组成。看下面一例，不需要解释你马上就明白了。 +----------+ | Input 1 +---+ +----------+ | | +----------+ +--&gt;+ | | OR +---+ +--&gt;+ | | | +----------+ | +----------+ +----------+ | +---&gt;+ | | Input 2 +---+ | AND +---&gt; Output +----------+ +---&gt;+ | +----------+ | +----------+ | | | +--&gt;+ NOT +---+ | | | +----------+ | +----------+ | Input 3 +---+ +----------+ 这是个较简单的逻辑电路，当输入 1、输入 2、输入 3分别为 True、True、False 或 False、True、False 时，输出为True。 有输出无论如何都不可能为 True 的逻辑电路吗？有。下面就是一个简单的例子。 +----------+ | Input 1 +---+ +----------+ | | +----------+ +---+ | | AND +---+ +---+ | | | +----------+ | +----------+ | +---&gt;+ | | | AND +---&gt; Output | +---&gt;+ | | +----------+ | +----------+ | | | | +---+ NOT +---+ | | | +----------+ | +----------+ | Input 2 +---+ +----------+ 上面这个逻辑电路中，无论输入是什么，输出都是 False。我们就说，这个逻辑电路不存在使输出为 True 的一组输入。 回到上文，给定一个逻辑电路，问是否存在一种输入使输出为 True，这即逻辑电路问题。 逻辑电路问题属于 NPC 问题。这是有严格证明的。它显然属于 NP 问题，并且可以直接证明所有的 NP 问题都可以约化到它（不要以为 NP 问题有无穷多个将给证明造成不可逾越的困难）。证明过程相当复杂，其大概意思是说任意一个 NP 问题的输入和输出都可以转换成逻辑电路的输入和输出（想想计算机内部也不过是一些 0 和 1 的运算），因此对于一个 NP 问题来说，问题转化为了求出满足结果为 True 的一个输入（即一个可行解）。 有了第一个 NPC 问题后，一大堆 NPC 问题就出现了，因为再证明一个新的 NPC 问题只需要将一个已知的 NPC 问题约化到它就行了。后来，Hamilton 回路成了 NPC 问题，TSP 问题也成了 NPC 问题。现在被证明是 NPC 问题的有很多，任何一个找到了多项式算法的话所有的 NP 问题都可以完美解决了。因此说，正是因为 NPC 问题的存在，P=NP 变得难以置信。P=NP 问题还有许多有趣的东西，有待大家自己进一步的挖掘。攀登这个信息学的巅峰是我们这一代的终极目标。现在我们需要做的，至少是不要把概念弄混淆了。 ","link":"https://faded.auspicious.space/post/what-is-p-problem-np-problem-and-npc-problem/"},{"title":"NP 完全性理论","content":"1 计算模型 1.1 随机存取机 RAM 1.2 随机存取存储程序机 RASP 1.3 图灵机 1.4 图灵机模型与 RAM 模型的关系 1.5 问题变换与计算复杂性归约 1.1 随机存取机RAM 1.1.1 RAM 的结构 1.1.2 RAM 程序 一个RAM程序定义了从输入带到输出带的一个映射。可以对这种映射关系作 2 种不同的解释。 解释一：把 RAM 程序看成是计算一个函数 若一个 RAM 程序 PPP 总是从输入带前 nnn 个方格中读入 nnn 个整数 x1,x2,…,xnx_1, x_2,\\ldots,x_nx1​,x2​,…,xn​，并且在输出带的第一个方格上输出一个整数 yyy 后停机，那么就说程序 PPP 计算了函数 f(x1,x2,…,xn)=yf(x_1, x_2,\\ldots,x_n)=yf(x1​,x2​,…,xn​)=y。 解释二：把 RAM 程序当作一个语言接受器。 将字符串 S=a1a2…anS=a_1a_2\\ldots a_nS=a1​a2​…an​ 放在输入带上。在输入带的第一个方格中放入符号 a1a_1a1​，第二个方格中放入符号 a2a_2a2​，……，第 nnn 个方格中放入符号 ana_nan​。然后在第 n+1n+1n+1 个方格中放入000，作为输入串的结束标志符。如果一个 RAM 程序 PPP 读了字符串 SSS 及结束标志符 000 后，在输出带的第一格输出一个 111 并停机，就说程序 PPP 接受字符串SSS。 1.1.3 RAM程序的耗费标准 标准一：均匀耗费标准 在均匀耗费标准下，每条 RAM 指令需要一个单位时间；每个寄存器占用一个单位空间。以后除特别注明，RAM 程序的复杂性将按照均匀耗费标准衡量。 标准二：对数耗费标准 对数耗费标准是基于这样的假定，即执行一条指令的耗费与以二进制表示的指令的操作数长度成比例。在 RAM 计算模型下，假定一个寄存器可存放一个任意大小的整数。 1.2 随机存取存储程序机 RASP 1.2.1 RASP的结构 RASP 的整体结构类似于 RAM，所不同的是 RASP 的程序是存储在寄存器中的。每条 RASP 指令占据 2 个连续的寄存器。第一个寄存器存放操作码的编码，第二个寄存器存放地址。RASP 指令用整数进行编码。 1.2.2 RASP程序的复杂性 不管是在均匀耗费标准下，还是在对数耗费标准下，RAM 程序和 RASP 程序的复杂性只差一个常数因子。在一个计算模型下 T(n)T(n)T(n) 时间内完成的输入-输出映射可在另一个计算模型下模拟，并在 kT(n)kT(n)kT(n) 时间内完成。其中 kkk 是一个常数因子。空间复杂性的情况也是类似的。 1.3 图灵机 1.3.1 多带图灵机 根据有限状态控制器的当前状态及每个读写头读到的带符号，图灵机的一个计算步可实现下面 3 个操作之一或全部。 改变有限状态控制器中的状态。 清除当前读写头下的方格中原有带符号并写上新的带符号。 独立地将任何一个或所有读写头，向左移动一个方格（L）或向右移动一个方格（R）或停在当前单元不动（S）。 k 带图灵机可形式化地描述为一个 7 元组 (Q,T,I,δ,b,q0,qf)(Q,T,I,\\delta,b,q_0,q_f)(Q,T,I,δ,b,q0​,qf​)，其中: QQQ 是有限个状态的集合。 TTT 是有限个带符号的集合。 III 是输入符号的集合，I⊆TI\\subseteq TI⊆T。 bbb 是惟一的空白符，b∈T−Ib \\in T-Ib∈T−I。 q0q_0q0​ 是初始状态。 qfq_fqf​ 是终止（或接受）状态。 δ\\deltaδ 是移动函数。它是从 Q×TkQ\\times T^kQ×Tk 的某一子集映射到 Q×(T×{L,R,S})kQ\\times(T\\times \\lbrace L, R, S\\rbrace)^kQ×(T×{L,R,S})k 的函数。 与 RAM 模型类似，图灵机既可作为语言接受器，也可作为计算函数的装置。 图灵机 M 的时间复杂性 T(n)T(n)T(n) 是它处理所有长度为 nnn 的输入所需的最大计算步数。如果对某个长度为 nnn 的输入，图灵机不停机，T(n)T(n)T(n) 对这个 nnn 值无定义。 图灵机的空间复杂性 S(n)S(n)S(n) 是它处理所有长度为 nnn 的输入时，在 k 条带上所使用过的方格数的总和。如果某个读写头无限地向右移动而不停机，S(n)S(n)S(n) 也无定义。 1.4 图灵机模型与 RAM 模型的关系 图灵机模型与 RAM 模型的关系是指同一问题在这 2 种不同计算模型下的复杂性之间的关系。 定理 8-3 对于问题 PPP 的任何长度为 nnn 的输入，设求解问题 PPP 的算法 AAA 在 k 带图灵机模型 TM 下的时间复杂性为 T(n)T(n)T(n)，那么，算法 AAA 在 RAM 模型下的时间复杂性为 O(T2(n))O(T^2(n))O(T2(n))。 定理 8-4 对于问题 PPP 的任何长度为 nnn 的输入，设求解问题 PPP 的算法 AAA 在 RAM 模型下，不含有乘法和除法指令，且按对数耗费标准其时间复杂性为 T(n)T(n)T(n)，那么，算法 AAA 在 k 带图灵机模型 TM 下的时间复杂性为 O(T2(n))O(T^2(n))O(T2(n))。 1.5 问题变换与计算复杂性归约 通过问题变换的技巧，可以将 2 个不同问题的计算复杂性联系在一起。这样就可以将一个问题的计算复杂性归结为另一个问题的计算复杂性，从而实现问题的计算复杂性归约。 具体地说，假设有 2 个问题 A 和 B，将问题 A 变换为问题 B 是指： 将问题 A 的输入变换为问题 B 的适当输入。 解出问题 B。 把问题 B 的输出变换为问题 A 的正确解。 若用 O(τ(n))O(\\tau(n))O(τ(n)) 时间能完成上述变换的第 1 步和第 3 步，则称问题 A 是τ(n)\\tau(n)τ(n) 时间可变换到问题 B，且简记为 A∝τ(n)BA\\propto _{\\tau(n)}BA∝τ(n)​B。其中的 nnn 通常为问题 A 的规模(大小)。 当 τ(n)\\tau(n)τ(n) 为 nnn 的多项式时，称问题 A 可在多项式时间内变换为问题 B。特别地，当 τ(n)\\tau(n)τ(n) 为 nnn 的线性函数时，称问题 A 可线性地变换为问题 B。 问题的变换与问题的计算复杂性归约的关系： 命题 1（计算时间下界归约）：若已知问题 A 的计算时间下界为 T(n)T(n)T(n)，且问题 AAA 是τ(n)\\tau(n)τ(n) 可变换到问题 B，即 A∝τ(n)BA \\propto _{\\tau(n)}BA∝τ(n)​B，则 T(n)−O(τ(n))T(n)-O(\\tau(n))T(n)−O(τ(n)) 为问题 B 的一个计算时间下界。 命题 2（计算时间上界归约）：若已知问题 B 的计算时间上界为 T(n)T(n)T(n)，且问题 A 是 τ(n)\\tau(n)τ(n) 可变换到问题 B，即 A∝τ(n)BA\\propto _{\\tau(n)}BA∝τ(n)​B，则 T(n)+O(τ(n))T(n)+O(\\tau(n))T(n)+O(τ(n)) 是问题 A 的一个计算时间上界。 在命题 1 和命题 2 中，当 τ(n)=O(T(n))\\tau(n)=O(T(n))τ(n)=O(T(n)) 时，问题 A 的下界归约为问题 B 的下界，问题 B 的上界归约为问题 A 的上界。 2 P 类与 NP 类问题 2.1 非确定性图灵机 2.2 P类与NP类语言 2.3 多项式时间验证 2.1 非确定性图灵机 在图灵机计算模型中，移动函数 δ\\deltaδ 是单值的，即对于 Q×TkQ\\times T^kQ×Tk中的每一个值，当它属于 δ\\deltaδ 的定义域时，Q×(T×{L，R，S})kQ \\times (T \\times \\lbrace L，R，S\\rbrace)^kQ×(T×{L，R，S})k 中只有惟一的值与之对应，称这种图灵机为确定性图灵机，简记为 DTM(Deterministic Turing Machine)。 非确定性图灵机（NDTM）：一个 k 带的非确定性图灵机 M 是一个 7 元组：(Q,T,I,δ,b,q0,qf)(Q, T, I, \\delta, b, q_0, q_f)(Q,T,I,δ,b,q0​,qf​)。与确定性图灵机不同的是非确定性图灵机允许移动函数 δ\\deltaδ 具有不确定性，即对于 Q×TkQ\\times T^kQ×Tk 中的每一个值 (q;x1,x2,…,xk)(q; x_1, x_2,\\ldots, x_k)(q;x1​,x2​,…,xk​)，当它属于 δ\\deltaδ 的定义域时，Q×(T×{L,R,S})kQ \\times (T \\times \\lbrace L, R, S \\rbrace)^kQ×(T×{L,R,S})k 中有惟一的一个子集 δ(q;x1,x2,…,xk)\\delta(q; x_1, x_2,\\ldots, x_k)δ(q;x1​,x2​,…,xk​) 与之对应。可以在 δ(q;x1,x2,…,xk)\\delta(q; x_1, x_2, \\ldots, x_k)δ(q;x1​,x2​,…,xk​) 中随意选定一个值作为它的函数值。 2.2 P 类与 NP 类语言 2.2.1 P 类和 NP 类语言的定义： P = {L∣L\\lbrace L|L{L∣L 是一个能在多项式时间内被一台 DTM 所接受的语言}\\rbrace} NP = {L∣L\\lbrace L|L{L∣L 是一个能在多项式时间内被一台 NDTM 所接受的语言}\\rbrace} 由于一台确定性图灵机可看作是非确定性图灵机的特例，所以可在多项式时间内被确定性图灵机接受的语言也可在多项式时间内被非确定性图灵机接受。故 P⊆NPP \\subseteq NPP⊆NP。 2.2.2 NP 类语言举例——无向图的团问题 该问题的输入是一个有 nnn 个顶点的无向图 G=(V,E)G=(V, E)G=(V,E) 和一个整数 kkk。要求判定图 GGG 是否包含一个 kkk 顶点的完全子图（团），即判定是否存在 V′⊆V,∣V′∣=kV&#x27; \\subseteq V, \\vert V&#x27;\\vert=kV′⊆V,∣V′∣=k，且对于所有的 u,v∈V′u, v\\in V&#x27;u,v∈V′，有 (u,v)∈E(u, v)\\in E(u,v)∈E。 若用邻接矩阵表示图 GGG，用二进制串表示整数 kkk，则团问题的一个实例可以用长度为 n2+log⁡k+1n^2+\\log{k}+1n2+logk+1 的二进位串表示。因此，团问题可表示为语言： CLIQUE = {w#v∣w，v∈{0,1}∗\\lbrace w\\# v\\vert w，v\\in \\lbrace 0, 1\\rbrace ^*{w#v∣w，v∈{0,1}∗，以 www 为邻接矩阵的图 GGG 有一个 kkk 顶点的团，其中 vvv 是 kkk 的二进制表示。}\\rbrace} 接受该语言 CLIQUE 的非确定性算法：用非确定性选择指令选出包含 kkk 个顶点的候选顶点子集 VVV，然后确定性地检查该子集是否是团问题的一个解。算法分为 3 个阶段： 算法的第一阶段将输入串 w#vw\\#vw#v 分解，并计算出 n=∣w,∣n= \\sqrt{\\vert w, \\vert}n=∣w,∣​，以及用 vvv 表示的整数 kkk。若输入不具有形式 w#vw\\#vw#v 或 ∣w∣\\vert w\\vert∣w∣ 不是一个平方数就拒绝该输入。显而易见，第一阶段可 O(n2)O(n^2)O(n2) 在时间内完成。 在算法的第二阶段中，非确定性地选择V的一个 kkk 元子集 V′⊆VV&#x27;\\subseteq VV′⊆V。 算法的第三阶段是确定性地检查 V′V&#x27;V′ 的团性质。若 V′V&#x27;V′ 是一个团则接受输入，否则拒绝输入。这显然可以在 O(n4)O(n^4)O(n4) 时间内完成。因此，整个算法的时间复杂性为 O(n4)O(n^4)O(n4)。 非确定性算法在多项式时间内接受语言 CLIQUE，故 CLIQUE ∈\\in∈ NP 2.3 多项式时间验证 多项式时间可验证语言类 VP 可定义为： VP={L∣L∈∑∗\\text{VP}=\\lbrace L\\vert L\\in \\sum*VP={L∣L∈∑∗，∑\\sum∑ 为一有限字符集，存在一个多项式 ppp 和一个多项式时间验证算法 A(X,Y)A(X, Y)A(X,Y) 使得对任意 X∈∑∗X\\in \\sum*X∈∑∗，X∈LX\\in LX∈L 当且仅当存在 Y∈∑∗,∣Y∣≤p(∣X∣)Y\\in \\sum*, \\vert Y\\vert \\le p(\\vert X\\vert )Y∈∑∗,∣Y∣≤p(∣X∣) 且 A(X,Y)=1}A(X, Y)=1\\rbraceA(X,Y)=1}。 定理8-5：VP=NP 例如（哈密顿回路问题）：一个无向图 GGG 含有哈密顿回路吗? 无向图 GGG 的哈密顿回路是通过 GGG 的每个顶点恰好一次的简单回路。可用语言 HAM-CYCLE 定义该问题如下： HAM-CYCLE={G∣G含有哈密顿回路}\\text{HAM-CYCLE}=\\lbrace G \\vert G 含有哈密顿回路\\rbrace HAM-CYCLE={G∣G含有哈密顿回路} 3 NP 完全问题 3.1 多项式时间变换 3.2 Cook 定理 3.1 多项式时间变换 设 L1⊆∑1∗,L2⊆∑2∗L_1\\subseteq \\sum_1^*, L_2\\subseteq \\sum_2^*L1​⊆∑1∗​,L2​⊆∑2∗​， 是 2 个语言。所谓语言 L1L_1L1​ 能在多项式时间内变换为语言 L2L_2L2​(简记为 L1∝pL2L_1 \\propto _p L_2L1​∝p​L2​) 是指存在映身 f:⊆∑1∗→∑2∗f: \\subseteq \\sum_1^* \\to \\sum_2^*f:⊆∑1∗​→∑2∗​，且 fff 满足： 有一个计算 fff 的多项式时间确定性图灵机； 对于所有 x∈∑1∗,x∈L1x\\in \\sum_1^*, x\\in L_1x∈∑1∗​,x∈L1​，当且仅当 f(x)∈L2f(x)\\in L_2f(x)∈L2​。 定义： 语言 L 是 NP 完全的当且仅当 L∈NPL\\in \\text{NP}L∈NP； 对于所有 L′∈NPL&#x27; \\in \\text{NP}L′∈NP 有 L′∝pLL&#x27; \\propto_p LL′∝p​L。 如果有一个语言 LLL 满足上述性质 2，但不一定满足性质 1，则称该语言是 NP 难的。所有 NP 完全语言构成的语言类称为 NP 完全语言类，记为 NPC。 定理8-6：设 LLL 是 NP 完全的，则 L∈PL\\in PL∈P 当且仅当 P＝NPP＝\\text{NP}P＝NP； 若 L∝pL1L\\propto_p L_1L∝p​L1​，且 L1∈NPL_1\\in \\text{NP}L1​∈NP，则 L1L_1L1​ 是 NP 完全的。 定理 8-6 的 2 可用来证明问题的 NP 完全性。但前提是：要有第一个 NP 完全问题 LLL。 3.2 Cook 定理 定理 8-7（Cook 定理）：布尔表达式的可满足性问题 SAT 是 NP 完全的。 Cook 定理的重要性在于，它给出了第一个NP完全问题，使得对于任何问题 QQQ，只要能证明 Q∈NPQ \\in \\text{NP}Q∈NP 且 SAT∝pQ\\text{SAT} \\propto_p QSAT∝p​Q，就有 Q∈NPCQ\\in \\text{NPC}Q∈NPC. 4 一些典型的 NP 完全问题 4.1 合取范式的可满足性问题（CNF-SAT） 问题描述： 给定一个合取范式 α\\alphaα，判定它是否可满足。 如果一个布尔表达式是一些因子和之积，则称之为合取范式，简称 CNF (Conjunctive Normal Form)。这里的因子是变量 χ\\chiχ 或xxx。例如：(x1+x2)(x2+x3)(x1+x2+x3)(x_1+x_2)(x_2+x_3)(x_1+x_2+x_3)(x1​+x2​)(x2​+x3​)(x1​+x2​+x3​) 就是一个合取范式，而 x1x2+x3x_1x_2+x_3x1​x2​+x3​ 就不是合取范式。 要证明 CNF-SAT∈NPC\\text{CNF-SAT}\\in\\text{NPC}CNF-SAT∈NPC，只要证明在 Cook 定理中定义的布尔表达式 A,…,GA, \\ldots, GA,…,G 或者已是合取范式，或者有的虽然不是合取范式，但可以用布尔代数中的变换方法将它们化成合取范式，而且合取范式的长度与原表达式的长度只差一个常数因子。 4.2 三元合取范式的可满足性问题（3-SAT） 问题描述： 给定一个三元合取范式 α\\alphaα，判定它是否可满足。 证明思路： 3-SAT∈NP\\text{3-SAT}\\in\\text{NP}3-SAT∈NP 是显而易见的。为了证明 3-SAT∈NPC\\text{3-SAT}\\in\\text{NPC}3-SAT∈NPC，只要证明 CNF-SAT∝p3-SAT\\text{CNF-SAT}\\propto_p\\text{3-SAT}CNF-SAT∝p​3-SAT，即合取范式的可满足性问题可在多项式时间内变换为 3-SAT。 4.3 团问题（CLIQUE） 问题描述： 给定一个无向图 G=(V,E)G=(V, E)G=(V,E) 和一个正整数 kkk，判定图 GGG 是否包含一个 kkk 团，即是否存在，V′⊆V，∣V′∣=kV&#x27;\\subseteq V，\\vert V&#x27; \\vert=kV′⊆V，∣V′∣=k，且对任意 u,w∈V′u, w\\in V&#x27;u,w∈V′ 有 (u，w)∈E(u，w)\\in E(u，w)∈E。 证明思路： 已经知道 CLIQUE∈NP\\text{CLIQUE}\\in\\text{NP}CLIQUE∈NP。通过 3-SAT∝pCLIQUE\\text{3-SAT}\\propto_p\\text{CLIQUE}3-SAT∝p​CLIQUE 来证明 CLIQUE 是 NP 难的，从而证明团问题是 NP 完全的。 4.4 顶点覆盖问题（VERTEX-COVER） 问题描述： 给定一个无向图 G=(V,E)G=(V, E)G=(V,E) 和一个正整数 kkk，判定是否存在 V′⊆V,∣V′∣=kV&#x27; \\subseteq V, \\vert V&#x27;\\vert=kV′⊆V,∣V′∣=k，使得对于任意 (u,v)∈E(u, v)\\in E(u,v)∈E 有 u∈V′u\\in V&#x27;u∈V′ 或 v∈V′v\\in V&#x27;v∈V′。如果存在这样的 V′V&#x27;V′，就称 V′V&#x27;V′ 为图 GGG 的一个大小为 kkk 顶点覆盖。 证明思路： 首先，VERTEX-COVER∈NP\\text{VERTEX-COVER}\\in\\text{NP}VERTEX-COVER∈NP。因为对于给定的图 GGG 和正整数 kkk 以及一个“证书”V′V&#x27;V′，验证 ∣V′∣=k\\vert V&#x27;\\vert=k∣V′∣=k，然后对每条边 (u,v)∈E(u, v)\\in E(u,v)∈E，检查是否有 u∈V′u\\in V&#x27;u∈V′ 或 v∈V′v\\in V&#x27;v∈V′，显然可在多项式时间内完成。 其次，通过 CLIQUE∝pVERTEX-COVER\\text{CLIQUE}\\propto_p \\text{VERTEX-COVER}CLIQUE∝p​VERTEX-COVER 来证明顶点覆盖问题是 NP 难的。 4.5 子集和问题（SUBSET-SUM） 问题描述： 给定整数集合 SSS 和一个整数 ttt，判定是否存在 SSS 的一个子集S′⊆SS&#x27;\\subseteq SS′⊆S，使得 S′S&#x27;S′ 中整数的和为 ttt。例如，若 S={1,4,16,64,256,1040,1041,1093,1284,1344}S=\\lbrace 1, 4, 16, 64, 256, 1040, 1041, 1093, 1284, 1344\\rbraceS={1,4,16,64,256,1040,1041,1093,1284,1344} 且 t=3754t=3754t=3754，则子集 S′={1,16,64,256,1040,1093,1284}S&#x27;=\\lbrace 1, 16, 64, 256, 1040, 1093, 1284\\rbraceS′={1,16,64,256,1040,1093,1284} 是一个解。 证明思路： 首先，对于子集和问题的一个实例 ⟨S,t⟩\\langle S, t\\rangle⟨S,t⟩，给定一个“证书”S′S&#x27;S′，要验证 t=∑i∈S′it= \\sum_{i\\in S&#x27;}it=∑i∈S′​i 是否成立，显然可在多项式时间内完成。因此，SUBSET-SUM∈NP\\text{SUBSET-SUM}\\in \\text{NP}SUBSET-SUM∈NP； 其次，证明 VERTEX-COVER∝pSUBSET-SUM\\text{VERTEX-COVER}\\propto_p \\text{SUBSET-SUM}VERTEX-COVER∝p​SUBSET-SUM。 4.6 哈密顿回路问题（HAM-CYCLE） 问题描述： 给定无向图 G=(V,E)G=(V, E)G=(V,E)，判定其是否含有一哈密顿回路。 证明思路： 首先，已知哈密顿回路问题是一个 NP 类问题。 其次，通过证明 3-SAT∝pHAM-CYCLE\\text{3-SAT}\\propto_p\\text{HAM-CYCLE}3-SAT∝p​HAM-CYCLE。 得出：HAM-CYCLE∈NPC\\text{HAM-CYCLE}\\in\\text{NPC}HAM-CYCLE∈NPC。 4.7 旅行售货员问题（TSP） 问题描述： 给定一个无向完全图 G=(V,E)G=(V, E)G=(V,E) 及定义在 V×VV\\times VV×V 上的一个费用函数 ccc 和一个整数 kkk，判定 GGG 是否存在经过 VVV 中各顶点恰好一次的回路，使得该回路的费用不超过 kkk。 首先，给定 TSP 的一个实例 (G,c,k)(G, c, k)(G,c,k)，和一个由 nnn 个顶点组成的顶点序列。验证算法要验证这 nnn 个顶点组成的序列是图 GGG 的一条回路，且经过每个顶点一次。另外，将每条边的费用加起来，并验证所得的和不超过 kkk。这个过程显然可在多项式时间内完成，即 TSP∈NP\\text{TSP}\\in\\text{NP}TSP∈NP。 其次，旅行售货员问题与哈密顿回路问题有着密切的联系。哈密顿回路问题可在多项式时间内变换为旅行售货员问题。即 HAM-CYCLE∝pTSP\\text{HAM-CYCLE}\\propto_p\\text{TSP}HAM-CYCLE∝p​TSP。从而，旅行售货员问题是 NP 难的。 因此，TSP∈NPC\\text{TSP}\\in\\text{NPC}TSP∈NPC。 ","link":"https://faded.auspicious.space/post/np-completeness-theory/"},{"title":"算法复杂度比较","content":" 算法复杂度学习（上） 算法复杂度学习（下） 1 定义 时间复杂度一般采用 大 O 标记法, 即 T(n)=O(f(n))T(n)=O(f(n))T(n)=O(f(n)), 其中 T(n)T(n)T(n) 表示代码运行时间；nnn 表示数据规模大小；f(n)f(n)f(n) 表示每行代码执行次数总和，OOO 表示 T(n)T(n)T(n) 与 f(n)f(n)f(n) 的正比关系。大 OOO 时间复杂度实际上并不具体表示代码的真正运行时间，而是表示代码执行时间随数据规模增长的变化趋势。 在大 OOO 表示分析中，低阶项和常数项都可以省略，只保留最高阶项即可；如 f(n)=2n+2f(n)=2n+2f(n)=2n+2 在大 OOO 标记法中记为 T(n)=O(n)T(n)=O(n)T(n)=O(n)，而对于形如 f(n)=2n2+2n+3f(n)=2n^2+2n+3f(n)=2n2+2n+3 表示为 T(n)=O(n2)T(n)=O(n^2)T(n)=O(n2)。 2 时间复杂度分析 2.1 关注循环次数多的代码 public int accumulate(int n) { int sum = 0; int i = 1; for (; i &lt;= n; i++) { sum += i; } return sum; } 其中 for 循环内的代码执行 nnn 次，而其余代码执行 1 次，与 nnn 的大小无关，忽略常数项，该段代码的时间复杂度为 O(n)O(n)O(n)。 2.2 加法法则 总复杂度为量级最大的那段代码的复杂度，抽象为公式为： 若 T1(N)=O(f(n)),T2(N)=O(g(n))T_{1}(N)=O(f(n)), T_{2}(N)=O(g(n))T1​(N)=O(f(n)),T2​(N)=O(g(n))，那么 T(N)=T1(N)+T2(N)=O(f(n))+O(g(n))=max⁡(O(f(n)),O(g(n)))T(N)=T_{1}(N)+T_{2}(N)=O(f(n))+O(g(n)) = \\max(O(f(n)), O(g(n)))T(N)=T1​(N)+T2​(N)=O(f(n))+O(g(n))=max(O(f(n)),O(g(n))) public int accumulate(int n) { int sum1 = 0; for (int i = 1; i &lt;= 100; i++) { sum1 += i; } int sum2 = 0; for (int i = 1; i &lt;= n; i++) { sum2 += i; } int sum3 = 0; for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= n; j++) { sum3 += i * j; } } return sum1 + sum2 + sum3; } 其中 sum1 段的代码循环执行了 100 次，与 nnn 无关。sum2 段代码的复杂度为 O(N)O(N)O(N)，sum3 段的代码复杂度为 O(N2)O(N^2)O(N2)；根据加法法则，我们只去其中最大量级的复杂度，所以该段代码的时间复杂度为 O(N2)O(N^2)O(N2)。 2.3 乘法法则 嵌套代码的复杂度等于嵌套内外代码复杂度的乘积，抽象为公式为： 若 T1(N)=O(f(n)),T2(N)=O(g(n))T_{1}(N)=O(f(n)), T_{2}(N)=O(g(n))T1​(N)=O(f(n)),T2​(N)=O(g(n))，那么 T(N)=T1(N)×T2(N)=O(f(n)×g(n))T(N)=T_{1}(N) \\times T_{2}(N)=O(f(n) \\times g(n))T(N)=T1​(N)×T2​(N)=O(f(n)×g(n)) 3 常见时间复杂度量级 度量级 大 O 表示 常量阶 O(1)O(1)O(1) 对数阶 O(log⁡N)O(\\log{N})O(logN) 线性阶 O(N)O(N)O(N) 线性对数阶 O(Nlog⁡N)O(N\\log{N})O(NlogN) 平方阶 O(N2)O(N^2)O(N2) 立方阶 O(N3)O(N^3)O(N3) 指数阶 O(2n)O(2^n)O(2n) 阶乘阶 O(N!)O(N!)O(N!) 3.1 常见的时间复杂度 常见的时间复杂度有常量阶、对数阶、线性阶、线性对数阶以及平方阶，常量阶、线性阶与平方阶在第二节中已经分析，不再赘述；而一些高效的排序算法的时间复杂度就是线性对数阶，如快速排序，归并排序以及堆排序等。 3.2 对数阶 我们所熟知的二分查找的复杂度就是 O(log⁡N)O(\\log{N})O(logN)，以下通过一段代码来分析对数阶复杂度： public int test(int n) { int res = 1; while (res &lt;= n) { res *= 2; } return res; } 该段代码是求 2x=n2^x=n2x=n 的解，更确切的说，是找出 2x2^x2x 在小于或等于 nnn 的范围内最接近 nnn 的xxx 的值；其中 x=log⁡2nx=\\log_{2}{n}x=log2​n，即 while 循环体内代码要执行 log⁡2n\\log_{2}{n}log2​n 次，即其时间复杂度为 O(log⁡2n)O(\\log_{2}{n})O(log2​n)。 若把循环体内代码 res *= 2 改为 res *= 3，不难分析出其时间复杂度就变为 O(log⁡3n)O(\\log_{3}{n})O(log3​n)；但是为什么所有对数阶的时间复杂度都统一表示为 O(log⁡N)O(\\log{N})O(logN)？ 首先我们先复习对数换底公式: log⁡AB=log⁡CBlog⁡CA\\log_{A}{B}=\\frac{\\log_{C}{B}}{\\log_{C}{A}} logA​B=logC​AlogC​B​ 则 log⁡3n=log⁡2nlog⁡23=log⁡22log⁡23⋅log⁡2n=log⁡32⋅log⁡2n\\log_{3}{n}=\\frac{\\log_{2}{n}}{\\log_{2}{3}}=\\frac{\\log_{2}{2}}{\\log_{2}{3}}\\cdot\\log_{2}{n}=\\log_{3}{2}\\cdot\\log_{2}{n} log3​n=log2​3log2​n​=log2​3log2​2​⋅log2​n=log3​2⋅log2​n 所以 O(log⁡3n)=O(log⁡32⋅log⁡2n)O(\\log_{3}{n})=O(\\log_{3}{2}\\cdot\\log_{2}{n})O(log3​n)=O(log3​2⋅log2​n)，因为 log⁡32\\log_{3}{2}log3​2 为常数项，所以该项可以忽略，因此 O(log⁡3n)=O(log⁡2n)O(\\log_{3}{n})=O(\\log_{2}{n})O(log3​n)=O(log2​n)；所以无论对数以哪个数为底，最后都可以转化为一个常数项与以 222 为底的对数相乘，因此在对数阶时间复杂度的表示方法里，就忽略对数的底，统一表示为 O(log⁡N)O(\\log{N})O(logN) 3.3 O(m+n)O(m+n)O(m+n) 与 O(m×n)O(m \\times n)O(m×n) 此种表示形式的时间复杂度是由两个数据规模来决定的 public int accumulate(int m, int n) { int sum1 = 0; for (int i = 1; i &lt;= m; i++) { sum1 += i; } int sum2 = 0; for (int i = 1; i &lt;= n; i++) { sum2 += i; } return sum1 + sum2; } 由于我们不能事先知晓 mmm 与 nnn 哪个量级大，所以就不能简单的利用加法规则取其最大量级，那么像这种代码的时间复杂度就为 O(m+n)O(m+n)O(m+n)。 public int accumulate(int m, int n) { int sum = 0; for (int i = 1; i &lt;= m; i++) { for (int j = 1; j &lt;= n; j++) { sum += i * j; } } return sum; } 而类似上述代码依然可以使用乘法法则，其时间复杂度为 O(m×n)O(m \\times n)O(m×n)。 4 最好、最坏、平均和均摊时间复杂度 以下将通过一段代码来讲述这几个时间复杂度： public class Test { private int[] array = new int[5]; private int N = 0; public void push(int item) { if (N == array.length) { resize(2 * array.length); } array[N++] = item; } private void resize(int size) { int[] temp = new int[size]; for (int i = 0; i &lt; N; i++) { temp[i] = array[i]; } array = temp; } } 上述代码是用数组模拟一个栈的部分代码，其中 push 表示压栈操作，resize 表示对数组进行扩容的操作；当压入栈中的元素数量达到数组的容量时，就定义一个容量为之前两倍的新数组 temp，将旧数组 array 中的元素复制到新数组中，然后将 array 指向 temp。 4.1 最好时间复杂度 最理想的情况下，当前栈中元素数量比数组的容量小，此时就直接执行代码块 array[N++] = item;，即此时的时间复杂度为 O(1)O(1)O(1)。 4.2 最坏时间复杂度 最糟糕的情况下，当前栈中元素数量与数组的容量相等，此时就要执行 resize 方法进行扩容了，进入循环体，执行 N 次复制操作，此时的时间复杂度为 O(N)O(N)O(N)。 4.3 平均时间复杂度 当栈中元素小于数组容量时，此时进行压栈就有 NNN 种情况，且每种情况的时间复杂度为 O(1)O(1)O(1)；当栈中元素与数组容量相等时，此时进行压栈就只有一种情况了，要进行扩容操作，这种情况的时间复杂度为 O(N)O(N)O(N)；则总共有 N+N+N+` 种情况，对其取平均值： 1+1+1+…+1+NN+1=2NN+1\\cfrac{1+1+1+\\ldots+1+N}{N+1}=\\cfrac{2N}{N+1} N+11+1+1+…+1+N​=N+12N​ 在大 O 标记法中，可以省略系数与低阶项，所以其平均时间复杂度为 O(1)O(1)O(1) 下面使用概率来分析，由于有 N+1N+1N+1 种情况，每种情况的发生概率为 1N+1\\frac{1}{N+1}N+11​，则其平均时间复杂度为： 1×1N+1+1×1N+1+…+1×1N+1+N×1N+1=O(1)1\\times\\frac{1}{N+1}+1\\times\\frac{1}{N+1}+\\ldots+1\\times\\frac{1}{N+1}+N\\times\\frac{1}{N+1}=O(1) 1×N+11​+1×N+11​+…+1×N+11​+N×N+11​=O(1) 4.4 均摊时间复杂度 是一种特殊的平均时间复杂度，根据上述代码，每出现一次扩容操作时，即此时压栈的时间复杂度为 O(N)O(N)O(N)，那么后面的 NNN 次压栈操作的时间复杂度均为 O(1)O(1)O(1)，前后是连贯的，因此将 O(N)O(N)O(N) 平摊到前 NNN 次上，得出均摊时间复杂度为 O(1)O(1)O(1)。 5 不同时间复杂度算法对比 这一节将以一个具体的算法题给出 4 种不同解法，分析各自的时间复杂度并比较其各自的运行性能。 给出两个求和公式，以下分析中会用到： ∑i=1Ni=N(N+1)2∑i=1Ni2=N(N+1)(2N+1)6\\begin{aligned} \\sum_{i=1}^{N}i &amp;=\\frac{N(N+1)}{2} \\\\ \\sum_{i=1}^{N}i^2 &amp;=\\frac{N(N+1)(2N+1)}{6} \\end{aligned} i=1∑N​ii=1∑N​i2​=2N(N+1)​=6N(N+1)(2N+1)​​ 最大子序列和问题 A1,A2,A3,…,ANA_1, A_2, A_3, \\ldots, A_NA1​,A2​,A3​,…,AN​，求 ∑k=ijAk\\sum_{k=i}^{j}A_k∑k=ij​Ak​ 的最大值。（为方便起见，若所有整数均为负数，则最大子序列和为 0）。 例如：输入 −2,11,−4,13,−5,−2-2, 11, -4, 13, -5, -2−2,11,−4,13,−5,−2，其最大子序列和为 11+(−4)+13=2011+(-4)+13=2011+(−4)+13=20。 5.1 时间复杂度为 O(N3)O(N^3)O(N3) 的解法 public static int maxSubSum1(int[] a) { int maxSum = 0; for (int i = 0; i &lt; a.length; i++) { for (int j = i; j &lt; a.length; j++) { int thisSum = 0; for (int k = i; k &lt;= j; k++) { thisSum += a[k]; } if (thisSum &gt; maxSum) { maxSum = thisSum; } } } return maxSum; } 该种解法最简单暴力，定义子序列的起始位置为 i，结束位置为 j，假设数组 a 的长度为 NNN，当 i=0i=0i=0 时，j=0,1,2,3,…,N−1j=0,1,2,3, \\ldots,N-1j=0,1,2,3,…,N−1，共 NNN 种情况，当 N=1N=1N=1 时，j=1,2,3,⋯ ,N−1j=1,2,3,\\cdots,N-1j=1,2,3,⋯,N−1，共 N−1N-1N−1 种情况，以此类推，当 i=N−1i=N-1i=N−1 时，j=N−1j=N-1j=N−1，仅此一种情况；将 i 与 j 之间的所有元素和记为 thisSum，一旦 thisSum 的值比 maxSum 大，就更新 maxSum 的值为 thisSum。 第一个循环大小为 NNN，第二个循环大小为 N−iN-iN−i，第三个循环大小为 j−i+1j-i+1j−i+1，则总运行次数和为: ∑i=0N−1∑j=iN−1∑k=ij1\\sum_{i=0}^{N-1}\\sum_{j=i}^{N-1}\\sum_{k=i}^{j}1 i=0∑N−1​j=i∑N−1​k=i∑j​1 首先有： ∑k=ij1=j−i+1\\sum_{k=i}^{j}1 =j-i+1 k=i∑j​1=j−i+1 接着： ∑j=iN−1(j−i+1)=(N−i+1)(N−i)2\\sum_{j=i}^{N-1}(j-i+1)=\\frac{(N-i+1)(N-i)}{2} j=i∑N−1​(j−i+1)=2(N−i+1)(N−i)​ 那么： ∑i=0N−1(N−i+1)(N−i)2=∑i=1N(N−i+1)(N−i+2)2=12∑i=1Ni2−(N+32)∑i=1Ni+12(N2+3N+2)∑i=1N1=12N(N+1)(2N+1)6−(N+32)N(N+1)2+N2+3N+22N=N3+3N2+2N6\\begin{aligned} \\sum_{i=0}^{N-1} \\frac{(N-i+1)(N-i)}{2} &amp;= \\sum_{i=1}^{N}\\frac{(N-i+1)(N-i+2)}{2}\\\\ &amp;=\\frac{1}{2}\\sum_{i=1}^{N}i^2-(N+\\frac{3}{2})\\sum_{i=1}^{N}i +\\frac{1}{2}(N^2+3N+2)\\sum_{i=1}^{N}1\\\\ &amp;=\\frac{1}{2}\\frac{N(N+1)(2N+1)}{6}-(N+\\frac{3}{2})\\frac{N(N+1)}{2}+\\frac{N^2+3N+2}{2}N\\\\ &amp;=\\frac{N^3+3N^2+2N}{6} \\end{aligned} i=0∑N−1​2(N−i+1)(N−i)​​=i=1∑N​2(N−i+1)(N−i+2)​=21​i=1∑N​i2−(N+23​)i=1∑N​i+21​(N2+3N+2)i=1∑N​1=21​6N(N+1)(2N+1)​−(N+23​)2N(N+1)​+2N2+3N+2​N=6N3+3N2+2N​​ 所以该种解法的时间复杂度为：O(N3+3N2+2N6)=O(N3)O(\\frac{N^3+3N^2+2N}{6})=O(N^3)O(6N3+3N2+2N​)=O(N3)。 5.2 时间复杂度为 O(N2)O(N^2)O(N2)的解法 public static int maxSubSum2(int[] a) { int maxSum = 0; for (int i = 0; i &lt; a.length; i++) { int thisSum = 0; for (int j = i; j &lt; a.length; j++) { thisSum += a[j]; if (thisSum &gt; maxSum) { maxSum = thisSum; } } } return maxSum; } 在第一种解法中，拿掉最里面的那层循环，并稍做改动，就是现在的解法 2。 其中第一层循环大小为 NNN，第二层循环为 N−iN-iN−i，则总运行次数为： ∑i=0N−1∑j=iN−11\\sum_{i=0}^{N-1} \\sum_{j=i}^{N-1}1 i=0∑N−1​j=i∑N−1​1 其中： ∑j=iN−11=N−1−i+1=N−i\\sum_{j=i}^{N-1}1 = N-1-i+1=N-i j=i∑N−1​1=N−1−i+1=N−i 那么： ∑i=0N−1(N−i)=N∑i=0N−11−∑i=0N−1i=N(N−1+1)−(N−1)N2=N2−N2\\begin{aligned} \\sum_{i=0}^{N-1}(N-i) &amp;= N\\sum_{i=0}^{N-1}1- \\sum_{i=0}^{N-1} i \\\\ &amp;= N(N-1+1) - \\frac{(N-1)N}{2} \\\\ &amp;= \\frac{N^2-N}{2} \\end{aligned} i=0∑N−1​(N−i)​=Ni=0∑N−1​1−i=0∑N−1​i=N(N−1+1)−2(N−1)N​=2N2−N​​ 所以第二种解法的时间复杂度为 O(N2−N2)=O(N2)O(\\frac{N^2-N}{2})=O(N^2)O(2N2−N​)=O(N2)。 5.3 时间复杂度为 O(Nlog⁡N)O(N\\log{N})O(NlogN) 的解法 如下图所示，可以将数组分为三部分，分别为前中后三部分。 最大子序列和就可能出现在这三个部分中，其中 mid=start+end2=0+52=2\\text{mid}=\\frac{\\text{start}+\\text{end}}{2}=\\frac{0+5}{2}=2mid=2start+end​=20+5​=2，前半部分是从 start\\text{start}start 到 mid\\text{mid}mid 这一部分的元素，即 −2,11,−4-2,11,-4−2,11,−4，所以该部分最大元素为 111111；后半部分是从 mid+1\\text{mid+1}mid+1 到 end\\text{end}end 这一部分的元素，即 13,−5,−213,-5,-213,−5,−2，所以该部分最大元素为 13\\text{13}13；而中间部分元素是以 mid\\text{mid}mid 起始，分别向左和向右进行累加计算，分别求出其向左和向右部分的最大值，从 mid\\text{mid}mid 向左得到其最大值：−4+11=7-4+11=7−4+11=7，而向右是从 mid+1\\text{mid+1}mid+1 开始算起得到其最大值：131313，最后将左右两部分和相加即为中间部分的最大值：7+13=207+13=207+13=20；比较前中后部分的最大值，发现中间部分的值 202020 最大，所以该数组最大子序列和为 202020。 那么在程序中如何实现呢？这就要采用分治策略，将数组 a 分为前后两半子数组 b, c，再将前半数组 b 分为前后两半子数组 d, e，后半数组 c 分为前后两半子数组 f, g, ……，直到数组不能再分为止，此时子数组中就只有一个元素，一个元素就好判断了，该元素为正就直接把该元素值返回给上一级子数组，为负就返回 0，然后回到上一级子数组，将之前返回的前后部分子数组的最大值与中间部分最大值进行比较，得出其最大值，接着将最大值返回其上一级子数组，直至回到原数组，这时原数组就得到了前后部分子数组的最大值，接着求出中间部分子数组的最大值并与前后部分进行比较即可得到整个数组的最大子序列和。 public static int maxSubSum3(int[] a) { return a.length &gt; 0 ? maxSumRec(a, 0, a.length - 1) : 0; } private static int maxSumRec(int[] a, int left, int right) { if (left == right) { if (a[left] &gt; 0) { return a[left]; } else { return 0; } } int center = (left + right) / 2; int maxLeftSum = maxSumRec(a, left, center); int maxRightSum = maxSumRec(a, center + 1, right); int maxLeftBorderSum = 0; int leftBorderSum = 0; for (int i = center; i &gt;= left; i--) { leftBorderSum += a[i]; if (leftBorderSum &gt; maxLeftBorderSum) { maxLeftBorderSum = leftBorderSum; } } int maxRightBorderSum = 0; int rightBorderSum = 0; for (int i = center + 1; i &lt;= right; i++) { rightBorderSum += a[i]; if (rightBorderSum &gt; maxRightBorderSum) { maxRightBorderSum = rightBorderSum; } } return max3(maxLeftSum, maxRightSum, maxLeftBorderSum + maxRightBorderSum); } private static int max3(int a, int b, int c) { return a &gt; b ? a &gt; c ? a : c : b &gt; c ? b : c; } 其中 center 为数组中间元素的下标，maxLeftSum 和 maxRightSum 分别为数组前后部分的最大值，maxLeftBorderSum 为中间部分向左计算的最大值，maxRightBorderSum 为中间部分向右计算最大值；maxLeftBorderSum + maxRightBorderSum 即为中间部分的最大值。 计算中间部分，即计算 maxLeftBorderSum 和 maxRightBorderSum 总花费时间为 NNN，而计算前后两半部分，即 maxLeftSum 和 maxRightSum 每个花费 T(N/2)T(N/2)T(N/2) 个时间单元，则总共花费时间： T(N)=2T(N/2)+NT(N)=2T(N/2)+N T(N)=2T(N/2)+N 其中 T(1)=1T(1)=1T(1)=1，则 T(2)=4=2×2T(2)=4=2 \\times 2T(2)=4=2×2，T(4)=12=4×3T(4)=12=4 \\times 3T(4)=12=4×3，T(8)=32=8×4T(8)=32=8 \\times 4T(8)=32=8×4，T(16)=80=16×5T(16)=80=16 \\times 5T(16)=80=16×5。 那么当 N=2kN=2^kN=2k，则 T(N)=N×(k+1)=N(log⁡N+1)T(N)=N \\times (k+1)=N(\\log{N}+1)T(N)=N×(k+1)=N(logN+1)，忽略低阶项，所以该方法的时间复杂度为：O(Nlog⁡N)O(N\\log{N})O(NlogN)。 5.4 时间复杂度为 O(N)O(N)O(N) 的解法 public static int maxSubSum4(int[] a) { int maxSum = 0; int thisSum = 0; for (int i = 0; i &lt; a.length; i++) { thisSum += a[i]; if (thisSum &gt; maxSum) { maxSum = thisSum; } else if (thisSum &lt; 0) { thisSum = 0; } } return maxSum; } 此种方法将时间复杂度优化到了 O(N)O(N)O(N)，只需一轮循环即可找到最大子序列；其思路为：若当前子序列的和 thisSum 为负数，则将 thisSum 置为 000，下一个数组元素作为新的子序列的起始位置，thisSum 从该元素开始累加，直至找到最大子序列的和。 5.5 对比分析 使用下面代码测试上述 4 中解法所消耗的时间： public static void getTimingInfo(int n, int alg) { int[] test = new int[n]; Random rand = new Random(); long startTime = System.currentTimeMillis(); long totalTime = 0; int i; for (i = 0; totalTime &lt; 4000; i++) { for (int j = 0; j &lt; test.length; j++) { test[j] = rand.nextInt(100) - 50; } switch (alg) { case 1: maxSubSum1(test); break; case 2: maxSubSum2(test); break; case 3: maxSubSum3(test); break; case 4: maxSubSum4(test); break; default: } totalTime = System.currentTimeMillis() - startTime; } System.out.print(String.format(&quot;\\t%12.6f&quot;, (totalTime * 1000 / i) / (double) 1000000)); } public static void main(String[] args) { for (int n = 100; n &lt;= 1000000; n *= 10) { System.out.print(String.format(&quot;N = %7d&quot;, n)); for (int alg = 1; alg &lt;= 4; alg++) { if ((alg == 1 &amp;&amp; n &gt; 50000) || (alg == 2 &amp;&amp; n &gt; 500000)) { System.out.print(&quot;\\t NA &quot;); continue; } getTimingInfo(n, alg); } System.out.println(); } } 运行结果如下图，当预测时间过长，将其设为 NA，从图中可以看出，不同时间复杂度的程序虽然得出的结果是一样的，但运行性能相差巨大，犹如波音与摩拜的差别。 输入大小 N O(N3)O(N^3)O(N3) O(N2)O(N^2)O(N2) O(Nlog⁡N)O(N\\log{N})O(NlogN) O(N)O(N)O(N) 100 0.000063 0.000005 0.000003 0.000001 1000 0.054986 0.000201 0.000036 0.000014 10000 55.234000 0.018058 0.000371 0.000125 100000 NA 1.790000 0.003937 0.001249 1000000 NA NA 0.041979 0.012479 6 总结 以后写代码之前要多思考，避免一上来就暴力求解，造成巨大的性能开销，应尽量将程序优化到线性阶或线性对数阶以内。 ","link":"https://faded.auspicious.space/post/algorithm-complexity-comparison/"},{"title":"笔算平方根","content":"我以计算 2016 的算术平方根作为例子。全程用竖式计算。 首先， 以小数点为基准，每两位数作为一组。像这样写： 注意，平方根的两倍那个位置要往左边写一点，不然后面不够位置。接下来估算第一节，是 202020，42&lt;20&lt;524^2 \\lt 20 \\lt 5^242&lt;20&lt;52，所以在第一节的上面写上 444，对应的在左边写上 888，42=164^2=1642=16 写到 202020 的下面，减一下，把下一节拉下来： 估计下一位的方法是： 8?×?=4168?\\times?=4168?×?=416。因为 83×3=24983 \\times 3=24983×3=249，84×4=33684 \\times 4=33684×4=336，85×5=42585 \\times 5=42585×5=425， 425425425 大于 416416416 了，所以下一位就是 444 了，更新算式，把下一节拉下来： 再估计下一位： 88?×?=800088? \\times ?=800088?×?=8000。 888×8=7104888 \\times 8=7104888×8=7104，889×9=8001889 \\times 9=8001889×9=8001， 哎呀，差一点点，还是 888 吧： 下一位：896?×?=89600896? \\times ?=89600896?×?=89600， 由于刚才就差一点点，这次应该是 999 了。8969×9=807218969 \\times 9=807218969×9=80721，没问题： 8978?×?=8879008978? \\times ?=8879008978?×?=887900，凭感觉应该还是 999，89789×9=80810189789 \\times 9=80810189789×9=808101，OK： 89798?×?=797990089798? \\times ?=797990089798?×?=7979900，这回是 888 了。 不过我还是不写下去了, 因为示范了那么多步，大家应该知道步骤了吧？ ","link":"https://faded.auspicious.space/post/written-calculation-of-square-root/"},{"title":"算法复杂度分析","content":" 算法复杂度分析 为什么要进行算法分析？ 预测算法所需的资源 计算时间（CPU 消耗） 内存空间（RAM 消耗） 通信时间（带宽消耗） 预测算法的运行时间 在给定输入规模时，所执行的基本操作数量。 或者称为算法复杂度（Algorithm Complexity） 如何衡量算法复杂度？ 内存（Memory） 时间（Time） 指令的数量（Number of Steps） 特定操作的数量 磁盘访问数量 网络包数量 渐进复杂度（Asymptotic Complexity） 算法的运行时间与什么相关？ 取决于输入的数据。（例如：如果数据已经是排好序的，时间消耗可能会减少。） 取决于输入数据的规模。（例如：6 和 6 * 109） 取决于运行时间的上限。（因为运行时间的上限是对使用者的承诺。） 算法分析的种类： 最坏情况（Worst Case）：任意输入规模的最大运行时间。（Usually） 平均情况（Average Case）：任意输入规模的期待运行时间。（Sometimes） 最佳情况（Best Case）：通常最佳情况不会出现。（Bogus） 例如，在一个长度为 n 的列表中顺序搜索指定的值，则 最坏情况：n 次比较 平均情况：n/2 次比较 最佳情况：1 次比较 而实际中，我们一般仅考量算法在最坏情况下的运行情况，也就是对于规模为 n 的任何输入，算法的最长运行时间。这样做的理由是： 一个算法的最坏情况运行时间是在任何输入下运行时间的一个上界（Upper Bound）。 对于某些算法，最坏情况出现的较为频繁。 大体上看，平均情况通常与最坏情况一样差。 算法分析要保持大局观（Big Idea），其基本思路： 忽略掉那些依赖于机器的常量。 关注运行时间的增长趋势。 比如：T(n)=73n3+29n3+8888T(n) = 73n^3 + 29n^3 + 8888T(n)=73n3+29n3+8888 的趋势就相当于 T(n)=Θ(n3)T(n) = \\Theta(n^3)T(n)=Θ(n3)。 渐近记号（Asymptotic Notation）通常有 OOO、Θ\\ThetaΘ 和 Ω\\OmegaΩ 记号法。Θ\\ThetaΘ 记号渐进地给出了一个函数的上界和下界，当只有渐近上界时使用 OOO 记号，当只有渐近下界时使用 Ω\\OmegaΩ 记号。尽管技术上 Θ\\ThetaΘ 记号较为准确，但通常仍然使用 OOO 记号表示。 使用 OOO 记号法（Big O Notation）表示最坏运行情况的上界。例如， 线性复杂度 O(n)O(n)O(n) 表示每个元素都要被处理一次。 平方复杂度 O(n2)O(n^2)O(n2) 表示每个元素都要被处理 nnn 次。 Notation Intuition Informal Definition f(n)∈O(g(n))f(n) \\in O(g(n))f(n)∈O(g(n)) fff is bounded above by ggg asymptotically ∣f(n)∣≤g(n)⋅k\\lvert f(n) \\rvert \\le g(n) \\cdot k∣f(n)∣≤g(n)⋅k f(n)∈Ω(g(n))f(n) \\in \\Omega(g(n))f(n)∈Ω(g(n)) Two definitions: Number theory: fff is not dominated by ggg asymptotically Complexity theory: fff is bounded below by ggg asymptotically f(n)≥g(n)⋅kf(n) \\ge g(n) \\cdot kf(n)≥g(n)⋅k f(n)∈Θ(g(n))f(n) \\in \\Theta(g(n))f(n)∈Θ(g(n)) fff is bounded both above and below by ggg asymptotically g(n)⋅k1≤f(n)≤g(n)⋅k2g(n) \\cdot k_1 \\le f(n) \\le g(n) \\cdot k_2g(n)⋅k1​≤f(n)≤g(n)⋅k2​ 例如： T(n)=O(n3)T(n) = O(n^3)T(n)=O(n3) 等同于 T(n)∈O(n3)T(n) \\in O(n^3)T(n)∈O(n3) T(n)=Θ(n3)T(n) = \\Theta(n^3)T(n)=Θ(n3) 等同于 T(n)∈Θ(n3)T(n) \\in \\Theta(n3)T(n)∈Θ(n3). 相当于: T(n)T(n)T(n) 的渐近增长不快于 n3n^3n3。 T(n)T(n)T(n) 的渐近增长与 n3n^3n3 一样快。 复杂度 标记符号 描述 常量（Constant） O(1)O(1)O(1) 操作的数量为常数，与输入的数据的规模无关。 n = 1,000,000 →\\to→ 1-2 operations 对数（Logarithmic） O(log⁡2n)O(\\log_{2}{n})O(log2​n) 操作的数量与输入数据的规模 nnn 的比例是 log⁡2n\\log_{2}{n}log2​n。 n = 1,000,000 →\\to→ 30 operations 线性（Linear） O(n)O(n)O(n) 操作的数量与输入数据的规模 nnn 成正比。 n = 10,000 →\\to→ 5000 operations 平方（Quadratic） O(n2)O(n^2)O(n2) 操作的数量与输入数据的规模 nnn 的比例为二次平方。 n = 500 →\\to→ 250,000 operations 立方（Cubic） O(n3)O(n^3)O(n3) 操作的数量与输入数据的规模 nnn 的比例为三次方。 n = 200 →\\to→ 8,000,000 operations 指数（Exponential） O(2n)O(2^n)O(2n) O(kn)O(k^n)O(kn) O(n!)O(n!)O(n!) 指数级的操作，快速的增长。 n = 20 →\\to→ 1048576 operations 注1：快速的数学回忆，log⁡ab=y\\log_{a}{b} = yloga​b=y 其实就是 ay=ba^y = bay=b。所以，log⁡24=2\\log_{2}{4} = 2log2​4=2，因为 22=42^2 = 422=4。同样 log⁡28=3\\log_{2}{8} = 3log2​8=3，因为 23=82^3 = 823=8。我们说，log⁡2n\\log_{2}{n}log2​n 的增长速度要慢于 nnn，因为当 n=8n = 8n=8 时，log⁡2n=3\\log_{2}{n} = 3log2​n=3。 注2：通常将以 10 为底的对数叫做常用对数。为了简便，NNN 的常用对数 log⁡10N\\log_{10}{N}log10​N 简写做 lg⁡N\\lg{N}lgN，例如 log⁡105\\log_{10}{5}log10​5 记做 lg⁡5\\lg{5}lg5。 注3：通常将以无理数 eee 为底的对数叫做自然对数。为了方便，NNN 的自然对数 log⁡eN\\log_{e}{N}loge​N 简写做 ln⁡N\\ln{N}lnN，例如 loge3log_{e}{3}loge​3 记做 ln⁡3\\ln{3}ln3。 注4：在算法导论中，采用记号 lg⁡n=log⁡2n\\lg{n} = \\log_{2}{n}lgn=log2​n ，也就是以 2 为底的对数。改变一个对数的底只是把对数的值改变了一个常数倍，所以当不在意这些常数因子时，我们将经常采用 &quot;lg n&quot;记号，就像使用 OOO 记号一样。计算机工作者常常认为对数的底取 2 最自然，因为很多算法和数据结构都涉及到对问题进行二分。 而通常时间复杂度与运行时间有一些常见的比例关系： 复杂度 10 20 50 100 1000 10000 100000 O(1)O(1)O(1) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s O(log⁡2(n))O(\\log_{2}{(n)})O(log2​(n)) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s O(n)O(n)O(n) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s O(n∗log⁡2(n))O(n*\\log_{2}{(n)})O(n∗log2​(n)) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s O(n2)O(n^2)O(n2) &lt;1s &lt;1s &lt;1s &lt;1s &lt;1s 2s 3-4 min O(n3)O(n^3)O(n3) &lt;1s &lt;1s &lt;1s &lt;1s 20s 5 hours 231 days O(2n)O(2^n)O(2n) &lt;1s &lt;1s 260 days hangs hangs hangs hangs O(n!)O(n!)O(n!) &lt;1s hangs hangs hangs hangs hangs hangs O(nn)O(n^n)O(nn) 3-4 min hangs hangs hangs hangs hangs hangs 计算代码块的渐进运行时间的方法有如下步骤： 确定决定算法运行时间的组成步骤。 找到执行该步骤的代码，标记为 1。 查看标记为 1 的代码的下一行代码。如果下一行代码是一个循环，则将标记 1 修改为 1 倍于循环的次数 1 * n。如果包含多个嵌套的循环，则将继续计算倍数，例如 1 * n * m。 找到标记到的最大的值，就是运行时间的最大值，即算法复杂度描述的上界。 示例代码（1）： decimal Factorial(int n) { if (n == 0) return 1; else return n * Factorial(n - 1); } 阶乘（factorial），给定规模 nnn，算法基本步骤执行的数量为 nnn，所以算法复杂度为 O(n)O(n)O(n)。 示例代码（2）： int FindMaxElement(int[] array) { int max = array[0]; for (int i = 0; i &lt; array.Length; i++) { if (array[i] &gt; max) { max = array[i]; } } return max; } 这里，nnn 为数组 array 的大小，则最坏情况下需要比较 nnn 次以得到最大值，所以算法复杂度为 O(n)O(n)O(n)。 示例代码（3）： long FindInversions(int[] array) { long inversions = 0; for (int i = 0; i &lt; array.Length; i++) for (int j = i + 1; j &lt; array.Length; j++) if (array[i] &gt; array[j]) inversions++; return inversions; } 这里，nnn 为数组 array 的大小，则基本步骤的执行数量约为 n×n−12n \\times \\frac{n - 1}{2}n×2n−1​，所以算法复杂度为 O(n2)O(n^2)O(n2)。 示例代码（4）： long SumMN(int n, int m) { long sum = 0; for (int x = 0; x &lt; n; x++) for (int y = 0; y &lt; m; y++) sum += x * y; return sum; } 给定规模 nnn 和 mmm，则基本步骤的执行数量为 n×mn \\times mn×m，所以算法复杂度为 O(n2)O(n^2)O(n2)。 示例代码（5）： decimal Sum3(int n) { decimal sum = 0; for (int a = 0; a &lt; n; a++) for (int b = 0; b &lt; n; b++) for (int c = 0; c &lt; n; c++) sum += a * b * c; return sum; } 这里，给定规模 nnn，则基本步骤的执行数量约为 n×n×nn \\times n \\times nn×n×n ，所以算法复杂度为 O(n3)O(n^3)O(n3)。 示例代码（6）： decimal Calculation(int n) { decimal result = 0; for (int i = 0; i &lt; (1 &lt;&lt; n); i++) result += i; return result; } 这里，给定规模 nnn，则基本步骤的执行数量为 2n2^n2n，所以算法复杂度为 O(2n)O(2^n)O(2n)。 示例代码（7）： 斐波那契数列： fib(0)=0fib(0) = 0fib(0)=0 fib(1)=1fib(1) = 1fib(1)=1 fib(n)=fib(n−1)+fib(n−2)fib(n) = fib(n-1) + fib(n-2)fib(n)=fib(n−1)+fib(n−2) fib()=0,1,1,2,3,5,8,13,21,34...fib() = 0, 1, 1, 2, 3, 5, 8, 13, 21, 34 ...fib()=0,1,1,2,3,5,8,13,21,34... int Fibonacci(int n) { if (n &lt;= 1) return n; else return Fibonacci(n - 1) + Fibonacci(n - 2); } 这里，给定规模 nnn，计算 fib(n)fib(n)fib(n) 所需的时间为计算 fib(n−1)fib(n-1)fib(n−1) 的时间和计算 fib(n−2)fib(n-2)fib(n−2) 的时间的和。 T(n≤1)=O(1)T(n \\le 1) = O(1)T(n≤1)=O(1) T(n)=T(n−1)+T(n−2)+O(1)T(n) = T(n-1) + T(n-2) + O(1)T(n)=T(n−1)+T(n−2)+O(1) fib(5) / \\ fib(4) fib(3) / \\ / \\ fib(3) fib(2) fib(2) fib(1) / \\ / \\ / \\ 通过使用递归树的结构描述可知算法复杂度为 O(2n)O(2^n)O(2n)。 示例代码（8）： int Fibonacci(int n) { if (n &lt;= 1) return n; else { int[] f = new int[n + 1]; f[0] = 0; f[1] = 1; for (int i = 2; i &lt;= n; i++) { f[i] = f[i - 1] + f[i - 2]; } return f[n]; } } 同样是斐波那契数列，我们使用数组 f 来存储计算结果，这样算法复杂度优化为 O(n)O(n)O(n)。 示例代码（9）： int Fibonacci(int n) { if (n &lt;= 1) return n; else { int iter1 = 0; int iter2 = 1; int f = 0; for (int i = 2; i &lt;= n; i++) { f = iter1 + iter2; iter1 = iter2; iter2 = f; } return f; } } 同样是斐波那契数列，由于实际只有前两个计算结果有用，我们可以使用中间变量来存储，这样就不用创建数组以节省空间。同样算法复杂度优化为 O(n)。 示例代码（10）： 通过使用矩阵乘方的算法来优化斐波那契数列算法。 static int Fibonacci(int n) { if (n &lt;= 1) return n; int[,] f = { { 1, 1 }, { 1, 0 } }; Power(f, n - 1); return f[0, 0]; } static void Power(int[,] f, int n) { if (n &lt;= 1) return; int[,] m = { { 1, 1 }, { 1, 0 } }; Power(f, n / 2); Multiply(f, f); if (n % 2 != 0) Multiply(f, m); } static void Multiply(int[,] f, int[,] m) { int x = f[0, 0] * m[0, 0] + f[0, 1] * m[1, 0]; int y = f[0, 0] * m[0, 1] + f[0, 1] * m[1, 1]; int z = f[1, 0] * m[0, 0] + f[1, 1] * m[1, 0]; int w = f[1, 0] * m[0, 1] + f[1, 1] * m[1, 1]; f[0, 0] = x; f[0, 1] = y; f[1, 0] = z; f[1, 1] = w; } 优化之后算法复杂度为 O(log⁡2n)O(\\log_{2}{n})O(log2​n)。 示例代码（11）： 在 C# 中更简洁的代码如下。 static double Fibonacci(int n) { double sqrt5 = Math.Sqrt(5); double phi = (1 + sqrt5) / 2.0; double fn = (Math.Pow(phi, n) - Math.Pow(1 - phi, n)) / sqrt5; return fn; } 示例代码（12）： 插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的有序数据。算法适用于少量数据的排序，时间复杂度为 O(n2)O(n^2)O(n2)。 private static void InsertionSortInPlace(int[] unsorted) { for (int i = 1; i &lt; unsorted.Length; i++) { if (unsorted[i - 1] &gt; unsorted[i]) { int key = unsorted[i]; int j = i; while (j &gt; 0 &amp;&amp; unsorted[j - 1] &gt; key) { unsorted[j] = unsorted[j - 1]; j--; } unsorted[j] = key; } } } ","link":"https://faded.auspicious.space/post/algorithm-complexity-analysis/"},{"title":"一个漂亮的大 O 速查表","content":" 每个程序员都应该收藏的算法复杂度速查表 图例 绝佳 不错 一般 不佳 糟糕 数据结构操作 数据结构时间复杂度空间复杂度 &nbsp;平均最差最差 &nbsp;访问搜索插入删除访问搜索插入删除&nbsp; Array O(1) O(n) O(n) O(n) O(1) O(n) O(n) O(n) O(n) Stack O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Singly-Linked List O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Doubly-Linked List O(n) O(n) O(1) O(1) O(n) O(n) O(1) O(1) O(n) Skip List O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) O(n) O(n) O(n) O(n log(n)) Hash Table - O(1) O(1) O(1) - O(n) O(n) O(n) O(n) Binary Search Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) O(n) O(n) O(n) O(n) Cartesian Tree - O(log(n)) O(log(n)) O(log(n)) - O(n) O(n) O(n) O(n) B-Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) Red-Black Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) Splay Tree - O(log(n)) O(log(n)) O(log(n)) - O(log(n)) O(log(n)) O(log(n)) O(n) AVL Tree O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(n) 数组排序算法 算法时间复杂度空间复杂度 &nbsp;最佳平均最差最差 Quicksort O(n log(n)) O(n log(n)) O(n^2) O(log(n)) Mergesort O(n log(n)) O(n log(n)) O(n log(n)) O(n) Timsort O(n) O(n log(n)) O(n log(n)) O(n) Heapsort O(n log(n)) O(n log(n)) O(n log(n)) O(1) Bubble Sort O(n) O(n^2) O(n^2) O(1) Insertion Sort O(n) O(n^2) O(n^2) O(1) Selection Sort O(n^2) O(n^2) O(n^2) O(1) Shell Sort O(n) O((nlog(n))^2) O((nlog(n))^2) O(1) Bucket Sort O(n+k) O(n+k) O(n^2) O(n) Radix Sort O(nk) O(nk) O(nk) O(n+k) 图操作 节点 / 边界管理存储增加顶点增加边界移除顶点移除边界查询 Adjacency list O(|V|+|E|) O(1) O(1) O(|V| + |E|) O(|E|) O(|V|) Incidence list O(|V|+|E|) O(1) O(1) O(|E|) O(|E|) O(|E|) Adjacency matrix O(|V|^2) O(|V|^2) O(1) O(|V|^2) O(1) O(1) Incidence matrix O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|V| ⋅ |E|) O(|E|) 堆操作 类型时间复杂度 &nbsp;Heapify查找最大值分离最大值提升键插入删除合并 Linked List (sorted) - O(1) O(1) O(n) O(n) O(1) O(m+n) Linked List (unsorted) - O(n) O(n) O(1) O(1) O(1) O(1) Binary Heap O(n) O(1) O(log(n)) O(log(n)) O(log(n)) O(log(n)) O(m+n) Binomial Heap - O(1) O(log(n)) O(log(n)) O(1) O(log(n)) O(log(n)) Fibonacci Heap - O(1) O(log(n)) O(1) O(1) O(log(n)) O(1) 大 O 复杂度图表 ","link":"https://faded.auspicious.space/post/a-beautiful-big-o-cheatsheet/"},{"title":"《雷神之锤 3》中的平方根算法","content":"《雷神之锤 3》的作者是约翰卡马克，早前，《雷神之锤 3》的源码公开。卡马克大神有一段代码，简直是吊炸天。 float Q_rsqrt(float number) { long i; float x2, y; const float threehalfs = 1.5F; x2 = number * 0.5F; y = number; i = *(long) &amp;y; // evil floating point bit level hacking i = 0x5f3759df - (i &gt;&gt; 1); // what the fuck? y= *(float*) &amp;i; y = y * (threehalfs - (x2 * y * y)); //1st iteration // y = y * (threehalfs - (x2 * y * y)); // 2nd iteration, this can be removed #ifndef Q_3VM #ifdef __linux__ assert(!isnan(y)); //bk010122 - FPE? #endif #endif return y; } 这段代码，据说主要用处是把一个数开平方并且取倒。经过测试之后，据说上面这段代码，尽然比 (float)(1.0/sqrt(x)) 更快，而且是快 4 倍。 具体的实现过程比较复杂，下面是实现过程。 函数返回 1 / sqr(x)，这个函数在图像处理中比 sqrt(x) 更有用。 注意到这个函数只用了一次迭代！（其实就是根本没用迭代，直接运算）。编译，实验，这个函数不仅工作的很好，而且比标准的 sqrt() 函数快 4 倍！要知道，编译器自带的函数，可是经过严格仔细的汇编优化的啊！ 这个简洁的函数，最核心，也是最让人费解的，就是标注了 &quot;what the fuck?&quot; 的一句 i = 0x5f3759df - (i &gt;&gt; 1); 再加上 y = y * ( threehalfs - (x2 * y * y)); 两句话就完成了开方运算!而且注意到，核心那句是定点移位运算，速度极快!特别在很多没有乘法指令的 RISC结构 CPU上，这样做是极其高效的。算法的原理其实不复杂就是牛顿迭代法用 x−f(x)f′(x)x-f(x)f&#x27;(x)x−f(x)f′(x) 不断的逼近 f(x)=af(x)=af(x)=a 的根。 简单来说比如求平方根，f(x) = x ^ 2 = a，f'(x) = 2 * x，f(x) / f'(x) = x / 2， 把 f(x) 代入 x - f(x) / f'(x) 后有 (x + a / x) / 2，现在我们选 a = 5，选一个猜测值比如 2， 那么我们可以这么算 5 / 2 = 2.5; (2.5 + 2) / 2 = 2.25; 5 / 2 .25 = xxx; (2.25 + xxx) / 2 = xxxx ... 这样反复迭代下去，结果必定收敛于 sqrt(5)，没错，一般的求平方根都是这么算的 但是卡马克（quake 3 作者）真正牛B的地方是他选择了一个神秘的常数 0x5f3759df 来计算那个猜测值 就是我们加注释的那一行，那一行算出的值非常接近 1 / sqrt(n)，这样我们只需要 2 次牛顿迭代就可以达到我们所需要的精度。 ","link":"https://faded.auspicious.space/post/square-root-algorithm-in-quake-3/"},{"title":"Vim——常用命令大全","content":" VIM快捷键大全 目录 1 关于VIM 1.1 VIM 的几种模式 正常模式：可以使用快捷键命令，或按:输入命令行。 插入模式：可以输入文本，在正常模式下，按 i、a、o 等都可以进入插入模式。 可视模式：正常模式下按v可以进入可视模式， 在可视模式下，移动光标可以选择文本。按 V 进入可视行模式， 总是整行整行的选中。ctrl+v 进入可视块模式。 替换模式：正常模式下，按 R 进入。 2 启动Vim vim -c cmd file: 在打开文件前，先执行指定的命令； vim -r file: 恢复上次异常退出的文件； vim -R file: 以只读的方式打开文件，但可以强制保存； vim -M file: 以只读的方式打开文件，不可以强制保存； vim -y num file: 将编辑窗口的大小设为 num 行； vim + file: 从文件的末尾开始； vim +num file: 从第num行开始； vim +/string file: 打开 file，并将光标停留在第一个找到的 string 上。 vim --remote file: 用已有的 VIM 进程打开指定的文件。 如果你不想启用多个 VIM 会话，这个很有用。但要注意， 如果你用 VIM，会寻找名叫 VIM 的服务器；如果你已经有一个 gvim 在运行了， 你可以用 gvim --remote file 在已有的 gvim p 中打开文件。 3 文档操作 :e file --关闭当前编辑的文件，并开启新的文件。 如果对当前文件的修改未保存，vi 会警告。 :e! file --放弃对当前文件的修改，编辑新的文件。 :e+file -- 开始新的文件，并从文件尾开始编辑。 :e+n file -- 开始新的文件，并从第 n 行开始编辑。 :enew --编译一个未命名的新文档。(CTRL-W n)。 :e -- 重新加载当前文档。 :e! -- 重新加载当前文档，并丢弃已做的改动。 :e#或ctrl+^ -- 回到刚才编辑的文件，很实用。 :f或ctrl+g -- 显示文档名，是否修改，和光标位置。 :f filename -- 改变编辑的文件名，这时再保存相当于另存为。 gf -- 打开以光标所在字符串为文件名的文件。 :w -- 保存修改。 :n1,n2w filename -- 选择性保存从某 n1 行到另 n2 行的内容。 :wq -- 保存并退出。 ZZ -- 保存并退出。 :x -- 保存并退出。 :q[uit] --退出当前窗口。(CTRL-W q 或 CTRL-W CTRL-Q) :saveas newfilename -- 另存为 :browse e -- 会打开一个文件浏览器让你选择要编辑的文件。 如果是终端中，则会打开 netrw 的文件浏览窗口； 如果是 gvim，则会打开一个图形界面的浏览窗口。 实际上 :browse 后可以跟任何编辑文档的命令，如 sp 等。 用 browse 打开的起始目录可以由 browsedir 来设置： :set browsedir=last -- 用上次访问过的目录（默认）； :set browsedir=buffer -- 用当前文件所在目录； :set browsedir=current -- 用当前工作目录； :Sex -- 水平分割一个窗口，浏览文件系统； :Vex -- 垂直分割一个窗口，浏览文件系统； 4 光标的移动 4.1 基本移动 以下移动都是在 normal 模式下。 h 或退格: 左移一个字符； l 或空格: 右移一个字符； j: 下移一行； k: 上移一行； gj: 移动到一段内的下一行； gk: 移动到一段内的上一行； + 或 Enter: 把光标移至下一行第一个非空白字符。 -: 把光标移至上一行第一个非空白字符。 w: 前移一个单词，光标停在下一个单词开头； W: 移动下一个单词开头，但忽略一些标点； e: 前移一个单词，光标停在下一个单词末尾； E: 移动到下一个单词末尾，如果词尾有标点，则移动到标点； b: 后移一个单词，光标停在上一个单词开头； B: 移动到上一个单词开头，忽略一些标点； ge: 后移一个单词，光标停在上一个单词末尾； gE: 同 ge ，不过‘单词’包含单词相邻的标点。 (: 前移 1 句。 ): 后移 1 句。 {: 前移 1 段。 }: 后移 1 段。 fc: 把光标移到同一行的下一个 c 字符处 Fc: 把光标移到同一行的上一个 c 字符处 tc: 把光标移到同一行的下一个 c 字符前 Tc: 把光标移到同一行的上一个 c 字符后 ;: 配合 f &amp; t 使用，重复一次 ,: 配合 f &amp; t 使用，反向重复一次 上面的操作都可以配合 n 使用，比如在正常模式(下面会讲到)下输入 3h， 则光标向左移动 3 个字符。 27. 0: 移动到行首。 28. g0: 移到光标所在屏幕行行首。 29. ^: 移动到本行第一个非空白字符。 30. g^: 同 ^ ，但是移动到当前屏幕行第一个非空字符处。 31. $: 移动到行尾。 32. g$: 移动光标所在屏幕行行尾。 33. n|: 把光标移到递 n 列上。 34. nG: 到文件第 n 行。 35. :n 移动到第 n 行。 36. :$ 移动到最后一行。 37. H: 把光标移到屏幕最顶端一行。 38. M: 把光标移到屏幕中间一行。 39. L: 把光标移到屏幕最底端一行。 40. gg: 到文件头部。 41. G: 到文件尾部。 4.2 翻屏 ctrl+f: 下翻一屏。 ctrl+b: 上翻一屏。 ctrl+d: 下翻半屏。 ctrl+u: 上翻半屏。 ctrl+e: 向下滚动一行。 ctrl+y: 向上滚动一行。 n%: 到文件 n% 的位置。 zz: 将当前行移动到屏幕中央。 zt: 将当前行移动到屏幕顶端。 zb: 将当前行移动到屏幕底端。 4.3 标记 使用标记可以快速移动。到达标记后，可以用 Ctrl+o 返回原来的位置。Ctrl+o 和 Ctrl+i 很像浏览器上的 后退 和 前进 。 m{a-z}: 标记光标所在位置，局部标记，只用于当前文件。 m{A-Z}: 标记光标所在位置，全局标记。标记之后，退出 VIM， 重新启动，标记仍然有效。 `{a-z}: 移动到标记位置。 '{a-z}: 移动到标记行的行首。 `{0-9}：回到上 [2-10] 次关闭 VIM 时最后离开的位置。 ``: 移动到上次编辑的位置。'' 也可以，不过 `` 精确到列，而 '' 精确到行 。如果想跳转到更老的位置，可以按 C-o，跳转到更新的位置用 C-i。 `&quot;: 移动到上次离开的地方。 `.: 移动到最后改动的地方。 :marks 显示所有标记。 :delmarks a b -- 删除标记 a 和 b。 :delmarks a-c -- 删除标记 a、b 和 c。 :delmarks a c-f -- 删除标记 a、c、d、e、f。 :delmarks! -- 删除当前缓冲区的所有标记。 :help mark-motions 查看更多关于 mark 的知识。 5 插入文本 5.1 基本插入 i: 在光标前插入；一个小技巧：按 8，再按 i，进入插入模式，输入 =， 按 esc 进入命令模式，就会出现 8 个 =。 这在插入分割线时非常有用，如 30i+ 就插入了 36 个 + 组成的分割线。 I: 在当前行第一个非空字符前插入； gI: 在当前行第一列插入； a: 在光标后插入； A: 在当前行最后插入； o: 在下面新建一行插入； O: 在上面新建一行插入； :r filename 在当前位置插入另一个文件的内容。 :[n]r filename 在第 n 行插入另一个文件的内容。 :r !date 在光标处插入当前日期与时间。同理，:r !command 可以将其它 shell 命令的输出插入当前文档。 5.2 改写插入 c[n]w: 改写光标后 1(n) 个词。 c[n]l: 改写光标后 n 个字母。 c[n]h: 改写光标前 n 个字母。 [n]cc: 修改当前 [n] 行。 [n]s: 以输入的文本替代光标之后 1(n) 个字符，相当于 c[n]l。 [n]S: 删除指定数目的行，并以所输入文本代替之。 注意，类似 cnw，dnw，ynw 的形式同样可以写为 ncw，ndw，nyw。 6 剪切复制和寄存器 6.1 剪切和复制、粘贴 [n]x: 剪切光标右边 n 个字符，相当于 d[n]l。 [n]X: 剪切光标左边 n 个字符，相当于 d[n]h。 y: 复制在可视模式下选中的文本。 yy or Y: 复制整行文本。 y[n]w: 复制一(n)个词。 y[n]l: 复制光标右边1(n)个字符。 y[n]h: 复制光标左边1(n)个字符。 y$: 从光标当前位置复制到行尾。 y0: 从光标当前位置复制到行首。 :m,ny 复制 m 行到 n 行的内容。 y1G 或 ygg: 复制光标以上的所有行。 yG: 复制光标以下的所有行。 yaw 和 yas：复制一个词和复制一个句子，即使光标不在词首和句首也没关系。 d: 删除（剪切）在可视模式下选中的文本。 d$ or D: 删除（剪切）当前位置到行尾的内容。 d[n]w: 删除（剪切）1(n) 个单词。 d[n]l: 删除（剪切）光标右边 1(n) 个字符。 d[n]h: 删除（剪切）光标左边 1(n) 个字符。 d0: 删除（剪切）当前位置到行首的内容。 [n] dd: 删除（剪切）1(n) 行。 :m,nd 剪切 m 行到 n 行的内容。 d1G 或 dgg: 剪切光标以上的所有行。 dG: 剪切光标以下的所有行。 daw 和 das：剪切一个词和剪切一个句子，即使光标不在词首和句首也没关系。 d/f：这是一个比较高级的组合命令，它将删除当前位置 到下一个 f 之间的内容。 p: 在光标之后粘贴。 P: 在光标之前粘贴。 6.2 文本对象 aw：一个词 as：一句。 ap：一段。 ab：一块（包含在圆括号中的）。 y，d，c，v 都可以跟文本对象。 6.3 寄存器 a-z：都可以用作寄存器名。&quot;ayy 把当前行的内容放入 a 寄存器。 A-Z：用大写字母索引寄存器，可以在寄存器中追加内容。 如 &quot;Ayy 把当前行的内容追加到 a 寄存器中。 :reg 显示所有寄存器的内容。 &quot;&quot;：不加寄存器索引时，默认使用的寄存器。 &quot;*：当前选择缓冲区，&quot;*yy 把当前行的内容放入当前选择缓冲区。 &quot;+：系统剪贴板。&quot;+yy 把当前行的内容放入系统剪贴板。 7 查找与替换 7.1 查找 /something: 在后面的文本中查找 something。 ?something: 在前面的文本中查找 something。 /pattern/+number: 将光标停在包含 pattern 的行后面第 number 行上。 /pattern/-number: 将光标停在包含 pattern 的行前面第 number 行上。 n: 向后查找下一个。 N: 向前查找下一个。 可以用 grep 或 vimgrep 查找一个模式都在哪些地方出现过，其中: grep 是调用外部的 grep 程序，而 :vimgrep 是 VIM 自己的查找算法。用法为：:vim[grep]/pattern/[g] [j] files g 的含义是如果一个模式在一行中多次出现，则这一行也在结果中多次出现。j 的含义是 grep 结束后，结果停在第 j 项，默认是停在第一项。vimgrep 前面可以加数字限定搜索结果的上限，如 :1vim/pattern/ % 只查找那个模式在本文件中的第一个出现。 其实 vimgrep 在读纯文本电子书时特别有用，可以生成导航的目录。比如电子书中每一节的标题形式为：n. xxxx。你就可以这样：:vim/^d{1,}./ % 然后用 :cw 或 :copen 查看结果，可以用 C-w H 把 quickfix 窗口移到左侧，就更像个目录了。 7.2 替换 :s/old/new - 用 new 替换当前行第一个 old。 :s/old/new/g - 用 new 替换当前行所有的 old。 :n1,n2s/old/new/g - 用 new 替换文件 n1 行到 n2 行所有的 old。 :%s/old/new/g - 用 new 替换文件中所有的 old。 :%s/^/xxx/g - 在每一行的行首插入 xxx，^ 表示行首。 :%s/$/xxx/g - 在每一行的行尾插入 xxx，$ 表示行尾。 所有替换命令末尾加上 c，每个替换都将需要用户确认。 如：%s/old/new/gc，加上 i 则忽略大小写(ignore)。 还有一种比替换更灵活的方式，它是匹配到某个模式后执行某种命令， 语法为 :[range]g/pattern/command 例如 :%g/^ xyz/normal dd。 表示对于以一个空格和 xyz 开头的行执行 normal 模式下的 dd 命令。 关于 range 的规定为： 如果不指定 range，则表示当前行。 m,n: 从 m 行到 n 行。 0: 最开始一行（可能是这样）。 $: 最后一行 .: 当前行 %: 所有行 7.3 正则表达式 高级的查找替换就要用到正则表达式。 \\d: 表示十进制数（我猜的） \\s: 表示空格 \\S: 非空字符 \\a: 英文字母 \\|: 表示 或 \\.: 表示. {m,n}: 表示 m 到 n 个字符。这要和 \\s 与 \\a 等连用，如 \\a\\{m,n} 表示 m 到 n 个英文字母。 {m,}: 表示 m 到无限多个字符。 **: 当前目录下的所有子目录。 :help pattern 得到更多帮助。 8 排版 8.1 基本排版 &lt;&lt; 向左缩进一个 shiftwidth &gt;&gt; 向右缩进一个 shiftwidth :ce(nter) 本行文字居中 :le(ft) 本行文字靠左 :ri(ght) 本行文字靠右 gq 对选中的文字重排，即对过长的文字进行断行 gqq 重排当前行 gqnq 重排 n 行 gqap 重排当前段 gqnap 重排 n 段 gqnj 重排当前行和下面 n 行 gqQ 重排当前段对文章末尾 J 拼接当前行和下一行 gJ 同 J，不过合并后不留空格。 8.2 拼写检查 :set spell－开启拼写检查功能 :set nospell－关闭拼写检查功能 ]s－移到下一个拼写错误的单词 [s－作用与上一命令类似，但它是从相反方向进行搜索 z=－显示一个有关拼写错误单词的列表，可从中选择 zg－告诉拼写检查器该单词是拼写正确的 zw－与上一命令相反，告诉拼写检查器该单词是拼写错误的 8.3 统计字数 g ^g 可以统计文档字符数，行数。 将光标放在最后一个字符上，用字符数减去行数可以粗略统计中文文档的字数。 以上对 Mac 或 Unix 的文件格式适用。 如果是 Windows 文件格式（即换行符有两个字节），字数的统计方法为：字符数 - 行数 * 2。 9 编辑多个文件 9.1 一次编辑多个文件 我们可以一次打开多个文件，如 vi a.txt b.txt c.txt 使用 :next(:n) 编辑下一个文件。 :2n 编辑下 2 个文件。 使用 :previous 或 :N 编辑上一个文件。 使用 :wnext，保存当前文件，并编辑下一个文件。 使用 :wprevious，保存当前文件，并编辑上一个文件。 使用 :args 显示文件列表。 :n filenames 或 :args filenames 指定新的文件列表。 vi -o filenames 在水平分割的多个窗口中编辑多个文件。 vi -O filenames 在垂直分割的多个窗口中编辑多个文件。 9.2 多标签编辑 vim -p files: 打开多个文件，每个文件占用一个标签页。 :tabe, tabnew -- 如果加文件名，就在新的标签中打开这个文件， 否则打开一个空缓冲区。 ^w gf -- 在新的标签页里打开光标下路径指定的文件。 :tabn -- 切换到下一个标签。Control + PageDown，也可以。 :tabp -- 切换到上一个标签。Control + PageUp，也可以。 [n] gt -- 切换到下一个标签。如果前面加了 n ， 就切换到第 n 个标签。第一个标签的序号就是 1。 :tab split -- 将当前缓冲区的内容在新页签中打开。 :tabc[lose] -- 关闭当前的标签页。 :tabo[nly] -- 关闭其它的标签页。 :tabs -- 列出所有的标签页和它们包含的窗口。 :tabm[ove] [N] -- 移动标签页，移动到第 N 个标签页之后。 如 tabm 0 当前标签页，就会变成第一个标签页。 9.3 缓冲区 :buffers 或 :ls 或 :files 显示缓冲区列表。 ctrl+^：在最近两个缓冲区间切换。 :bn -- 下一个缓冲区。 :bp -- 上一个缓冲区。 :bl -- 最后一个缓冲区。 :b[n] 或 :[n]b -- 切换到第 n 个缓冲区。 :nbw(ipeout) -- 彻底删除第 n 个缓冲区。 :nbd(elete) -- 删除第 n 个缓冲区，并未真正删除，还在 unlisted 列表中。 :ba[ll] -- 把所有的缓冲区在当前页中打开，每个缓冲区占一个窗口。 10 分屏编辑 vim -o file1 file2: 水平分割窗口，同时打开 file1 和 file2 vim -O file1 file2: 垂直分割窗口，同时打开 file1 和 file2 10.1 水平分割 :split(:sp) -- 把当前窗水平分割成两个窗口。(CTRL-W s 或 CTRL-W CTRL-S) 注意如果在终端下，CTRL-S 可能会冻结终端，请按 CTRL-Q 继续。 :split filename -- 水平分割窗口，并在新窗口中显示另一个文件。 :nsplit(:nsp) -- 水平分割出一个 n 行高的窗口 :[N]new -- 水平分割出一个 N 行高的窗口，并编辑一个新文件。 (CTRL-W n 或 CTRL-W CTRL-N) ctrl+w f --水平分割出一个窗口，并在新窗口打开名称为光标所在词的文件 。 C-w C-^ -- 水平分割一个窗口，打开刚才编辑的文件。 10.2 垂直分割 :vsplit(:vsp) -- 把当前窗口分割成水平分布的两个窗口。 (CTRL-W v 或 CTRL CTRL-V) :[N]vne[w] -- 垂直分割出一个新窗口。 :vertical 水平分割的命令： 相应的垂直分割。 10.3 关闭子窗口 :qall -- 关闭所有窗口，退出 VIM。 :wall -- 保存所有修改过的窗口。 :only -- 只保留当前窗口，关闭其它窗口。(CTRL-W o) :close -- 关闭当前窗口，CTRL-W c 能实现同样的功能。 (象 :q :x 同样工作 ) 10.4 调整窗口大小 ctrl+w + --当前窗口增高一行。也可以用 n 增高 n 行。 ctrl+w - --当前窗口减小一行。也可以用 n 减小 n 行。 ctrl+w _ --当前窗口扩展到尽可能的大。也可以用 n 设定行数。 :resize n -- 当前窗口 n 行高。 ctrl+w = -- 所有窗口同样高度。 n ctrl+w _ -- 当前窗口的高度设定为 n 行。 ctrl+w &lt; --当前窗口减少一列。也可以用 n 减少 n 列。 ctrl+w &gt; --当前窗口增宽一列。也可以用 n 增宽 n 列。 ctrl+w | --当前窗口尽可能的宽。也可以用 n 设定列数。 10.5 切换和移动窗口 如果支持鼠标，切换和调整子窗口的大小就简单了。 ctrl+w ctrl+w: 切换到下一个窗口。或者是 ctrl+w w。 ctrl+w p: 切换到前一个窗口。 ctrl+w h(l,j,k):切换到左（右，下，上）的窗口。 ctrl+w t(b):切换到最上（下）面的窗口。 ctrl+w H(L,K,J): 将当前窗口移动到最左（右、上、下）面。 ctrl+w r：旋转窗口的位置。 ctrl+w T: 将当前的窗口移动到新的标签页上。 11 快速编辑 11.1 改变大小写 ~: 反转光标所在字符的大小写。 可视模式下的 U 或 u：把选中的文本变为大写或小写。 gu(U) 接范围（如 $，或 G），可以把从光标当前位置到指定位置之间字母全部转换成小写或大写。如 ggguG，就是把开头到最后一行之间的字母全部变为小 写。再如 gu5j，把当前行和下面四行全部变成小写。 11.2 替换（normal模式） r: 替换光标处的字符，同样支持汉字。 R: 进入替换模式，按 esc 回到正常模式。 11.3 撤消与重做（normal模式） [n] u: 取消一 (n) 个改动。 :undo 5 -- 撤销 5 个改变。 :undolist -- 你的撤销历史。 ctrl + r: 重做最后的改动。 U: 取消当前行中所有的改动。 :earlier 4m -- 回到 4 分钟前 :later 55s -- 前进 55 秒 11.4 宏 . --重复上一个编辑动作 qa：开始录制宏 a（键盘操作记录） q：停止录制 @a：播放宏 a 12 编辑特殊文件 12.1 文件加解密 vim -x file: 开始编辑一个加密的文件。 :X -- 为当前文件设置密码。 :set key= -- 去除文件的密码。 12.2 文件的编码 :e ++enc=utf8 filename, 让 VIM 用 utf-8 的编码打开这个文件。 :w ++enc=gbk，不管当前文件什么编码，把它转存成 gbk 编码。 :set fenc 或 :set fileencoding，查看当前文件的编码。 在 vimrc 中添加 set fileencoding=ucs-bom,utf-8,cp936，VIM 会根据要打开的文件选择合适的编码。 注意：编码之间不要留空格。cp936 对应于 gbk 编码。ucs-bom 对应于 Windows 下的文件格式。 让 VIM 正确处理文件格式和文件编码，有赖于 ~/.vimrc 的正确配置 12.3 文件格式 大致有三种文件格式：unix，dos，mac。 三种格式的区别主要在于回车键的编码：dos 下是回车加换行，unix 下只有换行符，mac 下只有回车符。 :e ++ff=dos filename, 让 VIM 用 dos 格式打开这个文件。 :w ++ff=mac filename, 以 mac 格式存储这个文件。 :set ff，显示当前文件的格式。 在 vimrc 中添加 set fileformats=unix,dos,mac，让 VIM 自动识别文件格式。 13 编程辅助 13.1 一些按键 gd: 跳转到局部变量的定义处； gD: 跳转到全局变量的定义处，从当前文件开头开始搜索； g;: 上一个修改过的地方； g,: 下一个修改过的地方； [[: 跳转到上一个函数块开始，需要有单独一行的 {。 ]]: 跳转到下一个函数块开始，需要有单独一行的 {。 []: 跳转到上一个函数块结束，需要有单独一行的 }。 ][: 跳转到下一个函数块结束，需要有单独一行的 }。 [{: 跳转到当前块开始处； ]}: 跳转到当前块结束处； [/: 跳转到当前注释块开始处； ]/: 跳转到当前注释块结束处； %: 不仅能移动到匹配的 (),{} 或 [] 上，而且能在 #if，#else，#endif 之间跳跃。 下面的括号匹配对编程很实用的。 ci', di', yi'：修改、剪切或复制 ' 之间的内容。 ca', da', ya'：修改、剪切或复制'之间的内容，包含 '。 ci&quot;, di&quot;, yi&quot;：修改、剪切或复制 &quot; 之间的内容。 ca&quot;, da&quot;, ya&quot;：修改、剪切或复制 &quot; 之间的内容，包含 &quot;。 ci(, di(, yi(：修改、剪切或复制 () 之间的内容。 ca(, da(, ya(：修改、剪切或复制 () 之间的内容，包含()。 ci[, di[, yi[：修改、剪切或复制 [] 之间的内容。 ca[, da[, ya[：修改、剪切或复制 [] 之间的内容，包含 []。 ci{, di{, yi{：修改、剪切或复制 {} 之间的内容。 ca{, da{, ya{：修改、剪切或复制 {} 之间的内容，包含 {}。 ci&lt;, di&lt;, yi&lt;：修改、剪切或复制 &lt;&gt; 之间的内容。 ca&lt;, da&lt;, ya&lt;：修改、剪切或复制 &lt;&gt; 之间的内容，包含 &lt;&gt;。 13.2 ctags ctags -R: 生成 tag 文件，-R 表示也为子目录中的文件生成 tags。 :set tags=path/tags -- 告诉 ctags 使用哪个 tag 文件。 :tag xyz -- 跳到 xyz 的定义处，或者将光标放在 xyz 上按 C-]，返回用 C-t :stag xyz -- 用分割的窗口显示 xyz 的定义，或者 C-w ]， 如果用 C-w n ]，就会打开一个 n 行高的窗口 :ptag xyz -- 在预览窗口中打开 xyz 的定义，热键是 C-w }。 :pclose -- 关闭预览窗口。热键是 C-w z。 :pedit abc.h -- 在预览窗口中编辑 abc.h :psearch abc -- 搜索当前文件和当前文件 include 的文件，显示包含 abc 的行。 有时一个 tag 可能有多个匹配，如函数重载，一个函数名就会有多个匹配。 这种情况会先跳转到第一个匹配处。 :[n]tnext -- 下一 [n] 个匹配。 :[n]tprev -- 上一 [n] 个匹配。 :tfirst -- 第一个匹配 :tlast -- 最后一个匹配 :tselect tagname -- 打开选择列表 tab 键补齐 :tag xyz-- 补齐以 xyz 开头的 tag 名，继续按 tab 键，会显示其他的。 :tag /xyz-- 会用名字中含有 xyz 的 tag 名补全。 13.3 cscope cscope -Rbq: 生成 cscope.out 文件 :cs add /path/to/cscope.out /your/work/dir :cs find c func -- 查找 func 在哪些地方被调用 :cw -- 打开 quickfix 窗口查看结果 13.4 gtags Gtags 综合了 ctags 和 cscope 的功能。 使用 Gtags 之前，你需要安装 GNU Gtags。 然后在工程目录运行 gtags 。 :Gtags funcname 定位到 funcname 的定义处。 :Gtags -r funcname 查询 funcname 被引用的地方。 :Gtags -s symbol 定位 symbol 出现的地方。 :Gtags -g string Goto string 出现的地方。:Gtags -gi string 忽略大小写。 :Gtags -f filename 显示 filename 中的函数列表。 你可以用 :Gtags -f % 显示当前文件。 :Gtags -P pattern 显示路径中包含特定模式的文件。 如 :Gtags -P .h$ 显示所有头文件，:Gtags -P /vm/ 显示 vm 目录下的文件。 13.5 编译 VIM 提供了 :make 来编译程序，默认调用的是 make， 如果你当前目录下有 makefile，简单地 :make 即可。 如果你没有 make 程序，你可以通过配置 makeprg 选项来更改 make 调用的程序。 如果你只有一个abc.java文件，你可以这样设置： set makeprg=javac\\ abc.java 然后 :make 即可。如果程序有错，可以通过 quickfix 窗口查看错误。 不过如果要正确定位错误，需要设置好 errorformat，让 VIM 识别错误信息。 如： :setl efm=%A%f:%l:\\ %m,%-Z%p^,%-C%.%# %f 表示文件名，%l 表示行号，%m 表示错误信息，其它的还不能理解。 请参考 :help errorformat。 13.6 快速修改窗口 其实是 quickfix 插件提供的功能， 对编译调试程序非常有用 😃 :copen -- 打开快速修改窗口。 :cclose -- 关闭快速修改窗口。 快速修改窗口在 make 程序时非常有用，当 make 之后： :cl -- 在快速修改窗口中列出错误。 :cn -- 定位到下一个错误。 :cp -- 定位到上一个错误。 :cr -- 定位到第一个错误。 13.7 自动补全 C-x C-s -- 拼写建议。 C-x C-v -- 补全 VIM 选项和命令。 C-x C-l -- 整行补全。 C-x C-f -- 自动补全文件路径。弹出菜单后，按 C-f 循环选择，当然也可以按 C-n 和 C-p。 C-x C-p 和 C-x C-n -- 用文档中出现过的单词补全当前的词。 直接按 C-p 和 C-n 也可以。 C-x C-o -- 编程时可以补全关键字和函数名啊。 C-x C-i -- 根据头文件内关键字补全。 C-x C-d -- 补全宏定义。 C-x C-n -- 按缓冲区中出现过的关键字补全。 直接按 C-n 或 C-p 即可。 当弹出补全菜单后： C-p 向前切换成员； C-n 向后切换成员； C-e 退出下拉菜单，并退回到原来录入的文字； C-y 退出下拉菜单，并接受当前选项。 13.8 多行缩进缩出 正常模式下，按两下 &gt;; 光标所在行会缩进。 如果先按了 n，再按两下 &gt;;，光标以下的 n 行会缩进。 对应的，按两下 &lt;;，光标所在行会缩出。 如果在编辑代码文件，可以用 = 进行调整。 在可视模式下，选择要调整的代码块，按 =，代码会按书写规则缩排好。 或者 n =，调整 n 行代码的缩排。 13.9 折叠 zf -- 创建折叠的命令，可以在一个可视区域上使用该命令； zd -- 删除当前行的折叠； zD -- 删除当前行的折叠； zfap -- 折叠光标所在的段； zo -- 打开折叠的文本； zc -- 收起折叠； za -- 打开/关闭当前折叠； zr -- 打开嵌套的折行； zm -- 收起嵌套的折行； zR (zO) -- 打开所有折行； zM (zC) -- 收起所有折行； zj -- 跳到下一个折叠处； zk -- 跳到上一个折叠处； zi -- enable/disable fold; 14 命令行 normal 模式下按:进入命令行模式 14.1 命令行模式下的快捷键： 上下方向键：上一条或者下一条命令。如果已经输入了部分命令，则找上一 条或者下一条匹配的命令。 左右方向键：左 / 右移一个字符。 C-w： 向前删除一个单词。 C-h： 向前删除一个字符，等同于 Backspace。 C-u： 从当前位置移动到命令行开头。 C-b： 移动到命令行开头。 C-e： 移动到命令行末尾。 Shift-Left：左移一个单词。 Shift-Right：右移一个单词。 @： 重复上一次的冒号命令。 q： 正常模式下，q 然后按 ':'，打开命令行历史缓冲区， 可以像编辑文件一样编辑命令。 q/ 和 q? 可以打开查找历史记录。 14.2 执行外部命令 :! cmd 执行外部命令。 :!! 执行上一次的外部命令。 :sh 调用 shell，用 exit 返回 VIM。 :r !cmd 将命令的返回结果插入文件当前位置。 :m,nw !cmd 将文件的 m 行到 n 行之间的内容做为命令输入执行命令。 15 其它 15.1 工作目录 :pwd 显示 VIM 的工作目录。 :cd path 改变 VIM 的工作目录。 :set autochdir 可以让 VIM 根据编辑的文件自动切换工作目录。 15.2 一些快捷键（收集中） K: 打开光标所在词的 manpage。 *: 向下搜索光标所在词。 g*: 同上，但部分符合即可。 #: 向上搜索光标所在词。 g#: 同上，但部分符合即可。 g C-g: 统计全文或统计部分的字数。 15.3 在线帮助 :h(elp) 或 F1 打开总的帮助。 :help user-manual 打开用户手册。 命令帮助的格式为：第一行指明怎么使用那个命令； 然后是缩进的一段解释这个命令的作用，然后是进一步的信息。 :helptags somepath 为 somepath 中的文档生成索引。 :helpgrep 可以搜索整个帮助文档，匹配的列表显示在 quickfix 窗口中。 Ctrl+] 跳转到 tag 主题，Ctrl+t 跳回。 :ver 显示版本信息。 15.4 一些小功能 简单计算器: 在插入模式下，输入 C-r =，然后输入表达式，就能在 光标处得到计算结果。 ","link":"https://faded.auspicious.space/post/vim-common-commands/"},{"title":"Vim——配置入门","content":" Vim 配置入门 Vim 的配置不太容易，它有自己的语法，许许多多的命令。我总是记不清楚，所以就整理了下面这篇文章，列出主要配置项的含义。 1 基础知识 Vim 的全局配置一般在 /etc/vim/vimrc 或者 /etc/vimrc，对所有用户生效。用户个人的配置在 ~/.vimrc。 如果只对单次编辑启用某个配置项，可以在命令模式下，先输入一个冒号，再输入配置。举例来说，set number 这个配置可以写在 .vimrc 里面，也可以在命令模式输入。 :set number 配置项一般都有“打开”和“关闭”两个设置。“关闭”就是在“打开”前面加上前缀 &quot;no&quot;。 &quot; 打开 set number &quot; 关闭 set nonumber 上面代码中，双引号开始的行表示注释。 查询某个配置项是打开还是关闭，可以在命令模式下，输入该配置，并在后面加上问号。 :set number? 上面的命令会返回 number 或者 nonumber。 如果想查看帮助，可以使用 help 命令。 :help number 2 基本配置 （1） set nocompatible 不与 Vi 兼容（采用 Vim 自己的操作命令）。 （2） syntax on 打开语法高亮。自动识别代码，使用多种颜色显示。 （3） set showmode 在底部显示，当前处于命令模式还是插入模式。 （4） set showcmd 命令模式下，在底部显示，当前键入的指令。比如，键入的指令是 2y3d，那么底部就会显示 2y3，当键入 d 的时候，操作完成，显示消失。 （5） set mouse=a 支持使用鼠标。 （6） set encoding=utf-8 使用 utf-8 编码。 （7） set t_Co=256 启用256色。 （8） filetype indent on 开启文件类型检查，并且载入与该类型对应的缩进规则。比如，如果编辑的是 .py 文件，Vim 就是会找 Python 的缩进规则 ~/.vim/indent/python.vim。 3 缩进 9） set autoindent 按下回车键后，下一行的缩进会自动跟上一行的缩进保持一致。 （10） set tabstop=2 按下 Tab 键时，Vim 显示的空格数。 （11） set shiftwidth=4 在文本上按下 &gt;&gt;（增加一级缩进）、&lt;&lt;（取消一级缩进）或者 ==（取消全部缩进）时，每一级的字符数。 （12） set expandtab 由于 Tab 键在不同的编辑器缩进不一致，该设置自动将 Tab 转为空格。 （13） set softtabstop=2 Tab 转为多少个空格。 4 外观 14） set number 显示行号 （15） set relativenumber 显示光标所在的当前行的行号，其他行都为相对于该行的相对行号。 （16） set cursorline 光标所在的当前行高亮。 （17） set textwidth=80 设置行宽，即一行显示多少个字符。 （18） set wrap 自动折行，即太长的行分成几行显示。 set nowrap 关闭自动折行 （19） set linebreak 只有遇到指定的符号（比如空格、连词号和其他标点符号），才发生折行。也就是说，不会在单词内部折行。 （20） set wrapmargin=2 指定折行处与编辑窗口的右边缘之间空出的字符数。 （21） set scrolloff=5 垂直滚动时，光标距离顶部/底部的位置（单位：行）。 （22） set sidescrolloff=15 水平滚动时，光标距离行首或行尾的位置（单位：字符）。该配置在不折行时比较有用。 （23） set laststatus=2 是否显示状态栏。0 表示不显示，1 表示只在多窗口时显示，2 表示显示。 （24） set ruler 在状态栏显示光标的当前位置（位于哪一行哪一列）。 5 搜索 25） set showmatch 光标遇到圆括号、方括号、大括号时，自动高亮对应的另一个圆括号、方括号和大括号。 （26） set hlsearch 搜索时，高亮显示匹配结果。 （27） set incsearch 输入搜索模式时，每输入一个字符，就自动跳到第一个匹配的结果。 （28） set ignorecase 搜索时忽略大小写。 （29） set smartcase 如果同时打开了 ignorecase，那么对于只有一个大写字母的搜索词，将大小写敏感；其他情况都是大小写不敏感。比如，搜索 Test 时，将不匹配 test；搜索 test 时，将匹配 Test。 6 编辑 30） set spell spelllang=en_us 打开英语单词的拼写检查。 （31） set nobackup 不创建备份文件。默认情况下，文件保存时，会额外创建一个备份文件，它的文件名是在原文件名的末尾，再添加一个波浪号（〜）。 （32） set noswapfile 不创建交换文件。交换文件主要用于系统崩溃时恢复文件，文件名的开头是 .、结尾是 .swp。 （33） set undofile 保留撤销历史。 Vim 会在编辑时保存操作历史，用来供用户撤消更改。默认情况下，操作记录只在本次编辑时有效，一旦编辑结束、文件关闭，操作历史就消失了。 打开这个设置，可以在文件关闭后，操作记录保留在一个文件里面，继续存在。这意味着，重新打开一个文件，可以撤销上一次编辑时的操作。撤消文件是跟原文件保存在一起的隐藏文件，文件名以 .un~ 开头。 （34） set backupdir=~/.vim/.backup// set directory=~/.vim/.swp// set undodir=~/.vim/.undo// 设置备份文件、交换文件、操作历史文件的保存位置。 结尾的 //表示生成的文件名带有绝对路径，路径中用 % 替换目录分隔符，这样可以防止文件重名。 （35） set autochdir 自动切换工作目录。这主要用在一个 Vim 会话之中打开多个文件的情况，默认的工作目录是打开的第一个文件的目录。该配置可以将工作目录自动切换到，正在编辑的文件的目录。 （36） set noerrorbells 出错时，不要发出响声。 （37） set visualbell 出错时，发出视觉提示，通常是屏幕闪烁。 （38） set history=1000 Vim 需要记住多少次历史操作。 （39） set autoread 打开文件监视。如果在编辑过程中文件发生外部改变（比如被别的编辑器编辑了），就会发出提示。 （40） set listchars=tab:»■,trail:■ set list 如果行尾有多余的空格（包括 Tab 键），该配置将让这些空格显示成可见的小方块。 （41） set wildmenu set wildmode=longest:list,full 命令模式下，底部操作指令按下 Tab 键自动补全。第一次按下 Tab，会显示所有匹配的操作指令的清单；第二次按下 Tab，会依次选择各个指令。 ","link":"https://faded.auspicious.space/post/vim-configuration-introduction/"},{"title":"Vim——重要的命令","content":" 一些不起眼但非常有用的 Vim 命令 1 保存文件并退出 :x :wq 都是保存当前文件并退出。这两个命令实际上并不完全等价，当文件被修改时两个命令时相同的。但如果未被修改，使用 :x 不会更改文件的修改时间，而使用 :wq 会改变文件的修改时间。 2 基本计算器 在插入模式下，你可以使用 Ctrl+r 键然后输入 =，再输入一个简单的算式。按 Enter 键，计算结果就会插入到文件中。例如，尝试输入： Ctrl+r '=2+2' ENTER 然后计算结果“4 ”会被插入到文件中。 3 查找重复的连续的单词 当你很快地打字时，很有可能会连续输入同一个单词两次，就像 this this。这种错误可能骗过任何一个人，即使是你自己重新阅读一遍也不可避免。幸运的是，有一个简单的正则表达式可以用来预防这个错误。使用搜索命令（默认时 /）然后输入： \\(\\&lt;\\w\\+\\&gt;\\)\\_s*\\1 这会显示所有重复的单词。要达到最好的效果，不要忘记把下面的命令： set hlsearch 放到你的 .vimrc 文件中高亮所有的匹配。 4 缩写 一个很可能是最令人印象深刻的窍门是你可以在 Vim 中定义缩写，它可以实时地把你输入的东西替换为另外的东西。语法格式如下： :ab [缩写] [要替换的文字] 一个通用的例子是： :ab asap as soon as possible 会把你输入的 “asap” 替换为 “as soon as possible”。 5 在你忘记用 root 方式打开文件时的文件保存 这可能是一个在论坛中一直受欢迎的命令。每当你打开一个你没有写入权限的文件（比如系统配置文件）并做了一些修改，Vim 无法通过普通的 :w 命令来保存。 你不需要重新以 root 方式打开文件再进行修改，只需要运行： :w !sudo tee % 这会直接以 root 方式保存。 6 实时加密文本 如果你不想让别人看懂你的屏幕上的内容，你可以使用一个内置的选项，通过下面的命令使用 ROT13 来对文本进行编码： ggVGg? gg 把光标移动到 Vim 缓冲区的第一行，V 进入可视模式，G 把光标移动到缓冲区的最后一行。因此，ggVG 使可视模式覆盖这个当前缓冲区。最后 g? 使用 ROT13 对整个区域进行编码。 注意它可以被映射到一个最常使用的键。它对字母符号也可以很好地工作。要对它进行撤销，最好的方法就是使用撤销命令：u。 7 自动补全 这是另外一个令我感到惭愧的功能，但我发现周围很多人并不知道。Vim 默认有自动补全的功能。的确这个功能是很基本的，并且可以通过插件来增强，但它也很有帮助。方法很简单。Vim 尝试通过已经输入的单词来预测单词的结尾。比如当你在同一个文件中第二次输入 “compiler” 时，仅仅输入 “com” 然后保持在插入模式，按 Ctrl+n 键就可以看到 Vim 为你补全了单词。很简单，但也很有用。 8 比较两个文件的不同 你们中的大多数很可能都知道 vimdiff 命令，它可以使用分离模式打开 Vim 并比较两个文件的不同。语法如下： $ vimdiff [文件1] [文件2] 但同样的结果也可以通过下面的 Vim 命令来获得： :diffthis 首先在 Vim 中打开原始文件。然后使用分离模式带来第二个文件： :vsp [文件2] 最后在第一个缓冲区里输入： :diffthis 通过 Ctrl+w 来切换缓冲区并再次输入： :diffthis 这样两个文件中不同的部分就会被高亮。 （译者注：可以直接在一个缓冲区里使用命令 :windo diffthis，而不用输入 :diffthis 两次） 要停止比较，使用： :diffoff 9 按时间回退文件 Vim 会记录文件的更改，你很容易可以回退到之前某个时间。该命令是相当直观的。比如： :earlier 1m 会把文件回退到 1 分钟以前的状态。 注意，你可以使用下面的命令进行相反的转换： :later 10 删除标记内部的文字 当我开始使用 Vim 时，一件我总是想很方便做的事情是如何轻松的删除方括号或圆括号里的内容。转到开始的标记，然后使用下面的语法： di[标记] 比如，把光标放在开始的圆括号上，使用下面的命令来删除圆括号内的文字： di( 如果是方括号或者是引号，则使用： di{ 和： di&quot; 11 删除指定标记前的内容 和删除标记内部有些相似，但目的不同。命令如下： dt[标记] 会删除所有光标和标记之间的内容（保持标记不动），如果在同一行有这个标记的话。例如 dt. 会删除至句子的末尾，但保持 . 不动。 12 把 Vim 变为十六进制编辑器 这不是我最喜欢的窍门，但有时会很有趣。你可以把 Vim 和 xxd 功能连起来来把文件转换为十六进制模式。命令如下：:%!xxd 类似的，你可以通过下面的命令恢复原来的状态： :%!xxd -r 13 把光标下的文字置于屏幕中央 我们所要做的事情如标题所示。如果你想强制滚动屏幕来把光标下的文字置于屏幕的中央，在可视模式中使用命令（译者注：在普通模式中也可以）： zz 14 跳到上一个／下一个位置 当你编辑一个很大的文件时，经常要做的事是在某处进行修改，然后跳到另外一处。如果你想跳回之前修改的地方，使用命令： Ctrl+o 来回到之前修改的地方；类似的： Ctrl+i 会回退上面的跳动。 15 把当前文件转化为网页 这会生成一个 HTML 文件来显示文本，并在分开的窗口显示源代码： :%TOhtml ","link":"https://faded.auspicious.space/post/vim-key-instruct/"},{"title":"Vim——光标移动篇","content":" Vim常用文档动作命令总结 1 基本方向移动 h ： 向左移动一列 l ： 向右移动一列 j ： 向下移动一个实际行 k ： 向上移动一个实际行 所谓列可能指一个字节，也可能是一个字符，根据文件内容决定。 实际行指的是文本截止到一个换行符为止称为一个实际行。有时因为文本太长，一个实际行在窗口中会显示成好几行。可以通过 :set number 命令查看实际的行数。 2 基于单词的移动 Vim有一组基于单词的正向和反向移动的命令。 w ： 正向移动到下一单词的开头 e ： 正向移动到当前/下一单词的结尾 b ： 反向移动到当前/上一单词的开头 ge ： 反向移动到上一单词的结尾 基于单词的移动命令可以和其他命令结合使用。例如 :ea 可以跳转到单词的结尾并进入插入模式。 3 基于查找的移动 f 命令是最常用的查找命令，用于当前行进行指定字符的查找。如果找到则光标移动到目标字符，否则不移动。 Vim 会记录上一次执行的查找命令，再次查找时可以使用 ; 命令来完成相同查找。如果查询跳过头了，可以使用 , 命令返回光标之前的位置。 查询不止 f 命令，其他命令总结如下 f{char} : 正向移动到下一个{char}所在位置 F{char} : 反向移动到上一个{char}所在位置 t{char} : 正向移动到下一个{char}的前一个字符上 T{char} : 反向移动到上一个{char}的后一个字符上 除了上述查询方式， / 也是一种常用的查询方式，基于字符串的查询，/{str} 可以高亮目标字符串。可以通过 n 命令跳到下一个匹配处， N 返回前一匹配处。 同样的， / 也可以和其他命令结合使用，例如选择文本。点击 v 进入可视模式，然后输入 /{str} 也有例如 d/{str} 删除光标到目标字符串之间的所有内容的操作方式。 4 精确的文本对象选择 这个是一个很NB的功能，完全颠覆了对文本编辑器的认知。 现在有一个 JS 文件，内容如图： 这里认识 a 和 i 两个命令，不是普通的插入命令，需要和 v 命令配合使用，选中匹配的文本对象。例如在当前光标所在处输入 vi} 会达到以下效果。 如果光标的位置在 href 上呢？相同命令下： 如果换做是 a 命令呢？ i 命令可以理解为 inside，即选中匹配符号之间不包含匹配符号的内容。而 a 则选中包含匹配项的内容。 常见分隔符总结： 'a)' 或 'ab' : 一对() 'a}' 或 'aB' : 一对{} a] : 一对[] a&gt; : 一对&lt;&gt; a' : 一对'' a&quot; : 一对&quot;&quot; a` : 一对`` at : 一对xml标签 i 与 a 对应，只不过是针对分隔符内部的内容而已。 5 删除周边、修改内部 Vim 除了可以根据分隔符操作，也可以操作文本块，如单词，句子，段落等。 常见文本范围： iw : 当前单词 aw : 当前单词及一个空格 iW : 当前字符串 aW : 当前字符串及一个空格 is : 当前句子 as : 当前句子及一个空格 ip : 当前段落 ap : 当前段落及一个空行 上面的范围命令可以和 v 、 c 等操作一起使用。 6 快速回跳 这些命令用的相对少一些，常用一些的有 `` : 当前文件上次跳转操作的位置 `. : 上次修改操作的地方 `^ : 上次插入的地方 `[ : 上次修改或复制的起始位置 `] : 上次修改或复制的结束位置 `&lt; : 上次高亮选区的起始位置 `&gt; : 上次高亮选区的结束位置 7 匹配括号间跳转 Vim的 % 命令允许光标在一对闭括号间跳转。例如当前光标在 [ 上， % 命令可以跳转到对应的 ] 上，反过来也一样ok。例如将一对 {} 修改为一对 []。 当前光标在 { 上，输入 % 命令 替换当前光标下的字符，通过 r] 将 } 替换为 ]。 输入 `` 命令，跳转回上次跳转的位置。 之后再通过 'r[' 将 '{' 转为 '['。 ","link":"https://faded.auspicious.space/post/vim-cursor-movement/"},{"title":"Bash 移动光标快捷键","content":" 快捷键 行为 ctrl+a 移动到行首 ctrl+e 移动到行尾 ctrl+f 向右移动一个字符 ctrl+b 向左移动一个字符 alt+f 向右移动一个单词 alt+b 向左移动一个单词 ","link":"https://faded.auspicious.space/post/bash-key-for-cursor-movement/"},{"title":"Vim——CheatSheet","content":" Vim速查表-帮你提高N倍效率 进入 vim 命令 描述 vim filename 打开或新建文件,并将光标置于第一行首 vim +n filename 打开文件，并将光标置于第n行首 vim + filename 打开文件，并将光标置于最后一行首 vim +/pattern filename 打开文件，并将光标置于第一个与pattern匹配的串处 vim -r filename 在上次正用vim编辑时发生系统崩溃，恢复filename vim filename….filename 打开多个文件，依次编辑 vim 配置 命令 描述 all 列出所有选项设置情况 term 设置终端类型 ignorance 在搜索中忽略大小写 list 显示制表位(Ctrl+I)和行尾标志（$) number 显示行号 report 显示由面向行的命令修改过的数目 terse 显示简短的警告信息 warn 在转到别的文件时若没保存当前文件则显示NO write信息 nomagic 允许在搜索模式中，使用前面不带“\\”的特殊字符 nowrapscan 禁止vi在搜索到达文件两端时，又从另一端开始 mesg 允许vi显示其他用户用write写到自己终端上的信息 :set number / set nonumber 显示/不显示行号 :set ruler /set noruler 显示/不显示标尺 :set hlsearch 高亮显示查找到的单词 :set nohlsearch 关闭高亮显示 :syntax on 语法高亮 :set nu 显示行号 :set tabstop=8 设置tab大小,8为最常用最普遍的设置 :set softtabstop=8 4:4个空格,8:正常的制表符,12:一个制表符4个空格,16:两个制表符 :set autoindent 自动缩进 :set cindent C语言格式里面的自动缩进 移动光标 命令 描述 k nk 上 向上移动n行 j nj 下 向下移动n行 h nh 左 向左移动n行 l nl 右 向右移动n行 Space 光标右移一个字符 Backspace 光标左移一个字符 Enter 光标下移一行 w/W 光标右移一个字至字首 b/B 光标左移一个字至字首 e或E 光标右移一个字至字尾 ) 光标移至句尾 ( 光标移至句首 } 光标移至段落开头 { 光标移至段落结尾 n$ 光标移至第n行尾 H 光标移至屏幕顶行 M 光标移至屏幕中间行 L 光标移至屏幕最后行 0 （注意是数字零）光标移至当前行首 ^ 移动光标到行首第一个非空字符上去 $ 光标移至当前行尾 gg 移到第一行 G 移到最后一行 f 移动光标到当前行的字符a上 F 相反 % 移动到与制匹配的括号上去（），{}，[]，&lt;&gt;等 nG 移动到第n行上 G 到最后一行 屏幕滚动 命令 描述 Ctrl+u 向文件首翻半屏 Ctrl+d 向文件尾翻半屏 Ctrl+f 向文件尾翻一屏 Ctrl＋b 向文件首翻一屏 nz 将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部 插入文本类 命令 描述 i 在光标前 I 在当前行首 a 光标后 A 在当前行尾 o 在当前行之下新开一行 O 在当前行之上新开一行 r 替换当前字符 R 替换当前字符及其后的字符，直至按ESC键 s 从当前光标位置处开始，以输入的文本替代指定数目的字符 S 删除指定数目的行，并以所输入文本代替之 ncw/nCW 修改指定数目的字 nCC 修改指定数目的行 删除命令 命令 描述 x/X 删除一个字符，x删除光标后的，而X删除光标前的 dw 删除一个单词(删除光标位置到下一个单词开始的位置) dnw 删除n个单词 dne 也可，只是删除到单词尾 do 删至行首 d$ 删至行尾 dd 删除一行 ndd 删除当前行及其后n-1行 dnl 向右删除n个字母 dnh 向左删除n个字母 dnj 向下删除n行,当前行+其上n行 dnk 向上删除n行,当期行+其下n行 cnw[word] 将n个word改变为word C$ 改变到行尾 cc 改变整行 shift+j 删除行尾的换行符，下一行接上来了 复制粘贴 命令 描述 p 粘贴用x或d删除的文本 ynw 复制n个单词 yy 复制一行 ynl 复制n个字符 y$ 复制当前光标至行尾处 nyy 拷贝n行 撤销 命令 描述 u 撤销前一次的操作 shif+u(U) 撤销对该行的所有操作 搜索及替换 命令 描述 /pattern 从光标开始处向文件尾搜索pattern ?pattern 从光标开始处向文件首搜索pattern n 在同一方向重复上一次搜索命令 N 在反方向上重复上一次搜索命令 cw newword 替换为newword n 继续查找 . 执行替换 :s/p1/p2/g 将当前行中所有p1均用p2替代,g表示执行 用c表示需要确认 :n1,n2 s/p1/p2/g 将第n1至n2行中所有p1均用p2替代 :g/p1/s//p2/g 将文件中所有p1均用p2替换 :1,$ s/string1/string2/g 在全文中将string1替换为string2 书签 命令 描述 m[a-z] 在文中做标记，标记号可为a-z的26个字母 `a 移动到标记a处 visual 模式 命令 描述 v 进入visual 模式 V 进入行的visual 模式 ctrl+v 进如块操作模式用o和O改变选择的边的大小 在所有行插入相同的内容如include&lt; 将光标移到开始插入的位置，按CTRL+V进入VISUAL模式，选择好模块后按I（shift+i)，后插入要插入的文本，按[ESC]完成 行方式命令 命令 描述 :n1,n2 co n3 将n1行到n2行之间的内容拷贝到第n3行下 :n1,n2 m n3 将n1行到n2行之间的内容移至到第n3行下 :n1,n2 d 将n1行到n2行之间的内容删除 :n1,n2 w!command 将文件中n1行至n2行的内容作为command的输入并执行之 若不指定n1，n2，则表示将整个文件内容作为command的输入 宏 命令 描述 q[a-z] 开始记录但前开始的操作为宏，名称可为【a-z】，然后用q终止录制宏 reg 显示当前定义的所有的宏，用@[a-z]来在当前光标处执行宏[a-z] 窗口操作 命令 描述 :split 分割一个窗口 :split file.c 为另一个文件file.c分隔窗口 :nsplit file.c 为另一个文件file.c分隔窗口，并指定其行数 ctrl＋w 在窗口中切换 :close 关闭当前窗口 文件及其他 命令 描述 :q 退出vi :q! 不保存文件并退出vi :e filename 打开文件filename进行编辑 :e! 放弃修改文件内容，重新载入该文件编辑 :w 保存当前文件 :wq 存盘退出 :ZZ 保存当前文档并退出VIM :!command 执行shell命令command :r!command 将命令command的输出结果放到当前行 :n1,n2 write temp.c :read file.c 将文件file.c的内容插入到当前光标所在的下面 几张图 vim 工作模式 vim 快捷键盘图 vim 快捷键思维导图 vimium 快捷键盘图 ","link":"https://faded.auspicious.space/post/vim-cheatsheet/"},{"title":"区块链——商用调查","content":" 区块链商用调查 1 信息共享——信息对齐、提高效率 这应该是区块链最简单的应用场景，就是信息互通有无。 1.1 传统的信息共享的痛点 要么是统一由一个中心进行信息发布和分发，要么是彼此之间定时批量对账（典型的每天一次），对于有时效性要求的信息共享，难以达到实时共享。 信息共享的双方缺少一种相互信任的通信方式，难以确定收到的信息是否是对方发送的。 1.2 区块链 + 信息共享 首先，区块链本身就是需要保持各个节点的数据一致性的，可以说是自带信息共享功能；其次，实时的问题通过区块链的 P2P 技术可以实现；最后，利用区块链的不可篡改和共识机制，可构建其一条安全可靠的信息共享通道。 也行你会有这样的疑问：解决上面的问题，不用区块链技术，我自己建个加密通道也可以搞定啊！但我想说，既然区块链技术能够解决这些问题，并且增加节点非常方便，在你没有已经建好一套安全可靠的信息共享系统之前，为什么不用区块链技术呢？ 2 版权保护——不可篡改、永久保存 2.1 传统鉴证证明的痛点 流程复杂：以版权保护为例，现有鉴证证明方式，登记时间长，且费用高。 公信力不足：以法务存证为例，个人或中心化的机构存在篡改数据的可能，公信力难以得到保证。 2.2 区块链 + 鉴证证明 流程简化：区块链应用到鉴证证明后，无论是登记还是查询都非常方便，无需再奔走于各个部门之间， 安全可靠：区块链的去中心化存储，保证没有一家机构可以任意篡改数据， 2.3 应用案例 区块链在鉴权证明领域的应用有版权保护、法务存证等，下面以版权保护为例，简单说下如何区块链如何实现版权登记和查询。 电子身份证：将“申请人+发布时间+发布内容”等版权信息加密后上传，版权信息用于唯一区块链 ID，相当拥有了一张电子身份证。 时间戳保护：版权信息存储时，是加上时间戳信息的，如右雷同，可用于证明先后。 可靠性保证：区块链的去中心化存储、私钥签名、不可篡改的特性提升了鉴权信息的可靠性。 2016 年 8 月，由 Onchain、微软（中国）、法大大等多个机构在北京成立了电子存证区块链联盟“法链”。 2017 年 12 月，微众银行、仲裁委（广州仲裁委）、杭州亦笔科技有限公司共同推出的仲裁联盟链，用于司法场景下的存证；2018 年 3 月，广州首个“仲裁链”判决书出炉。 3 物流链——溯源防伪 商品从生产商到消费者手中，需要经历多个环节（流程可能如上图所示），跨境购物则更加复杂；中间环节经常出问题，消费者很容易购买的假货。而假货问题正是困扰着各大商家和平台，至今无解。 3.1 传统是防伪溯源手段 以一直受假冒伪劣产品困扰的茅台酒的防伪技术为例，2000 年起，其酒盖里有一个唯一的 RFID 标签，可通过手机等设备以 NFC 方式读出，然后通过茅台的 APP 进行校验，以此防止伪造产品。 咋一看，这种防伪效果非常可靠。但 2016 年还是引爆了茅台酒防伪造假，虽然通过 NFC 方式验证 OK，但经茅台专业人士鉴定为假酒。后来，在“国酒茅台防伪溯源系统”数据库审计中发现 80 万条假的防伪标签记录，系防伪技术公司人员参与伪造；随后，茅台改用安全芯片防伪标签。 但这里暴露出来的痛点并没有解决，即防伪信息掌握在某个中心机构中，有权限的人可以任意修改。(备注：茅台的这种防伪方式，也衍生了旧瓶回收，旧瓶装假酒的产业，防伪道路任重而道远)。 2017 年 05 月贵阳数博会上，小马哥就建议茅台防伪使用区块链；那么区块链和物流链的结合有什么优势呢？ 3.2 区块链+物流链 区块链没有中心化节点，各节点是平等的，掌握单个节点无法实现修改数据；需要掌控足够多的节点，才可能伪造数据，大大提高伪造数据的成本。 区块链天生的开放、透明，使得任何人都可以公开查询，伪造数据被发现的概率大增。 区块链的数据不可篡改性，也保证了已销售出去的产品信息已永久记录，无法通过简单复制防伪信息蒙混过关，实现二次销售。 物流链的所有节点上区块链后，商品从生产商到消费者手里都有迹可循，形成完整链条；商品缺失的环节越多，将暴露出其是伪劣产品概率更大。 ##3.3 应用案例 目前，入局物流链的玩家较多，包括腾讯、阿里、京东、沃尔玛等。 据说，阿里的菜鸟在海淘进口应用区块链上，走在了前面，已经初步实现海外商品溯源，国际物流及进口申报溯源、境内物流溯源；下一步就是生产企业溯源了。下图是网上流传的关于阿里的菜鸟在海淘场景运用区块链的示意图。 4 供应链金融——解决中小微企业融资难 4.1 传统的供应链单点融资 在一般供应链贸易中，从原材料的采购、加工、组装到销售的各企业间都涉及到资金的支出和收入，而企业的资金支出和收入是有时间差的，这就形成了资金缺口，多数需要进行融资生产。我们先来看个简单的供应链，如下图： 我们再来看看图中各个角色的融资情况： 核心企业或大企业：规模大、信用好，议价能力强，通过先拿货后付款，延长账期将资金压力传导给后续供应商；此外，其融资能力也是最强的。 一级供应商：通过核心企业的债权转让，可以获得银行的融资。 其他供应商（多数是中小微企业）：规模小、发展不稳定、信用低，风险高，难以获得银行的贷款；也无法想核心企业一样有很长的账期；一般越小的企业其账期越短，微小企业还需要现金拿货。这样一出一入对比就像是：中小微企业无息借钱给大企业做生意。 4.2 区块链 + 供应链金融 面对，上述供应链里的中小微企业融资难问题，主要原因是银行和中小企业之间缺乏一个有效的信任机制。 假如供应链所有节点上链后，通过区块链的私钥签名技术，保证了核心企业等的数据可靠性；而合同、票据等上链，是对资产的数字化，便于流通，实现了价值传递。 如上图所示，在区块链解决了数据可靠性和价值流通后，银行等金融机构面对中小企业的融资，不再是对这个企业进行单独评估；而是站在整个供应链的顶端，通过信任核心企业的付款意愿，对链条上的票据、合同等交易信息进行全方位分析和评估。即借助核心企业的信用实力以及可靠的交易链条，为中小微企业融资背书，实现从单环节融资到全链条融资的跨越，从而缓解中小微企业融资难问题。 5 跨境支付——提高效率、降低费用 5.1 传统跨境支付 跨境支付涉及多种币种，存在汇率问题，传统跨境支付非常依赖于第三方机构，大致的简化模型如上图所示，存在着两个问题； 流程繁琐，结算周期长：传统跨境支付基本都是非实时的，银行日终进行交易的批量处理，通常一笔交易需要 24 小时以上才能完成；某些银行的跨境支付看起来是实时的，但实际上，是收款银行基于汇款银行的信用做了一定额度的垫付，在日终再进行资金清算和对账，业务处理速度慢。 手续费高：传统跨境支付模式存在大量人工对账操作，加之依赖第三方机构，导致手续费居高不下，麦肯锡《2016 全球支付》报告数据显示，通过代理行模式完成一笔跨境支付的平均成本在 25 美元到 35 美元之间。 5.2 区块链 + 跨境支付 这些问题的存在，很大原因还是信息不对称，没有建立有效的信任机制。 如上图所示，区块链的引入，解决了跨境支付信息不对称的问题，并建立起一定程度的信任机制；带来了两个好处。 效率提高，费用降低：接入区块链技术后，通过公私钥技术，保证数据的可靠性，再通过加密技术和去中心，达到数据不可篡改的目的，最后，通过 P2P 技术，实现点对点的结算；去除了传统中心转发，提高了效率，降低了成本(也展望了普及跨境小额支付的可能性)。 可追溯，符合监管需求：传统的点对点结算不能不规模应用，除了信任问题，还有就是存在监管漏洞（点对点私下交易，存在洗黑钱的风险），而区块链的交易透明，信息公开，交易记录永久保存实现了可追溯，符合监管的需求。 6 资产数字化——便于资产流通 6.1 实体资产存在的问题 实体资产往往难以分割，不便于流通 实体资产的流通难以监控，存在洗黑钱等风险 6.2 区块链实现资产数字化 资产数字化后，易于分割、流通方便，交易成本低 用区块链技术实现资产数字化后，所有资产交易记录公开、透明、永久存储、可追溯，完全符合监管需求 6.3 应用案例 还是以腾讯的微黄金应用为例，继续借用腾讯区块链官网（trustsql.qq.com）上的图片，可以看到，在资产数字化之后，流通更为方便了，不再依赖于发行机构；且购买 0.001g 黄金成为了可能，降低了参与门槛。 7 代币——去中介、去信任 本来不像把代币加进来的，但说到区块链，始终绕不开代币；因区块链脱胎于比特币，天生具有代币的属性，目前区块链最成功的应用也正是比特币。 7.1 传统货币存在的问题 传统的货币发行权掌握在国家手中，存在着货币滥发的风险 货币滥发案例 1：元朝自 1271 年建立后，依然四处征战，消耗大量的钱财和粮食，为了财政问题，长期滥发货币，造成严重通货膨胀，多数百姓生活在水生火热中，导致流民四起，国家大乱，1368 年，不可一世的元朝成了只有 97 年短命鬼，走向了灭亡。 货币滥发案例 2：1980 年津巴布韦独立，后因土改失败，经济崩溃，政府入不敷出，开始印钞；2001 年时 100 津巴布韦币可兑换约 1 美元；2009 年 1 月，津央行发行 100 万亿面值新津元（如下图）加速货币崩溃，最终津元被废弃，改用“美元化”货币政策。2017 年津巴布韦发生政变，总统穆加贝被赶下台。 传统的记账权掌握在一个中心化的中介机构手中，存在中介系统瘫痪、中介违约、中介欺瞒、甚至是中介耍赖等风险。 2013 年 3 月，塞浦路斯为获得救助，对银行储户进行一次性征税约 58 亿欧元, 向不低于 10 万欧元的存款一次性征税 9.9%，向低于 10 万欧元的一次性征税 6.75%。 2017 年 4 月，民生银行 30 亿假理财事件暴露，系一支行行长伪造保本保息理财产品所致，超过 150 名投资者被套。 7.2 区块链如何解决这些问题 比特币解决了货币在发行和记账环节的信任问题，我们来看下比特币是如何一一破解上面的两个问题。 7.2.1 滥发问题 比特币的获取只能通过挖矿获得，且比特币总量为 2100 万个，在发行环节解决了货币滥发的问题； 7.2.2 账本修改问题 比特币的交易记录通过链式存储和去中心化的全球节点构成网络来解决账本修改问题。 7.2.3 链式存储 可以简单理解为：存储记录的块是一块连着一块的，形成一个链条；除第一个块的所有区块都的记录包含了前一区块的校验信息，改变任一区块的信息，都将导致后续区块校验出错。因为这种关联性，中间也无法插入其他块，所以修改已有记录是困难的。 7.2.4 去中心化节点 可以简单理解为：全球的中心节点都是平等的，都拥有一模一样的账本，所以，任一节点出问题都不影响账本记录。而要修改账本，必须修改超过全球一半的节点才能完成；而这在目前看来几乎不可能。 既然账本无法修改，那要是记账的时候作弊呢？ 首先，比特币的每条交易记录是有私钥签名的，别人伪造不了这个记录。你能修改的仅仅自己发起的交易记录。 其次，是关于记账权问题：比特币的记账权，通过工作量证明获得，可以简单理解为：通过算法确定同一时刻，全球只有一个节点获得了记账权，基本规律是谁拥有的计算资源越多，谁获得记账权的概率越大，只有超过全网一半的算力，才可能实现双花。 7.2.5 备注 比特币的模式是不可复制的，比特币已经吸引了全球绝大多数的算力，从而降低 51% 攻击发生等问题；其他的复制品基本无法获得相应的算力保证。 目前，比特币还存在着 51% 和效率低等问题有待解决，另外，关于交易本身的信任问题是个社会问题，比特币是没有解决的，也解决不了的。 7.3 应用案例 最具代表性的当然是比特币，也不用多说了。 备注：代币这块真的不看好，比特币目前吸引了全球绝大部分的算力，有独一无二的算力资源作为支撑还稍好一点，其他的代币和传统的货币相比，其背后缺乏国家和武力为其做信用背书，且夺取了国家发币带来的各种好处（如宏观调控），仔细想想就知道有多不靠谱。 8 小结 区块链应用的场景肯定还有很多，但很多都还不大明朗，暂时就先梳理以上7种场景，顺便归纳一下。 ","link":"https://faded.auspicious.space/post/blockchain-commercial-survey/"},{"title":"区块链——行业名词","content":" 名称 中文 解释 2-Way Peg 双向锚定 一种跨链技术 ABI 智能合约的接口说明 Application Binary Interface，ABI 是以太坊的一种合约间调用的消息格式，类似于 WebService 的 SOAP 协议一样，也就是定义操作函数签名，参数编码，返回结果编码等的协议。 altcoin 山寨币 AML 反洗钱 Anti-Money Laundering ASIC 专用集成电路 Application Specific Integrated Circuit，通常，与 GPU 相比，ASIC 专门用于挖矿，可能会节省大量能源。 autonomous 自治 BAAS 区块链服务 Blockchain As A Service，区块链即服务。 BIP 比特币改进建议 Bitcoin Improvement Proposals Block 区块 用于记录区块链系统中数据的存储。 Block Explorer 区块资源管理器 区块资源管理器是一种用来来查看区块上的所有交易（过去和当前）在线工具。 它们提供有用的信息，如网络哈希率和交易增长率。 Block Height 区块高度 连接在区块链上的块数。 Block Reward 出块奖励 它是在采矿期间成功计算区块中的哈希的矿工的一种激励形式。 在区块链上的交易验证的过程中产生新的币，并且矿工被奖励其中的一部分。 Blockchain 区块链 分布式存储、加密算法、共识机制、P2P传输等计算机技术结合的新型应用模式。 Blockchain Wallet 区块链钱包 一个包含私钥的文件。 它通常包含一个软件客户端，允许访问查看和创建钱包所设计的特定块链的交易。 Bulletproofs Bulletproofs 由斯坦福大学提出的，把膨胀系数减少到普通交易的三倍（原来是 60 倍），可以大幅降低隐私交易的数据量大小的算法 CAP CAP 分布式异步网络模型中，不能同时保证**一致性**，**可用性**和**分区容错性**，只能三选二 Central Ledger 中央帐簿 由中央机构维持的分类帐。 Chain 链 区块头中通过引用哈希值链接。 Confirmation 确认 去中心化的一次交易，将其添加到 blockchain 的成功确认。 Consensus 共识机制 区块链中事务达成的分布式共识算法。 Consensus 共识 当所有网络参与者同意交易的有效性时，达成共识，确保分布式账本是彼此的精确副本。 Consortium Block Chains 联盟链 共识过程由预选节点控制，一般为各企业机构互联形成。 Corda Corda R3联盟推出的金融联盟“类区块链”技术架构，Corda 中同样是用交易组成账本，但并没有区块，交易仅在参与方和公证人间传播 Cryptocurrency 加密货币 也称为令牌，加密货币是数字资产的呈现方式。 Cryptographic Hash Function 加密哈希函数 密码哈希产生从可变大小交易输入固定大小和唯一哈希值。 SHA-256计算算法是加密散列的一个例子。 DAO 去中心化自治组织 Decentralized Autonomous Organizations，去中心化自治组织可以被认为是在没有任何人为干预的情况下运行的公司，并将一切形式的控制交给一套不可破坏的业务规则。 Dapp 去中心化应用 是一种开源的应用程序，自动运行，将其数据存储在区块链上，以密码令牌的形式激励，并以显示有价值证明的协议进行操作。 DD 尽职调查 Due Diligence Decentralized 分布式 不依赖中心服务器，分布的计算机资源进行计算处理的模式。 Difficulty 挖矿难度 这是指成功挖掘交易信息的数据块的容易程度。 Distributed Ledger 分布式账本 分布式账本，数据通过分布式节点网络进行存储。 分布式账本不是必须具有自己的货币，它可能会被许可和私有。 Distributed Network 分布式网络 处理能力和数据分布在节点上而不是拥有集中式数据中心的一种网络。 Double Spending 双重支付 当花费一笔钱多于一次支付限额时，就会发生双重支付。 DPoS 委托权益证明 Delegated Proof Of Stake，一种共识算法 EIP 以太坊改进建议 Ethereum Improvement Proposals EOA 外部账户 Externally Owned Accounts ERC 以太坊意见征求 Ethereum Requests for Comment，讨论项目时，一开始会用EIP提出建议，在讨论过程中有一些要征求更多人意见时，就会把细节放在ERC中，而且他们会用同一个号码，比如ERC-20 对应 EIP-20 Ethash Ethash 以前这个算法称为 Dagger Hashimoto，Ethash是最新版本的 Dagger-Hashimoto 改良算法，是 Hashimoto 算法结合 Dagger 算法产成的一个新变种。实现两个主要目的：抵抗 ASIC 矿机和轻客户端易验证 Ethereum 以太坊 Ethereum是一个基于blockchain的去中心化运行智能合约的平台，旨在解决与审查，欺诈和第三方干扰相关的问题。 EVM 以太坊虚拟机 Ethereum Virtual Machine，借助以太坊虚拟机将 Solidity 代码变成可以在区块链上执行的加密代码。以太坊虚拟机是设计运行在点对点网络中所有参与节点上的一个虚拟机，它可以读写一个区块链中可执行的代码和数据，校验数据签名，并以半图灵完备的方式来运行代码。每个Ethereum节点都运行在 EVM 上，以保持整个块链的一致性。 FLP FLP 在网络可靠并且存在节点失效的异步模型中，不存在一个可以解决一致性问题的确定性算法 Fork 分叉 分叉可以创建区块链的交叉版本，在网络不同的地方兼容的运行两个区块链。 Frontier 前沿 以太坊开发第一阶段 gas gas gas是在以太坊网络中用于衡量执行交易或智能合约工作量的计算单位 gas limit gas limit 某笔具体的交易能够消耗的 gas 最大值，一笔标准的以太坊交易需要 21,000 gas。当交易的 gas limit 不足时，会出现 out of gas 错误 gas price gas price 以另一种货币或 token（例如 Ether）计量交易花费的价格。为了稳定消耗 gas 的价值，gas price 是浮动的，根据货币或 token 价格浮动而相应变动以保持总价格稳定。gas price 由市场供需决定（用户愿意支出的价格和矿工节点愿意接受的价格的博弈） gas used gas used 有效支付用于计算或智能合约运行的 gas 数量（在成功的交易中 gas fee 小于 gas limit)，一笔以太坊交易的实际矿工费(Tx Fees) = gas used * gas price Genesis Block 创世区块 区块链的第一个区块。 Go Ethereum geth 实现了以太坊协议的 JavaScript运行时环境，可以以交互式或非交互式模式运行 Hard Fork 硬分叉 区块链发生永久性分歧，在新共识规则发布后，部分没有升级的节点无法验证已经升级的节点生产的区块，产生硬分叉。 Hash 哈希 对输出数据执行散列函数的行为。 这是用于确认货币交易。 Hash Rate 哈希率 采矿钻机的性能测量值以秒为单位表示。 Homestead 家园 以太坊开发第二阶段 Hybrid PoS/PoW 混合PoS / PoW 混合 PoS / PoW 可以将网络上的共享分发算法作为共享证明和工作证明。 在这种方法中，可以实现矿工和选民（持有者）之间的平衡，由内部人（持有人）和外部人（矿工）创建一个基于社区的治理体系。 I2P I2P Invisible Internet Project，建立在互联网上的隐匿网络层，用于为网络通讯提供隐私保护 Infura Infura 提供全球范围区块链集群和 API 端点等基础架构服务；可用于以太坊，IPFS 等其他新兴的分布式平台。致力于提供安全，稳定，高容错性金额可扩展的区块链访问接口 keccak keccak 一种SHA-3加密算法 Kovri Kovri I2P 网络的 C++ 实现版本，目前还在开发中尚未集成到门罗币中，可以提高交易的安全等级（可以隐藏 IP 地址） KYC 了解你的客户 Know Your Customer Metropolis 大都会 以太坊开发第三阶段 Mining 挖矿 挖矿是验证区块链交易的行为。 验证的必要性通常以货币的形式奖励给矿工。 在这个密码安全的繁荣期间，当正确完成计算，采矿可以是一个有利可图的业务。 通过选择最有效和最适合的硬件和采矿目标，采矿可以产生稳定的被动收入形式。 Multi-Signature 多重签名 多重签名地址需要一个以上的密钥来授权交易，从而增加了一层安全性。 Node 节点 由区块链网络的参与者操作的分类帐的副本。 Oracles 预言机 Oracle 通过向智能合约提供数据，它现实世界和区块链之间的桥梁。注意此 Oracle不是指数据库。预言机连接虚拟与现实，核心功能是提供数据上链服务，是实现智能合约的必要条件。智能合约是在区块链提供的沙盒环境中运行，沙盒是个封闭环境，使合约代码不能读取链外数据，但很多时候智能合约又必须依赖外部数据，Oracle 在这里就承担了提供外部数据的功能。 P2P Peer-to-Peer 对等互联网网络技术。 Paxos Paxos 一种用于传统分布式系统的共识协议 Payment Codes 可重用支付码 BIP47，支付码是一种用于创建永久性比特币地址的技术，这些地址可以重复使用，与现实生活中的身份公开相关，同时无损于财务隐私。它们类似于隐形地址。即使他人知道你的支付码也无法追踪你的交易历史，可以用于想要私密的接收BTC的场景 PBFT 实用拜占庭容错 Practical Byzantine Fault Tolerance pegged zone 锚定分区 一种锚定分区的桥接机制，出现于Cosmos项目 POA 权威证明 Proof Of Authority，一种共识算法 portfolio 投资组合 POS 权益证明 Proof of Stake，根据你持有货币的量和时间进行利息分配的制度，在 POS 模式下，你的“挖矿”收益正比于你的币龄，而与电脑的计算性能无关。 POW 工作量证明 Proof of Work，是指获得多少货币，取决于你挖矿贡献的工作量，电脑性能越好，分给你的矿就会越多。 Private Block Chains 私有链 私有区块链，数据记录在单一组织机构中，分权限对外开放，一般是单一企业机构构建。 Private Key 私钥 私钥是一串数据，它是允许您访问特定钱包中的令牌。 它们作为密码，除了地址的所有者之外，都被隐藏。 Public Address 公用地址 公共地址是公钥的密码哈希值。 它们作为可以在任何地方发布的电子邮件地址，与私钥不同。 Public Block Chains 公有链 公共网络中任何个人团体接入，任何节点均可参与共识过程。 Raft Raft Paxos协议的一种简单实现 Ring Signatures 环签名 用于隐匿发送发信息的技术，门罗币采用 RingCT 环加密交易 Ring Confidential Transactions，隐藏交易信息（包括交易双方信息和交易金额）的加密技术，门罗币采用 RLP RLP 编码 Recursive Length Prefix（递归长度前缀）是一种适用于任意二进制数据数组的编码。是以太坊中对象进行序列化/反序列化的主要编码方式。区块，交易等数据结构在持久化时会先经过RLP编码后再存储到持久层中。 RPCA 瑞波共识算法 Ripple Protocol Consensus Algorithm，类似PBFT的共识机制 Scrypt Scrypt 是一种由 Litecoin 使用加密算法。 与 SHA256 相比，它的速度更快，因为它不会占用很多处理时间。 Serenity 宁静 以太坊开发第四阶段（也是最后一个阶段） SHA-256 SHA-256 是比特币一些列数字货币使用的加密算法。 然而，它使用了大量的计算能力和处理时间，迫使矿工组建采矿池以获取收益。 Smart Contracts 智能合约 智能合约将可编程语言的业务规则编码到区块上，并由网络的参与者实施。部署在区块链系统中，一段合约代码，或一套以数字形式定义的承诺，包括合约参与方可以在其上执行承诺的协议。 Soft Fork 软分叉 软分叉与硬分叉不同之处在于，只有先前有效的交易才能使其无效。 由于旧节点将新的块识别为有效，所以软分叉基本上是向后兼容的。 这种分叉需要大多数矿工升级才能执行，而硬分叉需要所有节点就新版本达成一致。 Solidity Solidity 是 Ethereum 用于开发智能合约的编程语言。 SPV 简单支付验证 Simplified Payment Verification Stealth Address 隐匿地址 能够隐藏接收方信息 Swarm Swarm 去中心化的数据存储访问协议，以 ETH 作为激励。类似使用了 Filecoin 的 IPFS Sybil Attack 女巫攻击 P2P网络中的一种攻击形式：攻击者利用单个节点来伪造多个身份存在于 P2P 网络中，从而达到削弱网络的冗余性，降低网络健壮性，监视或干扰网络正常活动等目的 Testnet Testnet 开发商使用的测试区块链，它主要是用来防止改变在主链上的资产。 testrpc testrpc 以太坊节点客户端 Transaction Block 交易区块 聚集到一个块中的交易的集合，然后可以将其散列并添加到区块链中。 Transaction Fee 交易费 所有的加密货币交易都会涉及到一笔很小的手续费。这些手续费用加起来给矿工在成功处理区块时收到的区块奖励。 Truffle Truffle 一个基于以太坊技术的开发、测试和部署框架，旨在帮助以太坊开发者更容易开发去中心化应用（DApp） Turing Complete 图灵完备 图灵完备是指计算机中一切计算的问题都可以计算，这样的虚拟机或者编程语言称为图灵完备。一个例子是 Ethereum 虚拟机（EVM）。 Unlinkability 无关联性 whisper whisper 去中心化的通信协议 YC YC Y Combinator，成立于 2005 年是美国著名创业孵化器，扶持初创企业并为其提供创业指南（Airbnb，Dropbox，Stripe，Reddit, Docker, Coinbase 等），投资孵化过多个区块链项目 ZKRP 零知识范围证明 Zero Knownledge Range Proof，证明一个具体声明的真实性而不会泄露它试图证明的额外信息 ZK-SNARKs 零知识证明 ZK-Succint Non-interactive Arguments of Knownledge ","link":"https://faded.auspicious.space/post/blockchain-industry-terms/"},{"title":"区块链——行业名词","content":" 名称 中文 解释 2-Way Peg 双向锚定 一种跨链技术 ABI 智能合约的接口说明 Application Binary Interface，ABI 是以太坊的一种合约间调用的消息格式，类似于 WebService 的 SOAP 协议一样，也就是定义操作函数签名，参数编码，返回结果编码等的协议。 altcoin 山寨币 AML 反洗钱 Anti-Money Laundering ASIC 专用集成电路 Application Specific Integrated Circuit，通常，与 GPU 相比，ASIC 专门用于挖矿，可能会节省大量能源。 autonomous 自治 BAAS 区块链服务 Blockchain As A Service，区块链即服务。 BIP 比特币改进建议 Bitcoin Improvement Proposals Block 区块 用于记录区块链系统中数据的存储。 Block Explorer 区块资源管理器 区块资源管理器是一种用来来查看区块上的所有交易（过去和当前）在线工具。 它们提供有用的信息，如网络哈希率和交易增长率。 Block Height 区块高度 连接在区块链上的块数。 Block Reward 出块奖励 它是在采矿期间成功计算区块中的哈希的矿工的一种激励形式。 在区块链上的交易验证的过程中产生新的币，并且矿工被奖励其中的一部分。 Blockchain 区块链 分布式存储、加密算法、共识机制、P2P传输等计算机技术结合的新型应用模式。 Blockchain Wallet 区块链钱包 一个包含私钥的文件。 它通常包含一个软件客户端，允许访问查看和创建钱包所设计的特定块链的交易。 Bulletproofs Bulletproofs 由斯坦福大学提出的，把膨胀系数减少到普通交易的三倍（原来是 60 倍），可以大幅降低隐私交易的数据量大小的算法 CAP CAP 分布式异步网络模型中，不能同时保证**一致性**，**可用性**和**分区容错性**，只能三选二 Central Ledger 中央帐簿 由中央机构维持的分类帐。 Chain 链 区块头中通过引用哈希值链接。 Confirmation 确认 去中心化的一次交易，将其添加到 blockchain 的成功确认。 Consensus 共识机制 区块链中事务达成的分布式共识算法。 Consensus 共识 当所有网络参与者同意交易的有效性时，达成共识，确保分布式账本是彼此的精确副本。 Consortium Block Chains 联盟链 共识过程由预选节点控制，一般为各企业机构互联形成。 Corda Corda R3联盟推出的金融联盟“类区块链”技术架构，Corda 中同样是用交易组成账本，但并没有区块，交易仅在参与方和公证人间传播 Cryptocurrency 加密货币 也称为令牌，加密货币是数字资产的呈现方式。 Cryptographic Hash Function 加密哈希函数 密码哈希产生从可变大小交易输入固定大小和唯一哈希值。 SHA-256计算算法是加密散列的一个例子。 DAO 去中心化自治组织 Decentralized Autonomous Organizations，去中心化自治组织可以被认为是在没有任何人为干预的情况下运行的公司，并将一切形式的控制交给一套不可破坏的业务规则。 Dapp 去中心化应用 是一种开源的应用程序，自动运行，将其数据存储在区块链上，以密码令牌的形式激励，并以显示有价值证明的协议进行操作。 DD 尽职调查 Due Diligence Decentralized 分布式 不依赖中心服务器，分布的计算机资源进行计算处理的模式。 Difficulty 挖矿难度 这是指成功挖掘交易信息的数据块的容易程度。 Distributed Ledger 分布式账本 分布式账本，数据通过分布式节点网络进行存储。 分布式账本不是必须具有自己的货币，它可能会被许可和私有。 Distributed Network 分布式网络 处理能力和数据分布在节点上而不是拥有集中式数据中心的一种网络。 Double Spending 双重支付 当花费一笔钱多于一次支付限额时，就会发生双重支付。 DPoS 委托权益证明 Delegated Proof Of Stake，一种共识算法 EIP 以太坊改进建议 Ethereum Improvement Proposals EOA 外部账户 Externally Owned Accounts ERC 以太坊意见征求 Ethereum Requests for Comment，讨论项目时，一开始会用EIP提出建议，在讨论过程中有一些要征求更多人意见时，就会把细节放在ERC中，而且他们会用同一个号码，比如ERC-20 对应 EIP-20 Ethash Ethash 以前这个算法称为 Dagger Hashimoto，Ethash是最新版本的 Dagger-Hashimoto 改良算法，是 Hashimoto 算法结合 Dagger 算法产成的一个新变种。实现两个主要目的：抵抗 ASIC 矿机和轻客户端易验证 Ethereum 以太坊 Ethereum是一个基于blockchain的去中心化运行智能合约的平台，旨在解决与审查，欺诈和第三方干扰相关的问题。 EVM 以太坊虚拟机 Ethereum Virtual Machine，借助以太坊虚拟机将 Solidity 代码变成可以在区块链上执行的加密代码。以太坊虚拟机是设计运行在点对点网络中所有参与节点上的一个虚拟机，它可以读写一个区块链中可执行的代码和数据，校验数据签名，并以半图灵完备的方式来运行代码。每个Ethereum节点都运行在 EVM 上，以保持整个块链的一致性。 FLP FLP 在网络可靠并且存在节点失效的异步模型中，不存在一个可以解决一致性问题的确定性算法 Fork 分叉 分叉可以创建区块链的交叉版本，在网络不同的地方兼容的运行两个区块链。 Frontier 前沿 以太坊开发第一阶段 gas gas gas是在以太坊网络中用于衡量执行交易或智能合约工作量的计算单位 gas limit gas limit 某笔具体的交易能够消耗的 gas 最大值，一笔标准的以太坊交易需要 21,000 gas。当交易的 gas limit 不足时，会出现 out of gas 错误 gas price gas price 以另一种货币或 token（例如 Ether）计量交易花费的价格。为了稳定消耗 gas 的价值，gas price 是浮动的，根据货币或 token 价格浮动而相应变动以保持总价格稳定。gas price 由市场供需决定（用户愿意支出的价格和矿工节点愿意接受的价格的博弈） gas used gas used 有效支付用于计算或智能合约运行的 gas 数量（在成功的交易中 gas fee 小于 gas limit)，一笔以太坊交易的实际矿工费(Tx Fees) = gas used * gas price Genesis Block 创世区块 区块链的第一个区块。 Go Ethereum geth 实现了以太坊协议的 JavaScript运行时环境，可以以交互式或非交互式模式运行 Hard Fork 硬分叉 区块链发生永久性分歧，在新共识规则发布后，部分没有升级的节点无法验证已经升级的节点生产的区块，产生硬分叉。 Hash 哈希 对输出数据执行散列函数的行为。 这是用于确认货币交易。 Hash Rate 哈希率 采矿钻机的性能测量值以秒为单位表示。 Homestead 家园 以太坊开发第二阶段 Hybrid PoS/PoW 混合PoS / PoW 混合 PoS / PoW 可以将网络上的共享分发算法作为共享证明和工作证明。 在这种方法中，可以实现矿工和选民（持有者）之间的平衡，由内部人（持有人）和外部人（矿工）创建一个基于社区的治理体系。 I2P I2P Invisible Internet Project，建立在互联网上的隐匿网络层，用于为网络通讯提供隐私保护 Infura Infura 提供全球范围区块链集群和 API 端点等基础架构服务；可用于以太坊，IPFS 等其他新兴的分布式平台。致力于提供安全，稳定，高容错性金额可扩展的区块链访问接口 keccak keccak 一种SHA-3加密算法 Kovri Kovri I2P 网络的 C++ 实现版本，目前还在开发中尚未集成到门罗币中，可以提高交易的安全等级（可以隐藏 IP 地址） KYC 了解你的客户 Know Your Customer Metropolis 大都会 以太坊开发第三阶段 Mining 挖矿 挖矿是验证区块链交易的行为。 验证的必要性通常以货币的形式奖励给矿工。 在这个密码安全的繁荣期间，当正确完成计算，采矿可以是一个有利可图的业务。 通过选择最有效和最适合的硬件和采矿目标，采矿可以产生稳定的被动收入形式。 Multi-Signature 多重签名 多重签名地址需要一个以上的密钥来授权交易，从而增加了一层安全性。 Node 节点 由区块链网络的参与者操作的分类帐的副本。 Oracles 预言机 Oracle 通过向智能合约提供数据，它现实世界和区块链之间的桥梁。注意此 Oracle不是指数据库。预言机连接虚拟与现实，核心功能是提供数据上链服务，是实现智能合约的必要条件。智能合约是在区块链提供的沙盒环境中运行，沙盒是个封闭环境，使合约代码不能读取链外数据，但很多时候智能合约又必须依赖外部数据，Oracle 在这里就承担了提供外部数据的功能。 P2P Peer-to-Peer 对等互联网网络技术。 Paxos Paxos 一种用于传统分布式系统的共识协议 Payment Codes 可重用支付码 BIP47，支付码是一种用于创建永久性比特币地址的技术，这些地址可以重复使用，与现实生活中的身份公开相关，同时无损于财务隐私。它们类似于隐形地址。即使他人知道你的支付码也无法追踪你的交易历史，可以用于想要私密的接收BTC的场景 PBFT 实用拜占庭容错 Practical Byzantine Fault Tolerance pegged zone 锚定分区 一种锚定分区的桥接机制，出现于Cosmos项目 POA 权威证明 Proof Of Authority，一种共识算法 portfolio 投资组合 POS 权益证明 Proof of Stake，根据你持有货币的量和时间进行利息分配的制度，在 POS 模式下，你的“挖矿”收益正比于你的币龄，而与电脑的计算性能无关。 POW 工作量证明 Proof of Work，是指获得多少货币，取决于你挖矿贡献的工作量，电脑性能越好，分给你的矿就会越多。 Private Block Chains 私有链 私有区块链，数据记录在单一组织机构中，分权限对外开放，一般是单一企业机构构建。 Private Key 私钥 私钥是一串数据，它是允许您访问特定钱包中的令牌。 它们作为密码，除了地址的所有者之外，都被隐藏。 Public Address 公用地址 公共地址是公钥的密码哈希值。 它们作为可以在任何地方发布的电子邮件地址，与私钥不同。 Public Block Chains 公有链 公共网络中任何个人团体接入，任何节点均可参与共识过程。 Raft Raft Paxos协议的一种简单实现 Ring Signatures 环签名 用于隐匿发送发信息的技术，门罗币采用 RingCT 环加密交易 Ring Confidential Transactions，隐藏交易信息（包括交易双方信息和交易金额）的加密技术，门罗币采用 RLP RLP 编码 Recursive Length Prefix（递归长度前缀）是一种适用于任意二进制数据数组的编码。是以太坊中对象进行序列化/反序列化的主要编码方式。区块，交易等数据结构在持久化时会先经过RLP编码后再存储到持久层中。 RPCA 瑞波共识算法 Ripple Protocol Consensus Algorithm，类似PBFT的共识机制 Scrypt Scrypt 是一种由 Litecoin 使用加密算法。 与 SHA256 相比，它的速度更快，因为它不会占用很多处理时间。 Serenity 宁静 以太坊开发第四阶段（也是最后一个阶段） SHA-256 SHA-256 是比特币一些列数字货币使用的加密算法。 然而，它使用了大量的计算能力和处理时间，迫使矿工组建采矿池以获取收益。 Smart Contracts 智能合约 智能合约将可编程语言的业务规则编码到区块上，并由网络的参与者实施。部署在区块链系统中，一段合约代码，或一套以数字形式定义的承诺，包括合约参与方可以在其上执行承诺的协议。 Soft Fork 软分叉 软分叉与硬分叉不同之处在于，只有先前有效的交易才能使其无效。 由于旧节点将新的块识别为有效，所以软分叉基本上是向后兼容的。 这种分叉需要大多数矿工升级才能执行，而硬分叉需要所有节点就新版本达成一致。 Solidity Solidity 是 Ethereum 用于开发智能合约的编程语言。 SPV 简单支付验证 Simplified Payment Verification Stealth Address 隐匿地址 能够隐藏接收方信息 Swarm Swarm 去中心化的数据存储访问协议，以 ETH 作为激励。类似使用了 Filecoin 的 IPFS Sybil Attack 女巫攻击 P2P网络中的一种攻击形式：攻击者利用单个节点来伪造多个身份存在于 P2P 网络中，从而达到削弱网络的冗余性，降低网络健壮性，监视或干扰网络正常活动等目的 Testnet Testnet 开发商使用的测试区块链，它主要是用来防止改变在主链上的资产。 testrpc testrpc 以太坊节点客户端 Transaction Block 交易区块 聚集到一个块中的交易的集合，然后可以将其散列并添加到区块链中。 Transaction Fee 交易费 所有的加密货币交易都会涉及到一笔很小的手续费。这些手续费用加起来给矿工在成功处理区块时收到的区块奖励。 Truffle Truffle 一个基于以太坊技术的开发、测试和部署框架，旨在帮助以太坊开发者更容易开发去中心化应用（DApp） Turing Complete 图灵完备 图灵完备是指计算机中一切计算的问题都可以计算，这样的虚拟机或者编程语言称为图灵完备。一个例子是 Ethereum 虚拟机（EVM）。 Unlinkability 无关联性 whisper whisper 去中心化的通信协议 YC YC Y Combinator，成立于 2005 年是美国著名创业孵化器，扶持初创企业并为其提供创业指南（Airbnb，Dropbox，Stripe，Reddit, Docker, Coinbase 等），投资孵化过多个区块链项目 ZKRP 零知识范围证明 Zero Knownledge Range Proof，证明一个具体声明的真实性而不会泄露它试图证明的额外信息 ZK-SNARKs 零知识证明 ZK-Succint Non-interactive Arguments of Knownledge ","link":"https://faded.auspicious.space/post/blockchain-profession-words/"},{"title":"区块链——六大核心算法","content":" 区块链技术六大核心算法 拜占庭协定 拜占庭的故事大概是这么说的：拜占庭帝国拥有巨大的财富，周围 10 个邻邦垂诞已久，但拜占庭高墙耸立，固若金汤，没有一个单独的邻邦能够成功入侵。任何单个邻邦入侵的都会失败，同时也有可能自身被其他 9 个邻邦入侵。拜占庭帝国防御能力如此之强，至少要有十个邻邦中的一半以上同时进攻，才有可能攻破。然而，如果其中的一个或者几个邻邦本身答应好一起进攻，但实际过程出现背叛，那么入侵者可能都会被歼灭。于是每一方都小心行事，不敢轻易相信邻国。这就是拜占庭将军问题。 在这个分布式网络里：每个将军都有一份实时与其他将军同步的消息账本。账本里有每个将军的签名都是可以验证身份的。如果有哪些消息不一致，可以知道消息不一致的是哪些将军。尽管有消息不一致的，只要超过半数同意进攻，少数服从多数，共识达成。 由此，在一个分布式的系统中，尽管有坏人，坏人可以做任意事情（不受protocol限制），比如不响应、发送错误信息、对不同节点发送不同决定、不同错误节点联合起来干坏事等等。但是，只要大多数人是好人，就完全有可能去中心化地实现共识。 非对称加密技术 在上述拜占庭协定中，如果 10 个将军中的几个同时发起消息，势必会造成系统的混乱，造成各说各的攻击时间方案，行动难以一致。谁都可以发起进攻的信息，但由谁来发出呢？其实这只要加入一个成本就可以了，即：一段时间内只有一个节点可以传播信息。当某个节点发出统一进攻的消息后，各个节点收到发起者的消息必须签名盖章，确认各自的身份。 在如今看来，非对称加密技术完全可以解决这个签名问题。非对称加密算法的加密和解密使用不同的两个密钥.这两个密钥就是我们经常听到的“公钥”和“私钥”。公钥和私钥一般成对出现, 如果消息使用公钥加密,那么需要该公钥对应的私钥才能解密; 同样，如果消息使用私钥加密,那么需要该私钥对应的公钥才能解密。 容错问题 我们假设在此网络中，消息可能会丢失、损坏、延迟、重复发送，并且接受的顺序与发送的顺序不一致。此外，节点的行为可以是任意的：可以随时加入、退出网络，可以丢弃消息、伪造消息、停止工作等，还可能发生各种人为或非人为的故障。我们的算法对由共识节点组成的共识系统，提供的容错能力，这种容错能力同时包含安全性和可用性，并适用于任何网络环境。 Paxos 算法（一致性算法） Paxos算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。 节点通信存在两种模型：共享内存和消息传递。Paxos 算法就是一种基于消息传递模型的一致性算法。 共识机制 区块链共识算法主要是工作量证明和权益证明。拿比特币来说，其实从技术角度来看可以把 PoW 看做重复使用的 Hashcash，生成工作量证明在概率上来说是一个随机的过程。开采新的机密货币，生成区块时，必须得到所有参与者的同意，那矿工必须得到区块中所有数据的 PoW 工作证明。与此同时矿工还要时时观察调整这项工作的难度，因为对网络要求是平均每 10 分钟生成一个区块。 分布式存储 分布式存储是一种数据存储技术，通过网络使用每台机器上的磁盘空间，并将这些分散的存储资源构成一个虚拟的存储设备，数据分散的存储在网络中的各个角落。所以，分布式存储技术并不是每台电脑都存放完整的数据，而是把数据切割后存放在不同的电脑里。就像存放 100 个鸡蛋，不是放在同一个篮子里，而是分开放在不同的地方，加起来的总和是 100 个。 ","link":"https://faded.auspicious.space/post/blockchain-core-algorithms/"},{"title":"区块链——入门","content":"狭义来讲，区块链是一种按照时间顺序将数据区块以顺序相连的方式组合成的一种链式数据结构， 并以密码学方式保证的不可篡改和不可伪造的分布式账本。广义来讲，区块链技术是利用块链式数据结构来验证与存储数据、利用分布式节点共识算法来生成和更新数据、利用密码学的方式保证数据传输和访问的安全、利用由自动化脚本代码组成的智能合约来编程和操作数据的一种全新的分布式基础架构与计算范式。 1 涉及到的技术 密码学 分布式一致性协议 点对点网络通信技术 智能合约编程语言等。 2 区块链的分类 区块链严格定义上被划分为 3 种类型：公有链，私有链、和联盟链，但是在实际应用中单一的某种链常常无法满足用户需求，就出现了多种类型的结合，比如私有链 + 联盟链、联盟链 + 公有链等不同组合形式，最后产生了侧链和互联链。掌握了这 5 种区块链类型的各自特点，是理解和设计区块链网络系统架构的基础和核心，其重要性不言而喻。 2.1 公有链（Public blockchains） 公有链是对所有人公开，用户不需要注册和授权就能够匿名访问网络和区块，任何人都可以自由加入和退出网络，并参与记账和交易。 公有链是真正完全意义上的去中心化区块链，它通过密码学（非对称加密）算法保证了交易的安全性和不可篡改性，在陌生的网络（非安全）环境中，建立了互信和共识机制。在公有链中共识机制一般是工作量证明（POW）和权益证明（POS）。 公有链因为人人可参与，无需授权的特点又被称为非许可链，即不需要验证身份即可参与一切网络活动。目前比特币、以太坊、超级账本、大多数山寨币以及智能合约都是建立在公有链上，其中公有链的始祖是比特币区块链。 公有链适用于数字货币、电子商务、互联网金融、知识产权等应用场景。 2.2 联盟链（Consortium blockchains） 联盟链仅限于联盟成员，因其只针对成员开放全部或部分功能，所以联盟链上的读写权限、以及记账规则都按联盟规则来“私人定制”。联盟链上的共识过程由预先选好的节点控制，一般来说，他适用于机构间的交易、结算、或清算等 B2B 场景。比如人民银行开发一个基于联盟链的结算、清算系统，工建中农等银行作为联盟成员加入这个系统，获得相应的授权，就可以实时进行不同银行之间的实时结算、清算，与现有的中心化系统相比，这样不仅大大提升了结算、清算效率，几乎不需要人工参与，还能大大降低结算、清算成本。联盟链几乎不采用工作量证明共识机制而是采用权益证明或PBTF等共识算法。 联盟链由参与成员机构共同维护，并提供了对参与成员的管理、认证、授权、监控、审计等全套安全管理功能。2015 年成立的 R3 联盟，就是银行业的一个联盟链，目前已加入的成员多达 40 多个，包括世界著名的银行摩根大通、汇丰、高盛等。 联盟链适用于行业协会、高级别机构组织、大型连锁企业对下属单位和分管机构的交易和监管。 2.3 私有链（Private blockchain） 私有链对单独的个人或实体开放，仅在私有组织，比如公司内部使用，私有链上的读写权限，参与记账的权限都由私有组织来制定。比如企业内部的办公审批、财务审计；政府行业的预算和执行。私有链的主要价值在于提供安全、可塑源，不可篡改，自动执行，这是传统系统很难同时做到的。 因为私有链加入结点少，所以交易速度快。私有链的交易速度可以比任何其他的区块链都快，甚至接近了并不是一个区块链的常规数据库的速度。而且因为就算少量的节点，也都具有很高的信任度，所以并不需要每个节点来验证一个交易(无需挖矿)。 由于私有链和联盟链都需要授权加入和访问，私有链和联盟链也被称作许可链。 私有链适用于企业、组织内部。 2.4 侧链（Side Chains） 严格来说侧链不是区块链的一种类型，它只是在现实应用中，开发者对区块链的一种延伸（扩展），而特别取了个绰号。目前，市场上公开的虚拟货币系统，绝大多数都是基于比特币系统进行规则修改或扩展而来，因为比特币的设计规则已十分固定，难以做出较大修改和扩展，于是这些代币系统的开发者门干脆以比特币平台为基础，重构出一条区块链，然后使用新的规则，发布新的虚拟货币，这条重构出来的区块链就被称为侧链。普遍认为能和比特币区块链进行交互，并能与比特币挂钩的区块链就是侧链。 侧链目前主要适用于代币发行。 2.5 互联链（InteChains） 互联链就是各种不同的区块链之间的互联互通所形成的一个更大的生态区块链。比如电商平台公有链 + 物流公有链 + 物流联盟链 + 银行联盟链 +.....，它们之间的相互协作、通讯、共识、就是一个典型的互联链。 3 区块链的工作量证明机制 3.1 POW：proof of power, 工作量证明机制 PoW（工作量证明），也就是像比特币的挖矿机制，矿工通过把网络尚未记录的现有交易打包到一个区块，然后不断遍历尝试来寻找一个随机数，使得新区块加上随机数的哈希值满足一定的难度条件，例如前面 10 位是零。找到满足条件的随机数，就相当于确定了区块链最新的一个区块，也相当于获得了区块链的本轮记账权。矿工把满足挖矿难度条件的区块在网络中广播出去，全网其他节点在验证该区块满足挖矿难度条件，同时区块里的交易数据符合协议规范后，将各自把该区块链接到自己版本的区块链上，从而在全网形成对当前网络状态的共识。 优点：完全去中心化，节点自由进出，避免了建立和维护中心化信用机构的成本。只要网络破坏者的算力不超过网络总算力的 50%，网络的交易状态就能达成一致。 缺点：目前比特币挖矿造成大量的资源浪费；另外挖矿的激励机制也造成矿池算力的高度集中，背离了当初去中心化设计的初衷。更大的问题是 PoW 机制的共识达成的周期较长，每秒只能最多做 7 笔交易，不适合商业应用。 3.2 POS：proof of stake, 股权证明 PoS 权益证明，要求节点提供拥有一定数量的代币证明来获取竞争区块链记账权的一种分布式共识机制。如果单纯依靠代币余额来决定记账者必然使得富有者胜出，导致记账权的中心化，降低共识的公正性，因此不同的 PoS 机制在权益证明的基础上，采用不同方式来增加记账权的随机性来避免中心化。例如点点币（PeerCoin）PoS 机制中，拥有最多链龄长的比特币获得记账权的几率就越大。NXT 和 Blackcoin 则采用一个公式来预测下一个记账的节点。拥有多的代币被选为记账节点的概率就会大。未来以太坊也会从目前的 PoW 机制转换到 PoS 机制，从目前看到的资料看，以太坊的 PoS 机制将采用节点下赌注来赌下一个区块，赌中者有额外以太币奖，赌不中者会被扣以太币的方式来达成下一区块的共识。 优点：在一定程度上缩短了共识达成的时间，降低了 PoW 机制的资源浪费。 缺点：破坏者对网络攻击的成本低，网络的安全性有待验证。另外拥有代币数量大的节点获得记账权的几率更大，会使得网络的共识受少数富裕账户支配，从而失去公正性。 3.3 DPOS：delegated proof of stake, 共识机制，委托权以证明 DPoS（股份授权证明）机制，类似于董事会投票。比特股（bitshares）采用的 PoS 机制是持股者投票选出一定数量的见证人，每个见证人按序有两秒的权限时间生成区块，若见证人在给定的时间片不能生成区块，区块生成权限交给下一个时间片对应的见证人。持股人可以随时通过投票更换这些见证人。DPoS 的这种设计使得区块的生成更为快速，也更加节能。 优点：大幅缩小参与验证和记账节点的数量，可以达到秒级的共识验证。 缺点：选举固定数量的见证人作为记账候选人有可能不适合于完全去中心化的场景。另外在网络节点数少的场景，选举的见证人的代表性也不强。 4 分布式一致性算法 分布式一致性算法是基于传统的分布式一致性技术。其中有分为解决拜占庭将军问题的拜占庭容错算法，如 PBFT。另外解决非拜占庭问题的分布式一致性算法（Pasox、Raft）。该类算法目前是联盟链和私有链场景中常用的共识机制。 优点：实现秒级的快速共识机制，保证一致性。 缺点：去中心化程度不如公有链上的共识机制；更适合多方参与的多中心商业模式。 4.1 拜占庭将军问题/ Byzantine Generals Problem/ BGP 拜占庭将军问题由莱斯利·兰波特在其同名论文中提出的分布式对等网络通信容错问题。在分布式计算中，不同的计算机通过通讯交换信息达成共识而按照同一套协作策略行动。但有时候，系统中的成员计算机可能出错而发送错误的信息，用于传递信息的通讯网络也可能导致信息损坏，使得网络中不同的成员关于全体协作的策略得出不同结论，从而破坏系统一致性。拜占庭将军问题被认为是容错性问题中最难的问题类型之一。 4.2 改进型实用拜占庭容错/ Practical Byzantine Fault Tolerance/ PBFT PBET 共识机制是少数服从多数，根据信息在分布式网络中节点间互相交换后各节点列出所有得到的信息，一个节点代表一票，选择大多数的结果作为解决办法。PBET 将容错量控制在全部节点数的 1/3，即如只要有超过 2/3 的正常节点，整个系统便可正常运作。 4.3 授权拜占庭容错算法/ Delegated Byzantine Fault Tolerance /dBFT dBFT，是基于持有权益比例来选出专门的记账人（记账节点），然后记账人之间通过拜占庭容错算法（即少数服从多数的投票机制）来达成共识，决定动态参与节点。dBFT 可以容忍任何类型的错误，且专门的多个记账人使得每一个区块都有最终性、不会分叉。 4.4 联邦拜占庭协议/ Federated Byzantine Agreement / FBA 联邦拜占庭协议的主要特性是去中心化和任意行为容错，通过分布式的方法，达到法定人数或者节点足够的群体能达成共识，每一个节点不需要依赖相同的参与者就能决定信任的对象来完成共识。 5 图灵完备 一切可计算的问题都能计算，这样的虚拟机或者编程语言就叫图灵完备的。 5.1 图灵完备的系统和图灵完备的语言 一个能计算出每个图灵可计算函数（Turing-computable function）的计算系统被称为图灵完备的。一个语言是图灵完备的，意味着该语言的计算能力与一个通用图灵机 （Universal Turing Machine）相当，这也是现代计算机语言所能拥有的最高能力。 5.2 图灵完备深入解释 在可计算理论中，当一组数据操作的规则（一组指令集，编程语言，或者元胞自动机）满足任意数据按照一定的顺序可以计算出结果，被称为图灵完备（turing complete）。一个有图灵完备指令集的设备被定义为通用计算机。如果是图灵完备的，它（计算机设备）有能力执行条件跳转（“if” 和 “goto”语句）以及改变内存数据。 如果某个东西展现出了图灵完备，它就有能力表现出可以模拟原始计算机，而即使最简单的计算机也能模拟出最复杂的计算机。所有的通用编程语言和现代计算机的指令集都是图灵完备的（C++ template 就是图灵完备的），都能解决内存有限的问题。图灵完备的机器都被定义有无限内存，但是机器指令集却通常定义为只工作在特定的，有限数量的 RAM 上。 5.3 图灵完备优缺点 图灵完备意味着你的语言可以做到能够用图灵机能做到的所有事情，可以解决所有的可计算问题。 图灵不完备也不是没有意义，有些场景我们需要限制语言本身。 如限制循环和递归，可以保证该语言能写的程序一定是终止的。图灵不完备会更安全些，图灵完备会更智能些。 5.4比特币的图灵非完备性 比特币脚本语言包含许多操作，但都故意限定为一种重要的方式——没有循环或者复杂流控制功能以外的其他条件的流控制。这样就保证了脚本语言的图灵非完备性，这意味着脚本的复杂性有限，交易可执行的次数也可预见。脚本并不是一种通用语言，施加的这些限制确保该语言不被用于创造无限循环或其它类型的逻辑炸弹，这样的炸弹可以植入在一笔交易中，通过引起拒绝服务的方式攻击比特币网络。受限制的语言能防止交易激活机制被人当作薄弱环节而加以利用。 5.5 以太坊是一个图灵完备的区块链 以太坊的核心就是能够运行“无所不能”的智能合约，拥有图灵完备的编程语言，比如 Solidity，可以解决所有可计算问题。 6 零知识证明 “零知识证明”－zero-knowledge proof，是由S.Goldwasser、S.Micali及C.Rackoff在20世纪80年代初提出的。它指的是证明者能够在不向验证者提供任何有用的信息的情况下，使验证者相信某个论断是正确的。零知识证明实质上是一种涉及两方或更多方的协议，即两方或更多方完成一项任务所需采取的一系列步骤。证明者向验证者证明并使其相信自己知道或拥有某一消息，但证明过程不能向验证者泄漏任何关于被证明消息的信息。大量事实证明，零知识证明在密码学中非常有用。如果能够将零知识证明用于验证，将可以有效解决许多问题。 6.1 定义 零知识证明满足三个属性： 如果语句为真，诚实的验证者（即，正确遵循协议的验证者）将由诚实的证明者确信这一事实。 如果语句为假，不排除有概率欺骗者可以说服诚实的验证者它是真的。 如果语句为真，证明者的目的就是向验证者证明并使验证者相信自己知道或拥有某一消息，而在证明过程中不可向验证者泄漏任何有关被证明消息的内容。 零知识证明并不是数学意义上的证明，因为它存在小概率的误差，欺骗者有可能通过虚假陈述骗过证明者。换句话来说，零知识证明是概率证明而不是确定性证明。但是也存在有技术能将误差降低到可以忽略的值。 零知识的形式定义必须使用一些计算模型，最常见的是图灵机的计算模型。 6.2 证明举例 6.2.1 案例一 A 要向 B 证明自己拥有某个房间的钥匙，假设该房间只能用钥匙打开锁，而其他任何方法都打不开。这时有 2 个方法： A 把钥匙出示给 B，B 用这把钥匙打开该房间的锁，从而证明 A 拥有该房间的正确的钥匙。 B 确定该房间内有某一物体，A 用自己拥有的钥匙打开该房间的门，然后把物体拿出来出示给 B，从而证明自己确实拥有该房间的钥匙。 后面的方法 2 属于零知识证明。好处在于在整个证明的过程中，B 始终不能看到钥匙的样子，从而避免了钥匙的泄露。 6.2.2 案例二 A 拥有 B 的公钥，A 没有见过 B，而 B 见过 A 的照片，偶然一天 2 人见面了，B 认出了 A，但 A 不能确定面前的人是否是 B，这时 B 要向 A 证明自己是 B，也有 2 个方法。 B 把自己的私钥给 A，A 用这个私钥对某个数据加密，然后用 B 的公钥解密，如果正确，则证明对方确实是B。 A 给出一个随机值，B 用自己的私钥对其加密，然后把加密后的数据交给 A，A 用 B 的公钥解密，如果能够得到原来的随机值，则证明对方是 B。 后面方法 2 属于零知识证明。 ","link":"https://faded.auspicious.space/post/blockchain-introduction/"},{"title":"正则表达式——完整版教程","content":" JS正则表达式完整教程（略长） 引言 本文内容共有七章，用 JavaScript 语言完整地讨论了正则表达式的方方面面。 具体章节如下： 引言 第 1 章 正则表达式字符匹配攻略 第 2 章 正则表达式位置匹配攻略 第 3 章 正则表达式括号的作用 第 4 章 正则表达式回溯法原理 第 5 章 正则表达式的拆分 第 6 章 正则表达式的构建 第 7 章 正则表达式编程后记 下面简单地说说每一章都讨论了什么。 正则是匹配模式，要么匹配字符，要么匹配位置。 第 1 章和第 2 章以这个角度去讲解了正则的基础。 在正则中可以使用括号捕获数据，要么在 API 中进行分组引用，要么在正则里进行反向引用。 这是第 3 章的主题，讲解了正则中括号的作用。 学习正则表达式，是需要了解其匹配原理的。第 4 章，讲解了正则了正则表达式的回溯法原理。另外在第 6 章里，也讲解了正则的表达式的整体工作原理。 不仅能看懂别人的正则，还要自己会写正则。 第 5 章，是从读的角度，去拆分一个正则表达式，而第 6 章是从写的角度，去构建一个正则表达式。 学习正则，是为了在真实世界里应用的。 第 7 章讲解了正则的用法，和相关 API 需要注意的地方。 第 1 章 正则表达式字符匹配攻略 正则表达式是匹配模式，要么匹配字符，要么匹配位置。请记住这句话。 然而关于正则如何匹配字符的学习，大部分人都觉得这块比较杂乱。 毕竟元字符太多了，看起来没有系统性，不好记。本章就解决这个问题。 内容包括： 两种模糊匹配 字符组 量词 多选分支 案例分析 1.1 两种模糊匹配 如果正则只有精确匹配是没多大意义的，比如 /hello/，也只能匹配字符串中的 &quot;hello&quot; 这个子串。 const regex = /hello/; console.log(regex.test('hello')); // =&gt; true 正则表达式之所以强大，是因为其能实现模糊匹配。而模糊匹配，有两个方向上的“模糊”：横向模糊匹配和纵向模糊匹配。 1.1.1 横向模糊匹配 横向模糊指的是，一个正则可匹配的字符串的长度不是固定的，可以是多种情况的。其实现的方式是使用量词。譬如 {m,n}，表示连续出现最少 m 次，最多 n 次。比如 /ab{2,5}c/ 表示匹配这样一个字符串：第一个字符是 &quot;a&quot;，接下来是 2 到 5 个字符是 &quot;b&quot;，最后是字符 &quot;c&quot;。测试如下： const regex = /ab{2,5}c/g; const string = 'abc abbc abbbc abbbbc abbbbbc abbbbbbc'; console.log(string.match(regex)); // =&gt; [&quot;abbc&quot;, &quot;abbbc&quot;, &quot;abbbbc&quot;, &quot;abbbbbc&quot;] 注意：案例中用的正则是 /ab{2,5}c/g，后面多了 g，它是正则的一个修饰符。表示全局匹配，即在目标字符串中按顺序找到满足匹配模式的所有子串，强调的是“所有”，而不只是“第一个”。g 是单词 global 的首字母。 1.1.2 纵向模糊匹配 纵向模糊指的是，一个正则匹配的字符串，具体到某一位字符时，它可以不是某个确定的字符，可以有多种可能。其实现的方式是使用字符组。譬如 [abc]，表示该字符是可以字符 &quot;a&quot;、&quot;b&quot;、&quot;c&quot; 中的任何一个。比如 /a[123]b/ 可以匹配如下三种字符串：&quot;a1b&quot;、&quot;a2b&quot;、&quot;a3b&quot;。测试如下： const regex = /a[123]b/g; const string = 'a0b a1b a2b a3b a4b'; console.log(string.match(regex)); // =&gt; [&quot;a1b&quot;, &quot;a2b&quot;, &quot;a3b&quot;] 以上就是本章讲的主体内容，只要掌握横向和纵向模糊匹配，就能解决很大部分正则匹配问题。 接下来的内容就是展开说了，如果对此都比较熟悉的话，可以跳过，直接看本章案例那节。 1.2 字符组 需要强调的是，虽叫字符组（字符类），但只是其中一个字符。例如 [abc]，表示匹配一个字符，它可以是 &quot;a&quot;、&quot;b&quot;、&quot;c&quot; 之一。 1.2.1 范围表示法 如果字符组里的字符特别多的话，怎么办？可以使用范围表示法。 比如 [123456abcdefGHIJKLM]，可以写成 [1-6a-fG-M]。用连字符 - 来省略和简写。 因为连字符有特殊用途，那么要匹配 &quot;a&quot;、&quot;-&quot;、&quot;z&quot; 这三者中任意一个字符，该怎么做呢？ 不能写成 [a-z]，因为其表示小写字符中的任何一个字符。 可以写成如下的方式：[-az] 或[az-] 或 [a\\-z]。即要么放在开头，要么放在结尾，要么转义。总之不会让引擎认为是范围表示法就行了。 1.2.2 排除字符组 纵向模糊匹配，还有一种情形就是，某位字符可以是任何东西，但就不能是 &quot;a&quot;、&quot;b&quot;、&quot;c&quot;。 此时就是排除字符组（反义字符组）的概念。例如 [^abc]，表示是一个除 &quot;a&quot;、&quot;b&quot;、&quot;c&quot; 之外的任意一个字符。字符组的第一位放 ^（脱字符），表示求反的概念。 当然，也有相应的范围表示法。 1.2.3 常见的简写形式 有了字符组的概念后，一些常见的符号我们也就理解了。因为它们都是系统自带的简写形式。 \\d 就是 [0-9]。表示是一位数字。记忆方式：其英文是 digit（数字）； \\D 就是 [^0-9]。表示除数字外的任意字符； \\w 就是 [0-9a-zA-Z_]。表示数字、大小写字母和下划线。记忆方式：w 是 word 的简写，也称单词字符； \\W 是 [^0-9a-zA-Z_]。非单词字符； \\s是 [ \\t\\v\\n\\r\\f]。表示空白符，包括空格、水平制表符、垂直制表符、换行符、回车符、换页符。记忆方式：s 是 space character 的首字母； \\S 是 [^ \\t\\v\\n\\r\\f]。 非空白符。 . 就是 [^\\n\\r\\u2028\\u2029]。通配符，表示几乎任意字符。换行符、回车符、行分隔符和段分隔符除外。记忆方式：想想省略号...中的每个点，都可以理解成占位符，表示任何类似的东西。 如果要匹配任意字符怎么办？可以使用 [\\d\\D]、[\\w\\W]、[\\s\\S] 和 [^] 中任何的一个。 1.3 量词 量词也称重复。掌握 {m,n} 的准确含义后，只需要记住一些简写形式。 1.3.1 简写形式 {m,} 表示至少出现 m 次。 {m} 等价于 {m,m}，表示出现 m 次。 ? 等价于 {0,1}，表示出现或者不出现。记忆方式：问号的意思表示，有吗？ + 等价于 {1,}，表示出现至少一次。记忆方式：加号是追加的意思，得先有一个，然后才考虑追加。 * 等价于 {0,}，表示出现任意次，有可能不出现。记忆方式：看看天上的星星，可能一颗没有，可能零散有几颗，可能数也数不过来。 1.3.2 贪婪匹配和惰性匹配 看如下的例子： const regex = /\\d{2,5}/g; const string = '123 1234 12345 123456'; console.log(string.match(regex)); // =&gt; [&quot;123&quot;, &quot;1234&quot;, &quot;12345&quot;, &quot;12345&quot;] 其中正则 /\\d{2,5}/，表示数字连续出现 2 到 5 次。会匹配 2 位、3 位、4 位、5 位连续数字。 但是其是贪婪的，它会尽可能多的匹配。你能给我 6 个，我就要 5 个。你能给我3个，我就要 3 个。反正只要在能力范围内，越多越好。 我们知道有时贪婪不是一件好事（请看文章最后一个例子）。而惰性匹配，就是尽可能少的匹配： const regex = /\\d{2,5}?/g; const string = '123 1234 12345 123456'; console.log(string.match(regex)); // =&gt; [&quot;12&quot;, &quot;12&quot;, &quot;34&quot;, &quot;12&quot;, &quot;34&quot;, &quot;12&quot;, &quot;34&quot;, &quot;56&quot;] 其中 /\\d{2,5}?/ 表示，虽然 2 到 5 次都行，当 2 个就够的时候，就不在往下尝试了。 通过在量词后面加个问号就能实现惰性匹配，因此所有惰性匹配情形如下： {m,n}? {m,}? ?? +? *? 1.4 多选分支 一个模式可以实现横向和纵向模糊匹配。而多选分支可以支持多个子模式任选其一。 具体形式如下：(p1|p2|p3)，其中 p1、p2 和 p3 是子模式，用 |（管道符）分隔，表示其中任何之一。 例如要匹配 &quot;good&quot; 和 &quot;nice&quot; 可以使用 /good|nice/。测试如下： const regex = /good|nice/g; const string = 'good idea, nice try.'; console.log(string.match(regex)); // =&gt; [&quot;good&quot;, &quot;nice&quot;] 但有个事实我们应该注意，比如我用 /good|goodbye/，去匹配 &quot;goodbye&quot; 字符串时，结果是 &quot;good&quot;： const regex = /good|goodbye/g; const string = 'goodbye'; console.log(string.match(regex)); // =&gt; [&quot;good&quot;] 而把正则改成 /goodbye|good/，结果是： var regex = /goodbye|good/g; var string = 'goodbye'; console.log(string.match(regex)); // =&gt; [&quot;goodbye&quot;] 也就是说，分支结构也是惰性的，即当前面的匹配上了，后面的就不再尝试了。 1.5 案例分析 匹配字符，无非就是字符组、量词和分支结构的组合使用罢了。 下面找几个例子演练一下（其中，每个正则并不是只有唯一写法）： 1.5.1 匹配 16 进制颜色值 要求匹配： #ffbbad #Fc01DF #FFF #ffE 分析： 表示一个 16 进制字符，可以用字符组 [0-9a-fA-F]。 其中字符可以出现 3 或 6 次，需要是用量词和分支结构。 使用分支结构时，需要注意顺序。 正则如下： const regex = /#([0-9a-fA-F]{6}|[0-9a-fA-F]{3})/g; const string = '#ffbbad #Fc01DF #FFF #ffE'; console.log(string.match(regex)); // =&gt; [&quot;#ffbbad&quot;, &quot;#Fc01DF&quot;, &quot;#FFF&quot;, &quot;#ffE&quot;] 1.5.2 匹配时间 以 24 小时制为例。 要求匹配： 23:59 02:07 分析： 共 4 位数字，第一位数字可以为 [0-2]； 当第 1 位为 2 时，第2位可以为 [0-3]，其他情况时，第 2 位为 [0-9]； 第 3 位数字为 [0-5]，第 4 位为 [0-9]。 正则如下： const regex = /^([01][0-9]|[2][0-3]):[0-5][0-9]$/; console.log(regex.test('23:59')); console.log(regex.test('02:07')); // =&gt; true // =&gt; true 如果也要求匹配 7:9，也就是说时分前面的 0 可以省略。 此时正则变成： const regex = /^(0?[0-9]|1[0-9]|[2][0-3]):(0?[0-9]|[1-5][0-9])$/; console.log( regex.test('23:59') ); console.log( regex.test('02:07') ); console.log( regex.test('7:9') ); // =&gt; true // =&gt; true // =&gt; true 1.5.3 匹配日期 比如 yyyy-mm-dd 格式为例。 要求匹配： 2017-06-10 分析： 年，四位数字即可，可用 [0-9]{4}； 月，共 12 个月，分两种情况 01、02、……、09 和 10、11、12，可用 (0[1-9]|1[0-2])； 日，最大 31 天，可用 (0[1-9]|[12][0-9]|3[01])。 正则如下： const regex = /^[0-9]{4}-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])$/; console.log(regex.test('2017-06-10')); // =&gt; true 1.5.4 Window 操作系统文件路径 要求匹配： F:\\study\\javascript\\regex\\regular expression.pdf F:\\study\\javascript\\regex\\ F:\\study\\javascript -F:\\ 分析： 整体模式是: 盘符:\\文件夹\\文件夹\\文件夹\\； 其中匹配 F:\\，需要使用[a-zA-Z]:\\\\，其中盘符不区分大小写，注意 \\ 字符需要转义； 文件名或者文件夹名，不能包含一些特殊字符，此时我们需要排除字符组 [^\\\\:*&lt;&gt;|&quot;?\\r\\n/] 来表示合法字符。另外不能为空名，至少有一个字符，也就是要使用量词 +。因此匹配 &quot;文件夹&quot;，可用[^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+\\\\； 另外“文件夹\\”，可以出现任意次。也就是 ([^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+\\\\)*。其中括号提供子表达式； 路径的最后一部分可以是“文件夹”，没有 \\，因此需要添加 ([^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+)?。 最后拼接成了一个看起来比较复杂的正则： const regex = /^[a-zA-Z]:\\\\([^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+\\\\)*([^\\\\:*&lt;&gt;|&quot;?\\r\\n/]+)?$/; console.log(regex.test('F:\\\\study\\\\javascript\\\\regex\\\\regular expression.pdf')); console.log(regex.test('F:\\\\study\\\\javascript\\\\regex\\\\')); console.log(regex.test('F:\\\\study\\\\javascript')); console.log(regex.test('F:\\\\')); // =&gt; true // =&gt; true // =&gt; true // =&gt; true 其中，JS 中字符串表示 \\ 时，也要转义。 1.5.5 匹配 id 要求从 &lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt; 提取出 id=&quot;container&quot;。 可能最开始想到的正则是： const regex = /id=&quot;.*&quot;/ const string = '&lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt;'; console.log(string.match(regex)[0]); // =&gt; id=&quot;container&quot; class=&quot;main&quot; 因为 . 是通配符，本身就匹配双引号的，而量词 * 又是贪婪的，当遇到 container 后面双引号时，不会停下来，会继续匹配，直到遇到最后一个双引号为止。 解决之道，可以使用惰性匹配： const regex = /id=&quot;.*?&quot;/ const string = '&lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt;'; console.log(string.match(regex)[0]); // =&gt; id=&quot;container&quot; 当然，这样也会有个问题。效率比较低，因为其匹配原理会涉及到“回溯”这个概念（这里也只是顺便提一下，第四章会详细说明）。可以优化如下： const regex = /id=&quot;[^&quot;]*&quot;/ const string = '&lt;div id=&quot;container&quot; class=&quot;main&quot;&gt;&lt;/div&gt;'; console.log(string.match(regex)[0]); // =&gt; id=&quot;container&quot; 第 1 章小结 字符匹配相关的案例，挺多的，不一而足。 掌握字符组和量词就能解决大部分常见的情形，也就是说，当你会了这二者，JS 正则算是入门了。 第 2 章 正则表达式位置匹配攻略 正则表达式是匹配模式，要么匹配字符，要么匹配位置。请记住这句话。 然而大部分人学习正则时，对于匹配位置的重视程度没有那么高。 本章讲讲正则匹配位置的总总。 内容包括： 什么是位置？ 如何匹配位置？ 位置的特性 几个应用实例分析 2.1 什么是位置呢？ 位置是相邻字符之间的位置。比如，下图中箭头所指的地方： 2.2. 如何匹配位置呢？ 在 ES5 中，共有 6 个锚字符：^ $ \\b \\B (?=p) (?!p)。 2.2.1 ^ 和 $ ^（脱字符）匹配开头，在多行匹配中匹配行开头； $（美元符号）匹配结尾，在多行匹配中匹配行结尾。 比如我们把字符串的开头和结尾用“#”替换（位置是可以替换成字符的！）： const result = 'hello'.replace(/^|$/g, '#'); console.log(result); // =&gt; &quot;#hello#&quot; 多行匹配模式时，二者是行的概念，这个需要我们的注意： const result = 'I\\nlove\\njavascript'.replace(/^|$/gm, '#'); console.log(result); /* #I# #love# #javascript# */ 2.2.2 \\b 和 \\B \\b 是单词边界，具体就是 \\w 和 \\W 之间的位置，也包括 \\w 和 ^ 之间的位置，也包括 \\w和 $ 之间的位置。 比如一个文件名是 &quot;[JS] Lesson_01.mp4&quot; 中的 \\b，如下： const result = '[JS] Lesson_01.mp4'.replace(/\\b/g, '#'); console.log(result); // =&gt; &quot;[#JS#] #Lesson_01#.#mp4#&quot; 为什么是这样呢？这需要仔细看看。 首先，我们知道，\\w 是字符组 [0-9a-zA-Z_] 的简写形式，即 \\w 是字母数字或者下划线的中任何一个字符。而 \\W 是排除字符组 [^0-9a-zA-Z_] 的简写形式，即 \\W 是 \\w 以外的任何一个字符。此时我们可以看看 &quot;[#JS#] #Lesson_01#.#mp4#&quot; 中的每一个 &quot;#&quot;，是怎么来的。 第一个&quot;#&quot;，两边是 &quot;[&quot;与 &quot;J&quot;，是 \\W 和 \\w 之间的位置； 第二个&quot;#&quot;，两边是 &quot;S&quot; 与 &quot;]&quot;，也就是 \\w 和 \\W 之间的位置； 第三个&quot;#&quot;，两边是空格与 &quot;L&quot;，也就是 \\W 和 \\w 之间的位置； 第四个&quot;#&quot;，两边是 &quot;1&quot; 与 &quot;.&quot;，也就是 \\w 和 \\W 之间的位置； 第五个&quot;#&quot;，两边是 &quot;.&quot;与 &quot;m&quot;，也就是 \\W 和 \\w 之间的位置； 第六个&quot;#&quot;，其对应的位置是结尾，但其前面的字符 &quot;4&quot; 是 \\w，即 \\w 和 $ 之间的位置。 知道了 \\b 的概念后，那么 \\B 也就相对好理解了。 \\B 就是 \\b 的反面的意思，非单词边界。例如在字符串中所有位置中，扣掉 \\b，剩下的都是 \\B 的。 具体说来就是 \\w 与 \\w、\\W 与 \\W、^ 与 \\W，\\W 与 $ 之间的位置。 比如上面的例子，把所有 \\B 替换成 &quot;#&quot;： const result = '[JS] Lesson_01.mp4'.replace(/\\B/g, '#'); console.log(result); // =&gt; &quot;#[J#S]# L#e#s#s#o#n#_#0#1.m#p#4&quot; 2.2.3 (?=p) 和 (?!p) (?=p)，其中 p 是一个子模式，即 p 前面的位置。 比如 (?=l)，表示 &quot;l&quot; 字符前面的位置，例如： const result = 'hello'.replace(/(?=l)/g, '#'); console.log(result); // =&gt; &quot;he#l#lo&quot; 而 (?!p) 就是 (?=p) 的反面意思，比如： const result = 'hello'.replace(/(?!l)/g, '#'); console.log(result); // =&gt; &quot;#h#ell#o#&quot; 二者的学名分别是 positive lookahead 和 negative lookahead。 中文翻译分别是正向先行断言和负向先行断言。 ES6中，还支持 positive lookbehind 和 negative lookbehind。 具体是 (?&lt;=p) 和 (?&lt;!p)。 也有书上把这四个东西，翻译成环视，即看看右边或看看左边。 但一般书上，没有很好强调这四者是个位置。 比如 (?=p)，一般都理解成：要求接下来的字符与 p 匹配，但不能包括 p 的那些字符。 而在本人看来 (?=p) 就与 ^ 一样好理解，就是 p 前面的那个位置。 2.3. 位置的特性 对于位置的理解，我们可以理解成空字符&quot;&quot;。 比如 &quot;hello&quot; 字符串等价于如下的形式： 'hello' == '' + 'h' + '' + 'e' + '' + 'l' + '' + 'l' + 'o' + ''; 也等价于： 'hello' == '' + '' + 'hello'; 因此，把 /^hello$/ 写成 /^^hello$$$/，是没有任何问题的： const result = /^^hello$$$/.test('hello'); console.log(result); // =&gt; true 甚至可以写成更复杂的： const result = /(?=he)^^he(?=\\w)llo$\\b\\b$/.test('hello'); console.log(result); // =&gt; true 也就是说字符之间的位置，可以写成多个。 把位置理解空字符，是对位置非常有效的理解方式。 2.4 相关案例 2.4.1 不匹配任何东西的正则 让你写个正则不匹配任何东西 easy，/.^/ 因为此正则要求只有一个字符，但该字符后面是开头。 2.4.2 数字的千位分隔符表示法 比如把 &quot;12345678&quot;，变成 &quot;12,345,678&quot;。 可见是需要把相应的位置替换成 &quot;,&quot;。 思路是什么呢？ 2.4.2.1 弄出最后一个逗号 使用 (?=\\d{3}$) 就可以做到： const result = '12345678'.replace(/(?=\\d{3}$)/g, ',') console.log(result); // =&gt; &quot;12345,678&quot; 2.4.2.2 弄出所有的逗号 因为逗号出现的位置，要求后面 3 个数字一组，也就是 \\d{3} 至少出现一次。 此时可以使用量词 +： const result = '12345678'.replace(/(?=(\\d{3})+$)/g, ',') console.log(result); // =&gt; &quot;12,345,678&quot; 2.4.2.3 匹配其余案例 写完正则后，要多验证几个案例，此时我们会发现问题： const result = '123456789'.replace(/(?=(\\d{3})+$)/g, ',') console.log(result); // =&gt; &quot;,123,456,789&quot; 因为上面的正则，仅仅表示把从结尾向前数，一但是 3 的倍数，就把其前面的位置替换成逗号。因此才会出现这个问题。 怎么解决呢？我们要求匹配的到这个位置不能是开头。 我们知道匹配开头可以使用 ^，但要求这个位置不是开头怎么办？easy，(?!^)，你想到了吗？测试如下： const string1 = '12345678'; const string2 = '123456789'; const reg = /(?!^)(?=(\\d{3})+$)/g; const result = string1.replace(reg, ',') console.log(result); // =&gt; &quot;12,345,678&quot; result = string2.replace(reg, ','); console.log(result); // =&gt; &quot;123,456,789&quot; 2.4.2.4 支持其他形式 如果要把 &quot;12345678 123456789&quot; 替换成 &quot;12,345,678 123,456,789&quot;。 此时我们需要修改正则，把里面的开头 ^ 和结尾 $，替换成 \\b： const string = '12345678 123456789'; const reg = /(?!\\b)(?=(\\d{3})+\\b)/g; const result = string.replace(reg, ','); console.log(result); // =&gt; &quot;12,345,678 123,456,789&quot; 其中 (?!\\b) 怎么理解呢？ 要求当前是一个位置，但不是 \\b 前面的位置，其实 (?!\\b) 说的就是 \\B。 因此最终正则变成了：/\\B(?=(\\d{3})+\\b)/g。 2.4.3 验证密码问题 密码长度 6-12 位，由数字、小写字符和大写字母组成，但必须至少包括 2 种字符。 此题，如果写成多个正则来判断，比较容易。但要写成一个正则就比较困难。 那么，我们就来挑战一下。看看我们对位置的理解是否深刻。 2.4.3.1 简化 不考虑“但必须至少包括 2 种字符”这一条件。我们可以容易写出： const reg = /^[0-9A-Za-z]{6,12}$/; 2.4.3.2 判断是否包含有某一种字符 假设，要求的必须包含数字，怎么办？此时我们可以使用 (?=.*[0-9]) 来做。 因此正则变成： const reg = /(?=.*[0-9])^[0-9A-Za-z]{6,12}$/; 2.4.3.3 同时包含具体两种字符 比如同时包含数字和小写字母，可以用 (?=.*[0-9])(?=.*[a-z]) 来做。 因此正则变成： const reg = /(?=.*[0-9])(?=.*[a-z])^[0-9A-Za-z]{6,12}$/; 2.4.3.4 解答 我们可以把原题变成下列几种情况之一： 同时包含数字和小写字母； 同时包含数字和大写字母； 同时包含小写字母和大写字母； 同时包含数字、小写字母和大写字母。 以上的 4 种情况是或的关系（实际上，可以不用第 4 条）。 最终答案是： const reg = /((?=.*[0-9])(?=.*[a-z])|(?=.*[0-9])(?=.*[A-Z])|(?=.*[a-z])(?=.*[A-Z]))^[0-9A-Za-z]{6,12}$/; console.log(reg.test('1234567')); // false 全是数字 console.log(reg.test('abcdef')); // false 全是小写字母 console.log(reg.test('ABCDEFGH')); // false 全是大写字母 console.log(reg.test('ab23C')); // false 不足 6 位 console.log(reg.test('ABCDEF234')); // true 大写字母和数字 console.log(reg.test('abcdEF234')); // true 三者都有 2.4.3.5 解惑 上面的正则看起来比较复杂，只要理解了第二步，其余就全部理解了。 /(?=.*[0-9])^[0-9A-Za-z]{6,12}$/ 对于这个正则，我们只需要弄明白 (?=.*[0-9])^即可。 分开来看就是 (?=.*[0-9]) 和 ^。 表示开头前面还有个位置（当然也是开头，即同一个位置，想想之前的空字符类比）。 (?=.*[0-9]) 表示该位置后面的字符匹配 .*[0-9]，即，有任何多个任意字符，后面再跟个数字。 翻译成大白话，就是接下来的字符，必须包含个数字。 2.4.3.6 另外一种解法 “至少包含两种字符”的意思就是说，不能全部都是数字，也不能全部都是小写字母，也不能全部都是大写字母。 那么要求“不能全部都是数字”，怎么做呢？(?!p) 出马！ 对应的正则是： const reg = /(?!^[0-9]{6,12}$)^[0-9A-Za-z]{6,12}$/; 三种“都不能”呢？ 最终答案是： const reg = /(?!^[0-9]{6,12}$)(?!^[a-z]{6,12}$)(?!^[A-Z]{6,12}$)^[0-9A-Za-z]{6,12}$/; console.log(reg.test('1234567')); // false 全是数字 console.log(reg.test('abcdef')); // false 全是小写字母 console.log(reg.test('ABCDEFGH')); // false 全是大写字母 console.log(reg.test('ab23C')); // false 不足 6 位 console.log(reg.test('ABCDEF234')); // true 大写字母和数字 console.log(reg.test('abcdEF234')); // true 三者都有 第 2 章小结 位置匹配相关的案例，挺多的，不一而足。 掌握匹配位置的这 6 个锚字符，给我们解决正则问题一个新工具。 第 3 章 正则表达式括号的作用 不管哪门语言中都有括号。正则表达式也是一门语言，而括号的存在使这门语言更为强大。 对括号的使用是否得心应手，是衡量对正则的掌握水平的一个侧面标准。 括号的作用，其实三言两语就能说明白，括号提供了分组，便于我们引用它。 引用某个分组，会有两种情形：在 JavaScript 里引用它，在正则表达式里引用它。 本章内容虽相对简单，但我也要写长点。内容包括： 分组和分支结构 引用分组 反向引用 非捕获分组 相关案例 3.1 分组和分支结构 这二者是括号最直觉的作用，也是最原始的功能。 3.1.1 分组 我们知道 /a+/ 匹配连续出现的 &quot;a&quot;，而要匹配连续出现的 &quot;ab&quot; 时，需要使用 /(ab)+/。 其中括号是提供分组功能，使量词 + 作用于 &quot;ab&quot; 这个整体，测试如下： const regex = /(ab)+/g; const string = 'ababa abbb ababab'; console.log(string.match(regex)); // =&gt; [&quot;abab&quot;, &quot;ab&quot;, &quot;ababab&quot;] 3.1.2 分支结构 而在多选分支结构 (p1|p2) 中，此处括号的作用也是不言而喻的，提供了子表达式的所有可能。 比如，要匹配如下的字符串： I love JavaScript I love Regular Expression 可以使用正则： const regex = /^I love (JavaScript|Regular Expression)$/; console.log(regex.test('I love JavaScript')); console.log(regex.test('I love Regular Expression')); // =&gt; true // =&gt; true 如果去掉正则中的括号，即 /^I love JavaScript|Regular Expression$/，匹配字符串是 &quot;I love JavaScript&quot; 和 &quot;Regular Expression&quot;，当然这不是我们想要的。 3.2 引用分组 这是括号一个重要的作用，有了它，我们就可以进行数据提取，以及更强大的替换操作。 而要使用它带来的好处，必须配合使用实现环境的 API。 以日期为例。假设格式是 yyyy-mm-dd 的，我们可以先写一个简单的正则： const regex = /\\d{4}-\\d{2}-\\d{2}/; 然后再修改成括号版的： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; 为什么要使用这个正则呢？ 3.2.1 提取数据 比如提取出年、月、日，可以这么做： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; console.log(string.match(regex)); // =&gt; [&quot;2017-06-12&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;12&quot;, index: 0, input: &quot;2017-06-12&quot;] match 返回的一个数组，第一个元素是整体匹配结果，然后是各个分组（括号里）匹配的内容，然后是匹配下标，最后是输入的文本。（注意：如果正则是否有修饰符 g，match 返回的数组格式是不一样的）。 另外也可以使用正则对象的 exec 方法： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; console.log(regex.exec(string)); // =&gt; [&quot;2017-06-12&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;12&quot;, index: 0, input: &quot;2017-06-12&quot;] 同时，也可以使用构造函数的全局属性 $1 至 $9 来获取： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; regex.test(string); // 正则操作即可，例如 //regex.exec(string); //string.match(regex); console.log(RegExp.$1); // &quot;2017&quot; console.log(RegExp.$2); // &quot;06&quot; console.log(RegExp.$3); // &quot;12&quot; 3.2.2 替换数据 比如，想把 yyyy-mm-dd 格式，替换成 mm/dd/yyyy 怎么做？ const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; const result = string.replace(regex, '$2/$3/$1'); console.log(result); // =&gt; &quot;06/12/2017&quot; 其中 replace 中的，第二个参数里用 $1、$2、$3 指代相应的分组。等价于如下的形式： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; const result = string.replace(regex, function() { return RegExp.$2 + '/' + RegExp.$3 + '/' + RegExp.$1; }); console.log(result); // =&gt; &quot;06/12/2017&quot; 也等价于： const regex = /(\\d{4})-(\\d{2})-(\\d{2})/; const string = '2017-06-12'; const result = string.replace(regex, function(match, year, month, day) { return month + '/' + day + '/' + year; }); console.log(result); // =&gt; &quot;06/12/2017&quot; 3.3 反向引用 除了使用相应 API 来引用分组，也可以在正则本身里引用分组。但只能引用之前出现的分组，即反向引用。 还是以日期为例。 比如要写一个正则支持匹配如下三种格式： 2016-06-12 2016/06/12 2016.06.12 最先可能想到的正则是： const regex = /\\d{4}(-|\\/|\\.)\\d{2}(-|\\/|\\.)\\d{2}/; const string1 = '2017-06-12'; const string2 = '2017/06/12'; const string3 = '2017.06.12'; const string4 = '2016-06/12'; console.log(regex.test(string1)); // true console.log(regex.test(string2)); // true console.log(regex.test(string3)); // true console.log(regex.test(string4)); // true 其中 / 和 . 需要转义。虽然匹配了要求的情况，但也匹配 &quot;2016-06/12&quot; 这样的数据。 假设我们想要求分割符前后一致怎么办？此时需要使用反向引用： const regex = /\\d{4}(-|\\/|\\.)\\d{2}\\1\\d{2}/; const string1 = '2017-06-12'; const string2 = '2017/06/12'; const string3 = '2017.06.12'; const string4 = '2016-06/12'; console.log(regex.test(string1)); // true console.log(regex.test(string2)); // true console.log(regex.test(string3)); // true console.log(regex.test(string4)); // false 注意里面的 \\1，表示的引用之前的那个分组 (-|\\/|\\.)。不管它匹配到什么（比如 -），\\1 都匹配那个同样的具体某个字符。 我们知道了 \\1 的含义后，那么 \\2 和 \\3 的概念也就理解了，即分别指代第二个和第三个分组。 看到这里，此时，恐怕你会有三个问题。 3.3.1 括号嵌套怎么办？ 以左括号（开括号）为准。比如： const regex = /^((\\d)(\\d(\\d)))\\1\\2\\3\\4$/; const string = '1231231233'; console.log(regex.test(string)); // true console.log(RegExp.$1); // 123 console.log(RegExp.$2 ); // 1 console.log(RegExp.$3); // 23 console.log(RegExp.$4); // 3 我们可以看看这个正则匹配模式： 第一个字符是数字，比如说 1， 第二个字符是数字，比如说 2， 第三个字符是数字，比如说 3， 接下来的是 \\1，是第一个分组内容，那么看第一个开括号对应的分组是什么，是 123， 接下来的是 \\2，找到第 2 个开括号，对应的分组，匹配的内容是 1， 接下来的是 \\3，找到第 3 个开括号，对应的分组，匹配的内容是 23， 最后的是 \\4，找到第 3 个开括号，对应的分组，匹配的内容是 3。 这个问题，估计仔细看一下，就该明白了。 3.3.2 \\10 表示什么呢？ 另外一个疑问可能是，即 \\10 是表示第 10 个分组，还是 \\1 和 0 呢？ 答案是前者，虽然一个正则里出现 \\10 比较罕见。测试如下： const regex = /(1)(2)(3)(4)(5)(6)(7)(8)(9)(#) \\10+/; const string = '123456789# ######'; console.log(regex.test(string)); // =&gt; true 3.3.3 引用不存在的分组会怎样？ 因为反向引用，是引用前面的分组，但我们在正则里引用了不存在的分组时，此时正则不会报错，只是匹配反向引用的字符本身。例如 \\2，就匹配“\\2”。注意“\\2”表示对“2”进行了转意。 const regex = /\\1\\2\\3\\4\\5\\6\\7\\8\\9/; console.log(regex.test('\\1\\2\\3\\4\\5\\6\\7\\8\\9')); console.log('\\1\\2\\3\\4\\5\\6\\7\\8\\9'.split('')); Chrome 浏览器打印的结果： Node 打印的结果： 4. 非捕获分组 之前文中出现的分组，都会捕获它们匹配到的数据，以便后续引用，因此也称他们是捕获型分组。 如果只想要括号最原始的功能，但不会引用它，即，既不在 API 里引用，也不在正则里反向引用。此时可以使用非捕获分组 (?:p)，例如本文第一个例子可以修改为： const regex = /(?:ab)+/g; const string = 'ababa abbb ababab'; console.log(string.match(regex)); // =&gt; [&quot;abab&quot;, &quot;ab&quot;, &quot;ababab&quot;] 3.5 相关案例 至此括号的作用已经讲完了，总结一句话，就是提供了可供我们使用的分组，如何用就看我们的了。 3.5.1 字符串 trim 方法模拟 trim 方法是去掉字符串的开头和结尾的空白符。有两种思路去做。 第一种，匹配到开头和结尾的空白符，然后替换成空字符。如： function trim(str) { return str.replace(/^\\s+|\\s+$/g, ''); } console.log(trim(' foobar ')); // =&gt; &quot;foobar&quot; 第二种，匹配整个字符串，然后用引用来提取出相应的数据： function trim(str) { return str.replace(/^\\s*(.*?)\\s*$/g, '$1'); } console.log(trim(' foobar ')); // =&gt; &quot;foobar&quot; 这里使用了惰性匹配 *?，不然也会匹配最后一个空格之前的所有空格的。 当然，前者效率高。 3.5.2 将每个单词的首字母转换为大写 function titleize(str) { return str.toLowerCase().replace(/(?:^|\\s)\\w/g, function(c) { return c.toUpperCase(); }); } console.log(titleize('my name is epeli')); // =&gt; &quot;My Name Is Epeli&quot; 思路是找到每个单词的首字母，当然这里不使用非捕获匹配也是可以的。 3.5.3 驼峰化 function camelize(str) { return str.replace(/[-_\\s]+(.)?/g, function(match, c) { return c ? c.toUpperCase() : ''; }); } console.log(camelize('-moz-transform')); // =&gt; &quot;MozTransform&quot; 其中分组 (.) 表示首字母。单词的界定是，前面的字符可以是多个连字符、下划线以及空白符。正则后面的 ? 的目的，是为了应对 str 尾部的字符可能不是单词字符，比如 str 是'-moz-transform'。 3.5.4 中划线化 function dasherize(str) { return str.replace(/([A-Z])/g, '-$1').replace(/[-_\\s]+/g, '-').toLowerCase(); } console.log(dasherize('MozTransform')); // =&gt; &quot;-moz-transform&quot; 驼峰化的逆过程。 3.5.5 html 转义和反转义 // 将HTML特殊字符转换成等值的实体 function escapeHTML(str) { var escapeChars = { '¢' : 'cent', '£' : 'pound', '¥' : 'yen', '€': 'euro', '©' :'copy', '®' : 'reg', '&lt;' : 'lt', '&gt;' : 'gt', '&quot;' : 'quot', '&amp;' : 'amp', '\\'' : '#39' }; return str.replace(new RegExp('[' + Object.keys(escapeChars).join('') +']', 'g'), function(match) { return '&amp;' + escapeChars[match] + ';'; }); } console.log(escapeHTML('&lt;div&gt;Blah blah blah&lt;/div&gt;')); // =&gt; &quot;&amp;lt;div&amp;gt;Blah blah blah&amp;lt;/div&amp;gt&quot;; 其中使用了用构造函数生成的正则，然后替换相应的格式就行了，这个跟本章没多大关系。 倒是它的逆过程，使用了括号，以便提供引用，也很简单，如下： // 实体字符转换为等值的HTML。 function unescapeHTML(str) { var htmlEntities = { nbsp: ' ', cent: '¢', pound: '£', yen: '¥', euro: '€', copy: '©', reg: '®', lt: '&lt;', gt: '&gt;', quot: '&quot;', amp: '&amp;', apos: '\\'' }; return str.replace(/\\&amp;([^;]+);/g, function(match, key) { if (key in htmlEntities) { return htmlEntities[key]; } return match; }); } console.log(unescapeHTML('&amp;lt;div&amp;gt;Blah blah blah&amp;lt;/div&amp;gt;')); // =&gt; &quot;&lt;div&gt;Blah blah blah&lt;/div&gt;&quot; 通过 key 获取相应的分组引用，然后作为对象的键。 3.5.6 匹配成对标签 要求匹配： &lt;title&gt;regular expression&lt;/title&gt; &lt;p&gt;laoyao bye bye&lt;/p&gt; 不匹配： &lt;title&gt;wrong!&lt;/p&gt; 匹配一个开标签，可以使用正则 &lt;[^&gt;]+&gt;， 匹配一个闭标签，可以使用 &lt;\\/[^&gt;]+&gt;， 但是要求匹配成对标签，那就需要使用反向引用，如： const regex = /&lt;([^&gt;]+)&gt;[\\d\\D]*&lt;\\/\\1&gt;/; const string1 = '&lt;title&gt;regular expression&lt;/title&gt;'; const string2 = '&lt;p&gt;laoyao bye bye&lt;/p&gt;'; const string3 = '&lt;title&gt;wrong!&lt;/p&gt;'; console.log(regex.test(string1)); // true console.log(regex.test(string2)); // true console.log(regex.test(string3)); // false 其中开标签 &lt;[^&gt;]+&gt; 改成 &lt;([^&gt;]+)&gt;，使用括号的目的是为了后面使用反向引用，而提供分组。闭标签使用了反向引用，&lt;\\/\\1&gt;。 另外 [\\d\\D] 的意思是，这个字符是数字或者不是数字，因此，也就是匹配任意字符的意思。 第 3 章小结 正则中使用括号的例子那可是太多了，不一而足。 重点理解括号可以提供分组，我们可以提取数据，应该就可以了。 例子中的代码，基本没做多少分析，相信你都能看懂的。 第 4 章 正则表达式回溯法原理 学习正则表达式，是需要懂点儿匹配原理的。 而研究匹配原理时，有两个字出现的频率比较高：“回溯”。 听起来挺高大上，确实还有很多人对此不明不白的。 因此，本章就简单扼要地说清楚回溯到底是什么东西。 内容包括： 没有回溯的匹配 有回溯的匹配 常见的回溯形式 4.1 没有回溯的匹配 假设我们的正则是 /ab{1,3}c/，其可视化形式是： 而当目标字符串是 &quot;abbbc&quot; 时，就没有所谓的“回溯”。其匹配过程是： 其中子表达式 b{1,3} 表示 &quot;b&quot;字符连续出现 1 到 3 次。 4.2 有回溯的匹配 如果目标字符串是 &quot;abbc&quot;，中间就有回溯。 图中第 5 步有红颜色，表示匹配不成功。此时 b{1,3} 已经匹配到了 2 个字符 &quot;b&quot;，准备尝试第三个时，结果发现接下来的字符是 &quot;c&quot;。那么就认为 b{1,3} 就已经匹配完毕。然后状态又回到之前的状态（即第 6 步，与第 4 步一样），最后再用子表达式 c，去匹配字符 &quot;c&quot;。当然，此时整个表达式匹配成功了。 图中的第 6 步，就是“回溯”。 你可能对此没有感觉，这里我们再举一个例子。正则是： 目标字符串是 &quot;abbbc&quot;，匹配过程是： 其中第 7 步和第 10 步是回溯。第 7 步与第 4 步一样，此时 b{1,3} 匹配了两个 &quot;b&quot;，而第 10 步与第 3 步一样，此时 b{1,3} 只匹配了一个 &quot;b&quot;，这也是 b{1,3} 的最终匹配结果。 这里再看一个清晰的回溯，正则是： 目标字符串是：&quot;acd&quot;ef，匹配过程是： 图中省略了尝试匹配双引号失败的过程。可以看出 .* 是非常影响效率的。 为了减少一些不必要的回溯，可以把正则修改为 /&quot;[^&quot;]*&quot;/。 4.3 常见的回溯形式 正则表达式匹配字符串的这种方式，有个学名，叫回溯法。 回溯法也称试探法，它的基本思想是：从问题的某一种状态（初始状态）出发，搜索从这种状态出发所能达到的所有“状态”，当一条路走到“尽头”的时候（不能再前进），再后退一步或若干步，从另一种可能“状态”出发，继续搜索，直到所有的“路径”（状态）都试探过。这种不断“前进”、不断“回溯”寻找解的方法，就称作“回溯法”。（来自百度百科）。 本质上就是深度优先搜索算法。其中退到之前的某一步这一过程，我们称为“回溯”。从上面的描述过程中，可以看出，路走不通时，就会发生“回溯”。即，尝试匹配失败时，接下来的一步通常就是回溯。 道理，我们是懂了。那么 JS 中正则表达式会产生回溯的地方都有哪些呢？ 4.3.1 贪婪量词 之前的例子都是贪婪量词相关的。比如 b{1,3}，因为其是贪婪的，尝试可能的顺序是从多往少的方向去尝试。首先会尝试 &quot;bbb&quot;，然后再看整个正则是否能匹配。不能匹配时，吐出一个 &quot;b&quot;，即在 &quot;bb&quot; 的基础上，再继续尝试。如果还不行，再吐出一个，再试。如果还不行呢？只能说明匹配失败了。 虽然局部匹配是贪婪的，但也要满足整体能正确匹配。否则，皮之不存，毛将焉附？ 此时我们不禁会问，如果当多个贪婪量词挨着存在，并相互有冲突时，此时会是怎样？ 答案是，先下手为强！因为深度优先搜索。测试如下： const string = '12345'; const regex = /(\\d{1,3})(\\d{1,3})/; console.log(string.match(regex)); // =&gt; [&quot;12345&quot;, &quot;123&quot;, &quot;45&quot;, index: 0, input: &quot;12345&quot;] 其中，前面的 \\d{1,3} 匹配的是 &quot;123&quot;，后面的 \\d{1,3} 匹配的是 &quot;45&quot;。 4.3.2 惰性量词 惰性量词就是在贪婪量词后面加个问号。表示尽可能少的匹配，比如： const string = '12345'; const regex = /(\\d{1,3}?)(\\d{1,3})/; console.log(string.match(regex)); // =&gt; [&quot;1234&quot;, &quot;1&quot;, &quot;234&quot;, index: 0, input: &quot;12345&quot;] 其中 \\d{1,3}? 只匹配到一个字符 &quot;1&quot;，而后面的 \\d{1,3} 匹配了 &quot;234&quot;。 虽然惰性量词不贪，但也会有回溯的现象。比如正则是： 目标字符串是 &quot;12345&quot;，匹配过程是： 知道你不贪、很知足，但是为了整体匹配成，没办法，也只能给你多塞点了。因此最后 \\d{1,3}? 匹配的字符是 &quot;12&quot;，是两个数字，而不是一个。 4.3.3 分支结构 我们知道分支也是惰性的，比如/can|candy/，去匹配字符串&quot;candy&quot;，得到的结果是&quot;can&quot;，因为分支会一个一个尝试，如果前面的满足了，后面就不会再试验了。 分支结构，可能前面的子模式会形成了局部匹配，如果接下来表达式整体不匹配时，仍会继续尝试剩下的分支。这种尝试也可以看成一种回溯。 比如正则： 目标字符串是 &quot;candy&quot;，匹配过程： 上面第 5 步，虽然没有回到之前的状态，但仍然回到了分支结构，尝试下一种可能。所以，可以认为它是一种回溯的。 第 4 章小结 其实回溯法，很容易掌握的。 简单总结就是，正因为有多种可能，所以要一个一个试。直到，要么到某一步时，整体匹配成功了；要么最后都试完后，发现整体匹配不成功。 贪婪量词“试”的策略是：买衣服砍价。价钱太高了，便宜点，不行，再便宜点。 惰性量词“试”的策略是：卖东西加价。给少了，再多给点行不，还有点少啊，再给点。 分支结构“试”的策略是：货比三家。这家不行，换一家吧，还不行，再换。 既然有回溯的过程，那么匹配效率肯定低一些。相对谁呢？相对那些 DFA 引擎。 而 JS 的正则引擎是 NFA，NFA 是“非确定型有限自动机”的简写。 大部分语言中的正则都是 NFA，为啥它这么流行呢？ 答：你别看我匹配慢，但是我编译快啊，而且我还有趣哦。 第 5 章 正则表达式的拆分 对于一门语言的掌握程度怎么样，可以有两个角度来衡量：读和写。 不仅要求自己能解决问题，还要看懂别人的解决方案。代码是这样，正则表达式也是这样。 正则这门语言跟其他语言有一点不同，它通常就是一大堆字符，而没有所谓“语句”的概念。 如何能正确地把一大串正则拆分成一块一块的，成为了破解“天书”的关键。 本章就解决这一问题，内容包括： 结构和操作符 注意要点 案例分析 5.1 结构和操作符 编程语言一般都有操作符。只要有操作符，就会出现一个问题。当一大堆操作在一起时，先操作谁，又后操作谁呢？为了不产生歧义，就需要语言本身定义好操作顺序，即所谓的优先级。 而在正则表达式中，操作符都体现在结构中，即由特殊字符和普通字符所代表的一个个特殊整体。 JS 正则表达式中，都有哪些结构呢？ 字符字面量，匹配一个具体字符，包括不用转义的和需要转义的。比如 a 匹配字符 &quot;a&quot;，又比如 \\n 匹配换行符，又比如 \\. 匹配小数点。 字符组，匹配一个字符，可以是多种可能之一，比如 [0-9]，表示匹配一个数字。也有 \\d 的简写形式。另外还有反义字符组，表示可以是除了特定字符之外任何一个字符，比如 [^0-9]，表示一个非数字字符，也有 \\D的简写形式。 量词，表示一个字符连续出现，比如 a{1,3}表示 &quot;a&quot; 字符连续出现 3 次。另外还有常见的简写形式，比如 a+ 表示 &quot;a&quot; 字符连续出现至少一次。 锚字符，匹配一个位置，而不是字符。比如 ^ 匹配字符串的开头，又比如 \\b 匹配单词边界，又比如 (?=\\d) 表示数字前面的位置。 分组，用括号表示一个整体，比如 (ab)+，表示 &quot;ab&quot; 两个字符连续出现多次，也可以使用非捕获分组 (?:ab)+。 选择分支，多个子表达式多选一，比如 abc|bcd，表达式匹配 &quot;abc&quot; 或者 &quot;bcd&quot; 字符子串。 反向引用，比如 \\2，表示引用第 2 个分组。 其中涉及到的操作符有： 转义符 \\ 括号和方括号 (...)、(?:...)、(?=...)、(?!...)、[...] 量词限定符 {m}、{m,n}、{m,}、?、*、+ 位置和序列 ^、$、\\ 元字符、 一般字符 管道符（竖杠）| 上面操作符的优先级从上至下，由高到低。这里，我们来分析一个正则：/ab?(c|de*)+|fg/： 由于括号的存在，所以，(c|de*) 是一个整体结构。 在 (c|de*) 中，注意其中的量词 *，因此 e* 是一个整体结构。 又因为分支结构 | 优先级最低，因此 c 是一个整体、而 de* 是另一个整体。 同理，整个正则分成了 a、b?、(...)+、f、g。而由于分支的原因，又可以分成 ab?(c|de*)+ 和 fg 这两部分。 希望你没被我绕晕，上面的分析可用其可视化形式描述如下： 5.2 注意要点 关于结构和操作符，还是有几点需要强调： 2.1 匹配字符串整体问题 因为是要匹配整个字符串，我们经常会在正则前后中加上锚字符 ^ 和 $。 比如要匹配目标字符串 &quot;abc&quot; 或者 &quot;bcd&quot; 时，如果一不小心，就会写成 /^abc|bcd$/。 而位置字符和字符序列优先级要比竖杠高，故其匹配的结构是： 应该修改成： 5.2.2 量词连缀问题 假设，要匹配这样的字符串： 每个字符为a、b、c任选其一； 字符串的长度是 3 的倍数。 此时正则不能想当然地写成 /^[abc]{3}+$/，这样会报错，说 + 前面没什么可重复的： 此时要修改成： 5.2.3 元字符转义问题 所谓元字符，就是正则中有特殊含义的字符。 所有结构里，用到的元字符总结如下：^ $ . * + ? | \\ / ( ) [ ] { } = ! : - ,。 当匹配上面的字符本身时，可以一律转义： const string = '^$.*+?|\\\\/[]{}=!:-,'; const regex = /\\^\\$\\.\\*\\+\\?\\|\\\\\\/\\[\\]\\{\\}\\=\\!\\:\\-\\,/; console.log(regex.test(string)); // =&gt; true 其中 string 中的 \\ 字符也要转义的。 另外，在 string 中，也可以把每个字符转义，当然，转义后的结果仍是本身： const string = '^$.*+?|\\\\/[]{}=!:-,'; const string2 = '\\^\\$\\.\\*\\+\\?\\|\\\\\\/\\[\\]\\{\\}\\=\\!\\:\\-\\,'; console.log(string == string2); // =&gt; true 现在的问题是，是不是每个字符都需要转义呢？否，看情况。 5.2.3.1 字符组中的元字符 跟字符组相关的元字符有 []、^、-。因此在会引起歧义的地方进行转义。例如开头的 ^ 必须转义，不然会把整个字符组，看成反义字符组。 const string = '^$.*+?|\\\\/[]{}=!:-,'; const regex = /[\\^$.*+?|\\\\/\\[\\]{}=!:\\-,]/g; console.log(string.match(regex)); // =&gt; [&quot;^&quot;, &quot;$&quot;, &quot;.&quot;, &quot;*&quot;, &quot;+&quot;, &quot;?&quot;, &quot;|&quot;, &quot;\\&quot;, &quot;/&quot;, &quot;[&quot;, &quot;]&quot;, &quot;{&quot;, &quot;}&quot;, &quot;=&quot;, &quot;!&quot;, &quot;:&quot;, &quot;-&quot;, &quot;,&quot;] 5.2.3.2 匹配 &quot;[abc]&quot; 和 &quot;{3,5}&quot; 我们知道 [abc]，是个字符组。如果要匹配字符串 &quot;[abc]&quot; 时，该怎么办？ 可以写成 /\\[abc\\]/，也可以写成 /\\[abc]/，测试如下： const string = '[abc]'; const regex = /\\[abc]/g; console.log(string.match(regex)[0]); // =&gt; &quot;[abc]&quot; 只需要在第一个方括号转义即可，因为后面的方括号构不成字符组，正则不会引发歧义，自然不需要转义。 同理，要匹配字符串 &quot;{3,5}&quot;，只需要把正则写成 /\\{3,5}/ 即可。 另外，我们知道量词有简写形式 {m,}，却没有 {,n} 的情况。虽然后者不构成量词的形式，但此时并不会报错。当然，匹配的字符串也是 &quot;{,n}&quot;，测试如下： const string = '{,3}'; const regex = /{,3}/g; console.log(string.match(regex)[0]); // =&gt; &quot;{,3}&quot; 5.2.3.3 其余情况 比如 = ! : - , 等符号，只要不在特殊结构中，也不需要转义。 但是，括号需要前后都转义的，如 /\\(123\\)/。 至于剩下的 ^ $ . * + ? | \\ / 等字符，只要不在字符组内，都需要转义的。 5.3 案例分析 接下来分析两个例子，一个简单的，一个复杂的。 5.3.1 身份证 正则表达式是：/^(\\d{15}|\\d{17}[\\dxX])$/，因为竖杠 | 的优先级最低，所以正则分成了两部分 \\d{15} 和 \\d{17}[\\dxX]。 \\d{15} 表示 15 位连续数字。 \\d{17}[\\dxX] 表示 17 位连续数字，最后一位可以是数字可以大小写字母 &quot;x&quot;。 可视化如下： 5.3.2 IPv4 地址 正则表达式是： /^((0{0,2}\\d|0?\\d{2}|1\\d{2}|2[0-4]\\d|25[0-5])\\.){3}(0{0,2}\\d|0?\\d{2}|1\\d{2}|2[0-4]\\d|25[0-5])$/ 这个正则，看起来非常吓人。但是熟悉优先级后，会立马得出如下的结构： ((...)\\.){3}(...) 上面的两个 (...) 是一样的结构。表示匹配的是 3 位数字。因此整个结构是： 3位数.3位数.3位数.3位数 然后再来分析 (...)： (0{0,2}\\d|0?\\d{2}|1\\d{2}|2[0-4]\\d|25[0-5])(0{0,2}\\d|0?\\d{2}|1\\d{2}|2[0-4]\\d|25[0-5]) 它是一个多选结构，分成 5 个部分： 0{0,2}\\d，匹配一位数，包括 0 补齐的。比如 9、09、009； 0?\\d{2}，匹配两位数，包括 0 补齐的，也包括一位数； 1\\d{2}，匹配 100 到 199; 2[0-4]\\d，匹配 200-249； 25[0-5]，匹配 250-255。 最后来看一下其可视化形式： 第 5 章小结 掌握正则表达式中的优先级后，再看任何正则应该都有信心分析下去了。 至于例子，不一而足，没有写太多。 这里稍微总结一下，竖杠的优先级最低，即最后运算。 只要知道这一点，就能读懂大部分正则。 另外关于元字符转义问题，当自己不确定与否时，尽管去转义，总之是不会错的。 第 6 章 正则表达式的构建 对于一门语言的掌握程度怎么样，可以有两个角度来衡量：读和写。 不仅要看懂别人的解决方案，也要能独立地解决问题。代码是这样，正则表达式也是这样。 与“读”相比，“写”往往更为重要，这个道理是不言而喻的。 对正则的运用，首重就是：如何针对问题，构建一个合适的正则表达式？ 本章就解决该问题，内容包括： 平衡法则 构建正则前提 准确性 效率 6.1 平衡法则 构建正则有一点非常重要，需要做到下面几点的平衡： 匹配预期的字符串 不匹配非预期的字符串 可读性和可维护性 效率 6.2 构建正则前提 6.2.1 是否能使用正则 正则太强大了，以至于我们随便遇到一个操作字符串问题时，都会下意识地去想，用正则该怎么做。但我们始终要提醒自己，正则虽然强大，但不是万能的，很多看似很简单的事情，还是做不到的。 比如匹配这样的字符串：1010010001.... 虽然很有规律，但是只靠正则就是无能为力。 6.2.2 是否有必要使用正则 要认识到正则的局限，不要去研究根本无法完成的任务。同时，也不能走入另一个极端：无所不用正则。能用字符串API解决的简单问题，就不该正则出马。 比如，从日期中提取出年月日，虽然可以使用正则： const string = '2017-07-01'; const regex = /^(\\d{4})-(\\d{2})-(\\d{2})/; console.log(string.match(regex)); // =&gt; [&quot;2017-07-01&quot;, &quot;2017&quot;, &quot;07&quot;, &quot;01&quot;, index: 0, input: &quot;2017-07-01&quot;] 其实，可以使用字符串的 split 方法来做，即可： const string = '2017-07-01'; const result = string.split('-'); console.log(result); // =&gt; [&quot;2017&quot;, &quot;07&quot;, &quot;01&quot;] 比如，判断是否有问号，虽然可以使用： const string = '?id=xx&amp;act=search'; console.log(string.search(/\\?/)); // =&gt; 0 其实，可以使用字符串的 indexOf 方法： const string = '?id=xx&amp;act=search'; console.log(string.indexOf('?')); // =&gt; 0 比如获取子串，虽然可以使用正则： const string = 'JavaScript'; console.log(string.match(/.{4}(.+)/)[1]); // =&gt; Script 其实，可以直接使用字符串的 substring 或 substr 方法来做： const string = 'JavaScript'; console.log(string.substring(4)); // =&gt; Script 6.2.3 是否有必要构建一个复杂的正则 比如密码匹配问题，要求密码长度 6-12 位，由数字、小写字符和大写字母组成，但必须至少包括 2 种字符。 在第 2 章里，我们写出了正则是：/(?!^[0-9]{6,12}$)(?!^[a-z]{6,12}$)(?!^[A-Z]{6,12}$)^[0-9A-Za-z]{6,12}$/ 其实可以使用多个小正则来做： const regex1 = /^[0-9A-Za-z]{6,12}$/; const regex2 = /^[0-9]{6,12}$/; const regex3 = /^[A-Z]{6,12}$/; const regex4 = /^[a-z]{6,12}$/; function checkPassword(string) { if (!regex1.test(string)) return false; if ( regex2.test(string)) return false; if ( regex3.test(string)) return false; if ( regex4.test(string)) return false; return true; } 6.3. 准确性 所谓准确性，就是能匹配预期的目标，并且不匹配非预期的目标。 这里提到了“预期”二字，那么我们就需要知道目标的组成规则。 不然没法界定什么样的目标字符串是符合预期的，什么样的又不是符合预期的。 下面将举例说明，当目标字符串构成比较复杂时，该如何构建正则，并考虑到哪些平衡。 6.3.1 匹配固定电话 比如要匹配如下格式的固定电话号码： 055188888888 0551-88888888 (0551)88888888 第一步，了解各部分的模式规则。 上面的电话，总体上分为区号和号码两部分（不考虑分机号和 +86 的情形）。 区号是 0 开头的 3 到 4 位数字，对应的正则是：0\\d{2,3} 号码是非 0 开头的 7 到 8 位数字，对应的正则是：[1-9]\\d{6,7} 因此，匹配 055188888888 的正则是：/^0\\d{2,3}[1-9]\\d{6,7}$/ 匹配 0551-88888888 的正则是：/^0\\d{2,3}-[1-9]\\d{6,7}$/ 匹配 (0551)88888888 的正则是：/^\\(0\\d{2,3}\\)[1-9]\\d{6,7}$/ 第二步，明确形式关系。 这三者情形是或的关系，可以构建分支： /^0\\d{2,3}[1-9]\\d{6,7}$|^0\\d{2,3}-[1-9]\\d{6,7}$|^\\(0\\d{2,3}\\)[1-9]\\d{6,7}$/ 提取公共部分： /^(0\\d{2,3}|0\\d{2,3}-|\\(0\\d{2,3}\\))[1-9]\\d{6,7}$/ 进一步简写： /^(0\\d{2,3}-?|\\(0\\d{2,3}\\))[1-9]\\d{6,7}$/ 其可视化形式： 上面的正则构建过程略显罗嗦，但是这样做，能保证正则是准确的。 上述三种情形是或的关系，这一点很重要，不然很容易按字符是否出现的情形把正则写成： /^\\(?0\\d{2,3}\\)?-?[1-9]\\d{6,7}$/ 虽然也能匹配上述目标字符串，但也会匹配 (0551-88888888 这样的字符串。当然，这不是我们想要的。 其实这个正则也不是完美的，因为现实中，并不是每个 3 位数和 4 位数都是一个真实的区号。 这就是一个平衡取舍问题，一般够用就行。 6.3.2 匹配浮点数 要求匹配如下的格式： 1.23、+1.23、-1.23 10、+10、-10 .2、+.2、-.2 可以看出正则分为三部分。 符号部分：[+-] 整数部分：\\d+ 小数部分：\\.\\d+ 上述三个部分，并不是全部都出现。如果此时很容易写出如下的正则： /^[+-]?(\\d+)?(\\.\\d+)?$/ 此正则看似没问题，但这个正则也会匹配空字符&quot;&quot;。 因为目标字符串的形式关系不是要求每部分都是可选的。 要匹配 1.23、+1.23、-1.23，可以用 /^[+-]?\\d+\\.\\d+$/ 要匹配 10、+10、-10，可以用 /^[+-]?\\d+$/ 要匹配.2、+.2、-.2，可以用 /^[+-]?\\.\\d+$/ 因此整个正则是这三者的或的关系，提取公众部分后是： /^[+-]?(\\d+\\.\\d+|\\d+|\\.\\d+)$/ 其可视化形式是： 如果要求不匹配 +.2 和 -.2，此时正则变成： /^([+-]?(\\d+\\.\\d+|\\d+)|\\.\\d+)$/ 其可视化形式是： 当然，/^[+-]?(\\d+\\.\\d+|\\d+|\\.\\d+)$/ 也不是完美的，我们也是做了些取舍，比如： 它也会匹配 012 这样以 0 开头的整数。如果要求不匹配的话，需要修改整数部分的正则。 一般进行验证操作之前，都要经过 trim 和判空。那样的话，也许那个错误正则也就够用了。 也可以进一步改写成：/^[+-]?(\\d+)?(\\.)?\\d+$/，这样我们就需要考虑可读性和可维护性了。 6.4 效率 保证了准确性后，才需要是否要考虑要优化。大多数情形是不需要优化的，除非运行的非常慢。什么情形正则表达式运行才慢呢？我们需要考察正则表达式的运行过程（原理）。 正则表达式的运行分为如下的阶段： 编译； 设定起始位置； 尝试匹配； 匹配失败的话，从下一位开始继续第 3 步； 最终结果：匹配成功或失败。 下面以代码为例，来看看这几个阶段都做了什么： const regex = /\\d+/g; console.log(regex.lastIndex, regex.exec('123abc34def')); console.log(regex.lastIndex, regex.exec('123abc34def')); console.log(regex.lastIndex, regex.exec('123abc34def')); console.log(regex.lastIndex, regex.exec('123abc34def')); // =&gt; 0 [&quot;123&quot;, index: 0, input: &quot;123abc34def&quot;] // =&gt; 3 [&quot;34&quot;, index: 6, input: &quot;123abc34def&quot;] // =&gt; 8 null // =&gt; 0 [&quot;123&quot;, index: 0, input: &quot;123abc34def&quot;] 具体分析如下： const regex = /\\d+/g; 当生成一个正则时，引擎会对其进行编译。报错与否出现这这个阶段。 regex.exec('123abc34def') 当尝试匹配时，需要确定从哪一位置开始匹配。一般情形都是字符串的开头，即第 0 位。 但当使用 test 和 exec 方法，且正则有 g 时，起始位置是从正则对象的 lastIndex 属性开始。 因此第一次 exec 是从第 0 位开始，而第二次是从 3 开始的。 设定好起始位置后，就开始尝试匹配了。 比如第一次 exec，从 0 开始，去尝试匹配，并且成功地匹配到 3 个数字。此时结束时的下标是 2，因此下一次的起始位置是 3。 而第二次，起始下标是 3，但第 3 个字符是 &quot;a&quot;，并不是数字。但此时并不会直接报匹配失败，而是移动到下一位置，即从第 4 位开始继续尝试匹配，但该字符是 b，也不是数字。再移动到下一位，是 c 仍不行，再移动一位是数字 3，此时匹配到了两位数字 34。此时，下一次匹配的位置是 d 的位置，即第 8 位。 第三次，是从第 8 位开始匹配，直到试到最后一位，也没发现匹配的，因此匹配失败，返回 null。同时设置 lastIndex 为 0，即，如要再尝试匹配的话，需从头开始。 从上面可以看出，匹配会出现效率问题，主要出现在上面的第 3 阶段和第 4 阶段。 因此，主要优化手法也是针对这两阶段的。 6.4.1 使用具体型字符组来代替通配符，来消除回溯 而在第三阶段，最大的问题就是回溯。 例如，匹配双引用号之间的字符。如，匹配字符串 123&quot;abc&quot;456 中的 &quot;abc&quot;。 如果正则用的是：/&quot;.*&quot;/，会在第 3 阶段产生 4 次回溯（粉色表示 .* 匹配的内容）： 如果正则用的是：/&quot;.*?&quot;/，会产生 2 次回溯（粉色表示 .*? 匹配的内容）： 因为回溯的存在，需要引擎保存多种可能中未尝试过的状态，以便后续回溯时使用。注定要占用一定的内存。 此时要使用具体化的字符组，来代替通配符.，以便消除不必要的字符，此时使用正则 /&quot;[^&quot;]*&quot;/，即可。 6.4.2 使用非捕获型分组 因为括号的作用之一是，可以捕获分组和分支里的数据。那么就需要内存来保存它们。 当我们不需要使用分组引用和反向引用时，此时可以使用非捕获分组。例如： /^[+-]?(\\d+\\.\\d+|\\d+|\\.\\d+)$/ 可以修改成：/^[+-]?(?:\\d+\\.\\d+|\\d+|\\.\\d+)$/ 6.4.3 独立出确定字符 例如 /a+/，可以修改成 /aa*/。 因为后者能比前者多确定了字符 a。这样会在第四步中，加快判断是否匹配失败，进而加快移位的速度。 6.4.4 提取分支公共部分 比如 /^abc|^def/，修改成 /^(?:abc|def)/。 又比如 /this|that/，修改成 /th(?:is|at)/。 这样做，可以减少匹配过程中可消除的重复。 6.4.5 减少分支的数量，缩小它们的范围 /red|read/，可以修改成 /rea?d/。此时分支和量词产生的回溯的成本是不一样的。但这样优化后，可读性会降低的。 第 6 章小结 本章涉及的内容并不多。一般情况下，针对某问题能写出一个满足需求的正则，基本上就可以了。至于准确性和效率方面的追求，纯属看个人要求了。我觉得够用就行了。关于准确性，本章关心的是最常用的解决思路：针对每种情形，分别写出正则，然用分支把他们合并在一起，再提取分支公共部分，就能得到准确的正则。至于优化，本章没有为了凑数，去写一大堆。了解了匹配原理，常见的优化手法也就这么几种。 第 7 章 正则表达式编程 什么叫知识，能指导我们实践的东西才叫知识。学习一样东西，如果不能使用，最多只能算作纸上谈兵。 正则表达式的学习，也不例外。掌握了正则表达式的语法后，下一步，也是关键的一步，就是在真实世界中使用它。那么如何使用正则表达式呢？有哪些关键的点呢？本章就解决这个问题。内容包括： 正则表达式的四种操作 相关API注意要点 真实案例 7.1 正则表达式的四种操作 正则表达式是匹配模式，不管如何使用正则表达式，万变不离其宗，都需要先“匹配”。 有了匹配这一基本操作后，才有其他的操作：验证、切分、提取、替换。 进行任何相关操作，也需要宿主引擎相关 API 的配合使用。当然，在 JS 中，相关 API 也不多。 7.1.1 验证 验证是正则表达式最直接的应用，比如表单验证。 在说验证之前，先要说清楚匹配是什么概念。 所谓匹配，就是看目标字符串里是否有满足匹配的子串。因此，“匹配”的本质就是“查找”。 有没有匹配，是不是匹配上，判断是否的操作，即称为“验证”。 这里举一个例子，来看看如何使用相关API进行验证操作的。 比如，判断一个字符串中是否有数字。 使用 search const regex = /\\d/; const string = 'abc123'; console.log(!!~string.search(regex)); // =&gt; true 使用 test const regex = /\\d/; const string = 'abc123'; console.log(regex.test(string)); // =&gt; true 使用 match const regex = /\\d/; const string = 'abc123'; console.log(!!string.match(regex)); // =&gt; true 使用 exec const regex = /\\d/; const string = 'abc123'; console.log(!!regex.exec(string)); // =&gt; true 其中，最常用的是 test。 7.1.2 切分 匹配上了，我们就可以进行一些操作，比如切分。 所谓“切分”，就是把目标字符串，切成一段一段的。在 JS 中使用的是 split。 比如，目标字符串是 &quot;html,css,javascript&quot;，按逗号来切分： const regex = /,/; const string = 'html,css,javascript'; console.log(string.split(regex)); // =&gt; [&quot;html&quot;, &quot;css&quot;, &quot;javascript&quot;] 又比如，如下的日期格式： 2017/06/26 2017.06.26 2017-06-26 可以使用 split“切出”年月日： const regex = /\\D/; console.log('2017/06/26'.split(regex)); console.log('2017.06.26'.split(regex)); console.log('2017-06-26'.split(regex)); // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;26&quot;] // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;26&quot;] // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;26&quot;] 7.1.3 提取 虽然整体匹配上了，但有时需要提取部分匹配的数据。 此时正则通常要使用分组引用（分组捕获）功能，还需要配合使用相关 API。 这里，还是以日期为例，提取出年月日。注意下面正则中的括号： match const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; console.log(string.match(regex)); // =&gt;[&quot;2017-06-26&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;26&quot;, index: 0, input: &quot;2017-06-26&quot;] exec const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; console.log(regex.exec(string)); // =&gt;[&quot;2017-06-26&quot;, &quot;2017&quot;, &quot;06&quot;, &quot;26&quot;, index: 0, input: &quot;2017-06-26&quot;] test const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; regex.test(string); console.log(RegExp.$1, RegExp.$2, RegExp.$3); // =&gt; &quot;2017&quot; &quot;06&quot; &quot;26&quot; search const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; string.search(regex); console.log(RegExp.$1, RegExp.$2, RegExp.$3); // =&gt; &quot;2017&quot; &quot;06&quot; &quot;26&quot; replace const regex = /^(\\d{4})\\D(\\d{2})\\D(\\d{2})$/; const string = '2017-06-26'; const date = []; string.replace(regex, function(match, year, month, day) { date.push(year, month, day); }); console.log(date); // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;26&quot;] 其中，最常用的是 match。 7.1.4 替换 找，往往不是目的，通常下一步是为了替换。在 JS 中，使用 replace 进行替换。 比如把日期格式，从 yyyy-mm-dd 替换成 yyyy/mm/dd： const string = '2017-06-26'; const today = new Date(string.replace(/-/g, '/')); console.log(today); // =&gt; Mon Jun 26 2017 00:00:00 GMT+0800 (中国标准时间) 这里只是简单地应用了一下 replace。但，replace 方法是强大的，是需要重点掌握的。 7.2. 相关API注意要点 从上面可以看出用于正则操作的方法，共有 6 个，字符串实例 4 个，正则实例 2 个： String#search String#split String#match String#replace RegExp#test RegExp#exec 本文不打算详细地讲解它们的方方面面细节，具体可以参考《JavaScript权威指南》的第三部分。本文重点列出一些容易忽视的地方，以飨读者。 7.2.1 search 和 match 的参数问题 我们知道字符串实例的那 4 个方法参数都支持正则和字符串。 但 search 和 match，会把字符串转换为正则的。 const string = '2017.06.27'; console.log(string.search('.')); // =&gt; 0 //需要修改成下列形式之一 console.log(string.search('\\\\.')); console.log(string.search(/\\./)); // =&gt; 4 // =&gt; 4 console.log(string.match('.')); // =&gt; [&quot;2&quot;, index: 0, input: &quot;2017.06.27&quot;] //需要修改成下列形式之一 console.log(string.match('\\\\.')); console.log(string.match(/\\./)); // =&gt; [&quot;.&quot;, index: 4, input: &quot;2017.06.27&quot;] // =&gt; [&quot;.&quot;, index: 4, input: &quot;2017.06.27&quot;] console.log(string.split('.')); // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;27&quot;] console.log(string.replace('.', '/')); // =&gt; &quot;2017/06.27&quot; 7.2.2 match 返回结果的格式问题 match 返回结果的格式，与正则对象是否有修饰符 g 有关。 const string = '2017.06.27'; const regex1 = /\\b(\\d+)\\b/; const regex2 = /\\b(\\d+)\\b/g; console.log(string.match(regex1)); console.log(string.match(regex2)); // =&gt; [&quot;2017&quot;, &quot;2017&quot;, index: 0, input: &quot;2017.06.27&quot;] // =&gt; [&quot;2017&quot;, &quot;06&quot;, &quot;27&quot;] 没有 g，返回的是标准匹配格式，即，数组的第一个元素是整体匹配的内容，接下来是分组捕获的内容，然后是整体匹配的第一个下标，最后是输入的目标字符串。 有 g，返回的是所有匹配的内容。 当没有匹配时，不管有无 g，都返回 null。 7.2.3 exec比match更强大 当正则没有 g 时，使用 match 返回的信息比较多。但是有 g 后，就没有关键的信息 index 了。 而 exec 方法就能解决这个问题，它能接着上一次匹配后继续匹配： const string = '2017.06.27'; const regex2 = /\\b(\\d+)\\b/g; console.log(regex2.exec(string)); console.log(regex2.lastIndex); console.log(regex2.exec(string)); console.log(regex2.lastIndex); console.log(regex2.exec(string)); console.log(regex2.lastIndex); console.log(regex2.exec(string)); console.log(regex2.lastIndex); // =&gt; [&quot;2017&quot;, &quot;2017&quot;, index: 0, input: &quot;2017.06.27&quot;] // =&gt; 4 // =&gt; [&quot;06&quot;, &quot;06&quot;, index: 5, input: &quot;2017.06.27&quot;] // =&gt; 7 // =&gt; [&quot;27&quot;, &quot;27&quot;, index: 8, input: &quot;2017.06.27&quot;] // =&gt; 10 // =&gt; null // =&gt; 0 其中正则实例 lastIndex 属性，表示下一次匹配开始的位置。 比如第一次匹配了 &quot;2017&quot;，开始下标是 0，共 4 个字符，因此这次匹配结束的位置是 3，下一次开始匹配的位置是 4。 从上述代码看出，在使用 exec 时，经常需要配合使用 while 循环： const string = '2017.06.27'; const regex2 = /\\b(\\d+)\\b/g; const result; while (result = regex2.exec(string)) { console.log(result, regex2.lastIndex); } // =&gt; [&quot;2017&quot;, &quot;2017&quot;, index: 0, input: &quot;2017.06.27&quot;] 4 // =&gt; [&quot;06&quot;, &quot;06&quot;, index: 5, input: &quot;2017.06.27&quot;] 7 // =&gt; [&quot;27&quot;, &quot;27&quot;, index: 8, input: &quot;2017.06.27&quot;] 10 7.2.4 修饰符g，对exex和test的影响 上面提到了正则实例的 lastIndex 属性，表示尝试匹配时，从字符串的 lastIndex 位开始去匹配。 字符串的四个方法，每次匹配时，都是从 0 开始的，即 lastIndex 属性始终不变。 而正则实例的两个方法 exec、test，当正则是全局匹配时，每一次匹配完成后，都会修改 lastIndex。下面让我们以 test 为例，看看你是否会迷糊： const regex = /a/g; console.log(regex.test('a'), regex.lastIndex); console.log(regex.test('aba'), regex.lastIndex); console.log(regex.test('ababc'), regex.lastIndex); // =&gt; true 1 // =&gt; true 3 // =&gt; false 0 注意上面代码中的第三次调用 test，因为这一次尝试匹配，开始从下标 lastIndex 即 3 位置处开始查找，自然就找不到了。 如果没有 g，自然都是从字符串第 0 个字符处开始尝试匹配： const regex = /a/; console.log(regex.test('a'), regex.lastIndex); console.log(regex.test('aba'), regex.lastIndex); console.log(regex.test('ababc'), regex.lastIndex); // =&gt; true 0 // =&gt; true 0 // =&gt; true 0 7.2.5 test 整体匹配时需要使用 ^ 和 $ 这个相对容易理解，因为 test 是看目标字符串中是否有子串匹配正则，即有部分匹配即可。 如果，要整体匹配，正则前后需要添加开头和结尾： console.log(/123/.test('a123b')); // =&gt; true console.log(/^123$/.test('a123b')); // =&gt; false console.log(/^123$/.test('123')); // =&gt; true 7.2.6 split 相关注意事项 split 方法看起来不起眼，但要注意的地方有两个的。 第一，它可以有第二个参数，表示结果数组的最大长度： const string = 'html,css,javascript'; console.log(string.split(/,/, 2)); // =&gt;[&quot;html&quot;, &quot;css&quot;] 第二，正则使用分组时，结果数组中是包含分隔符的： const string = 'html,css,javascript'; console.log(string.split(/(,)/)); // =&gt;[&quot;html&quot;, &quot;,&quot;, &quot;css&quot;, &quot;,&quot;, &quot;javascript&quot;] 7.2.7 replace 是很强大的 《JavaScript权威指南》认为 exec 是这 6 个 API 中最强大的，而我始终认为 replace 才是最强大的。因为它也能拿到该拿到的信息，然后可以假借替换之名，做些其他事情。 总体来说 replace 有两种使用形式，这是因为它的第二个参数，可以是字符串，也可以是函数。 当第二个参数是字符串时，如下的字符有特殊的含义： $1,$2,...,$99 匹配第 1~99 个分组里捕获的文本 $&amp; 匹配到的子串文本 $` 匹配到的子串的左边文本 $' 匹配到的子串的右边文本 $$ 美元符号 例如，把 &quot;2,3,5&quot;，变成 &quot;5=2+3&quot;： const result = '2,3,5'.replace(/(\\d+),(\\d+),(\\d+)/, '$3=$1+$2'); console.log(result); // =&gt; &quot;5=2+3&quot; 又例如，把 &quot;2,3,5&quot;，变成 &quot;222,333,555&quot;: const result = '2,3,5'.replace(/(\\d+)/g, '$&amp;$&amp;$&amp;'); console.log(result); // =&gt; &quot;222,333,555&quot; 当第二个参数是函数时，我们需要注意该回调函数的参数具体是什么： '1234 2345 3456'.replace(/(\\d)\\d{2}(\\d)/g, function(match, $1, $2, index, input) { console.log([match, $1, $2, index, input]); }); // =&gt; [&quot;1234&quot;, &quot;1&quot;, &quot;4&quot;, 0, &quot;1234 2345 3456&quot;] // =&gt; [&quot;2345&quot;, &quot;2&quot;, &quot;5&quot;, 5, &quot;1234 2345 3456&quot;] // =&gt; [&quot;3456&quot;, &quot;3&quot;, &quot;6&quot;, 10, &quot;1234 2345 3456&quot;] 此时我们可以看到 replace 拿到的信息，并不比 exec 少。 7.2.8 使用构造函数需要注意的问题 一般不推荐使用构造函数生成正则，而应该优先使用字面量。因为用构造函数会多写很多 \\。 const string = '2017-06-27 2017.06.27 2017/06/27'; const regex = /\\d{4}(-|\\.|\\/)\\d{2}\\1\\d{2}/g; console.log(string.match(regex)); // =&gt; [&quot;2017-06-27&quot;, &quot;2017.06.27&quot;, &quot;2017/06/27&quot;] regex = new RegExp('\\\\d{4}(-|\\\\.|\\\\/)\\\\d{2}\\\\1\\\\d{2}', 'g'); console.log(string.match(regex)); // =&gt; [&quot;2017-06-27&quot;, &quot;2017.06.27&quot;, &quot;2017/06/27&quot;] 7.2.9 修饰符 ES5中修饰符，共3个： g 全局匹配，即找到所有匹配的，单词是 global i 忽略字母大小写，单词 ingoreCase m 多行匹配，只影响 ^ 和 $，二者变成行的概念，即行开头和行结尾。单词是 multiline 当然正则对象也有相应的只读属性： const regex = /\\w/img; console.log(regex.global); console.log(regex.ignoreCase); console.log(regex.multiline); // =&gt; true // =&gt; true // =&gt; true 7.2.10 source 属性 正则实例对象属性，除了 global、ingnoreCase、multiline、lastIndex 属性之外，还有一个 source 属性。 它什么时候有用呢？ 比如，在构建动态的正则表达式时，可以通过查看该属性，来确认构建出的正则到底是什么： const className = 'high'; const regex = new RegExp('(^|\\\\s)' + className + '(\\\\s|$)'); console.log(regex.source) // =&gt; (^|\\s)high(\\s|$) 即字符串&quot;(^|\\\\s)high(\\\\s|$)&quot; 7.2.11 构造函数属性 构造函数的静态属性基于所执行的最近一次正则操作而变化。除了是 $1,...,$9 之外，还有几个不太常用的属性（有兼容性问题）： RegExp.input 最近一次目标字符串，简写成 RegExp[&quot;$_&quot;] RegExp.lastMatch 最近一次匹配的文本，简写成 RegExp[&quot;$&amp;&quot;] RegExp.lastParen 最近一次捕获的文本，简写成 RegExp[&quot;$+&quot;] RegExp.leftContext 目标字符串中 lastMatch 之前的文本，简写成 RegExp[&quot;$`&quot;] RegExp.rightContext 目标字符串中 lastMatch 之后的文本，简写成 RegExp[&quot;$'&quot;] 测试代码如下： const regex = /([abc])(\\d)/g; const string = 'a1b2c3d4e5'; string.match(regex); console.log(RegExp.input); console.log(RegExp['$_']); // =&gt; &quot;a1b2c3d4e5&quot; console.log(RegExp.lastMatch); console.log(RegExp['$&amp;']); // =&gt; &quot;c3&quot; console.log(RegExp.lastParen); console.log(RegExp['$+']); // =&gt; &quot;3&quot; console.log(RegExp.leftContext); console.log(RegExp[&quot;$`&quot;]); // =&gt; &quot;a1b2&quot; console.log(RegExp.rightContext); console.log(RegExp[&quot;$'&quot;]); // =&gt; &quot;d4e5&quot; 7.3 真实案例 7.3.1 使用构造函数生成正则表达式 我们知道要优先使用字面量来创建正则，但有时正则表达式的主体是不确定的，此时可以使用构造函数来创建。模拟 getElementsByClassName 方法，就是很能说明该问题的一个例子。 这里 getElementsByClassName 函数的实现思路是： 比如要获取 className 为 &quot;high&quot; 的 dom 元素； 首先生成一个正则：/(^|\\s)high(\\s|$)/； 然后再用其逐一验证页面上的所有 dom 元素的类名，拿到满足匹配的元素即可。 代码如下(可以直接复制到本地查看运行效果)： &lt;p class=&quot;high&quot;&gt;1111&lt;/p&gt; &lt;p class=&quot;high&quot;&gt;2222&lt;/p&gt; &lt;p&gt;3333&lt;/p&gt; &lt;script&gt; function getElementsByClassName(className) { var elements = document.getElementsByTagName(&quot;*&quot;); var regex = new RegExp(&quot;(^|\\\\s)&quot; + className + &quot;(\\\\s|$)&quot;); var result = []; for (var i = 0; i &lt; elements.length; i++) { var element = elements[i]; if (regex.test(element.className)) { result.push(element) } } return result; } var highs = getElementsByClassName('high'); highs.forEach(function(item) { item.style.color = 'red'; }); &lt;/script&gt; 7.3.2 使用字符串保存数据 一般情况下，我们都愿意使用数组来保存数据。但我看到有的框架中，使用的却是字符串。 使用时，仍需要把字符串切分成数组。虽然不一定用到正则，但总感觉酷酷的，这里分享如下： const utils = {}; 'Boolean|Number|String|Function|Array|Date|RegExp|Object|Error'.split('|').forEach(function(item) { utils['is' + item] = function(obj) { return {}.toString.call(obj) == '[object ' + item + ']'; }; }); console.log( utils.isArray([1, 2, 3]) ); // =&gt; true 7.3.3 if 语句中使用正则替代 &amp;&amp; 比如，模拟 ready 函数，即加载完毕后再执行回调（不兼容 IE 的）： const readyRE = /complete|loaded|interactive/; function ready(callback) { if (readyRE.test(document.readyState) &amp;&amp; document.body) { callback() } else { document.addEventListener( 'DOMContentLoaded', function () { callback() }, false ); } }; ready(function() { alert('加载完毕！') }); 7.3.4 使用强大的 replace 因为 replace 方法比较强大，有时用它根本不是为了替换，只是拿其匹配到的信息来做文章。 这里以查询字符串（querystring）压缩技术为例，注意下面 replace 方法中，回调函数根本没有返回任何东西。 function compress(source) { var keys = {}; source.replace(/([^=&amp;]+)=([^&amp;]*)/g, function(full, key, value) { keys[key] = (keys[key] ? keys[key] + ',' : '') + value; }); var result = []; for (var key in keys) { result.push(key + '=' + keys[key]); } return result.join('&amp;'); } console.log(compress(&quot;a=1&amp;b=2&amp;a=3&amp;b=4&quot;)); // =&gt; &quot;a=1,3&amp;b=2,4&quot; 7.3.5 综合运用 最后这里再做个简单实用的正则测试器。 具体效果如下： 代码，直接贴了，相信你能看得懂： &lt;section&gt; &lt;div id=&quot;err&quot;&gt;&lt;/div&gt; &lt;input id=&quot;regex&quot; placeholder=&quot;请输入正则表达式&quot;&gt; &lt;input id=&quot;text&quot; placeholder=&quot;请输入测试文本&quot;&gt; &lt;button id=&quot;run&quot;&gt;测试一下&lt;/button&gt; &lt;div id=&quot;result&quot;&gt;&lt;/div&gt; &lt;/section&gt; &lt;style&gt; section{ display:flex; flex-direction:column; justify-content:space-around; height:300px; padding:0 200px; } section *{ min-height:30px; } #err { color:red; } #result{ line-height:30px; } .info { background:#00c5ff; padding:2px; margin:2px; display:inline-block; } &lt;/style&gt; &lt;script&gt; (function() { // 获取相应dom元素 var regexInput = document.getElementById(&quot;regex&quot;); var textInput = document.getElementById(&quot;text&quot;); var runBtn = document.getElementById(&quot;run&quot;); var errBox = document.getElementById(&quot;err&quot;); var resultBox = document.getElementById(&quot;result&quot;); // 绑定点击事件 runBtn.onclick = function() { // 清除错误和结果 errBox.innerHTML = &quot;&quot;; resultBox.innerHTML = &quot;&quot;; // 获取正则和文本 var text = textInput.value; var regex = regexInput.value; if (regex == &quot;&quot;) { errBox.innerHTML = &quot;请输入正则表达式&quot;; } else if (text == &quot;&quot;) { errBox.innerHTML = &quot;请输入测试文本&quot;; } else { regex = createRegex(regex); if (!regex) return; var result, results = []; // 没有修饰符g的话，会死循环 if (regex.global) { while(result = regex.exec(text)) { results.push(result); } } else { results.push(regex.exec(text)); } if (results[0] == null) { resultBox.innerHTML = &quot;匹配到0个结果&quot;; return; } // 倒序是有必要的 for (var i = results.length - 1; i &gt;= 0; i--) { var result = results[i]; var match = result[0]; var prefix = text.substr(0, result.index); var suffix = text.substr(result.index + match.length); text = prefix + '&lt;span class=&quot;info&quot;&gt;' + match + '&lt;/span&gt;' + suffix; } resultBox.innerHTML = &quot;匹配到&quot; + results.length + &quot;个结果:&lt;br&gt;&quot; + text; } }; // 生成正则表达式，核心函数 function createRegex(regex) { try { if (regex[0] == &quot;/&quot;) { regex = regex.split(&quot;/&quot;); regex.shift(); var flags = regex.pop(); regex = regex.join(&quot;/&quot;); regex = new RegExp(regex, flags); } else { regex = new RegExp(regex, &quot;g&quot;); } return regex; } catch(e) { errBox.innerHTML = &quot;无效的正则表达式&quot;; return false; } } })(); &lt;/script&gt; 第 7 章小结 相关API的注意点，本章基本上算是一网打尽了。 至于文中的例子，都是点睛之笔，没有详细解析。如有理解不透的，建议自己敲一敲。 后记 文章要结束了，最后还要有几点说明。 1. 需要注意的地方 本文主要讨论的是 JavaScript 的正则表达式，更精确地说是 ES5 的正则表达式。 JavaScript 的正则表达式引擎是传统型 NFA 的，因此本系列的讨论是适合任何一门正则引擎是传统型 NFA 的编程语言。当然，市面上大部分语言的正则引擎都是这种的。而 JS 里正则涉及到的所有语法要点，是这种引擎支持的核心子集。也就是说，要学正则表达式，不妨以 JS 正则为出发点。 2. 参考资料 当然本文不是无本之末。主要参考的是几本书籍。 以下书籍中核心章节都认真阅读过，甚至阅读多遍。 《JavaScript权威指南》，看完本系列，再去看书中的第 10 章，你就知道了什么叫字字珠玑。 《精通正则表达式》，权威且比较杂乱，我阅读的第一本正则表达式书籍。 《正则表达式必知必会》，这是我看的第二本正则，看完后，确定自己算是入门了。 《正则指引》，《精通正则表达式》的译者写的，相对清晰。 《正则表达式入门》，我看的是英文版的，对于已经入门的我，基本没多少收获了。 《正则表达式经典实例》，除了第 3 章，比较杂外，也有收获，以实例为主导的一本书。 《JavaScript Regular Expressions》，为数不多转讲 JS 正则的。页数不多，也有收获。 《高性能JavaScript 》第 5 章，我看的是英文版的。第 5 章，讲了回溯和优化。 《JavaScript忍者秘籍》第 7 章，大概讲了一下正则的用法，几个例子还不错。 《JavaScript高级程序设计》第 5.4 节，比较简短的介绍。 使用的工具： Regulex，一款可视化工具 ProcessOn - 免费在线作图，实时协作 LICEcap – 灵活好用，GIF 屏幕录制工具 ","link":"https://faded.auspicious.space/post/regular-expression-full-tutorial/"},{"title":"正则表达式——断言人话版","content":" 这次不会说我的正则教程没写全了吧？？ 零宽断言 断言：俗话的断言就是“我断定什么什么”，而正则中的断言，就是说正则可以指明在指定内容的前面或后面会出现满足指定规则的内容，意思正则也可以像人类那样断定什么什么，比如“ss1aa2bb3”，正则可以用断言找出 aa2 前面有 bb3，也可以找出 aa2 后面有 ss1。 零宽：就是没有宽度，在正则中，断言只是匹配位置，不占字符，也就是说，匹配结果里是不会返回断言本身。 假设我们要用爬虫抓取 csdn 里的文章阅读量。通过查看源代码可以看到文章阅读量这个内容是这样的结构： &lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt; 需要获得这里边的‘641’有很多种办法，但如果使用正则应该怎么匹配呢？下面先讲一下几种类型的断言： 💡正向先行断言（正前瞻） 语法：(?=pattern)； 作用：匹配 pattern 表达式的前面内容，不返回本身。 要取到阅读量，在正则表达式中就意味着要能匹配到‘&lt;/span&gt;’前面的数字内容，按照上所说的正向先行断言可以匹配表达式前面的内容，那意思就是：(?=&lt;/span&gt;) 就可以匹配到前面的内容了。 const regExp = /.+(?=&lt;\\/span&gt;)/; const str = &quot;&lt;span class=\\&quot;read-count\\&quot;&gt;阅读数：641&lt;/span&gt;&quot; console.log(regExp.exec(str)); // 匹配结果： [ '&lt;span class=&quot;read-count&quot;&gt;阅读数：641', index: 0, input: '&lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt;', groups: undefined ] 仅匹配前面的数字： const regExp = /\\d+(?=&lt;\\/span&gt;)/; const str = &quot;&lt;span class=\\&quot;read-count\\&quot;&gt;阅读数：641&lt;/span&gt;&quot; console.log(regExp.exec(str)); // 匹配结果： [ '641', index: 29, input: '&lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt;', groups: undefined ] 💡正向后行断言（正后顾）: 语法：(?&lt;=pattern)； 作用：匹配 pattern 表达式的后面的内容，不返回本身。 有先行就有后行，先行是匹配前面的内容，那后行就是匹配后面的内容啦。上面的栗子，我们也可以用后行断言来处理。 const regExp= /(?&lt;=&lt;span class=\\&quot;read-count\\&quot;&gt;阅读数：)\\d+/; const str = &quot;&lt;span class=\\&quot;read-count\\&quot;&gt;阅读数：641&lt;/span&gt;&quot; console.log(regExp.exec(str)); // 匹配结果 [ '641', index: 29, input: '&lt;span class=&quot;read-count&quot;&gt;阅读数：641&lt;/span&gt;', groups: undefined ] 💡负向先行断言（负前瞻） 语法：(?!pattern)； 作用：匹配非 pattern 表达式的前面内容，不返回本身。 有正向也有负向，负向在这里其实就是非的意思。举个栗子：比如有一句 “我爱祖国，我是祖国的花朵”，现在要找到不是 “的花朵”前面的“祖国”，用正则就可以这样写：祖国(?!的花朵)。 💡负向后行断言（负后顾） 语法：(?&lt;!pattern)； 作用：匹配非 pattern 表达式的后面内容，不返回本身。 捕获和非捕获 单纯说到捕获，他的意思是匹配表达式，但捕获通常和分组联系在一起，也就是“捕获组”。捕获组：匹配子表达式的内容，把匹配结果保存到内存中数字编号或显示命名的组里，以深度优先进行编号，之后可以通过序号或名称来使用这些匹配结果。 而根据命名方式的不同，又可以分为两种组： 💡数字编号捕获组 语法：(exp)； 解释：从表达式左侧开始，每出现一个左括号和它对应的右括号之间的内容为一个分组，在分组中，第 0 组为整个表达式，第一组开始为分组。 比如固定电话的：020-85653333，它的正则表达式为：(0\\d{2})-(\\d{8})，按照左括号的顺序，这个表达式有如下分组： 序号 编号 分组 内容 0 0 (0\\d{2})-(\\d{8}) 020-85653333 1 1 (0\\d{2}) 020 2 2 (\\d{8}) 85653333 下面来验证一下： const str = '020-85653333'; const regExp=/(0\\d{2})-(\\d{8})/; console.log(regExp.exec(str)); // 输出结果： [ '020-85653333', '020', '85653333', index: 0, input: '020-85653333', groups: undefined ] 可见，分组个数是2，但是因为第0个为整个表达式本身，因此也一起输出了。 💡命名编号捕获组： 语法：(?&lt;name&gt;exp)； 解释：分组的命名由表达式中的name指定。 比如区号也可以这样写: (?&lt;quhao&gt;\\0\\d{2})-(?&lt;haoma&gt;\\d{8})，按照左括号的顺序，这个表达式有如下分组： 序号 名称 分组 内容 0 0 (0\\d{2})-(\\d{8}) 020-85653333 1 quhao (0\\d{2}) 020 2 haoma (\\d{8}) 85653333 const str = '020-85653333'; const regExp=/(?&lt;quhao&gt;0\\d{2})-(?&lt;haoma&gt;\\d{8})/; console.log(regExp.exec(str)); // 输出结果： [ '020-85653333', '020', '85653333', index: 0, input: '020-85653333', groups: [Object: null prototype] { quhao: '020', haoma: '85653333' } ] 💡非捕获组： 语法：(?:exp)； 解释：和捕获组刚好相反，它用来标识那些不需要捕获的分组，说的通俗一点，就是你可以根据需要去保存你的分组。 比如上面的正则表达式，程序不需要用到第一个分组，那就可以这样写：1(?:\\0\\d{2})-(\\d{8})。 序号 编号 分组 内容 0 0 (0\\d{2})-(\\d{8}) 020-85653333 1 1 (\\d{8}) 85653333 const str = '020-85653333'; const regExp=/(?:0\\d{2})-(\\d{8})/; console.log(regExp.exec(str)); // 运行结果： [ '020-85653333', '85653333', index: 0, input: '020-85653333', groups: undefined ] 反向引用 上面讲到捕获，我们知道：捕获会返回一个捕获组，这个分组是保存在内存中，不仅可以在正则表达式外部通过程序进行引用，也可以在正则表达式内部进行引用，这种引用方式就是反向引用。 根据捕获组的命名规则，反向引用可分为： 数字编号组反向引用：\\k 或 \\number； 命名编号组反向引用：\\k或者 \\'name'。 捕获组通常是和反向引用一起使用的。上面说到捕获组是匹配子表达式的内容按序号或者命名保存起来以便使用。注意两个字眼：“内容” 和 “使用”，这里所说的“内容”，是匹配结果，而不是子表达式本身。这里所说的“使用”的作用主要是用来查找一些重复的内容或者做替换指定字符。 还是举栗子吧：比如要查找一串字母 &quot;aabbbbgbddesddfiid&quot; 里成对的字母，如果按照我们之前学到的正则，什么区间啊限定啊断言啊可能是办不到的，现在我们先用程序思维理一下思路： 匹配到一个字母； 匹配第下一个字母，检查是否和上一个字母是否一样； 如果一样，则匹配成功，否则失败； 这里的思路 2 中匹配下一个字母时，需要用到上一个字母，那怎么记住上一个字母呢？这下子捕获就有用处啦，我们可以利用捕获把上一个匹配成功的内容用来作为本次匹配的条件。好了，有思路就要实践，首先匹配一个字母：\\w，我们需要做成分组才能捕获，因此写成这样：(\\w)，那这个表达式就有一个捕获组：(\\w)，然后我们要用这个捕获组作为条件，那就可以：(\\w)\\1，这样就大功告成了，可能有人不明白了，\\1 是什么意思呢？ 还记得捕获组有两种命名方式吗，一种是是根据捕获分组顺序命名，一种是自定义命名来作为捕获组的命名。在默认情况下都是以数字来命名，而且数字命名的顺序是从 1 开始的。因此要引用第一个捕获组，根据反向引用的数字命名规则 就需要 \\k&lt;1&gt; 或者 \\1 当然，通常都是是后者。 我们来测试一下： const str = 'aabbbbgbddesddfiid'; const regExp=/(\\w)\\1/g; console.log(str.match(regExp)); 运行结果： [ 'aa', 'bb', 'bb', 'dd', 'dd', 'ii' ] 再举个替换的例子，假如想要把字符串中 abc 换成 a： const str = 'abcbbabcbcgbddesddfiid'; const regExp=/(a)(b)c/g; console.log(str.replace(regExp, '$1')); // 输出结果： abcbbabcbcgbddesddfiid 贪婪和非贪婪 💡贪婪 贪婪匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符，这匹配方式叫做贪婪匹配。 特性：一次性读入整个字符串进行匹配，每当不匹配就舍弃最右边一个字符，继续匹配，依次匹配和舍弃（这种匹配-舍弃的方式也叫做回溯），直到匹配成功或者把整个字符串舍弃完为止，因此它是一种最大化的数据返回，能多不会少。 前面我们讲过重复限定符，其实这些限定符就是贪婪量词，比如表达式：\\d{3,6} 用来匹配 3 到 6 位数字，在这种情况下，它是一种贪婪模式的匹配，也就是假如字符串里有 6 个数字可以匹配，那它就是全部匹配到。例如： const str = &quot;61762828 176 2991 871&quot;; const regExp=/\\d{3,6}/g; console.log(str.match(regExp)); // 输出结果： [ '617628', '176', '2991', '871' ] 由结果可见：本来字符串中的“61762828”这一段，其实只需要出现3个（617）就已经匹配成功了的，但是他并不满足，而是匹配到了最大能匹配的字符，也就是6个。 一个量词就如此贪婪了，那有人会问，如果多个贪婪量词凑在一起，那他们是如何支配自己的匹配权的呢？是这样的，多个贪婪在一起时，如果字符串能满足他们各自最大程度的匹配时，就互不干扰，但如果不能满足时，会根据深度优先原则，也就是从左到右的每一个贪婪量词，优先最大数量的满足，剩余再分配下一个量词匹配。 const str = &quot;61762828 176 2991 87321&quot;; const regExp=/(\\d{1,2})(\\d{3,4})/g; console.log(str.match(regExp)); // 输出结果： [ '617628', '2991', '87321' ] 解答： “617628” 是前面的 \\d{1,2} 匹配出了 61，后面的匹配出了 7628； “2991”是前面的 \\d{1,2} 匹配出了 2 ，后面的匹配出了 991(满足匹配优先，再最大程度的贪婪)； “87321”是前面的 \\d{1,2} 匹配出了 87，后面的匹配出了 321。 💡懒惰（非贪婪） 懒惰匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能少的字符，这匹配方式叫做懒惰匹配。 特性：从左到右，从字符串的最左边开始匹配，每次试图不读入字符匹配，匹配成功，则完成匹配，否则读入一个字符再匹配，依此循环（读入字符、匹配）直到匹配成功或者把字符串的字符匹配完为止。 懒惰量词是在贪婪量词后面加个“?”。 代码 说明 *? 重复任意次，但尽可能少重复 +? 重复 1 次或更多次，但尽可能少重复 ?? 重复 0 次或 1 次，但尽可能少重复 {n,m}? 重复 n 到 m 次，但尽可能少重复 {n,}? 重复 n 次以上，但尽可能少重复 const str = &quot;61762828 176 2991 87321&quot;; const regExp=/(\\d{1,2}?)(\\d{3,4})/g; console.log(str.match(regExp)); // 输出结果： [ '61762', '2991', '87321' ] 解答： “61762”是左边的懒惰匹配出 6，右边的贪婪匹配出 1762； “2991”是左边的懒惰匹配出 2，右边的贪婪匹配出 991； “87321”左边的懒惰匹配出 8，右边的贪婪匹配出 7321。 反义 前面说到元字符的都是要匹配什么什么，当然如果你想反着来，不想匹配某些字符，正则也提供了一些常用的反义元字符： 元字符 解释 \\W 匹配任意不是字母，数字，下划线，汉字的字符 \\S 匹配任意不是空白符的字符 \\D 匹配任意非数字的字符 \\B 匹配不是单词开头或结束的位置 [^x] 匹配除了 x 以外的任意字符 [^aeiou] 匹配除了 aeiou 这几个字母以外的任意字符 ","link":"https://faded.auspicious.space/post/regular-expression-assert-mandarin/"},{"title":"正则表达式——NFA","content":" 正则表达式和NFA NFA NFA 是指 Nondeterministic Finite Automaton，非确定有限状态自动机。 目前正则表达式引擎主要有两种：NFA 和 DFA； JavaScript 采用的是 NFA 引擎。 状态机中有这样一些要素，对照上图分别说下： 开始状态：圆圈表示状态，被一个“没有起点的箭头”指向的状态，是开始状态，上例中是 S1； 最终状态：也叫接受状态，图中用双圆圈表示，这个例子中也是 S1； 输入：在一个状态下，向状态机输入的符号/信号，不同输入导致状态机产生不同的状态改变； 转换：在一个状态下，根据特定输入，改变到特定状态的过程，就是转换。 所以有限状态机的工作过程，就是从开始状态，根据不同的输入，自动进行状态转换的过程。 上图中的状态机的功能，是检测二进制数是否含有偶数个 0。从图上可以看出，输入只有 1 和 0 两种。从 S1 状态开始，只有输入 0 才会转换到 S2 状态，同样 S2 状态下只有输入 0 才会转换到 S1。所以，二进制数输入完毕，如果满足最终状态，也就是最后停在 S1 状态，那么输入的二进制数就含有偶数个 0。 正则表达式，可以认为是对一组字符串集合的描述。例如 (a+|b)c 对应的字符串集合是： ac bc aac aaac aaaac ... 有限状态机也可以用来描述字符串集合，同样是正则表达式所描述的集合，用有限状态机来表示，可以是这样的： 并且，有限状态机是可以“执行”的，给出如上的状态机之后，就可以用来对输入的字符串进行检测。如果最终匹配，也就意味着输入的字符串和正则表达式 (a+|b)c 匹配。 所以，编程语言中的正则表达式，一般是通过有限状态机来实现。正则表达式匹配字符串的过程，可以分解为： 正则表达式转换为等价的有限状态机； 有限状态机输入字符串执行。 这里再讲一下 NFA 和 DFA 的区别。DFA 是 Deterministic Finite Automaton，确定有限状态机。DFA 可以认为是一种特殊的 NFA，它最大的特点，就是确定性。它的确定性在于，在一个状态下，输入一个符号，一定是转换到确定的状态，没有其他的可能性。 举个例子，对于正则表达式 ab|ac，对应 NFA 可以是这样的： 可以看到，在状态 1 这里，如果输入 a，其实有两种可能，如果后面的符号是 b，那么可以匹配成功，后面符号是 c 也能匹配成功。所以状态机在执行过程中，可能要尝试所有的可能性。在尝试一种可能路径匹配失败后，还要回到之前的状态再尝试其他的路径，这就是“回溯”。 但是 DFA 消除了这种不确定性，所以可以想见，其执行性能应该要比 NFA 更好，因为不需要回溯。 NFA 是可以转换为等价的 DFA 的，也就是说，理论上讲，正则表达式可以用 DFA 来实现，从而获得优于 NFA 的执行性能。但是 NFA 转换 DFA 的过程，会消耗更多资源，甚至最终得到的 DFA 要占用大量存储空间（据有的资料的说法，可能会产生指数级增长）。而且，DFA 相比 NFA，在实现一些正则表达式的特性时会更复杂，成本更高。所以当前的许多编程语言，其正则表达式引擎为 NFA 模式。 /nfa|nfa not/.test('nfa not'); 用上面的正则表达式来测试字符串 nfa not，NFA 引擎在检测满足 nfa 就返回匹配成功的结果了，而 DFA 则会尝试继续查找，也就是说会得到“最长的匹配结果”。 从正则表达式到 NFA 🏈Thompson 算法 Thompson 算法用于转换正则表达式为 NFA，它并非最高效的算法，但是实用，易于理解。 Thompson 算法中使用最基本的两种转换： 普通转换就是在一个状态下，输入字符 a 后转换至另一个状态；epsilon转换则不需要有输入，就从一个状态转换至另一个状态。 正则表达式中的各种运算，可以通过组合上述两种转换实现： 组合转换 RS： 替换转换 R|S： 重复转换 R*： 上面图中的 R、S 是有开始状态和结束状态的 NFA。 以正则表达式 ab|c 为例，包括两个运算： ab 组合 ab 的结果，与 c 替换 这样我们把正则表达式视为一系列输入和运算，进行分解、组合，就可以得到最终的 NFA。 首先，我们要把正则表达式转换为方便记录输入、运算的方式。 🏈正则表达式 → 后缀表达式 后缀表达式是一种方便记录输入、运算的表达式，本身已包含了运算符的优先级，也称为逆波兰表示法（Reverse Polish Notation，简写为 RPN）。 为方便记录运算，我们为正则表达式中的组合运算也创建一个运算符“.”（本文只涉及最简单的正则表达式形式，这里的“.”不是用于匹配任意字符的特殊符号）。 正则表达式 ab|c对应的后缀表达式为 ab.c|。 这样，通过逐个扫描后缀表达式，并识别其中的运算符来执行，就可以对后缀表达式进行求解。对于正则表达式来说，则是在将其变为后缀表达式后，通过“求值”的过程来进一步构建并得到最终的 NFA。 用于创建后缀表达式的是调度场算法。 对于这里的正则表达式处理的场景，算法的大致描述如下： 创建输出队列 output 和运算符栈 ops； 依次读取输入字符串中每一个字符 ch； 如果 ch 是普通字符，追加到 output； 如果 ch 是运算符，只要 ops 栈顶的运算符优先级不低于 ch，依次出栈并追加到 output，最后将 ch 入栈 ops； 如果 ch 是“(”，入栈 ops； 如果 ch 是“)”，只要 ops 栈顶不是“(”，依次出栈并追加到 output； 将 ops 中运算符依次出栈追加到 output； 返回 output。 具体处理过程中，由于原始正则表达式中并没有组合运算符，所以需要自行判断合理的插入位置。 运算符优先级如下（由高到低）： * ? + . | ( 🏈后缀表达式 → NFA 基于后缀表达式创建 NFA，是一个由简单的 NFA 进行不断组合得到复杂 NFA 的过程。 用于表示状态 State 的数据结构为： // State { id: String, type: String, // 'n' - normal, 'e' - epsilon, 'end' symbol: String, // 普通状态对应的输入字符 out: State, // 允许的下一个状态 out1: State // 允许的下一个状态 } 每个状态可以对应最多两个 out 状态，像 a|b|c 的表达式，会被分解为 (a|b)|c，每次运算符“|”都只处理两个（子）表达式。 在构造最终 NFA 过程中，每次会创建 NFA 的片段 Fragment： // Fragment { start: State, out: State } 不管 NFA 片段内部是怎样复杂，它都只有一个入口（开始状态），一个出口（最终状态）。 处理的过程大致为： 创建用于记录 NFA 片段的栈 stack； 依次读取输入的后缀表达式的每个字符 ch； 如果 ch 是运算符，从 stack 出栈所需数目的 NFA 片段，构建新的 NFA 片段后入栈 stack； 如果 ch 是普通字符，创建新的状态，并构建只包含此状态的 NFA 片段入栈 stack； 返回 stack 栈顶的 NFA 片段，即最终结果。 以对组合运算的处理为例： const e2 = stack.pop(); const e1 = stack.pop(); e1.out.out = e2.start; stack.push(new Fragment(e1.start, e2.out)); 从 stack 出栈两个 NFA 片段，然后将其首尾相连后构建新的 NFA 片段再入栈。 NFA 的执行 NFA 的执行过程就是用当前状态来比对字符串的当前字符，如果匹配就继续比对下一个状态和下一个字符，否则匹配失败。 不过由于 NFA 的不确定性，所以可能会同时有多个匹配的状态。 总结 综上，正则表达式的执行，可以通过构建等价的 NFA，然后执行 NFA 来匹配输入的字符串。真实的 JavaScript 中的正则表达式拥有更多的特性，其正则表达式引擎也更加复杂。 简单正则表达式引擎的实现 简单的正则表达式引擎实现 🏈基本的数据结构定义 核心思路是读取正则表达式以后生成对应的NFA，NFA中有边和状态两个结构。边的结构记录了它的起点和终点，同时通过枚举类型记录匹配的其他需求。 //用于处理‘^’字符 enum { NEXCLUDED = false, EXCLUDED = true }; //用于处理预处理类型，0-128以内ASCII字符直接匹配 enum { LCASES=256, UCASES=257, NUM=258, EPSILON=259, ANY=260, WS=261 }; class Edge { public: State *start; State *end; int type; int exclude; Edge(State *s, State *e, int t, bool ex = NEXCLUDED) :start(s), end(e), type(t), exclude(ex) {}; } 状态有预备，成功和失败三种，同时每个状态维护两个向量，向量存储了出边和入边的指针。 enum { READY = -1, SUCCESS = 1, FAIL = 0}; class State { public: int status; std::list&lt;Edge *&gt; InEdges; std::list&lt;Edge *&gt; OutEdges; } NFA 类会存储一个正则表达式，同时存储 NFA 的起点和终点，并使用了两个链表来维护 NFA 的边和状态，同时用一个链表来存储匹配成功的字符串。两个静态的字符串指针用于记录文件和正则表达式字符串的读取状态，静态常量，使得最终函数只会对文件内容和正则表达式扫描一次，避免在匹配成功的字符串中再匹配子串。 char *regex; State *Start; State *End; std::list&lt;Edge *&gt; edgeList; std::list&lt;State *&gt; stateList; std::list&lt;char&gt; matchedChar; static char *regRead; static char *fileRead; } 生成NFA的过程中，通过 currentEnd 和 currentStart 两个指针分别指向当前字符读取完成后生成的最后一个状态和当前字符读取之前的开始状态，维护这两个指针的目的是为了记录 NFA 的生成过程，在处理‘*’、‘+’、‘？’等字符的时候起到了重要的作用。同时我们利用list内置的迭代器对链表进行遍历，这个方式在匹配过程中也用到了。 State *currentEnd, *currentStart; State *alternate; list&lt;Edge *&gt;::iterator itor; 🏈NFA的生成 关键的部分在于匹配字符串时采取的思路，尤其是特殊字符的生成 NFA 的方式，这个不同于课本上最开始的 NFA 生成算法，而是基于读取字符串的过程，同时避免了字符串的回退等，读取一个字符就生成一个对应的边并压入链表中，对‘*’、‘+’，‘？’和特殊符号也是如此，使得处理更加简单的同时避免生成过于冗余的状态，兼顾了时间和空间效率。以下举例说明。 🏈边和状态的生成 边的生成使用 newEdge 函数,需要记录起点和终点，以及类型，同时在生成边以后要用重载的两个 patch函数将状态和边完全连接起来。 void Nfa::newEdge(State * start, State * end, int type, int exclude = NEXCLUDED) { Edge *out = new Edge(start, end, type, exclude); end-&gt;patch(out, end); start-&gt;patch(start, out); edgeList.push_back(out); } 以普通字符的生成和‘.’字符的产生方式为例，他们都是生成一条边和一个新的状态。 case '.': /* any */ currentStart = currentEnd; currentEnd = new State(); newEdge(currentStart, currentEnd, ANY, NEXCLUDED); stateList.push_back(currentEnd); default: currentStart = currentEnd; currentEnd = new State(); newEdge(currentStart, currentEnd, *regRead, NEXCLUDED); stateList.push_back(currentEnd); break; 如下图所示： 接下来的符号处理都假定初始状态如下图所示： 🏈'|'的处理 以 currentStart 指向的状态作为子 NFA 的起点，同时将子 NFA 的终点状态和原 NFA 的终点进行合并。 case '|': // alternate regRead++; currentStart = start; alternate= regex2nfa(regRead, start); currentEnd-&gt;merge(alternate); stateList.remove(alternate); regRead--; 如下图所示： 🏈'?' &amp; '*' &amp; '+'的处理 读取到‘?’只需要在上一条边的基础上继续连接原有的边即可： case '?': // zero or one newEdge(currentStart, currentEnd, EPSILON, NEXCLUDED); break; 读取到‘\\*’后，直接将 currentStart 和 currentEnd 进行合并成环： case '*': // zero or more alternate = currentEnd; currentStart-&gt;merge(alternate); stateList.remove(alternate); currentEnd = currentStart; break; 读取到‘+’后，只需添加若干条边从 currentEnd 状态指向 currentStart 状态的下一个状态即可： case '+': /* one or more */ itor = currentStart-&gt;OutEdges.begin(); for (;itor != currentStart-&gt;OutEdges.end();itor++) newEdge(currentEnd, (*itor)-&gt;end, (*itor)-&gt;type, (*itor)-&gt;exclude); break; 如下图所示： 🏈简单的分组支持 对于中括号和括号进行了一定的支持，括号直接递归调用 NFA 的生成函数，中括号和预定义字符都有其对应的函数进行支持。 🏈NFA匹配 匹配过程采用了递归的方式，step函数调用match函数匹配边和文件字符，匹配成功后即递归调用进入下一个状态。 if (End-&gt;status == SUCCESS) return SUCCESS; for(;itor != current-&gt;OutEdges.end();itor++) { if ((*itor)-&gt;match(fileRead)) { (*itor)-&gt;end-&gt;status = SUCCESS; matchedChar.push_back(*fileRead); ++fileRead; if (step((*itor)-&gt;end)) return SUCCESS; --fileRead; matchedChar.pop_back(); } if ((*itor)-&gt;type == EPSILON &amp;&amp; step((*itor)-&gt;end)) return SUCCESS; } return FAIL; ","link":"https://faded.auspicious.space/post/regular-expression-nfa/"},{"title":"正则表达式——断言","content":" 正则表达式断言 正则表达式大多数结构匹配的文本会出现在最终的匹配结果中，但也有些结构并不真正匹配文本，而只是负责判断某个位置左/右侧是否符合要求，这种结构被称为断言（assertion）。常见的断言有三类： 单词边界、行起始/结束位置、环视。本文主要简单阐述对三类断言的理解。 单词边界 单词边界顾名思义，是指单词字符 (\\w) 能匹配的字符串的左右位置。在 JavaScript、php、Python 2、Ruby 中，单词字符 (\\w) 等同于 [0-9a-zA-Z]，所以在这些语言中，给定一段文本可以用 \\b\\w+\\b 把所有单词提取出来。 例如： ('Love is composed of a single soul inhabiting two bodies.').match(/\\b\\w+\\b/g) return [&quot;Love&quot;, &quot;is&quot;, &quot;composed&quot;, &quot;of&quot;, &quot;a&quot;, &quot;single&quot;, &quot;soul&quot;, &quot;inhabiting&quot;, &quot;two&quot;, &quot;bodies&quot;] 这里值得注意的是，有些单词例如 E-mail 和组合词 I'm 这样的，\\b\\w+\\b 是无法匹配的。如要匹配，可根据需求修改为 \\b['-\\w]\\b。 单词边界记为 \\b，它能匹配的位置：一边是单词字符 \\w，一边是非单词字符 \\W。 与单词边界对应的是非单词边界 \\B，两者关系类似 \\w 与 \\W、\\d 与 \\D。 这里注意，非单词边界（\\B）和单词字符（\\w）是不一样的，因为前者是断言，而后者是普通匹配。 例如： // 式一 String(1234567890).replace(/(?=(\\B)(\\d{3})+$)/g, ',') =&gt; 1,234,567,890 // 式二 String(1234567890).replace(/(?=(\\w)(\\d{3})+$)/g, ',') =&gt; ,123,456,7890 // 附加常用例子，20180911格式化为2018-09-11 '20180911'.replace(/(?=\\B(\\d{2})+$)/g, '-').replace(/-/, '') =&gt;2018-09-11 造成差异的原因就是: 式一中的 \\B 匹配边界（是断言）。第一次匹配时，在 1234567890 中数字 1 的前方时，会环视后方进行肯定断言(?=)：后方必须是满足两个 pattern 才通过。第一个 pattern (\\B)在数字 1 的前方匹配成功；故继续在此位置匹配第二个 pattern (\\d{3})+$，发现 123456789 之后并不是结束符（结束符和开始符也是断言，下文讲述），故匹配失败。开始第二次匹配，从数字 1 和数字 2 的中间开始...最后会匹配成功三个位置：1 和 2 之间、4 和 5 之间、7 和 8 之间，再被,替换，故得到结果。 同理，式二在第一次匹配时，在数字 1 的前方环视后方进行肯定断言：后方必须是满足两个 pattern 才通过。第一个 pattern (\\w) 在数字 1 的前方匹配成功，并将匹配位置移动到 1 和 2 之间；然后继续匹配第二个pattern (\\d{3})+$...第一次匹配成功，故数字 1 前方的断言是成功的，标记该位置...最后得到三个位置：1 前方、3 和 4 之间、6 和 7 之间，再被,替换，故得到结果。 所以 \\B 只是去判断该位置左右是否只有一边有单词字符，另一边不是单词字符，且在匹配成功时，不会导致匹配位置发生改变。说起来算是一种判断吧~ 这种只是匹配某个位置而不是文本的元字符，在正则中也被称为锚点。下文继续介绍常见锚点之二：行起始/结束位置。 行起始/结束位置 ^ 与 $ 分别表示（行）起始位置和（行）结束位置，比如正则表达式 /^lu.*r$/ 只能匹配的 lu 开始并以 r 结束的字符串，例如：luwuer、lu fd --r，不能匹配 nb luwuer、lu fd --rb等。 其实行起始/结束位置断言，常用在正则表达式开启多行模式（Multiline Mode）的情况下。 例如： ('first line\\nsecond line\\nlast line').match(/^\\w+/gm) return [&quot;first&quot;, &quot;second&quot;, &quot;last&quot;] 既然是多行匹配，这里说说如何划分行。 在编辑文本时，敲回车键就向文本输入了行终止符（line terminal），表示结束当前行。这里只需注意，敲入回车时向文本中输入的行终止符在主流平台上是有差别的： Windows 的行终止符是 \\r\\n。 UNIX/Linux/Mac OS 的行终止符是 \\n。 不过正则的行起始/结束位置断言都是可以识别的哈~ 环视 环视是指在某个位置向左/向右看，保证其左/右位置必须出现某类字符（包括单词字符 \\w 和非单词字符\\W），且环视也同上两个断言，只是做一个判断（匹配一个位置，本身不匹配任何字符，但又比上两个断言灵活）。也有人称环视为零宽断言。 环视分为四种： 肯定顺序环视（正向肯定断言）positive-lookahead: ?=pattern； 否定顺序环视（正向否定断言）negative-lookahead: ?!pattern； 肯定逆序环视（反向肯定断言）positive-lookahead: ?&lt;=pattern，js不支持； 否定逆序环视（反向否定断言）negative-lookahead: ?&lt;=pattern，js不支持。 比如我们要匹配一串文字中包含在书名号《》中的书名，如不考虑环视可能需要如下实现： ('三体是刘慈欣创作的系列长篇科幻小说，由《三体》、《三体Ⅱ·黑暗森林》、《三体Ⅲ·死神永生》组成。').match(/《.*?》/g).join(',').replace(/[《》]/g, '').split(',') return [&quot;三体&quot;, &quot;三体Ⅱ·黑暗森林&quot;, &quot;三体Ⅲ·死神永生&quot;] 正则默认是贪婪模式（在整个表达式匹配成功的前提下，尽可能多的匹配），开启非贪婪模式（在整个表达式匹配成功的前提下，尽可能少的匹配）的方法：在贪婪量词 {m,n}、{m,}、?、*、+ 后加上一个 ? 号，例如 +?。 而在使用环视时会更简单： ('三体是刘慈欣创作的系列长篇科幻小说，由《三体》、《三体Ⅱ·黑暗森林》、《三体Ⅲ·死神永生》组成。').replace(/《/g,'\\n').match(/^.*?(?=》)/gm) return [&quot;三体&quot;, &quot;三体Ⅱ·黑暗森林&quot;, &quot;三体Ⅲ·死神永生&quot;] 似乎也没简单多少...当然最主要的原因是js不支持逆序环视啦啦啦 再举例，匹配6位数字构成的字符串： // 无环视 'http://luwuer.com/629212/1234567890'.match(/[^\\d]\\d{6}[^\\d]/g).join('').match(/\\d{6}/g) return [&quot;629212&quot;] // 环视 'http://luwuer.com/629212/1234567890'.match(/(?!\\d).\\d{6}(?!\\d)/g).join('').match(/\\d{6}/g) return [&quot;629212&quot;] 其实环视在js中更多的是与replace函数组合，就像在单词边界一节中最后的例子。 ","link":"https://faded.auspicious.space/post/regular-expression-assert/"},{"title":"jQuery——拓展","content":"😲 extend函数 $.extend(target,[object1],[onjectN]) $.extend([deep],target,object1,[objectN]) var obj1 = { height: 100, width: 100, length: 100, div: { x: 100, y: 100 } }; var obj2 = { height: 200, width: 200, div: { x: 200 } }; $.extend(obj1, obj2); console.log(obj1.height); console.log(obj1.div.y); //result:200,undefined 当使用true参数时， var obj1 = { height: 100, width: 100, length: 100, div: { x: 100, y: 100 } }; var obj2 = { height: 200, width: 200, div: { x: 200 } }; $.extend(true, obj1, obj2); console.log(obj1.height); console.log(obj1.div.y); //result:200,100 拓展jQuery的公共函数 $.extend({ minValue: function(a, b) { return a &gt; b ? a: b } }); var a = prompt(&quot;input a&quot;); var b = prompt(&quot;input b&quot;); console.log($.minValue(a, b)); $.fn.extend() 方法可以创建 jQuery 对象方法 $.fn.extend({ test: function() { alert(&quot;click &quot; + $(this).html() + &quot; this is test function&quot;); } }); $(&quot;#fnExtend&quot;).click(function() { $(this).test(); }); 😲 自定义jQuery函数 🤗 添加新的全局函数 $.clickDiv = function(node) { console.log(node.text() + &quot; click&quot;); }; $(&quot;div&quot;).click(function() { $.clickDiv($(this)); }); 🤗 通过 extend 函数添加全局函数 $.extend({ foo: function() { alert(&quot;this is a new function 'foo()'&quot;); } }); $.foo(); 🤗 使用命名空间 $.myPluin = { ale: function() { alert(&quot;function from myPluin&quot;); } }; $.nextPluin = { ale: function() { alert(&quot;function from nextPluin&quot;); } } $.myPluin.ale(); $.nextPluin.ale(); 😲 自定义选择器 $.myPluin = { ale: function() { alert(&quot;function from myPluin&quot;); } }; $.nextPluin = { ale: function() { alert(&quot;function from nextPluin&quot;); } }; index = -1; //定义全局变量 index jQuery.expr[&quot;:&quot;].le = function(elem, i, match) { // return i&gt;match[3]-0||i==match[3] console.log(index); index++; return index &gt; match[3] - 0; // 返回索引大于 3 的元素 }; $(&quot;p:le(2)&quot;).css(&quot;color&quot;, &quot;red&quot;); // 返回元素索引值大于等于 2 的元素 $.myPluin.ale(); $.nextPluin.ale(); ","link":"https://faded.auspicious.space/post/jquery-extension/"},{"title":"jQuery——选择器","content":"基本选择器 🎼 ID 选择器： // 选中 id 为 myDiv 的元素，速度最快 $(&quot;#myDiv&quot;) 🎼 类选择器： // 选中 class 属性为 red 的所有元素 $(&quot;.red&quot;) 🎼 元素选择器： // 选中所有 div 元素 $(&quot;div&quot;) 🎼 通配符选择器： // 选中所有元素 $(&quot;*&quot;) 🎼 复合选择器： // 选中所有 span 元素和所有 id 为 myDiv 的元素 $(&quot;span,#myDiv&quot;) 层次选择器 🎼 选择器1 选择器2： // 选中 body 内的所有 div 元素 $(&quot;body div&quot;) 🎼 选择器1 &gt; 选择器2： // 选中 body 内的所有直接 div 元素，不查找间接元素 $(&quot;body &gt; div&quot;) 🎼 选择器1 + 选择器2： // 选中 body 内的所有 div 元素 $(&quot;body div&quot;) 🎼 选择器1 ~ 选择器2： // 选中 body 内的所有 div 元素 $(&quot;body div&quot;) 基本过滤选择器 🎼 第一个元素选择器 // 选中第一个 div 元素 $(&quot;div:first&quot;) 🎼 最后一个元素选择器 // 选中最后一个 div 元素 $(&quot;div:last&quot;) 🎼 排除选择器 // 选中 class 不为 red 的所有 div 元素 $(&quot;div:not(.red)&quot;) 🎼 偶数选择器 // 选中索引值为偶数的 div 元素 $(&quot;div:even&quot;) 🎼 奇数选择器 // 选中索引值为奇数的 div 元素 $(&quot;div:odd&quot;) 🎼 索引值选择器 // 选中索引值为 2 的 div 元素 $(&quot;div:eq(2)&quot;) // 选中索引值大于 2 的 div 元素 $(&quot;div:gt(2)&quot;) // 选中索引值小于2的 div 元素 $(&quot;div:lt(2)&quot;) 内容过滤选择器 // 选中所有包含文本 ok 的 div 元素 $(&quot;div:contains(ok)&quot;) // 选中所有为空的 div 元素 $(&quot;div:empty&quot;) // 选中所有包含 class 为 red 的 div 元素 $(&quot;div:has(.red)&quot;) // 选中所有不为空的 div 元素 $(&quot;div:parent&quot;) 可见性过滤选择器 // 选中所有不可见的 div 元素 $(&quot;div:hidden&quot;) // 选中所有可见的 div 元素 $(&quot;div:visible&quot;) 属性过滤选择器 // 选中所有包含属性 title 的 div 元素 $(&quot;div[title]&quot;) // 选中所有属性 title 等于 ok 的 div 元素 $(&quot;div[title=ok]&quot;) // 选中所有属性 title 不等于 ok 的 div 元素 $(&quot;div[title!=ok]&quot;) // 选中所有属性 title 值以 ok 开头的 div 元素 $(&quot;div[title^=ok]&quot;) // 选中所有属性 title 值含有 ok 的 div 元素 $(&quot;div[title*=ok]&quot;) // 选中所有包含属性 id，并且属性 title 值以 ok 开头的 div 元素 $(&quot;div[id][title^=ok]&quot;) 子元素过滤选择器 // 选中所有是第二个子结点的 div 元素 $(&quot;div:nth-child(2)&quot;) // 选中所有是第一个子结点的 div 元素 $(&quot;div:first-child&quot;) // 选中所有是最后一个子结点的 div 元素 $(&quot;div:last-child&quot;) // 选中所有是唯一子结点的 div 元素 $(&quot;div:only-child&quot;) 表单属性过滤选择器 // 选中表单内可用 input $(&quot;#form1 input:enabled&quot;) // 选中表单内不可用 input $(&quot;#form1 input:disabled&quot;) // 选中表单内所有选中的元素 $(&quot;#form1 input:checked&quot;) // 选中下拉列表中选中的元素 $(&quot;select &gt; option:selected&quot;) ","link":"https://faded.auspicious.space/post/jquery-selectors/"},{"title":"正则表达式——匹配","content":"💊(?:pattern) 非获取匹配，匹配 pattern 但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。 💊 (?=pattern) 非获取匹配，正向肯定预查，在任何匹配 pattern 的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如，“Windows(?=95|98|NT|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 💊 (?!pattern) 非获取匹配，正向否定预查，在任何不匹配 pattern 的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如“Windows(?!95|98|NT|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。 💊 (?&lt;=pattern) 非获取匹配，反向肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?&lt;=95|98|NT|2000)Windows”能匹配“2000Windows”中的“Windows”，但不能匹配“3.1Windows”中的“Windows”。 💊 (?&lt;!pattern) 非获取匹配，反向否定预查，与正向否定预查类似，只是方向相反。例如“(?&lt;!95|98|NT|2000)Windows”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。这个地方不正确，有问题 ","link":"https://faded.auspicious.space/post/regular-expression-pattern-matching/"},{"title":"设计师网站","content":"设计师导航 网站 网址 全球100+知名设计网站 http://www.bigbigwork.com/nav/6.html CND设计网址导航 - 优秀设计网站排名大全 http://wz.cndesign.com/ 拍信 https://www.paixin.com/ 我图网 https://www.ooopic.com/ 包图网 https://ibaotu.com/ 素材天下 http://www.sucaitianxia.net/ 素材中国 http://www.sccnn.com/ 站长素材 http://sc.chinaz.com/ 红动中国 https://www.redocn.com/ 千库网 https://588ku.com/ 觅元素 http://www.51yuansu.com/ unDraw https://undraw.co/ DrawKit https://www.drawkit.io/ pngtree https://pngtree.com/ VCG https://www.vcg.com/ Textures for 3D, graphic design and Photoshop! https://www.textures.com/ 無料DTP素材 【素材ページ 】食材・料理の著作権フリー写真 http://www.sozai-page.com/index.html 免费模板网 http://www.wangjie.org/ Landing page templates for startups https://cruip.com/ Avataaars Generator https://getavataaars.com/?avatarStyle=Circle 中国色 http://zhongguose.com/ 完美对称无缝平铺背景图底纹素材 - 图鱼 https://www.hituyu.com/ 花瓣网_陪你做生活的设计师（创意灵感天堂，搜索、发现设计灵感、设计素材） https://huaban.com/ 站酷 (ZCOOL) - 设计师互动平台 - 打开站酷，发现更好的设计！ https://www.zcool.com.cn/ UI中国用户体验设计平台 https://www.ui.cn/ 68Design - 找兼职设计师就上68Design - 【设计师接单平台】 https://www.68design.net/ Flat Design Inspiration - Flat UI https://flatui.com/ UI Movement - The best UI design inspiration, every day https://uimovement.com/ Collect UI - Daily inspiration collected from daily ui archive and beyond. Based on Dribbble shots, hand picked, updating daily. http://www.collectui.com/ siteInspire - Web Design Inspiration https://www.siteinspire.com/ Dribbble - Discover the World’s Top Designers &amp; Creative Professionals https://dribbble.com/ Blocs - Fast, easy to use and powerful visual web design tool, that lets you create responsive websites without writing code. https://blocsapp.com/ UI Design Resources, UI Kits, Wireframes, Icons and More - UI8 https://ui8.net/ UI-Patterns.com https://ui-patterns.com/ 学UI网-UI设计师导航网，最专业的UI设计网站 http://hao.xueui.cn/ 优设导航 - 学设计从这里开始！ http://hao.uisdc.com/ 饭团导航 精选设计师实用工具导航 hao.psefan.com http://hao.psefan.com/ 设计导航 - 精选最好的设计网站大全 https://hao.shejidaren.com/ 优波设计 - 设计师必备网址导航 ubuuk.com https://www.ubuuk.com/ 设计订阅 - 腾讯设计导航 https://idesign.qq.com/#!index/feed http://www.bigbigwork.com/nav/6.html http://www.foolo.cn/ 工业设计网站导航 | 设计癖 http://hao.shejipi.com/ 46设计导航_设计网站大全_46design.com http://www.46design.com/2019/ UI设计师导航网 - 优阁 http://so.uigreat.com/ Canva在线平面设计软件_免费设计模板素材和海量正版图片 - Canva中文官网 https://www.canva.cn/ 创客贴_平面设计作图神器_免费设计模板_在线稿定设计印刷 https://www.chuangkit.com/ 轻量级在线平面设计工具 - 图帮主 https://www.tubangzhu.com/ 图怪兽作图神器-在线图片编辑器-PS图片制作-搞定平面设计不求人 https://818ps.com/ Fotor在线设计工具_免费设计素材和模板_在线平面设计网站 https://www.fotor.com.cn/ Presentation Software Online Presentation Tools 设计癖 | 关注设计癖 提升幸福感 http://www.shejipi.com/ xiaopiu-产品原型设计工具与团队实时协作平台 https://www.xiaopiu.com/ 燃设计-共享全球好设计_软装素材分享_软装设计灵感图库 http://www.ransheji.com/ Themes - macOS - Human Interface Guidelines - Apple Developer https://developer.apple.com/design/human-interface-guidelines/macos/overview/themes/ Overview - Atlassian Design https://atlassian.design/guidelines/product/overview 介绍 - Ant Design https://ant.design/docs/spec/introduce-cn WeUI https://weui.io/ Documentation - Materialize https://materializecss.com/ Styleguide https://www.yelp.com/styleguide/mobile 优优灵感-设计师灵感展现与启发-优优教程网 https://uiiiuiii.com/inspiration Crello — Free Graphic Design Software Create Images Online Tool 优设导航 - 学设计从这里开始！ https://hao.uisdc.com/ Creative Mass https://creativemass.cn/#/ 设计师之家 https://www.51sjsj.com/ Design Seeds for all who ♥ color The Nordnet Brand - Nordnet Brand https://brand.nordnet.se/ STUDIO Design to live website in one click. KOPPT，一个做PPT的神器！ http://koppt.cn/ 图片素材 网站 网址 Unsplash https://unsplash.com/ Pexels https://www.pexels.com/zh-cn/ Gratisography https://gratisography.com/ Beautiful free stock photos https://stocksnap.io/ Foodiesfeed https://www.foodiesfeed.com/ Freephotos https://freephotos.cc/zh Uniquely free photos. https://www.reshot.com/ Free images for creatives, by creatives https://morguefile.com/quest 沙沙野 https://www.ssyer.com/ 图虫 https://tuchong.com/ 摄图网 https://699pic.com/ 7MX——Home Business Advertising Ideas https://7mx.com/ 图品汇 https://www.88tph.com/ Free Photos for bloggers and creatives! http://photopin.com/ 花瓣美素 http://www.meisupic.com/ PAKUTASO https://www.pakutaso.com/ 懒人图库 http://www.lanrentuku.com/ SEARCH FOR CONTENT TO REUSE https://search.creativecommons.org/ Free Stock Photos by Canva https://www.canva.com/photos/free/ Creative Briefs. Request for photos https://morguefile.com/quest ImageFinder https://imagefinder.co/ 泼辣有图 http://www.polayoutu.com/collections visualhunt https://visualhunt.com/ foter https://foter.com/ Free high resolution photography - Life of Pix - Home https://www.lifeofpix.com/ New Old Stock https://nos.twnsnd.co/ 千图网 https://www.58pic.com/ Hand-picked free photos for your inspiration - Magdeleine https://magdeleine.co/ 昵图网 http://www.nipic.com/ photock https://www.photock.jp/ 免费正版高清图片素材库 https://pixabay.com/zh/ piqsels https://www.piqsels.com/zh DesignersPics http://www.designerspics.com/ freeimages https://cn.freeimages.com/ StreetWill http://www.streetwill.co/ Discover and share the world's best photos https://web.500px.com/ FREE TRAVEL PHOTOS https://www.bucketlistly.blog/photos Free Stock Photos For Commercial Use. https://www.splitshire.com/splitshire-free-stock-photos/ BURST https://burst.shopify.com/ FOCA https://focastock.com/ jay mantri https://jaymantri.com/#= LET'S FIND THE PERFECT PHOTO FOR YOU https://kaboompics.com/ A curated collection of free web design resources, all for commercial use. http://imcreator.com/free Zoommy https://zoommyapp.com/ STOKPIC - Free Stock Photos For Commercial Use https://stokpic.com/ Cupcake http://cupcake.nilssonlee.se/ Folkert Gorter Superfamous Images https://images.superfamous.com/ PICGRAPHY https://picography.co/ Free stock illustrations, Beautiful Free Art - Mixkit https://mixkit.co/free-stock-art/ Free Stock Photos https://photo-ac.com/ scrolller https://scrolller.com/art JOHN KRAUS PHOTOS https://www.johnkrausphotos.com/Portfolio/ Picrew https://picrew.me/ GENERATED FACES https://generated.photos/faces 用大作，不用翻墙和VPN秒看pixabay上的设计 http://www.bigbigwork.com/pixabay.html Awesome Wallpapers - wallhaven.cc https://wallhaven.cc/ 摄图网-正版高清图片免费下载_商用设计素材图库http://699pic.com/ 纹理 网站 网址 Subtle Patterns Free textures for your next web project 完美对称无缝平铺背景图底纹素材 - 图鱼 https://www.hituyu.com/ The Pattern Library http://thepatternlibrary.com 渐变 网站 网址 Fresh Background Gradients WebGradients.com 💎 uiGradients - Beautiful colored gradients https://uigradients.com/#TalkingToMiceElf LowPoly背景下载网站 网站 网址 uiGradients - Beautiful colored gradients https://uigradients.com/#Blu 地图生成网站 网站 网址 Pixel Map Generator amCharts 样机生成网站 网站 网址 Smartmockups - Free product mockup generator https://smartmockups.com/ Sketchsheets - Ready to print sketch sheet templates for UX designers https://sketchsheets.com/ Make Mockups, Logos, Videos and Designs in Seconds https://placeit.net/ GIF 网站 网址 With Stock Animated GIFs Crafted for Commercial Use https://cliply.co/ SOOGIF，找动图做动图.gif https://www.soogif.com/ Search all the GIFs and Stickers https://giphy.com/ LOGO 网站 网址 Instant Logo Search http://instantlogosearch.com/ Logo Maker - Create Your Own Logo, It's Free! - FreeLogoDesign https://www.freelogodesign.org/ PNG 网站 网址 free PNGs https://www.freepngs.com/search-pngs CLEAN PNG https://www.cleanpng.com/ 365psd https://cn.365psd.com/free-psd Download Free Vectors, Clipart Graphics, Vector Art &amp; Design Templates https://www.vecteezy.com/ freepik https://www.freepik.com/ humaaans https://www.humaaans.com/ illustrations 网站 网址 Free Vector Illustrations to Class up Your Project https://icons8.com/ouch IRA Design - Build your own amazing illustrations @ Creative Tim https://iradesign.io/ absurd illustrations that make sense https://absurd.design/ Illustration Gallery by ManyPixels Open-Source Editable Illustrations Free Vectors, Stock Photos &amp; PSD Downloads Freepik Illustration Gallery https://www.manypixels.co/gallery/ Illustration Gallery https://www.manypixels.co/gallery/ FREE ILLUSTRATIONS https://lukaszadam.com/illustrations 视频素材 网站 网址 Thousands of Free High-Resolution CC0 Photos and Videos https://isorepublic.com/ NASA Image and Video Library https://images.nasa.gov/ COVERR - Beautiful Free Stock Video Footage https://coverr.co/ Golden Wolf https://goldenwolf.tv/ 场库 https://www.vmovier.com/ Free stock videos · Pexels Videos https://www.pexels.com/videos/ 天空之城 https://www.skypixel.com/ Distill: Free HD Stock Video &amp; HD Video Clips https://wedistill.io/ Free Video Footage - Best Free Backgrounds Stock Video Footage https://www.free-video-footage.com/ Free Motion Backgrounds MP4, MOV video backgrounds for FREE! Free Stock Video Footage HD 4K Download Motion Graphics https://www.videvo.net/ Free Stock Footage Videos, 4k After Effects Templates and More! https://www.videezy.com/ Free 4K Stock Video | Stock Footage for Free – {Dareful} Completely Free 4K Stock Video https://www.dareful.com/ Free Stock Video Footage HD Royalty-Free Videos Download https://mazwai.com/#/ iTunes Movie Trailers https://trailers.apple.com/ Mixkit - Awesome free assets for your next video project https://mixkit.co/ XStockvideo http://www.xstockvideo.com/ ICON 网站 网址 IconMoon https://icomoon.io/ iconmonstr https://iconmonstr.com/ Zwicon – Icon set https://www.zwicon.com/cheatsheet.html Find Similar Icons http://compute.vision/nouns/index.html 图标下载，ICON(SVG/PNG/ICO/ICNS)图标搜索下载 - Easyicon http://www.easyicon.net Icon Ninja - 33350 vector icons and 700081 png icons for free download https://www.iconninja.com/ iconSweets — DesignBombs https://designbombs.com/iconsweets/ easyicon https://www.easyicon.net/ Icons for everything https://thenounproject.com/ SVG Icons Library - Vivid.js https://webkul.github.io/vivid/ 字体 网站 网址 iconfont https://www.iconfont.cn/ 100font.com - 免版权字体下载、免费商用字体下载网站 https://www.100font.com/ 造字工房 https://www.makefont.com/ 方正字库 http://www.foundertype.com/ 汉仪字库-用心绽放文字之美 http://www.hanyi.com.cn/ Font-To-Width http://font-to-width.com/ 字体下载-求字体网提供中文和英文字体库下载、识别与预览服务，找字体的好帮手 http://www.qiuziti.com/ ","link":"https://faded.auspicious.space/post/su-cai-wang-zhan/"},{"title":"资源网站","content":"PPT 网站 网址 51PPT模板 http://www.51pptmoban.com/ 优品PPT http://www.ypppt.com/ Office PLUS http://www.officeplus.cn/Template/Home.shtml 办公资源 https://www.bangongziyuan.com/ PPT Boss https://www.pptboss.com/template-center PPT之家 https://www.52ppt.com/moban/ 第一PPT http://www.1ppt.com/ 比格PPT http://www.tretars.com/ppt-templates 叮当设计PPT http://www.dingdangsheji.com/category/ppt/ 我图网精选PPT https://www.ooopic.com/intro/kidHome/ppt/ 设计师导航 网站 网址 叮当设计 http://www.dingdangsheji.com/ ","link":"https://faded.auspicious.space/post/zi-yuan-wang-zhan/"},{"title":"特色搜索","content":"网盘搜索 网站 网址 盘搜搜 https://www.pansoso.com/ 如风搜 http://www.rufengso.net/ 6miu百度云搜索 http://baiduyun.6miu.com/ 57分享百度云 https://www.57fx.com/user-drnew-daren/ 小不点搜索 https://www.xiaoso.net/ 特色搜索 网站 网址 龙轩搜索 http://ilxdh.com/ 虫部落搜索 https://www.chongbuluo.com/ neets搜索站 https://neets.cc/ 西林街搜索 https://xilinjie.cc/ 茶杯狐 https://www.cupfox.com/ 疯狂影视搜索 http://ifkdy.com/ AnywhereAnything http://lackar.com/aa/ 源代码搜索 https://publicwww.com/ 变量名搜索 https://unbug.github.io/codelf/ 比菲尔德学术搜索 https://www.base-search.net/ 吉他尤克里里谱搜索 https://sopu.52cmajor.com/ Classcentral在线课程搜索 https://www.classcentral.com/ Coursade在线课程搜索 http://www.coursade.com/ Chinese Etymology 字源 https://hanziyuan.net/ 汉典 https://www.zdic.net/ 新华字典 https://zidian.911cha.com/ 导航站 网站 网址 创造狮导航 http://chuangzaoshi.com/ 导航湾 https://www.daohangwan.com/ 好用好玩导航 http://www.haoyonghaowan.com/ 比格张 https://bigezhang.com/ Web前端导航 http://nav.web-hub.cn/ 阿猫阿狗导航 https://dh.woshipm.com/ BTMoo导航 https://www.btmoo.net/ ","link":"https://faded.auspicious.space/post/te-se-sou-suo/"},{"title":"电子书下载","content":"电子书下载 网站 网址 Baen free library https://www.baen.com/allbooks/category/index/id/2012 智奇搜书 https://www.zqbook.top/ 云海电子图书馆 http://www.pdfbook.cn/ 必看网 https://www.biikan.com/ bookboon https://bookboon.com/en Free-Ebooks https://www.free-ebooks.net/ ZLibrary https://b-ok.org/ 书格 https://new.shuge.org/ Academia https://www.academia.edu/ 图灵社区 https://www.ituring.com.cn/ 书伴 https://bookfere.com/ 好读 http://haodoo.net/ ePUBee http://cn.epubee.com/books/ 三秋书屋 https://www.d4j.cn/ SoBooks https://sobooks.cc/ i-Book.in https://book.tstrs.me/ WOW! eBook https://www.wowebook.org/ 计算机书籍控 http://bestcbooks.com/ 鸠摩搜索 https://www.jiumodiary.com/ Library Genesis http://gen.lib.rus.ec/ Library Genesis 2M http://libgen.io/ 免费的计算机编程类中文书籍 https://github.com/justjavac/free-programming-books-zh_CN 国立国会图书馆 https://dl.ndl.go.jp/ ZLibrary https://b-ok.cc/s/ 电子书转换 网站 网址 在线电子书转换器 http://cn.epubee.com/ 文本或 eBook 转换为 Mobi 格式 https://ebook.online-convert.com/convert-to-mobi ","link":"https://faded.auspicious.space/post/ebooks-download/"},{"title":"正则表达式——银行卡号","content":"记录中国主要银行发行的银行卡号的正则表达式 多种银行卡正则 var bankcardList = [{ bankName: &quot;中国邮政储蓄银行&quot;, bankCode: &quot;PSBC&quot;, patterns: [{ reg: /^(621096|621098|622150|622151|622181|622188|622199|955100|621095|620062|621285|621798|621799|621797|620529|621622|621599|621674|623218|623219)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(62215049|62215050|62215051|62218850|62218851|62218849)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622812|622810|622811|628310|625919)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;中国工商银行&quot;, bankCode: &quot;ICBC&quot;, patterns: [{ reg: /^(620200|620302|620402|620403|620404|620406|620407|620409|620410|620411|620412|620502|620503|620405|620408|620512|620602|620604|620607|620611|620612|620704|620706|620707|620708|620709|620710|620609|620712|620713|620714|620802|620711|620904|620905|621001|620902|621103|621105|621106|621107|621102|621203|621204|621205|621206|621207|621208|621209|621210|621302|621303|621202|621305|621306|621307|621309|621311|621313|621211|621315|621304|621402|621404|621405|621406|621407|621408|621409|621410|621502|621317|621511|621602|621603|621604|621605|621608|621609|621610|621611|621612|621613|621614|621615|621616|621617|621607|621606|621804|621807|621813|621814|621817|621901|621904|621905|621906|621907|621908|621909|621910|621911|621912|621913|621915|622002|621903|622004|622005|622006|622007|622008|622010|622011|622012|621914|622015|622016|622003|622018|622019|622020|622102|622103|622104|622105|622013|622111|622114|622017|622110|622303|622304|622305|622306|622307|622308|622309|622314|622315|622317|622302|622402|622403|622404|622313|622504|622505|622509|622513|622517|622502|622604|622605|622606|622510|622703|622715|622806|622902|622903|622706|623002|623006|623008|623011|623012|622904|623015|623100|623202|623301|623400|623500|623602|623803|623901|623014|624100|624200|624301|624402|623700|624000)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622200|622202|622203|622208|621225|620058|621281|900000|621558|621559|621722|621723|620086|621226|621618|620516|621227|621288|621721|900010|623062|621670|621720|621379|621240|621724|621762|621414|621375|622926|622927|622928|622929|622930|622931|621733|621732|621372|621369|621763)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(402791|427028|427038|548259|621376|621423|621428|621434|621761|621749|621300|621378|622944|622949|621371|621730|621734|621433|621370|621764|621464|621765|621750|621377|621367|621374|621731|621781)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(9558)\\d{15}$/g, cardType: &quot;DC&quot; }, { reg: /^(370246|370248|370249|370247|370267|374738|374739)\\d{9}$/g, cardType: &quot;CC&quot; }, { reg: /^(427010|427018|427019|427020|427029|427030|427039|438125|438126|451804|451810|451811|458071|489734|489735|489736|510529|427062|524091|427064|530970|530990|558360|524047|525498|622230|622231|622232|622233|622234|622235|622237|622239|622240|622245|622238|451804|451810|451811|458071|628288|628286|622206|526836|513685|543098|458441|622246|544210|548943|356879|356880|356881|356882|528856|625330|625331|625332|622236|524374|550213|625929|625927|625939|625987|625930|625114|622159|625021|625022|625932|622889|625900|625915|625916|622171|625931|625113|625928|625914|625986|625925|625921|625926|625942|622158|625917|625922|625934|625933|625920|625924|625017|625018|625019)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(45806|53098|45806|53098)\\d{11}$/g, cardType: &quot;CC&quot; }, { reg: /^(622210|622211|622212|622213|622214|622220|622223|622225|622229|622215|622224)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(620054|620142|620184|620030|620050|620143|620149|620124|620183|620094|620186|620148|620185)\\d{10}$/g, cardType: &quot;PC&quot; }, { reg: /^(620114|620187|620046)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;中国农业银行&quot;, bankCode: &quot;ABC&quot;, patterns: [{ reg: /^(622841|622824|622826|622848|620059|621282|622828|622823|621336|621619|622821|622822|622825|622827|622845|622849|623018|623206|621671|622840|622843|622844|622846|622847|620501)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(95595|95596|95597|95598|95599)\\d{14}$/g, cardType: &quot;DC&quot; }, { reg: /^(103)\\d{16}$/g, cardType: &quot;DC&quot; }, { reg: /^(403361|404117|404118|404119|404120|404121|463758|519412|519413|520082|520083|552599|558730|514027|622836|622837|628268|625996|625998|625997|622838|625336|625826|625827|544243|548478|628269)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622820|622830)\\d{10}$/g, cardType: &quot;SCC&quot; }] }, { bankName: &quot;中国银行&quot;, bankCode: &quot;BOC&quot;, patterns: [{ reg: /^(621660|621661|621662|621663|621665|621667|621668|621669|621666|456351|601382|621256|621212|621283|620061|621725|621330|621331|621332|621333|621297|621568|621569|621672|623208|621620|621756|621757|621758|621759|621785|621786|621787|621788|621789|621790|622273|622274|622771|622772|622770|621741|621041)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(621293|621294|621342|621343|621364|621394|621648|621248|621215|621249|621231|621638|621334|621395|623040|622348)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625908|625910|625909|356833|356835|409665|409666|409668|409669|409670|409671|409672|512315|512316|512411|512412|514957|409667|438088|552742|553131|514958|622760|628388|518377|622788|628313|628312|622750|622751|625145|622479|622480|622789|625140|622346|622347)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(518378|518379|518474|518475|518476|524865|525745|525746|547766|558868|622752|622753|622755|524864|622757|622758|622759|622761|622762|622763|622756|622754|622764|622765|558869|625905|625906|625907|625333)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(53591|49102|377677)\\d{11}$/g, cardType: &quot;SCC&quot; }, { reg: /^(620514|620025|620026|620210|620211|620019|620035|620202|620203|620048|620515|920000)\\d{10}$/g, cardType: &quot;PC&quot; }, { reg: /^(620040|620531|620513|921000|620038)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;中国建设银行&quot;, bankCode: &quot;CCB&quot;, patterns: [{ reg: /^(621284|436742|589970|620060|621081|621467|621598|621621|621700|622280|622700|623211|623668)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(421349|434061|434062|524094|526410|552245|621080|621082|621466|621488|621499|622966|622988|622382|621487|621083|621084|620107)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(436742193|622280193)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(553242)\\d{12}$/g, cardType: &quot;CC&quot; }, { reg: /^(625362|625363|628316|628317|356896|356899|356895|436718|436738|436745|436748|489592|531693|532450|532458|544887|552801|557080|558895|559051|622166|622168|622708|625964|625965|625966|628266|628366|622381|622675|622676|622677)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(5453242|5491031|5544033)\\d{11}$/g, cardType: &quot;CC&quot; }, { reg: /^(622725|622728|436728|453242|491031|544033|622707|625955|625956)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(53242|53243)\\d{11}$/g, cardType: &quot;SCC&quot; }] }, { bankName: &quot;中国交通银行&quot;, bankCode: &quot;COMM&quot;, patterns: [{ reg: /^(622261|622260|622262|621002|621069|621436|621335)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(620013)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(405512|601428|405512|601428|622258|622259|405512|601428)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(49104|53783)\\d{11}$/g, cardType: &quot;CC&quot; }, { reg: /^(434910|458123|458124|520169|522964|552853|622250|622251|521899|622253|622656|628216|622252|955590|955591|955592|955593|628218|625028|625029)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622254|622255|622256|622257|622284)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(620021|620521)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;招商银行&quot;, bankCode: &quot;CMB&quot;, patterns: [{ reg: /^(402658|410062|468203|512425|524011|622580|622588|622598|622609|95555|621286|621483|621485|621486|621299)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(690755)\\d{9}$/g, cardType: &quot;DC&quot; }, { reg: /^(690755)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(356885|356886|356887|356888|356890|439188|439227|479228|479229|521302|356889|545620|545621|545947|545948|552534|552587|622575|622576|622577|622578|622579|545619|622581|622582|545623|628290|439225|518710|518718|628362|439226|628262|625802|625803)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(370285|370286|370287|370289)\\d{9}$/g, cardType: &quot;CC&quot; }, { reg: /^(620520)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;中国民生银行&quot;, bankCode: &quot;CMBC&quot;, patterns: [{ reg: /^(622615|622616|622618|622622|622617|622619|415599|421393|421865|427570|427571|472067|472068|622620)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(545392|545393|545431|545447|356859|356857|407405|421869|421870|421871|512466|356856|528948|552288|622600|622601|622602|517636|622621|628258|556610|622603|464580|464581|523952|545217|553161|356858|622623|625912|625913|625911)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(377155|377152|377153|377158)\\d{9}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;中国光大银行&quot;, bankCode: &quot;CEB&quot;, patterns: [{ reg: /^(303)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(90030)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(620535)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(620085|622660|622662|622663|622664|622665|622666|622667|622669|622670|622671|622672|622668|622661|622674|622673|620518|621489|621492)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(356837|356838|486497|622657|622685|622659|622687|625978|625980|625981|625979|356839|356840|406252|406254|425862|481699|524090|543159|622161|622570|622650|622655|622658|625975|625977|628201|628202|625339|625976)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;中信银行&quot;, bankCode: &quot;CITIC&quot;, patterns: [{ reg: /^(433670|433680|442729|442730|620082|622690|622691|622692|622696|622698|622998|622999|433671|968807|968808|968809|621771|621767|621768|621770|621772|621773|622453|622456)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622459)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(376968|376969|376966)\\d{9}$/g, cardType: &quot;CC&quot; }, { reg: /^(400360|403391|403392|404158|404159|404171|404172|404173|404174|404157|433667|433668|433669|514906|403393|520108|433666|558916|622678|622679|622680|622688|622689|628206|556617|628209|518212|628208|356390|356391|356392|622916|622918|622919)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;华夏银行&quot;, bankCode: &quot;HXBANK&quot;, patterns: [{ reg: /^(622630|622631|622632|622633|999999|621222|623020|623021|623022|623023)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(523959|528709|539867|539868|622637|622638|628318|528708|622636|625967|625968|625969)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;深发/平安银行&quot;, bankCode: &quot;SPABANK&quot;, patterns: [{ reg: /^(621626|623058)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(602907|622986|622989|622298|627069|627068|627066|627067|412963|415752|415753|622535|622536|622538|622539|998800|412962|622983)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(531659|622157|528020|622155|622156|526855|356869|356868|625360|625361|628296|435744|435745|483536|622525|622526|998801|998802)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620010)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;兴业银行&quot;, bankCode: &quot;CIB&quot;, patterns: [{ reg: /^(438589)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(90592)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(966666|622909|438588|622908)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(461982|486493|486494|486861|523036|451289|527414|528057|622901|622902|622922|628212|451290|524070|625084|625085|625086|625087|548738|549633|552398|625082|625083|625960|625961|625962|625963)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620010)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;上海银行&quot;, bankCode: &quot;SHBANK&quot;, patterns: [{ reg: /^(621050|622172|622985|622987|620522|622267|622278|622279|622468|622892|940021)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(438600)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(356827|356828|356830|402673|402674|486466|519498|520131|524031|548838|622148|622149|622268|356829|622300|628230|622269|625099|625953)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;浦东发展银行&quot;, bankCode: &quot;SPDB&quot;, patterns: [{ reg: /^(622516|622517|622518|622521|622522|622523|984301|984303|621352|621793|621795|621796|621351|621390|621792|621791)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(84301|84336|84373|84385|84390|87000|87010|87030|87040|84380|84361|87050|84342)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(356851|356852|404738|404739|456418|498451|515672|356850|517650|525998|622177|622277|628222|622500|628221|622176|622276|622228|625957|625958|625993|625831)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622520|622519)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(620530)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;广发银行&quot;, bankCode: &quot;GDB&quot;, patterns: [{ reg: /^(622516|622517|622518|622521|622522|622523|984301|984303|621352|621793|621795|621796|621351|621390|621792|621791)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622568|6858001|6858009|621462)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(9111)\\d{15}$/g, cardType: &quot;DC&quot; }, { reg: /^(406365|406366|428911|436768|436769|436770|487013|491032|491033|491034|491035|491036|491037|491038|436771|518364|520152|520382|541709|541710|548844|552794|493427|622555|622556|622557|622558|622559|622560|528931|558894|625072|625071|628260|628259|625805|625806|625807|625808|625809|625810)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(685800|6858000)\\d{13}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;渤海银行&quot;, bankCode: &quot;BOHAIB&quot;, patterns: [{ reg: /^(621268|622684|622884|621453)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;广州银行&quot;, bankCode: &quot;GCB&quot;, patterns: [{ reg: /^(603445|622467|940016|621463)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;金华银行&quot;, bankCode: &quot;JHBANK&quot;, patterns: [{ reg: /^(622449|940051)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622450|628204)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;温州银行&quot;, bankCode: &quot;WZCB&quot;, patterns: [{ reg: /^(621977)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622868|622899|628255)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;徽商银行&quot;, bankCode: &quot;HSBANK&quot;, patterns: [{ reg: /^(622877|622879|621775|623203)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(603601|622137|622327|622340|622366)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(628251|622651|625828)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;江苏银行&quot;, bankCode: &quot;JSBANK&quot;, patterns: [{ reg: /^(621076|622173|622131|621579|622876)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(504923|622422|622447|940076)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628210|622283|625902)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;南京银行&quot;, bankCode: &quot;NJCB&quot;, patterns: [{ reg: /^(621777|622305|621259)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622303|628242|622595|622596)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;宁波银行&quot;, bankCode: &quot;NBBANK&quot;, patterns: [{ reg: /^(621279|622281|622316|940022)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621418)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625903|622778|628207|512431|520194|622282|622318)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;北京银行&quot;, bankCode: &quot;BJBANK&quot;, patterns: [{ reg: /^(623111|421317|422161|602969|422160|621030|621420|621468)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(522001|622163|622853|628203|622851|622852)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;北京农村商业银行&quot;, bankCode: &quot;BJRCB&quot;, patterns: [{ reg: /^(620088|621068|622138|621066|621560)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625526|625186|628336)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;汇丰银行&quot;, bankCode: &quot;HSBC&quot;, patterns: [{ reg: /^(622946)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622406|621442)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622407|621443)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622360|622361|625034|625096|625098)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;渣打银行&quot;, bankCode: &quot;SCB&quot;, patterns: [{ reg: /^(622948|621740|622942|622994)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622482|622483|622484)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;花旗银行&quot;, bankCode: &quot;CITI&quot;, patterns: [{ reg: /^(621062|621063)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625076|625077|625074|625075|622371|625091)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;东亚银行&quot;, bankCode: &quot;HKBEA&quot;, patterns: [{ reg: /^(622933|622938|623031|622943|621411)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622372|622471|622472|622265|622266|625972|625973)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622365)\\d{11}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;广东华兴银行&quot;, bankCode: &quot;GHB&quot;, patterns: [{ reg: /^(621469|621625)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;深圳农村商业银行&quot;, bankCode: &quot;SRCB&quot;, patterns: [{ reg: /^(622128|622129|623035)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;广州农村商业银行股份有限公司&quot;, bankCode: &quot;GZRCU&quot;, patterns: [{ reg: /^(909810|940035|621522|622439)\\d{12}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;东莞农村商业银行&quot;, bankCode: &quot;DRCBCL&quot;, patterns: [{ reg: /^(622328|940062|623038)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625288|625888)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;东莞市商业银行&quot;, bankCode: &quot;BOD&quot;, patterns: [{ reg: /^(622333|940050)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621439|623010)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622888)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;广东省农村信用社联合社&quot;, bankCode: &quot;GDRCC&quot;, patterns: [{ reg: /^(622302)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622477|622509|622510|622362|621018|621518)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;大新银行&quot;, bankCode: &quot;DSB&quot;, patterns: [{ reg: /^(622297|621277)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622375|622489)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622293|622295|622296|622373|622451|622294|625940)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;永亨银行&quot;, bankCode: &quot;WHB&quot;, patterns: [{ reg: /^(622871|622958|622963|622957|622861|622932|622862|621298)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622798|625010|622775|622785)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;星展银行香港有限公司&quot;, bankCode: &quot;DBS&quot;, patterns: [{ reg: /^(621016|621015)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622487|622490|622491|622492)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622487|622490|622491|622492|621744|621745|621746|621747)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;恒丰银行&quot;, bankCode: &quot;EGBANK&quot;, patterns: [{ reg: /^(623078)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622384|940034)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;天津市商业银行&quot;, bankCode: &quot;TCCB&quot;, patterns: [{ reg: /^(940015|622331)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(6091201)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622426|628205)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;浙商银行&quot;, bankCode: &quot;CZBANK&quot;, patterns: [{ reg: /^(621019|622309|621019)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(6223091100|6223092900|6223093310|6223093320|6223093330|6223093370|6223093380|6223096510|6223097910)\\d{9}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;南洋商业银行&quot;, bankCode: &quot;NCB&quot;, patterns: [{ reg: /^(621213|621289|621290|621291|621292|621042|621743)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(623041|622351)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625046|625044|625058|622349|622350)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620208|620209|625093|625095)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;厦门银行&quot;, bankCode: &quot;XMBANK&quot;, patterns: [{ reg: /^(622393|940023)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(6886592)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(623019|621600|)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;福建海峡银行&quot;, bankCode: &quot;FJHXBC&quot;, patterns: [{ reg: /^(622388)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621267|623063)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(620043|)\\d{12}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;吉林银行&quot;, bankCode: &quot;JLBANK&quot;, patterns: [{ reg: /^(622865|623131)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(940012)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622178|622179|628358)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;汉口银行&quot;, bankCode: &quot;HKB&quot;, patterns: [{ reg: /^(990027)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622325|623105|623029)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;盛京银行&quot;, bankCode: &quot;SJBANK&quot;, patterns: [{ reg: /^(566666)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622455|940039)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(623108|623081)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622466|628285)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;大连银行&quot;, bankCode: &quot;DLB&quot;, patterns: [{ reg: /^(603708)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622993|623069|623070|623172|623173)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622383|622385|628299)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;河北银行&quot;, bankCode: &quot;BHB&quot;, patterns: [{ reg: /^(622498|622499|623000|940046)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622921|628321)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;乌鲁木齐市商业银行&quot;, bankCode: &quot;URMQCCB&quot;, patterns: [{ reg: /^(621751|622143|940001|621754)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622476|628278)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;绍兴银行&quot;, bankCode: &quot;SXCB&quot;, patterns: [{ reg: /^(622486)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(603602|623026|623086)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(628291)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;成都商业银行&quot;, bankCode: &quot;CDCB&quot;, patterns: [{ reg: /^(622152|622154|622996|622997|940027|622153|622135|621482|621532)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;抚顺银行&quot;, bankCode: &quot;FSCB&quot;, patterns: [{ reg: /^(622442)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(940053)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622442|623099)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;郑州银行&quot;, bankCode: &quot;ZZBANK&quot;, patterns: [{ reg: /^(622421)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(940056)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(96828)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;宁夏银行&quot;, bankCode: &quot;NXBANK&quot;, patterns: [{ reg: /^(621529|622429|621417|623089|623200)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628214|625529|622428)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;重庆银行&quot;, bankCode: &quot;CQBANK&quot;, patterns: [{ reg: /^(9896)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622134|940018|623016)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;哈尔滨银行&quot;, bankCode: &quot;HRBANK&quot;, patterns: [{ reg: /^(621577|622425)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(940049)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622425)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;兰州银行&quot;, bankCode: &quot;LZYH&quot;, patterns: [{ reg: /^(622139|940040|628263)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621242|621538|621496)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;青岛银行&quot;, bankCode: &quot;QDCCB&quot;, patterns: [{ reg: /^(621252|622146|940061|628239)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621419|623170)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;秦皇岛市商业银行&quot;, bankCode: &quot;QHDCCB&quot;, patterns: [{ reg: /^(62249802|94004602)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(621237|623003)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;青海银行&quot;, bankCode: &quot;BOQH&quot;, patterns: [{ reg: /^(622310|940068)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622817|628287|625959)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(62536601)\\d{8}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;台州银行&quot;, bankCode: &quot;TZCB&quot;, patterns: [{ reg: /^(622427)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(940069)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(623039)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622321|628273)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(625001)\\d{10}$/g, cardType: &quot;SCC&quot; }] }, { bankName: &quot;长沙银行&quot;, bankCode: &quot;CSCB&quot;, patterns: [{ reg: /^(694301)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(940071|622368|621446)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625901|622898|622900|628281|628282|622806|628283)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620519)\\d{13}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;泉州银行&quot;, bankCode: &quot;BOQZ&quot;, patterns: [{ reg: /^(683970|940074)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622370)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(621437)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628319)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;包商银行&quot;, bankCode: &quot;BSB&quot;, patterns: [{ reg: /^(622336|621760)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622165)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622315|625950|628295)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;龙江银行&quot;, bankCode: &quot;DAQINGB&quot;, patterns: [{ reg: /^(621037|621097|621588|622977)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(62321601)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622860)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622644|628333)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;上海农商银行&quot;, bankCode: &quot;SHRCB&quot;, patterns: [{ reg: /^(622478|940013|621495)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625500)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(622611|622722|628211|625989)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;浙江泰隆商业银行&quot;, bankCode: &quot;ZJQL&quot;, patterns: [{ reg: /^(622717)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(628275|622565|622287)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;内蒙古银行&quot;, bankCode: &quot;H3CB&quot;, patterns: [{ reg: /^(622147|621633)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628252)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;广西北部湾银行&quot;, bankCode: &quot;BGB&quot;, patterns: [{ reg: /^(623001)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628227)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(622335)\\d{10}$/g, cardType: &quot;CC&quot; } ] }, { bankName: &quot;桂林银行&quot;, bankCode: &quot;GLBANK&quot;, patterns: [{ reg: /^(621456)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(621562)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628219)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;龙江银行&quot;, bankCode: &quot;DAQINGB&quot;, patterns: [{ reg: /^(621037|621097|621588|622977)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(62321601)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622475|622860)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625588)\\d{10}$/g, cardType: &quot;SCC&quot; }, { reg: /^(622270|628368|625090|622644|628333)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;成都农村商业银行&quot;, bankCode: &quot;CDRCB&quot;, patterns: [{ reg: /^(623088)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622829|628301|622808|628308)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;福建省农村信用社联合社&quot;, bankCode: &quot;FJNX&quot;, patterns: [{ reg: /^(622127|622184|621701|621251|621589|623036)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628232|622802|622290)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;天津农村商业银行&quot;, bankCode: &quot;TRCB&quot;, patterns: [{ reg: /^(622531|622329)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622829|628301)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;江苏省农村信用社联合社&quot;, bankCode: &quot;JSRCU&quot;, patterns: [{ reg: /^(621578|623066|622452|622324)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622815|622816|628226)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;湖南农村信用社联合社&quot;, bankCode: &quot;SLH&quot;, patterns: [{ reg: /^(622906|628386|625519|625506)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;江西省农村信用社联合社&quot;, bankCode: &quot;JXNCX&quot;, patterns: [{ reg: /^(621592)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628392)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;商丘市商业银行&quot;, bankCode: &quot;SCBBANK&quot;, patterns: [{ reg: /^(621748)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628271)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;华融湘江银行&quot;, bankCode: &quot;HRXJB&quot;, patterns: [{ reg: /^(621366|621388)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628328)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;衡水市商业银行&quot;, bankCode: &quot;HSBK&quot;, patterns: [{ reg: /^(621239|623068)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;重庆南川石银村镇银行&quot;, bankCode: &quot;CQNCSYCZ&quot;, patterns: [{ reg: /^(621653004)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;湖南省农村信用社联合社&quot;, bankCode: &quot;HNRCC&quot;, patterns: [{ reg: /^(622169|621519|621539|623090)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;邢台银行&quot;, bankCode: &quot;XTB&quot;, patterns: [{ reg: /^(621238|620528)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;临汾市尧都区农村信用合作联社&quot;, bankCode: &quot;LPRDNCXYS&quot;, patterns: [{ reg: /^(628382|625158)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;东营银行&quot;, bankCode: &quot;DYCCB&quot;, patterns: [{ reg: /^(621004)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(628217)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;上饶银行&quot;, bankCode: &quot;SRBANK&quot;, patterns: [{ reg: /^(621416)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628217)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;德州银行&quot;, bankCode: &quot;DZBANK&quot;, patterns: [{ reg: /^(622937)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628397)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;承德银行&quot;, bankCode: &quot;CDB&quot;, patterns: [{ reg: /^(628229)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;云南省农村信用社&quot;, bankCode: &quot;YNRCC&quot;, patterns: [{ reg: /^(622469|628307)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;柳州银行&quot;, bankCode: &quot;LZCCB&quot;, patterns: [{ reg: /^(622292|622291|621412)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622880|622881)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(62829)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;威海市商业银行&quot;, bankCode: &quot;WHSYBANK&quot;, patterns: [{ reg: /^(623102)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628234)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;湖州银行&quot;, bankCode: &quot;HZBANK&quot;, patterns: [{ reg: /^(628306)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;潍坊银行&quot;, bankCode: &quot;BANKWF&quot;, patterns: [{ reg: /^(622391|940072)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(628391)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;赣州银行&quot;, bankCode: &quot;GZB&quot;, patterns: [{ reg: /^(622967|940073)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628233)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;日照银行&quot;, bankCode: &quot;RZGWYBANK&quot;, patterns: [{ reg: /^(628257)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;南昌银行&quot;, bankCode: &quot;NCB&quot;, patterns: [{ reg: /^(621269|622275)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(940006)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(628305)\\d{11}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;贵阳银行&quot;, bankCode: &quot;GYCB&quot;, patterns: [{ reg: /^(622133|621735)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(888)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628213)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;锦州银行&quot;, bankCode: &quot;BOJZ&quot;, patterns: [{ reg: /^(622990|940003)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(628261)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;齐商银行&quot;, bankCode: &quot;QSBANK&quot;, patterns: [{ reg: /^(622311|940057)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(628311)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;珠海华润银行&quot;, bankCode: &quot;RBOZ&quot;, patterns: [{ reg: /^(622363|940048)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628270)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;葫芦岛市商业银行&quot;, bankCode: &quot;HLDCCB&quot;, patterns: [{ reg: /^(622398|940054)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;宜昌市商业银行&quot;, bankCode: &quot;HBC&quot;, patterns: [{ reg: /^(940055)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622397)\\d{11}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;杭州商业银行&quot;, bankCode: &quot;HZCB&quot;, patterns: [{ reg: /^(603367|622878)\\d{12}$/g, cardType: &quot;DC&quot; }, { reg: /^(622397)\\d{11}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;苏州市商业银行&quot;, bankCode: &quot;JSBANK&quot;, patterns: [{ reg: /^(603506)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;辽阳银行&quot;, bankCode: &quot;LYCB&quot;, patterns: [{ reg: /^(622399|940043)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;洛阳银行&quot;, bankCode: &quot;LYB&quot;, patterns: [{ reg: /^(622420|940041)\\d{11}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;焦作市商业银行&quot;, bankCode: &quot;JZCBANK&quot;, patterns: [{ reg: /^(622338)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(940032)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;镇江市商业银行&quot;, bankCode: &quot;ZJCCB&quot;, patterns: [{ reg: /^(622394|940025)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;法国兴业银行&quot;, bankCode: &quot;FGXYBANK&quot;, patterns: [{ reg: /^(621245)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;大华银行&quot;, bankCode: &quot;DYBANK&quot;, patterns: [{ reg: /^(621328)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;企业银行&quot;, bankCode: &quot;DIYEBANK&quot;, patterns: [{ reg: /^(621651)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;华侨银行&quot;, bankCode: &quot;HQBANK&quot;, patterns: [{ reg: /^(621077)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;恒生银行&quot;, bankCode: &quot;HSB&quot;, patterns: [{ reg: /^(622409|621441)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622410|621440)\\d{11}$/g, cardType: &quot;DC&quot; }, { reg: /^(622950|622951)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625026|625024|622376|622378|622377|625092)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;临沂商业银行&quot;, bankCode: &quot;LSB&quot;, patterns: [{ reg: /^(622359|940066)\\d{13}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;烟台商业银行&quot;, bankCode: &quot;YTCB&quot;, patterns: [{ reg: /^(622886)\\d{10}$/g, cardType: &quot;DC&quot; }] }, { bankName: &quot;齐鲁银行&quot;, bankCode: &quot;QLB&quot;, patterns: [{ reg: /^(940008|622379)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(628379)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;BC卡公司&quot;, bankCode: &quot;BCCC&quot;, patterns: [{ reg: /^(620011|620027|620031|620039|620103|620106|620120|620123|620125|620220|620278|620812|621006|621011|621012|621020|621023|621025|621027|621031|620132|621039|621078|621220|621003)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(625003|625011|625012|625020|625023|625025|625027|625031|621032|625039|625078|625079|625103|625106|625006|625112|625120|625123|625125|625127|625131|625032|625139|625178|625179|625220|625320|625111|625132|625244)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;集友银行&quot;, bankCode: &quot;CYB&quot;, patterns: [{ reg: /^(622355|623042)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(621043|621742)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(622352|622353|625048|625053|625060)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620206|620207)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;大丰银行&quot;, bankCode: &quot;TFB&quot;, patterns: [{ reg: /^(622547|622548|622546)\\d{13}$/g, cardType: &quot;DC&quot; }, { reg: /^(625198|625196|625147)\\d{10}$/g, cardType: &quot;CC&quot; }, { reg: /^(620072)\\d{13}$/g, cardType: &quot;PC&quot; }, { reg: /^(620204|620205)\\d{10}$/g, cardType: &quot;PC&quot; }] }, { bankName: &quot;AEON信贷财务亚洲有限公司&quot;, bankCode: &quot;AEON&quot;, patterns: [{ reg: /^(621064|622941|622974)\\d{10}$/g, cardType: &quot;DC&quot; }, { reg: /^(622493)\\d{10}$/g, cardType: &quot;CC&quot; }] }, { bankName: &quot;澳门BDA&quot;, bankCode: &quot;MABDA&quot;, patterns: [{ reg: /^(621274|621324)\\d{13}$/g, cardType: &quot;DC&quot; }] }] //验证银行卡号 $(&quot;input[name='bankNum']&quot;).blur(function () { var num = $(this).val(); //去掉空格，因为input框中设置了自动空格，如果input框中没有设置自动空格可省略这句代码 num = num.replace(/\\s/g, &quot;&quot;); //判断卡号是否正确 for (var i = 0,len=bankcardList.length; i &lt; len; i++) { for (var j = 0,regLen = bankcardList[i].patterns.length; j &lt; regLen; j++) { var reg = bankcardList[i].patterns[j].reg.test(num); if(reg){ alert(&quot;输入的是&quot;+bankcardList[i].bankName+&quot;的卡号&quot;) return ; } } } }); ","link":"https://faded.auspicious.space/post/regular-expression-band-card/"},{"title":"正则表达式——简介","content":"在自然语言处理中，很多时候我们都需要从文本或字符串中抽取出想要的信息，并进一步做语义理解或其它处理。 常用正则表达式网站 Regex Dictionary https://visca.com/regexdict/ RegExr https://regexr.com/ RegExper https://regexper.com/ Regular Expressions 101 https://regex101.com/ 基本语句 ♍锚点：^ 和 $ ^The 匹配任何以“The”开头的字符串。 end$ 匹配以“end”为结尾的字符串。 ^The end$ 匹配从“The”开始到“end”结束的字符串。 roar 匹配任何带有文本“roar”的字符串。 ♍数量符：* 和 + 和 ? 和 {} abc* 匹配在“ab”后面跟着 0 个或多个“c”的字符串。 abc+ 匹配在“ab”后面跟着 1 个或多个“c”的字符串。 abc? 匹配在“ab”后面跟着 0 个或 1 个“c”的字符串。 abc{2} 匹配在“ab”后面跟着 2 个“c”的字符串。 abc{2,} 匹配在“ab”后面跟着 2 个或更多“c”的字符串。 abc{2,5} 匹配在“ab”后面跟着 2 到 5 个“c”的字符串。 a(bc)* 匹配在“a”后面跟着 0 个或更多“bc”序列的字符串。 a(bc){2,5} 匹配在“a”后面跟着 2 到 5 个“bc”序列的字符串。 ♍或运算符：| 和 [] a(b|c) 匹配在“a”后面跟着“b”或“c”的字符串。 a[bc] 匹配在“a”后面跟着“b”或“c”的字符串。 ♍字符类：\\d 和 \\w 和 \\s 和 . \\d 匹配数字型的单个字符。 \\w 匹配单个词字（字母加下划线）。 \\s 匹配单个空格字符（包括制表符和换行符）。 . 匹配任意字符。 使用 . 运算符需要非常小心，因为常见类或排除型字符类都要更快与精确。\\d、\\w 和 \\s 同样有它们各自的排除型字符类，即 \\D、\\W 和 \\S。例如 \\D 将执行与 \\d 完全相反的匹配方法： \\D 匹配单个非数字型的字符。 为了正确地匹配，我们必须使用转义符反斜杠 \\ 定义我们需要匹配的符号 ^.[$()|*+?{\\，因为我们可能认为这些符号在原文本中有特殊的含义。 \\$\\d 匹配在单个数字前有符号“$”的字符串。 注意我们同样能匹配 non-printable 字符，例如 Tab 符 \\t、换行符 \\n 和回车符 \\r。 ♍Flags 模式的结尾我们通常可以指定以下 flag 配置或它们的组合： g（global）在第一次完成匹配后并不会返回结果，它会继续搜索剩下的文本。 m（multi line）允许使用^和$匹配一行的开始和结尾，而不是整个序列。 i（insensitive）令整个表达式不区分大小写（例如/aBc/i 将匹配 AbC）。 中级语句 ♍分组和捕获：() a(bc) 圆括弧会创建一个捕获性分组，它会捕获匹配项“bc”。 a(?:bc)* 使用“?: ”会使捕获分组失效，只需要匹配前面的“a”。 a(?&lt;foo&gt;bc) 使用“?&lt;foo&gt;”会为分组配置一个名称 。 捕获性圆括号 () 和非捕获性圆括弧 (?:) 对于从字符串或数据中抽取信息非常重要，我们可以使用 Python 等不同的编程语言实现这一功能。从多个分组中捕获的多个匹配项将以经典的数组形式展示：我们可以使用匹配结果的索引访问它们的值。如果需要为分组添加名称（使用 (?&lt;foo&gt;...)），我们就能如字典那样使用匹配结果检索分组的值，其中字典的键为分组的名称。 ♍方括弧表达式：[] [abc] 匹配带有一个“a”、“ab”或“ac”的字符串。 [a-c] 匹配带有一个“a”、“ab”或“ac”的字符串。 [a-fA-F0-9] 匹配一个代表 16 进制数字的字符串，不区分大小写。 [0-9]% 匹配在 % 符号前面带有 0 到 9 这几个字符的字符串。 [^a-zA-Z] 匹配不带 a 到 z 或 A 到 Z 的字符串，其中 ^ 为否定表达式。 记住在方括弧内，所有特殊字符（包括反斜杠 \\ ）都会失去它们应有的意义。 ♍Greedy 和 Lazy 匹配 数量符（* + {}）是一种贪心运算符，所以它们会遍历给定的文本，并尽可能匹配。例如，&lt;.+&gt; 可以匹配文本 “This is a &lt;div&gt; simple div&lt;/div&gt; test” 中的 “&lt;div&gt;simple div&lt;/div&gt;&quot;。为了仅捕获 div 标签，我们需要使用 ? 令贪心搜索变得 Lazy 一点： &lt;.+?&gt; 一次或多次匹配“&lt;”和“&gt;”里面的任何字符，可按需扩展。 注意更好的解决方案应该需要避免使用 .，这有利于实现更严格的正则表达式： &lt;[^&lt;&gt;]+&gt; 一次或多次匹配“&lt;”和“&gt;”里面的任何字符，除去“&lt;”或“&gt;”字符。 高级语句 ♍边界符：\\b 和 \\B \\babc\\b 执行整词匹配搜索。 \\b 如插入符号那样表示一个锚点（它与 $ 和 ^ 相同）来匹配位置，其中一边是一个单词符号（如 \\w），另一边不是单词符号（例如它可能是字符串的起始点或空格符号）。 它同样能表达相反的非单词边界 \\B，它会匹配 \\b 不会匹配的位置，如果我们希望找到被单词字符环绕的搜索模式，就可以使用它。 \\Babc\\B 只要是被单词字符环绕的模式就会匹配。 ♍前向匹配和后向匹配：(?=) 和 (?&lt;=) d(?=r) 只有在后面跟着“r”的时候才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分。 (?&lt;=r)d 只有在前面跟着“r”时才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分。 我们同样能使用否定运算子： d(?!r) 只有在后面不跟着“r”的时候才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分。 (?&lt;!r)d 只有在前面不跟着“r”时才匹配“d”，但是“r”并不会成为整个正则表达式匹配的一部分。 结语 正如上文所示，正则表达式的应用领域非常广，很可能各位读者在开发的过程中已经遇到了它，下面是正则表达式常用的领域： 数据验证，例如检查时间字符串是否符合格式； 数据抓取，以特定顺序抓取包含特定文本或内容的网页； 数据包装，将数据从某种原格式转换为另外一种格式； 字符串解析，例如捕获所拥有 URL 的 GET 参数，或捕获一组圆括弧内的文本； 字符串替代，将字符串中的某个字符替换为其它字符。 ","link":"https://faded.auspicious.space/post/regular-expression-introduction/"},{"title":"有趣的网站","content":"一些平时遇到的有用有趣的网站 网站 网址 在浏览器中运行 Linux https://bellard.org/jslinux/ 一个修改漫画的小工具 https://moeka.me/mangaEditor/ AI 人工智能图片放大 https://bigjpg.com/ 黑白照片上色 https://colourise.sg/ 在线 Photoshop https://ps.gaoding.com/#/ GIF 加字幕 http://www.yingjingtu.com/index 证件照换底色 https://www.gaoding.com/koutu 图片背景消除 https://www.remove.bg/zh 快速去掉背景色 https://bgeraser.com/index.html 网版图制作 https://xoihazard.com/tools/halftone/ 双色套效果 https://duotones.co/ SVG在线压缩合并 https://www.zhangxinxu.com/sp/svgo/ Emoji 马赛克 https://ericandrewlewis.github.io/emoji-mosaic/ CSS 动画制作 https://animista.net/ SQL 语句在线格式化 https://sqlfum.pt/ 实时在线分享代码 https://codeshare.io/ gif 制作 https://gifs.com/ 生成漂亮的代码截图 https://carbon.now.sh/ 在线文件转换 https://cn.office-converter.com/ File Converter https://cloudconvert.com/ ToolFk 在线程序员开发工具 https://www.toolfk.com/ 在线工具 https://tool.lu/ 一个工具箱 http://www.atoolbox.net/ 爱资料工具 https://www.toolnb.com/ 孟坤工具箱 http://tool.mkblog.cn/ OKTools https://oktools.net/ 在线工具 https://helloacm.com/tools/ JS/HTML格式化 https://www.zxgj.cn/g/jshtmlformat 甜言蜜语 API https://api.tryto.cn/saylove/text 甜言蜜语 API https://api.tryto.cn/djt/text 码灵程序员网址导航 https://nav.imaring.com/ CSS 剪切路径生成器 https://bennettfeely.com/clippy/ 文章生成器 https://suulnnka.github.io/BullshitGenerator/index.html 在线屏幕录制 https://www.p2hp.com/screenrecord.html 高手工具 https://c.p2hp.com/ 在线加密算法 https://www.ssleye.com/ JSON在线格式化,JSON在线解析 https://json.im/ 哈希 https://haxi.im/ 图片隐写术加密、图片隐写术解密 https://c.p2hp.com/yinxietu/ 在线代码运行时 Labstack https://code.labstack.com/dart 在线文件加密 https://hat.sh/ 在线检测浏览器版本 https://liulanmi.com/labs/core.html 糖果短语视频生成器 https://hattemi.com/ 前端网址导航 http://www.daqianduan.com/nav 背景生成器 https://bggenerator.com/zh-cn.php “爱古典”数据库 http://www.iloveclassics.icoc.cc/ Compare package download counts over time https://www.npmtrends.com/ IP反查域名 https://dns.aizhan.com/ ","link":"https://faded.auspicious.space/post/you-qu-de-wang-zhan/"},{"title":"正则表达式——常用案例","content":"正则大全 https://any86.github.io/any-rule/ 火车车次 /^[GCDZTSPKXLY1-9]\\d{1,4}$/ 手机机身码(IMEI) /^\\d{15,17}$/ 必须带端口号的网址(或ip) /^(((ht|f)tps?):\\/\\/)?[\\w\\-]+(\\.[\\w\\-]+)+:\\d{0,5}\\/?/ 网址(支持端口和&quot;?+参数&quot;和&quot;#+参数) /^(((ht|f)tps?):\\/\\/)?[\\w\\-]+(\\.[\\w\\-]+)+([\\w\\-.,@?^=%&amp;:\\/~+#]*[\\w\\-@?^=%&amp;\\/~+#])?$/ 统一社会信用代码 /^[0-9A-HJ-NPQRTUWXY]{2}\\d{6}[0-9A-HJ-NPQRTUWXY]{10}$/ 迅雷链接 /^thunderx?:\\/\\/[a-zA-Z\\d]+=$/ ed2k链接(宽松匹配) /^ed2k:\\/\\/\\|file\\|.+\\|\\/$/ 磁力链接(宽松匹配) /^magnet:\\?xt=urn:btih:[0-9a-fA-F]{40,}.*$/ 子网掩码 /^(?:\\d{1,2}|1\\d\\d|2[0-4]\\d|25[0-5])(?:\\.(?:\\d{1,2}|1\\d\\d|2[0-4]\\d|25[0-5])){3}$/ Linux&quot;文件夹&quot;路径 /^\\/(\\w+\\/?)+$/ Linux&quot;文件&quot;路径 /^\\/(\\w+\\/)+\\w+\\.\\w+$/ Window下&quot;文件夹&quot;路径 /^[a-zA-Z]:\\\\(?:\\w+\\\\?)*$/ Window下&quot;文件&quot;路径 /^[a-zA-Z]:\\\\(?:\\w+\\\\)*\\w+\\.\\w+$/ A股代码 /^(s[hz]|S[HZ])(000[\\d]{3}|002[\\d]{3}|300[\\d]{3}|600[\\d]{3}|60[\\d]{4})$/ 考卷分数 /^150$|^(?:\\d|[1-9]\\d|1[0-4]\\d)(?:.5)?$/ 大于等于0, 小于等于150, 支持小数位出现5, 如145.5 校验密码强度 ^(?=.*\\\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$ 密码的强度必须是包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间。 /^(?=.*[0-9])(?=.*[a-z])(?=.*[A-Z])(?=.*\\_)\\w{8,20}$/ 只允许字母数字下划线，必须含有大小写和数字和下划线 校验中文 ^[\\\\u4e00-\\\\u9fa5]{0,}$ 由数字、26个英文字母或下划线组成的字符串 ^\\\\w+$ 校验E-Mail 地址 [\\\\w!#$%&amp;'*+/=?^_{|}~-]+(?:\\.[\\w!#$%&amp;'*+/=?^_{|}~-]+)*@(?:[\\\\w](?:[\\\\w-]*[\\\\w])?\\\\.)+[\\\\w](?:[\\\\w-]*[\\\\w])? 校验日期 ^(?:(?!0000)[0-9]{4}-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1[0-9]|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[0-9]{2}(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)-02-29)$ “yyyy-mm-dd“ 格式的日期校验，已考虑平闰年。 校验金额 ^[0-9]+(.[0-9]{2})?$ 金额校验，精确到2位小数。 判断IE的版本 ^.*MSIE [5-8](?:\\\\.[0-9]+)?(?!.*Trident\\\\/[5-9]\\\\.0).*$ 校验IPv4地址 \\\\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\b 校验IPv6地址 (([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])) 提取URL链接 ^(f|ht){1}(tp|tps):\\\\/\\\\/([\\\\w-]+\\\\.)+[\\\\w-]+(\\\\/[\\\\w- ./?%&amp;=]*)? 文件路径及扩展名校验 ^([a-zA-Z]\\\\:|\\\\\\\\)\\\\\\\\([^\\\\\\\\]+\\\\\\\\)*[^\\\\/:*?&quot;&lt;&gt;|]+\\\\.txt(l)?$ 验证windows下文件路径和扩展名（以 .txt 文件为例） 提取Color Hex Codes ^#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})$ 提取网页图片 \\\\&lt; *[img][^\\\\\\\\&gt;]*[src] *= *[\\\\&quot;\\\\']{0,1}([^\\\\&quot;\\\\'\\\\ &gt;]*) 提取页面超链接 (&lt;a\\\\s*(?!.*\\\\brel=)[^&gt;]*)(href=&quot;https?:\\\\/\\\\/)((?!(?:(?:www\\\\.)?'.implode('|(?:www\\\\.)?', $follow_list).'))[^&quot;]+)&quot;((?!.*\\\\brel=)[^&gt;]*)(?:[^&gt;]*)&gt; 查找CSS属性 ^\\\\s*[a-zA-Z\\\\-]+\\\\s*[:]{1}\\\\s[a-zA-Z0-9\\\\s.#]+[;]{1} 抽取注释 &lt;!--(.*?)--&gt; 匹配HTML标签 &lt;\\\\/?\\\\w+((\\\\s+\\\\w+(\\\\s*=\\\\s*(?:&quot;.*?&quot;|'.*?'|[\\\\^'&quot;&gt;\\\\s]+))?)+\\\\s*|\\\\s*)\\\\/?&gt; 银行卡四位一空格 str.replace(/\\s/g, '').replace(/(.{4})/g, &quot;$1 &quot;); 用户名正则 /^[a-zA-Z0-9_-]{4,16}$/ 4到16位（字母，数字，下划线，减号） 密码正则 ^[a-zA-Z]\\w{5,17}$ 以字母开头，长度在6~18之间，只能包含字母、数字和下划线 强密码正则 /^.*(?=.{6,})(?=.*\\d)(?=.*[A-Z])(?=.*[a-z])(?=.*[!@#$%^&amp;*? ]).*$/ 最少6位，包括至少1个大写字母，1个小写字母，1个数字，1个特殊字符 QQ 号正则 /^[1-9][0-9]{4,10}$/ 微信号正则 /^[a-zA-Z]([-_a-zA-Z0-9]{5,19})+$/ 6至20位，以字母开头，字母，数字，减号，下划线 特殊字符正则 /[&quot;'&lt;&gt;%;)(&amp;+]+-!！@#$~/ 域名正则 [a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.? 车牌号正则 /^[京津沪渝冀豫云辽黑湘皖鲁新苏浙赣鄂桂甘晋蒙陕吉闽贵粤青藏川宁琼使领A-Z]{1}[A-Z]{1}[A-Z0-9]{4}[A-Z0-9挂学警港澳]{1}$/ 护照正则 /^(P\\d{7}|G\\d{7,8}|TH\\d{7,8}|S\\d{7,8}|A\\d{7,8}|L\\d{7,8}|\\d{9}|D\\d+|1[4,5]\\d{7})$/ 固定电话正则 (\\(\\d{3,4}\\)|\\d{3,4}-|\\s)?\\d{8} 邮政编码正则 [1-9]{1}(\\d+){5} 经度正则 /^(\\-|\\+)?(((\\d|[1-9]\\d|1[0-7]\\d|0{1,3})\\.\\d{0,6})|(\\d|[1-9]\\d|1[0-7]\\d|0{1,3})|180\\.0{0,6}|180)$/ 维度正则 /^(\\-|\\+)?([0-8]?\\d{1}\\.\\d{0,6}|90\\.0{0,6}|[0-8]?\\d{1}|90)$/ ","link":"https://faded.auspicious.space/post/regular-expression-regular-cases/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://faded.auspicious.space/post/hello-gridea/"}]}